<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Message Passing</title>
    <link>https://messagepassing.github.io/</link>
    <description>Recent content on Message Passing</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://messagepassing.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>サワードウは育成ゲーム</title>
      <link>https://messagepassing.github.io/017-food/04-jmuk/</link>
      <pubDate>Wed, 26 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/017-food/04-jmuk/</guid>
      <description>自宅勤務になっても食生活には正直たいした変化はないなと思う。ふつうに自炊をしている（夫婦では自分のほうが料理を多くするほうなので、今もわたしがよく料理している）。昼食は追加要素だしかったるいけど、適当にこなしている。たまにデリバリーも頼んでいる。間食類は……まぁ食べてるけど、会社にいたときよりは減った気がする。会社にいると無尽蔵にストックがあるからよくない（責任転嫁）。なお間食をたべるときは適当に既製品のスナックが多いが、たまにクッキーとか焼いたりとかもしている。
飲料でいえば、お茶とかを飲んでいたりするが、それすらだんだん面倒になってきてたまに白湯を飲んでたりしている。白湯はけっこういける。もちろんコーヒーはよく飲んでいるけれど、どちらかといえば、淹れる手続きも楽しんで休憩時間にしている系の飲み物になってるので、そんなに頻度は高くない。それから、これは妻の妊娠が契機だったのだが、さいきんはデカフェがメインになってる。デカフェのコーヒーは飲んでみたらとても美味しいものが多くて、これで別によかったことがわかった。といっても理由が理由なので、カフェインを本気で排除したいというほどでもない。適当にやっている。
それ以外だとなにかあるかねえ……そういえばたまにサワードウを焼くようになった。
 1年ちょっと前くらい、パンデミックでみんな自宅にこもるようになって、日本では「蘇」なるものが流行っていたころ、アメリカではパン作りが人気になっていた。スーパーとかでは小麦粉が売り切れるくらいの人気。時間もあってヒマなのでパンでも作ってみるか、となったようだ。おんなじころにパンを焼いてみたりしていた。やったことがあればわかるけど、パンは生地の発酵（おもに放置）に時間がかかるけど、手を加える時間はそんなに多くなくて、うまく焼けたらまあまあうまい。あとアメリカの家のキッチンにはたいていオーブンがついているから気軽に試せる。流行したこともわかる。
そのなかでもエクストリームなのがサワードウ。ふつうのパンはイースト（酵母）を買ってきて生地に使うが、サワードウはイーストをつかわない。自然酵母と小麦粉と水から「スターター」を自作して、これを使う。自然酵母っていうとかっこいいけど、ようするにそのへんの空気中に漂ってるもののことだ（最初にだけりんごなどの果物の皮を添加し、その表面の酵母を転用する派もある）。スターターを作るのはじゃっかん面倒だが、作業自体は単純で、小麦粉（全粒粉がよい、ライ麦粉もいれるとよい、など無数のtipsがある）と水を同量ビンに入れ、放置する。1日1回、（追加で増えていくと収拾がつかないので）一部を残して捨て、そこに飼料として小麦粉と水を追加してよく混ぜる。7-10日ぐらい続けたらだいたい完成。いったんできたスターターはいったんできたスターターは定期的に餌として小麦粉と水を与える必要はあるが、それさえ維持できれば半永久的にもつと言われている。
サワードウは小麦粉と水、スターター、少量の塩から生地を作る。スターターはふつうのイーストより発酵の速度が遅く、すごい時間がかかる（朝9時にこね始めて焼くのは夕方とか夜ぐらい。そもそもスターターをアクティブにするために前夜から餌をあげたりする）。とはいえ大半の時間はほっとくだけ。たまにこねて、数時間様子を見て、みたいな。サワードウにはいろんなノウハウやら謎のおまじないやらが大量にあり、youtubeなどにも動画がたくさんあって味わい深い。自分はある日思い立ってTartine Breadの本を買ってからは、その手法をずっと踏襲している。このためにキャストアイアンの鍋まで買った（最初に鍋のなかに生地を入れて焼くことで蒸気を維持するという手法があるのだ）。
サワードウはある種の育成ゲームといった趣があると思っている。スターターを育て、キープし、たまにパンを焼く。パンを焼くときも、いい感じに育ってくれよーみたいに考えながら生地をこねている。少し楽しい。うまくできれば美味しいところもいい。毎回毎回、売ってるやつみたいにうまくいくわけじゃないが、失敗といってもあんまり膨らまなかったなーというぐらいで、食べられないほどの大失敗ということはほぼない。
ところでサワードウ自作には副産物もある。スターターには定期的に餌をやるわけだけど、そのまま全量に餌をあげると際限なく増えてしまうので、適当に不要分は捨てることになる。が、ただ捨てるのは忍びないので、ほかの料理に転用したりする。クッキー生地にしたり、ホットケーキ生地に混ぜたり。そういうのも、好きな人は好きかもしれない。
難点についても書いておくと、スターターはあまりにも長期間放置すると死んでしまうので、長期旅行があると困ったりするようだ。あとどうでもいいんだけど、パン食があんまり自分の生活に根付いておらず、パンを焼いたがいいが、あんまり食べる機会がなく、気づいたら歯がかけそうなぐらい固くなっていたりカビが生えてたり、といったことがありがち。
ただコーヒーを淹れるのもそうだけど、どちらかといえばその行為自体を娯楽としてやっている面もあったりするので、まあそれでいいんじゃないか、という気がしている。
というわけで何の話だっけ？　サワードウ作るの楽しいですよという話でした。
余談：そういえば、元ツイッター社員の小説家、ロビン・スローンという人の書いた『ロイスと歌うパンの種』という小説があって、サンフランシスコのテック企業で働いてゾンビのような生活をしていた主人公が、ふとしたきっかけでサワードウを焼くようになって人生が一変するというような話なのだが、これは今読むとまた別な意味で面白いのかもしれない。
 morrita サワードウほど大掛かりじゃないけど、自分の家では納豆をたまに作ってますね。 サワードウ勢を見習い酵母の育成にもっと気を使えば粘り気などでもっと上を目指せるのだろうか・・・。   </description>
      <content:encoded><![CDATA[<p>自宅勤務になっても食生活には正直たいした変化はないなと思う。ふつうに自炊をしている（夫婦では自分のほうが料理を多くするほうなので、今もわたしがよく料理している）。昼食は追加要素だしかったるいけど、適当にこなしている。たまにデリバリーも頼んでいる。間食類は……まぁ食べてるけど、会社にいたときよりは減った気がする。会社にいると無尽蔵にストックがあるからよくない（責任転嫁）。なお間食をたべるときは適当に既製品のスナックが多いが、たまにクッキーとか焼いたりとかもしている。</p>
<p>飲料でいえば、お茶とかを飲んでいたりするが、それすらだんだん面倒になってきてたまに白湯を飲んでたりしている。白湯はけっこういける。もちろんコーヒーはよく飲んでいるけれど、どちらかといえば、淹れる手続きも楽しんで休憩時間にしている系の飲み物になってるので、そんなに頻度は高くない。それから、これは妻の妊娠が契機だったのだが、さいきんはデカフェがメインになってる。デカフェのコーヒーは飲んでみたらとても美味しいものが多くて、これで別によかったことがわかった。といっても理由が理由なので、カフェインを本気で排除したいというほどでもない。適当にやっている。</p>
<p>それ以外だとなにかあるかねえ……そういえばたまにサワードウを焼くようになった。</p>
<hr>
<p>1年ちょっと前くらい、パンデミックでみんな自宅にこもるようになって、日本では「蘇」なるものが流行っていたころ、アメリカではパン作りが人気になっていた。スーパーとかでは小麦粉が売り切れるくらいの人気。時間もあってヒマなのでパンでも作ってみるか、となったようだ。おんなじころにパンを焼いてみたりしていた。やったことがあればわかるけど、パンは生地の発酵（おもに放置）に時間がかかるけど、手を加える時間はそんなに多くなくて、うまく焼けたらまあまあうまい。あとアメリカの家のキッチンにはたいていオーブンがついているから気軽に試せる。流行したこともわかる。</p>
<p>そのなかでもエクストリームなのがサワードウ。ふつうのパンはイースト（酵母）を買ってきて生地に使うが、サワードウはイーストをつかわない。自然酵母と小麦粉と水から「スターター」を自作して、これを使う。自然酵母っていうとかっこいいけど、ようするにそのへんの空気中に漂ってるもののことだ（最初にだけりんごなどの果物の皮を添加し、その表面の酵母を転用する派もある）。スターターを作るのはじゃっかん面倒だが、作業自体は単純で、小麦粉（全粒粉がよい、ライ麦粉もいれるとよい、など無数のtipsがある）と水を同量ビンに入れ、放置する。1日1回、（追加で増えていくと収拾がつかないので）一部を残して捨て、そこに飼料として小麦粉と水を追加してよく混ぜる。7-10日ぐらい続けたらだいたい完成。いったんできたスターターはいったんできたスターターは定期的に餌として小麦粉と水を与える必要はあるが、それさえ維持できれば半永久的にもつと言われている。</p>
<p>サワードウは小麦粉と水、スターター、少量の塩から生地を作る。スターターはふつうのイーストより発酵の速度が遅く、すごい時間がかかる（朝9時にこね始めて焼くのは夕方とか夜ぐらい。そもそもスターターをアクティブにするために前夜から餌をあげたりする）。とはいえ大半の時間はほっとくだけ。たまにこねて、数時間様子を見て、みたいな。サワードウにはいろんなノウハウやら謎のおまじないやらが大量にあり、youtubeなどにも動画がたくさんあって味わい深い。自分はある日思い立って<a href="https://amzn.to/3uuFjyh">Tartine Bread</a>の本を買ってからは、その手法をずっと踏襲している。このためにキャストアイアンの鍋まで買った（最初に鍋のなかに生地を入れて焼くことで蒸気を維持するという手法があるのだ）。</p>
<p>サワードウはある種の育成ゲームといった趣があると思っている。スターターを育て、キープし、たまにパンを焼く。パンを焼くときも、いい感じに育ってくれよーみたいに考えながら生地をこねている。少し楽しい。うまくできれば美味しいところもいい。毎回毎回、売ってるやつみたいにうまくいくわけじゃないが、失敗といってもあんまり膨らまなかったなーというぐらいで、食べられないほどの大失敗ということはほぼない。</p>
<p>ところでサワードウ自作には副産物もある。スターターには定期的に餌をやるわけだけど、そのまま全量に餌をあげると際限なく増えてしまうので、適当に不要分は捨てることになる。が、ただ捨てるのは忍びないので、ほかの料理に転用したりする。クッキー生地にしたり、ホットケーキ生地に混ぜたり。そういうのも、好きな人は好きかもしれない。</p>
<p>難点についても書いておくと、スターターはあまりにも長期間放置すると死んでしまうので、長期旅行があると困ったりするようだ。あとどうでもいいんだけど、パン食があんまり自分の生活に根付いておらず、パンを焼いたがいいが、あんまり食べる機会がなく、気づいたら歯がかけそうなぐらい固くなっていたりカビが生えてたり、といったことがありがち。</p>
<p>ただコーヒーを淹れるのもそうだけど、どちらかといえばその行為自体を娯楽としてやっている面もあったりするので、まあそれでいいんじゃないか、という気がしている。</p>
<p>というわけで何の話だっけ？　サワードウ作るの楽しいですよという話でした。</p>
<p>余談：そういえば、元ツイッター社員の小説家、ロビン・スローンという人の書いた『<a href="https://www.amazon.co.jp/dp/4488010881">ロイスと歌うパンの種</a>』という小説があって、サンフランシスコのテック企業で働いてゾンビのような生活をしていた主人公が、ふとしたきっかけでサワードウを焼くようになって人生が一変するというような話なのだが、これは今読むとまた別な意味で面白いのかもしれない。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
サワードウほど大掛かりじゃないけど、自分の家では納豆をたまに作ってますね。
サワードウ勢を見習い酵母の育成にもっと気を使えば粘り気などでもっと上を目指せるのだろうか・・・。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>はなれて考えるオフィスのこと</title>
      <link>https://messagepassing.github.io/017-food/03-kzys/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/017-food/03-kzys/</guid>
      <description>私はそこまで大きなイノベーションないなあ。朝にコーヒーをいれて、昼はパスタとか一皿で完結するもので、夜はご飯とおかずとか。
コーヒー / 飲みもの コーヒーは近所のカフェでローストされた豆を買って、朝にいれたものを蓋の閉まる保温マグにいれて、少しづつ飲んでいる。といっても午前中には大体なくなってしまうので、そうしたら別の飲み物に移行する。出勤していたころは会社の無料インスタントコーヒーでよしとしていたことを考えると、この自宅勤務期間中にコーヒー偏差値は上がったかもしれない。
今は Hagen の豆だけど、あんまりこだわりがあるわけではなくて、近所のカフェいくつかをローテーションして、目についたものを買っている。
コーヒー以外だと、数年前に買った Sodastream が家にあって、味なしの炭酸水もよく飲む。パンデミック直後は世界的な二酸化炭素不足があったけど、いまは落ち着いているのかな。紅茶もたまには飲むけれど、これは奥さんが買ってきているものをもらうだけで、あまりこだわりなし。
自炊をよくするようになった 自炊は昔よりよくするようになっていて、気が向いたときは昼にパスタを作ったり、夜ご飯も作ったりしている。会社に行っていた時代だと、昼は不可能、夜も自分が作ろうとすると遅くなりすぎるので、基本的には奥さんの仕事になっていた。これを、その日の負荷に応じて2人でロードバランスできるようになったのは良い。
時間通り 12:00 に昼を食べているので、昼のスキップできなくもないチームミーティングとか、社内講演会とかはパスしがち。昔はむしろ結構好きだったんだけど、いまは休日出勤的な、プライベートを侵略される気持ちになってしまう。
はなれて考えるオフィスのこと 家で働いて、たまに料理したり、子供が喧嘩してるのを聞いたりしていると、オフィスというのは人々を仕事に集中させる仕組みだったのだなあと感心してしまう。家族を物理的に視界から排除して集中させるのって、なんか競走馬のマスク (遮眼革というらしい) を彷彿とさせて、そこまで集中してする仕事かなあとふと思うことがある。だんだんオフィスに戻るはなしも出てきているけど、できれば週の半分くらいは家にいたいなあ。
 morrita ミーティングといえば、食事時間はさておき自分が発言する必要のないアナウンス系のミーティングは参加するのがラクになりましたね。ラップトップなりスマホなり　VC している画面を台所に持っていき、カメラはオフで、話を聞き流しつつお茶いれたり間食を準備したりストレッチしたり。こういうの、理論上はオフィスでもできた気がするけど自宅の方が気楽。チームでの週次ミーティングとかみなが対面での参加してるなか自分だけ休憩コーナーでブラブラとか若干気が引けるからね。   kzys まじかー。普通に仕事机で座って聞いてました。確かにやればできるかも。   </description>
      <content:encoded><![CDATA[<p>私はそこまで大きなイノベーションないなあ。朝にコーヒーをいれて、昼はパスタとか一皿で完結するもので、夜はご飯とおかずとか。</p>
<h2 id="コーヒー--飲みもの">コーヒー / 飲みもの</h2>
<p>コーヒーは近所のカフェでローストされた豆を買って、朝にいれたものを蓋の閉まる保温マグにいれて、少しづつ飲んでいる。といっても午前中には大体なくなってしまうので、そうしたら別の飲み物に移行する。出勤していたころは会社の無料インスタントコーヒーでよしとしていたことを考えると、この自宅勤務期間中にコーヒー偏差値は上がったかもしれない。</p>
<p>今は <a href="https://www.hagencoffeeroasters.com/">Hagen</a> の豆だけど、あんまりこだわりがあるわけではなくて、近所のカフェいくつかをローテーションして、目についたものを買っている。</p>
<p>コーヒー以外だと、数年前に買った Sodastream が家にあって、味なしの炭酸水もよく飲む。<a href="https://www.forbes.com/sites/lanabandoim/2020/04/28/surprising-shortage-of-carbon-dioxide-threatens-food-and-beverage-industries/">パンデミック直後は世界的な二酸化炭素不足があったけど</a>、いまは落ち着いているのかな。紅茶もたまには飲むけれど、これは奥さんが買ってきているものをもらうだけで、あまりこだわりなし。</p>
<h2 id="自炊をよくするようになった">自炊をよくするようになった</h2>
<p>自炊は昔よりよくするようになっていて、気が向いたときは昼にパスタを作ったり、夜ご飯も作ったりしている。会社に行っていた時代だと、昼は不可能、夜も自分が作ろうとすると遅くなりすぎるので、基本的には奥さんの仕事になっていた。これを、その日の負荷に応じて2人でロードバランスできるようになったのは良い。</p>
<p>時間通り 12:00 に昼を食べているので、昼のスキップできなくもないチームミーティングとか、社内講演会とかはパスしがち。昔はむしろ結構好きだったんだけど、いまは休日出勤的な、プライベートを侵略される気持ちになってしまう。</p>
<h2 id="はなれて考えるオフィスのこと">はなれて考えるオフィスのこと</h2>
<p>家で働いて、たまに料理したり、子供が喧嘩してるのを聞いたりしていると、オフィスというのは人々を仕事に集中させる仕組みだったのだなあと感心してしまう。家族を物理的に視界から排除して集中させるのって、なんか競走馬のマスク (遮眼革というらしい) を彷彿とさせて、そこまで集中してする仕事かなあとふと思うことがある。だんだんオフィスに戻るはなしも出てきているけど、できれば週の半分くらいは家にいたいなあ。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
ミーティングといえば、食事時間はさておき自分が発言する必要のないアナウンス系のミーティングは参加するのがラクになりましたね。ラップトップなりスマホなり　VC している画面を台所に持っていき、カメラはオフで、話を聞き流しつつお茶いれたり間食を準備したりストレッチしたり。こういうの、理論上はオフィスでもできた気がするけど自宅の方が気楽。チームでの週次ミーティングとかみなが対面での参加してるなか自分だけ休憩コーナーでブラブラとか若干気が引けるからね。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
まじかー。普通に仕事机で座って聞いてました。確かにやればできるかも。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Food 2.0</title>
      <link>https://messagepassing.github.io/017-food/02-karino2/</link>
      <pubDate>Mon, 24 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/017-food/02-karino2/</guid>
      <description>ほー、ポップコーン、良さそう。自分も試そうかなぁ。
食事は自分的にはここ一年で一番大きく変わった所で、在宅なのと買い物にあまり行かないで済むように、という事の２つに最適化している。 たぶんここで書いている人の中では自分が圧倒的に一番生活水準が低いと思うので、その辺も多様性的な観点でいいんじゃないか。
配食サービス 毎日昼と夜、弁当のような物を届けてくれるサービスを使い始めた。これについては以前ブログにも書いたが、 簡単にここでも書いてみたい。
自分はふれ愛とかいう高齢者向けのサービスを使っている。月〜土だけやってて日曜は受け付けてない。一食500円くらい（なんでこんなに安いんだろう？）。 ただ別に配食サービスならなんでも良い気はする。
日曜は、週に一回くらいは買い物に行くのもいいか、という事で、普通に買い物に行きつつ弁当を買ったり外食したり、という感じにしている。 週に一回くらいだとちょっとカロリーの高い物を食べても太らないので、週一だけ違う物、というのは結構良い。
配食サービスは、カロリーが勝手に計算されるので、何も考えなくても太らない。 これは自分的にはイノベーションで、以前はちょっと太ってはダイエットして、またちょっと太ってはダイエットして、を繰り返していたのが、 完全にコンスタントな体重になった。健康にはきっとこっちの方が良い。 栄養バランスも良い。一食じゃなくて一週間でバランスが取れるので、栄養バランスはその他の手段に比べてすごく改善する。 自炊でもこれだけバランス取るのは難しい。 健康を重視する自分にとって、配食サービスによる健康の向上は本当にキラーだった。
ただ一度契約すると自動的に毎日届いてしまうので、とにかく外で飯を食べる事は出来なくなった。友人とちょっと飯を食べに行く、とか出来ない。 電話してキャンセル出来るらしいが、面倒なので自分は他人と飯は食べない、と割り切っている。 今の時期はこれでいいが、情勢が落ち着いた後はもうちょっと自由度が欲しいなぁ。 なんかここにはイノベーションの余地がある気がしている。 アプリで前日にチェック外すと来ない、くらいに出来たらいいのになぁ。
高齢者向けの配食サービスがここまで自分の需要にマッチしてしまうのは、自分が高齢者に近づいている証だなぁ…とちょっとブルーにもなるけれど、仕方ない。
配食サービスを使うようになってから、料理というのは趣味だったんだなぁ、と思うようになった。 趣味なので、やらない自由もあるべきで、やっているのも別に偉くもなんとも無い、という。 配食サービスを使ってない人とは価値観にギャップが出てしまっている気もするくらい価値観に大きな影響を与えている。 もちろん趣味なのでやっている事を後ろめたく思う必要も無いが。
スキムミルク 朝のシリアルのために、以前は牛乳を買っていたが、今はスキムミルクを使うようにした。保存が効くのでまとめて買っておけるので買い物に行く回数を減らす事が出来る。 あと冬場はお湯を少し混ぜる事であったかく出来るのも良かった。干しレーズンがふやけて美味しくなる。
ヨドバシの北海道スキムミルクが安くて良く使っているが、これだけを頼むのもちょっと悪い気もして、他に一緒に買う物が無い時はAEONなどで買う事もある。 牛乳はかさばるしすぐなくなるので頻繁に買い物に行かなくてはいけなかったが、スキムミルクは買いだめ出来るので買い物の必要度が大きく下がった。 配食サービスに比べれば些細な事だが、買い物にあまり行かなくて良くなったのは結構大きい。
果物を箱でAmazonで買うようになった 自分は三ヶ月に一回くらい引っ越して、定期的に田舎暮らしとかして直売所とかで果物を買ったりしていたのだけれど、 今はあまり引っ越しって感じの情勢でも無いし、田舎に行っても楽しくなさそうなので、 代わりにAmazonで箱で果物を買うようにした。
箱で買うのは意外と田舎暮らしの代わりになるなぁ、とか思ったりしている。
ただ、同じ果物を延々と食べなくてはいけないので飽きる。あと箱は結構邪魔。ガレージに置いて数日分だけ持ってくる、というスタイルだが。ガレージにネズミとか来ないかちょっと心配。
そういう訳で長所短所あるけれど、総合的には悪くない気がしている。
今の所、青りんごとはっさくがお気に入り。ただはっさくはそろそろシーズンが終わるのでなにか他のを考えないとなぁ。
飲み物 在宅で一番質が下がるのは飲み物周りだろうなぁ、と思っていたが、なんか慣れてきて適応してしまった。 在宅で仕事しながら飲むなら質より種類だな、というのが最近の結論。
メインはインスタントコーヒー。トップバリューの。トップバリュー大好き。 インスタントコーヒーは結構好き。ちゃんと淹れたコーヒーに比べると香りは大分劣るけれど、むしろこれくらいでいいという気がする今日このごろ。 カフェインを減らそうとかは全然思ってないが、コーヒーは一日二杯くらいかなぁ。
サブではインスタントのロイヤルミルクティー。トップバリューの。トップバリュー大好き。 紅茶的な何かじゃなくて、午後の紅茶とかのジュース的な何かとして消費している分には結構良い。 このチープさが良い。 これまでカフェで作業する時はタリーズとかのアイスロイヤルミルクティーとかを好んで飲んでいた。向こうの方が美味しいけれど、別にこれでも代わりになるな、と思うようになった。
サブサブにアールグレイのティーバッグ。これだけはトップバリューはダメで、Jagnatの奴にしてる。Jagnatのも安いが、なかなか美味しい。 最近インスタントのレベルが上がったと思うんだよなぁ。
カフェイン無い系だとルイボスティーのフレーバーをいろいろ買ってる。最近のお気に入りはリプトンのアップルルイボス。これ良くない？ 余談だが、トップバリューのルイボスティーは凄い覚醒効果あって全然寝れなくなるので、絶対カフェイン入っていると信じているんだが、気のせいなのかなぁ。
あと夜は良く白湯を飲んでる。 なんか自分の入り浸ってるmastodonで何故か白湯が流行ってるので。
自分はシェアハウスぐらしで、以前はキッチンまでお湯を沸かしに行ってたが、今は電気ケトル買って机の横に置いてある。水も空きペットボトルに水道水を入れて置いてある。 全然歩くかなくなるのでどうかなぁ、とも思ったが、最近は生活自体は全然歩かない形態になった。気晴らしに散歩に行くが、雨降ってる日とかは本当に歩かない。 引きこもりです。
間食 配食サービスは高齢者向けだからと思うが、少し足りない。カロリー的にも少し足りてない気がするので、間食は少しはしても良い感じになる（少なくとも太ってはいない）。 そこで間食はいろいろ考えているのだけれど、いまいち決定版が無い。ポップコーンいいかも、って思ったのはこの間食枠。
当初はクッキーとかバランスパワー的な栄養食とか買ってたが、カロリー的に微妙だし、クッキーとかは食べすぎてしまっていまいちだなぁ、とも思っていた。
もっとなんかおにぎりくらいでいいんだよなぁ、 と思って、今はレンジでチンするタイプのパックごはんでふりかけご飯にしている。 ふりかけご飯ってちょっとわびしすぎないか？と思ったが、栄養は他で取ってるし、間食としてはカロリーと腹持ちのバランス的にも保存的にも結構良い。 ただパックごはんは結構かさばるのと、安い奴は分量が多いのが多くてもうちょっと小さなパックで安い奴があればなぁ、とか思ってる。
プログラムしている間は良く飴をなめている。
あと最近はたまに散歩の帰りに菓子パンを買ったりしている。もうちょっと備蓄出来て配送される感じの菓子パン的な何かとかあればいいのになぁ。
なんか備蓄出来ていい感じの間食無いですかね〜。</description>
      <content:encoded><![CDATA[<p><a href="https://messagepassing.github.io/017-food/01-morrita/">ほー、ポップコーン</a>、良さそう。自分も試そうかなぁ。</p>
<p>食事は自分的にはここ一年で一番大きく変わった所で、在宅なのと買い物にあまり行かないで済むように、という事の２つに最適化している。
たぶんここで書いている人の中では自分が圧倒的に一番生活水準が低いと思うので、その辺も多様性的な観点でいいんじゃないか。</p>
<h3 id="配食サービス">配食サービス</h3>
<p>毎日昼と夜、弁当のような物を届けてくれるサービスを使い始めた。これについては<a href="https://karino2.github.io/2021/02/13/home_food_deli.html">以前ブログにも書いた</a>が、
簡単にここでも書いてみたい。</p>
<p>自分はふれ愛とかいう高齢者向けのサービスを使っている。月〜土だけやってて日曜は受け付けてない。一食500円くらい（なんでこんなに安いんだろう？）。
ただ別に配食サービスならなんでも良い気はする。</p>
<p>日曜は、週に一回くらいは買い物に行くのもいいか、という事で、普通に買い物に行きつつ弁当を買ったり外食したり、という感じにしている。
週に一回くらいだとちょっとカロリーの高い物を食べても太らないので、週一だけ違う物、というのは結構良い。</p>
<p>配食サービスは、カロリーが勝手に計算されるので、何も考えなくても太らない。
これは自分的にはイノベーションで、以前はちょっと太ってはダイエットして、またちょっと太ってはダイエットして、を繰り返していたのが、
完全にコンスタントな体重になった。健康にはきっとこっちの方が良い。
栄養バランスも良い。一食じゃなくて一週間でバランスが取れるので、栄養バランスはその他の手段に比べてすごく改善する。
自炊でもこれだけバランス取るのは難しい。
健康を重視する自分にとって、配食サービスによる健康の向上は本当にキラーだった。</p>
<p>ただ一度契約すると自動的に毎日届いてしまうので、とにかく外で飯を食べる事は出来なくなった。友人とちょっと飯を食べに行く、とか出来ない。
電話してキャンセル出来るらしいが、面倒なので自分は他人と飯は食べない、と割り切っている。
今の時期はこれでいいが、情勢が落ち着いた後はもうちょっと自由度が欲しいなぁ。
なんかここにはイノベーションの余地がある気がしている。
アプリで前日にチェック外すと来ない、くらいに出来たらいいのになぁ。</p>
<p>高齢者向けの配食サービスがここまで自分の需要にマッチしてしまうのは、自分が高齢者に近づいている証だなぁ…とちょっとブルーにもなるけれど、仕方ない。</p>
<p>配食サービスを使うようになってから、料理というのは趣味だったんだなぁ、と思うようになった。
趣味なので、やらない自由もあるべきで、やっているのも別に偉くもなんとも無い、という。
配食サービスを使ってない人とは価値観にギャップが出てしまっている気もするくらい価値観に大きな影響を与えている。
もちろん趣味なのでやっている事を後ろめたく思う必要も無いが。</p>
<h3 id="スキムミルク">スキムミルク</h3>
<p>朝のシリアルのために、以前は牛乳を買っていたが、今はスキムミルクを使うようにした。保存が効くのでまとめて買っておけるので買い物に行く回数を減らす事が出来る。
あと冬場はお湯を少し混ぜる事であったかく出来るのも良かった。干しレーズンがふやけて美味しくなる。</p>
<p>ヨドバシの北海道スキムミルクが安くて良く使っているが、これだけを頼むのもちょっと悪い気もして、他に一緒に買う物が無い時はAEONなどで買う事もある。
牛乳はかさばるしすぐなくなるので頻繁に買い物に行かなくてはいけなかったが、スキムミルクは買いだめ出来るので買い物の必要度が大きく下がった。
配食サービスに比べれば些細な事だが、買い物にあまり行かなくて良くなったのは結構大きい。</p>
<h3 id="果物を箱でamazonで買うようになった">果物を箱でAmazonで買うようになった</h3>
<p>自分は三ヶ月に一回くらい引っ越して、定期的に田舎暮らしとかして直売所とかで果物を買ったりしていたのだけれど、
今はあまり引っ越しって感じの情勢でも無いし、田舎に行っても楽しくなさそうなので、
代わりにAmazonで箱で果物を買うようにした。</p>
<p>箱で買うのは意外と田舎暮らしの代わりになるなぁ、とか思ったりしている。</p>
<p>ただ、同じ果物を延々と食べなくてはいけないので飽きる。あと箱は結構邪魔。ガレージに置いて数日分だけ持ってくる、というスタイルだが。ガレージにネズミとか来ないかちょっと心配。</p>
<p>そういう訳で長所短所あるけれど、総合的には悪くない気がしている。</p>
<p>今の所、青りんごとはっさくがお気に入り。ただはっさくはそろそろシーズンが終わるのでなにか他のを考えないとなぁ。</p>
<h3 id="飲み物">飲み物</h3>
<p>在宅で一番質が下がるのは飲み物周りだろうなぁ、と思っていたが、なんか慣れてきて適応してしまった。
在宅で仕事しながら飲むなら質より種類だな、というのが最近の結論。</p>
<p>メインはインスタントコーヒー。トップバリューの。トップバリュー大好き。
インスタントコーヒーは結構好き。ちゃんと淹れたコーヒーに比べると香りは大分劣るけれど、むしろこれくらいでいいという気がする今日このごろ。
カフェインを減らそうとかは全然思ってないが、コーヒーは一日二杯くらいかなぁ。</p>
<p>サブではインスタントのロイヤルミルクティー。トップバリューの。トップバリュー大好き。
紅茶的な何かじゃなくて、午後の紅茶とかのジュース的な何かとして消費している分には結構良い。
このチープさが良い。
これまでカフェで作業する時はタリーズとかのアイスロイヤルミルクティーとかを好んで飲んでいた。向こうの方が美味しいけれど、別にこれでも代わりになるな、と思うようになった。</p>
<p>サブサブにアールグレイのティーバッグ。これだけはトップバリューはダメで、Jagnatの奴にしてる。Jagnatのも安いが、なかなか美味しい。
最近インスタントのレベルが上がったと思うんだよなぁ。</p>
<p>カフェイン無い系だとルイボスティーのフレーバーをいろいろ買ってる。最近のお気に入りはリプトンのアップルルイボス。これ良くない？
余談だが、トップバリューのルイボスティーは凄い覚醒効果あって全然寝れなくなるので、絶対カフェイン入っていると信じているんだが、気のせいなのかなぁ。</p>
<p>あと夜は良く白湯を飲んでる。
なんか自分の入り浸ってるmastodonで何故か白湯が流行ってるので。</p>
<p>自分はシェアハウスぐらしで、以前はキッチンまでお湯を沸かしに行ってたが、今は電気ケトル買って机の横に置いてある。水も空きペットボトルに水道水を入れて置いてある。
全然歩くかなくなるのでどうかなぁ、とも思ったが、最近は生活自体は全然歩かない形態になった。気晴らしに散歩に行くが、雨降ってる日とかは本当に歩かない。
引きこもりです。</p>
<h3 id="間食">間食</h3>
<p>配食サービスは高齢者向けだからと思うが、少し足りない。カロリー的にも少し足りてない気がするので、間食は少しはしても良い感じになる（少なくとも太ってはいない）。
そこで間食はいろいろ考えているのだけれど、いまいち決定版が無い。ポップコーンいいかも、って思ったのはこの間食枠。</p>
<p>当初はクッキーとかバランスパワー的な栄養食とか買ってたが、カロリー的に微妙だし、クッキーとかは食べすぎてしまっていまいちだなぁ、とも思っていた。</p>
<p>もっとなんかおにぎりくらいでいいんだよなぁ、
と思って、今はレンジでチンするタイプのパックごはんでふりかけご飯にしている。
ふりかけご飯ってちょっとわびしすぎないか？と思ったが、栄養は他で取ってるし、間食としてはカロリーと腹持ちのバランス的にも保存的にも結構良い。
ただパックごはんは結構かさばるのと、安い奴は分量が多いのが多くてもうちょっと小さなパックで安い奴があればなぁ、とか思ってる。</p>
<p>プログラムしている間は良く飴をなめている。</p>
<p>あと最近はたまに散歩の帰りに菓子パンを買ったりしている。もうちょっと備蓄出来て配送される感じの菓子パン的な何かとかあればいいのになぁ。</p>
<p>なんか備蓄出来ていい感じの間食無いですかね〜。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>買いだめしやすい完食だと煎餅🍘とかですかね。カロリーそこそこあるけど、クッキーよりはマシ。あとナッツ系をよく食べてます。プロテイン。
オートミールも備蓄にはいいですよ。</p>
<p>サブスク型宅配弁当は、リモート時代には世代とわず需要がありそうなので誰かやってくれるといいですね。
そうなると前日までにアプリでキャンセルできるくらいの柔軟性は期待できそうだし。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>たしかにせんべいはいいかも。ただせんべいも食べすぎてしまうんだよなぁ。クッキーほどじゃないけれど。</p>
<p>ナッツはいいかもしれない。自分は水煮大豆を食べてた事があるのだが、どうも満たされ度合いが低いのとお箸を出さないといけないのでスナック感が足りない気がする。
以前はナッツはちょっと高いと思っていたが、他の出費が減っている分、食生活に出費を増やしてもいい気がするのでナッツを買ってみるかな。</p>
<p>オートミールもアリかもなぁ。たまにシリアルを間食に食べる事ががあるけれど、朝食とかぶってるので変化が欲しいんですよね。オートミールは間食にはちょうどいいかも。</p>
<p>良い間食の探求をしたい気がしてきた。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ポップコーンの話</title>
      <link>https://messagepassing.github.io/017-food/01-morrita/</link>
      <pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/017-food/01-morrita/</guid>
      <description>自宅勤務開始から一年以上がたち、もはや会社に行く気がおきない昨今ですが皆様いかがお過ごしでしょうか。 自宅勤務になると食事やらおやつやらも自前調達になるので、それなりに工夫してることがあると思うのだよね。 そういうのなんかあるかしら、というスレです。
ポップコーン というかポップコーンが素晴らしいという話をしたいのだよ！
ポップコーンはコーンなので、乾燥した実として売っている。こういうの。 この手の穀物は政府の助成をうけているおかげもあって安い。 この 30oz で 4 ドルのコーンとか、余裕で 10 食ぶん以上ある。 無駄にファンシーで高いやつもあるけど、コモディティの穀物。付加価値とかない。安いのを買えば良い。
作るのも簡単で、鍋に油をしいて熱するだけ(参考動画)。 電子レンジでもできるけど、個人的には油のコクがないと若干物足りないかな。 コーヒーの豆を挽くのが気分転換になるように、ポップコーンを炒めるのも息抜きに良い。 これに塩を振って食べます。
塩だけだとだんだん飽きてくるけど、味のバリエーションを色々試すのも楽しい。 ガーリックソルト、バター、パルメザンあたりが鉄板で、 個人的には鶏ガラスープ粉 みたいのも好き。あとふりかけ。この動画とかみると世の中の人も色々工夫しているのがわかる。 そのうち甘いやつもやってみたいなあ。
オートミール たまにおやつを準備するのは気分転換だけど、毎日つくる昼飯はめんどくさい。最近は手抜きでオートミールをよく食べている。
オートミール、昔は何がいいのかよくわかっていなかったけれど、実は種類が一杯あって自分が知っているのは茹で時間が短く調理がラクだが食感がよくない Quick/Instant Oats だったと知った。Rolled Oats などは比較的食感が良く、食べる気になる。ただし茹で時間が 10 分。
そこで茹でている間にトッピングを用意する。Oatmeal Recipe でイメージ検索するとわかるように、適当に果物を切って載せたりミックスナッツを混ぜたりする。りんごとかバナナとか。そこに軽く蜂蜜してもよい。果物だけだと果糖なのですぐ腹が減るけど oats とあわせるとそれなりに腹持ちする。調理のラクさとジャンク度の低さのバランスが昼飯に向いている。あとすごく美味しくはない（シュガー、油、塩などの食欲刺激成分が弱い）ので、食べすぎないのも利点。あと、やはりコモディティなので安い。トッピングの果物も、外食や冷凍食品などの半調理品に比べたら安いものです。
カフェイン もう半年以上、仕事中のコーヒーを減らした。週に 1-2 回くらい。 Why We Sleep という 睡眠に関する本を読んでしばらくやめてたけれど締切のプレッシャーで再開し、しかし飲み過ぎで不調を来し、またやめて、今は throttle しつつ解禁中。
カフェインを飲んでいる人にとやかくいう気はないけれど、 自分がやめたくても職場にいると難しいよね。無限コーヒーマシンがあるし、みんな飲んでるし。 自宅だとコーヒーは有料な上に自分で淹れなければならず、まわりに飲んでいる人もいないのでやめやすい・減らしやすい気がする。
なお Caffeine: How Caffeine Created the Modern World という短い audiobook でカフェインと労働の関係が紹介されていた。 すなわちイギリスにカフェイン(紅茶)がやってきたのと産業革命がおきたのは同時期で、 工場労働者を夜遅くまでこき使うにあたりカフェインが寄与したのだという。 つまりカフェインを断つのは資本階級に対する我々プロレタリアートの反逆なのである。うそです。 むしろイギリスから独立するにあたり紅茶を拒絶したアメリカ人はコーヒーを好んで飲むようになった そうなので(Wikipedia しらべ)、 愛国心としてコーヒーを飲む面はあるのかもしれない。まあ愛国心ないのでいいです。というか日本人だし。</description>
      <content:encoded><![CDATA[<p>自宅勤務開始から一年以上がたち、もはや会社に行く気がおきない昨今ですが皆様いかがお過ごしでしょうか。
自宅勤務になると食事やらおやつやらも自前調達になるので、それなりに工夫してることがあると思うのだよね。
そういうのなんかあるかしら、というスレです。</p>
<h2 id="ポップコーン">ポップコーン</h2>
<p>というかポップコーンが素晴らしいという話をしたいのだよ！</p>
<p>ポップコーンはコーンなので、乾燥した実として売っている。<a href="https://www.amazon.com/Orville-Redenbachers-Original-Gourmet-Popcorn/dp/B000RPYX4W/">こういうの</a>。
この手の穀物は<a href="https://en.wikipedia.org/wiki/Agricultural_subsidy#United_States">政府の助成をうけているおかげもあって</a>安い。
この 30oz で 4 ドルのコーンとか、余裕で 10 食ぶん以上ある。
無駄にファンシーで高いやつもあるけど、コモディティの穀物。付加価値とかない。安いのを買えば良い。</p>
<p>作るのも簡単で、鍋に油をしいて熱するだけ(<a href="https://www.youtube.com/watch?v=wUoKNn8l49U">参考動画</a>)。
電子レンジでもできるけど、個人的には油のコクがないと若干物足りないかな。
コーヒーの豆を挽くのが気分転換になるように、ポップコーンを炒めるのも息抜きに良い。
これに塩を振って食べます。</p>
<p>塩だけだとだんだん飽きてくるけど、味のバリエーションを色々試すのも楽しい。
ガーリックソルト、バター、パルメザンあたりが鉄板で、
個人的には<a href="https://www.ajinomoto.co.jp/products/detail/?ProductName=marudorigara_1">鶏ガラスープ粉</a>
みたいのも好き。あとふりかけ。<a href="https://www.youtube.com/watch?v=zyjzHqW-aCo">この動画とか</a>みると世の中の人も色々工夫しているのがわかる。
そのうち甘いやつもやってみたいなあ。</p>
<h2 id="オートミール">オートミール</h2>
<p>たまにおやつを準備するのは気分転換だけど、毎日つくる昼飯はめんどくさい。最近は手抜きでオートミールをよく食べている。</p>
<p>オートミール、昔は何がいいのかよくわかっていなかったけれど、実は<a href="https://simplyoatmeal.com/types-of-oats/">種類が一杯あって</a>自分が知っているのは茹で時間が短く調理がラクだが食感がよくない Quick/Instant Oats だったと知った。Rolled Oats などは比較的食感が良く、食べる気になる。ただし茹で時間が 10 分。</p>
<p>そこで茹でている間にトッピングを用意する。<a href="https://www.google.com/search?q=oatmeal+recipe&amp;tbm=isch">Oatmeal Recipe でイメージ検索するとわかる</a>ように、適当に果物を切って載せたりミックスナッツを混ぜたりする。りんごとかバナナとか。そこに軽く蜂蜜してもよい。果物だけだと果糖なのですぐ腹が減るけど oats とあわせるとそれなりに腹持ちする。調理のラクさとジャンク度の低さのバランスが昼飯に向いている。あとすごく美味しくはない（シュガー、油、塩などの食欲刺激成分が弱い）ので、食べすぎないのも利点。あと、やはりコモディティなので安い。トッピングの果物も、外食や冷凍食品などの半調理品に比べたら安いものです。</p>
<h2 id="カフェイン">カフェイン</h2>
<p>もう半年以上、仕事中のコーヒーを減らした。週に 1-2 回くらい。
<a href="https://www.amazon.com/Why-We-Sleep-Unlocking-Dreams/dp/1501144316">Why We Sleep</a> という
睡眠に関する本を読んでしばらくやめてたけれど締切のプレッシャーで再開し、しかし飲み過ぎで不調を来し、またやめて、今は throttle しつつ解禁中。</p>
<p>カフェインを飲んでいる人にとやかくいう気はないけれど、
自分がやめたくても職場にいると難しいよね。無限コーヒーマシンがあるし、みんな飲んでるし。
自宅だとコーヒーは有料な上に自分で淹れなければならず、まわりに飲んでいる人もいないのでやめやすい・減らしやすい気がする。</p>
<p>なお <a href="https://www.amazon.com/Caffeine-How-Created-Modern-World/dp/B083MYJXZT/">Caffeine: How Caffeine Created the Modern World</a> という短い audiobook でカフェインと労働の関係が紹介されていた。
すなわちイギリスにカフェイン(紅茶)がやってきたのと産業革命がおきたのは同時期で、
工場労働者を夜遅くまでこき使うにあたりカフェインが寄与したのだという。
つまりカフェインを断つのは資本階級に対する我々プロレタリアートの反逆なのである。うそです。
むしろイギリスから独立するにあたり紅茶を拒絶したアメリカ人はコーヒーを好んで飲むようになった
そうなので(<a href="https://en.wikipedia.org/wiki/Boston_Tea_Party#Legacy">Wikipedia しらべ</a>)、
愛国心としてコーヒーを飲む面はあるのかもしれない。まあ愛国心ないのでいいです。というか日本人だし。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re^2: 複雑さのはなし（から定番本について）</title>
      <link>https://messagepassing.github.io/016-complexity/03-karino2/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/016-complexity/03-karino2/</guid>
      <description>自分の最近の仕事はC++でアプリを書く、というものなので、Brooksの主張にかなり近い事をやっていますね。 C++はいろいろな事情でライブラリが使えない事が多いので、スクラッチから作るのが正当化される事もままある。 それがまさに時代遅れでもあるのだけれど。
そのまま複雑さの話を続けてもいいのだけれど、 自分がDan Luuのブログで面白いと思ったのは、複雑さよりも古典を批判する、という部分。なのでその話をしてみる。
持ち上げられ過ぎる古典 人月の神話は非常に良い本で、そこから引き出すべき教訓も多いと思う。 だが、さすがにコンピューティング事情は随分と変わっているので、現代には当てはまらない事も多い。 そしてそれは当たり前と思う。今となっては誤りになってしまった記述があったところで、Brooksの知性を疑わせるものでは無い。
問題なのは、その当たり前の事をわざわざ言わないといけない状況だ。 それは過去の本の引用で物を語る人が多く、それが間違っている事が多く、それを否定するのにいちいち通常よりもsolidな理論武装を要求されるせいだと思う。 持ち上げる方は空っぽでも問題無いのに。
そういう事にうんざりしているのは私だけじゃなくて、きっとDan Luuもそうだったのだろう。だから今更No Silver Bulletの批判をブログにしたのだろう。 それを読んで我々が痛快に思うのも、まさに日々そういう鬱陶しさを味わっているからでは無かろうか。
以前、達人プログラマーの新装版が出た時に、自分は同じような事を感じた事がある。(当時のブログ)
代わりとなる新しい定番本が出ない！ 何故古い本がこうも持ち上げられ続けてしまうのか？ 一つの理由として、新しい定番本が生まれていないせい、というのがあると思っている。
まず、プログラムという仕事の多様性が増したので、一般論は言いにくくなった。クラウドとC++アプリとAndroidアプリとwebフロントエンドはだいぶ違う。 業界ごとの特定のプロジェクトや企業の様子を語る書籍は今でもあるが、一般的な事を主張するのは昔より難しくなっている気がする。 現実は多様でケースバイケースです、では盛り上がらない。
それに付随して、そもそも最近技術書があまり読まれなくなった、という事情もあるかもしれない。 例えば先日の今年読んだものを見ても、 皆があまり本を読んでいない、と言っている。単にCovid-19のせいかもしれないけど。 読まれてないから書かれてない、という事もあるのでは。 技術書が読まれていないせいかは分からないけれど、自分の周りの有能なプログラマは、本を書いていない。コードを書いている方が明らかに報われる気がするから、さもありなん。
別の視点として、Brooksほど凄い奴はなかなか居ない、とう事もあるかもしれない。
やばいプロジェクトに巻き込まれた経験は、ここで文章を書いている人なら大なり小なりあるだろう。 かくいう自分も、やばいプロジェクトに巻き込まれた経験ならなかなかのレベルと言える。自慢にならない。
だが、やばいプロジェクトに巻き込まれた後に、それをちゃんと分析して、その場に居なかった人にも分かるように説明する、というのは、なかなか出来る事では無い。自分には無理そうだ。
会社がちゃんとそれを支援するのも、なかなか難しい。ちゃんとやったIBMは偉い。 プロジェクトが失敗したらその位当然やるだろう、と思うかもしれないが、残念ながらやらない会社の方がずっと多い。喉元過ぎれば熱さを忘れがち。
かっこよく怒りたいものだ 何故あたらしい定番本が生まれないのかはおいといて、それを所与とするなら。
古い本が持ち上げられ続けてしまうのは、誰かがたまにしっかりと反論していけば、それで防げるかもしれない。今回のDan Luuみたいに。 でも自分が何か思っても、なかなかああかっこよくビシッと反論するのは難しいんだよなぁ。
くだんのブログがかっこいいのは、出てくるのがPrestoでrustでggplotでビッグデータだからという事もあると思う（それだけでは無いだろうが）。 同じようにかっこよくやるには、かっこいい仕事をしている必要があるのかも。
などととりとめも無く書いて来ましたが、古典とか神話化してるが古くなった事とか、最近は結構ある気はするんですよね。どう思います？＞jmuk
 morrita 自分はあるとき良い本がないと感じるのをどちらかというと自分の問題のように感じていたのですが、 一方で推薦図書の世代交代の無さもそれはそれで事実な気がする。
古い本に反論するのもさておき、書籍に頼らない新しい学びのパスについて考えるのも有意義かなと思いました。
  karino2 それは自分も思ったけど、少し話が逸れるかな、と思って書かなかった＞実は自分の問題
実際の所は自分の問題と本が出てない問題のどちらなんですかね。両方な気もするけれど。
あと本に頼らない学びのパスは面白いかもしれない。公式文書はだいたいすでに他の技術を知っている前提で自身の技術を説明するので、新規に学ぶ人が難しくなっている気もしている。</description>
      <content:encoded><![CDATA[<p>自分の最近の仕事はC++でアプリを書く、というものなので、Brooksの主張にかなり近い事をやっていますね。
C++はいろいろな事情でライブラリが使えない事が多いので、スクラッチから作るのが正当化される事もままある。
それがまさに時代遅れでもあるのだけれど。</p>
<p>そのまま複雑さの話を続けてもいいのだけれど、
自分がDan Luuのブログで面白いと思ったのは、複雑さよりも古典を批判する、という部分。なのでその話をしてみる。</p>
<h2 id="持ち上げられ過ぎる古典">持ち上げられ過ぎる古典</h2>
<p>人月の神話は非常に良い本で、そこから引き出すべき教訓も多いと思う。
だが、さすがにコンピューティング事情は随分と変わっているので、現代には当てはまらない事も多い。
そしてそれは当たり前と思う。今となっては誤りになってしまった記述があったところで、Brooksの知性を疑わせるものでは無い。</p>
<p>問題なのは、その当たり前の事をわざわざ言わないといけない状況だ。
それは過去の本の引用で物を語る人が多く、それが間違っている事が多く、それを否定するのにいちいち通常よりもsolidな理論武装を要求されるせいだと思う。
持ち上げる方は空っぽでも問題無いのに。</p>
<p>そういう事にうんざりしているのは私だけじゃなくて、きっとDan Luuもそうだったのだろう。だから今更No Silver Bulletの批判をブログにしたのだろう。
それを読んで我々が痛快に思うのも、まさに日々そういう鬱陶しさを味わっているからでは無かろうか。</p>
<p>以前、達人プログラマーの新装版が出た時に、自分は同じような事を感じた事がある。(<a href="https://karino2.livejournal.com/424526.html">当時のブログ</a>)</p>
<h2 id="代わりとなる新しい定番本が出ない">代わりとなる新しい定番本が出ない！</h2>
<p>何故古い本がこうも持ち上げられ続けてしまうのか？
一つの理由として、新しい定番本が生まれていないせい、というのがあると思っている。</p>
<p>まず、プログラムという仕事の多様性が増したので、一般論は言いにくくなった。クラウドとC++アプリとAndroidアプリとwebフロントエンドはだいぶ違う。
業界ごとの特定のプロジェクトや企業の様子を語る書籍は今でもあるが、一般的な事を主張するのは昔より難しくなっている気がする。
現実は多様でケースバイケースです、では盛り上がらない。</p>
<p>それに付随して、そもそも最近技術書があまり読まれなくなった、という事情もあるかもしれない。
例えば先日の<a href="https://messagepassing-drafts.netlify.app/004-whatiread/01-morrita/">今年読んだもの</a>を見ても、
皆があまり本を読んでいない、と言っている。単にCovid-19のせいかもしれないけど。
読まれてないから書かれてない、という事もあるのでは。
技術書が読まれていないせいかは分からないけれど、自分の周りの有能なプログラマは、本を書いていない。コードを書いている方が明らかに報われる気がするから、さもありなん。</p>
<p>別の視点として、Brooksほど凄い奴はなかなか居ない、とう事もあるかもしれない。</p>
<p>やばいプロジェクトに巻き込まれた経験は、ここで文章を書いている人なら大なり小なりあるだろう。
かくいう自分も、やばいプロジェクトに巻き込まれた経験ならなかなかのレベルと言える。自慢にならない。</p>
<p>だが、やばいプロジェクトに巻き込まれた後に、それをちゃんと分析して、その場に居なかった人にも分かるように説明する、というのは、なかなか出来る事では無い。自分には無理そうだ。</p>
<p>会社がちゃんとそれを支援するのも、なかなか難しい。ちゃんとやったIBMは偉い。
プロジェクトが失敗したらその位当然やるだろう、と思うかもしれないが、残念ながらやらない会社の方がずっと多い。喉元過ぎれば熱さを忘れがち。</p>
<h2 id="かっこよく怒りたいものだ">かっこよく怒りたいものだ</h2>
<p>何故あたらしい定番本が生まれないのかはおいといて、それを所与とするなら。</p>
<p>古い本が持ち上げられ続けてしまうのは、誰かがたまにしっかりと反論していけば、それで防げるかもしれない。今回のDan Luuみたいに。
でも自分が何か思っても、なかなかああかっこよくビシッと反論するのは難しいんだよなぁ。</p>
<p>くだんのブログがかっこいいのは、出てくるのがPrestoでrustでggplotでビッグデータだからという事もあると思う（それだけでは無いだろうが）。
同じようにかっこよくやるには、かっこいい仕事をしている必要があるのかも。</p>
<p>などととりとめも無く書いて来ましたが、古典とか神話化してるが古くなった事とか、最近は結構ある気はするんですよね。どう思います？＞jmuk</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>自分はあるとき良い本がないと感じるのをどちらかというと<a href="https://anemone.dodgson.org/2019/05/14/falsely-blaming/">自分の問題のように感じていた</a>のですが、
一方で推薦図書の世代交代の無さもそれはそれで事実な気がする。</p>
<p>古い本に反論するのもさておき、書籍に頼らない新しい学びのパスについて考えるのも有意義かなと思いました。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>それは自分も思ったけど、少し話が逸れるかな、と思って書かなかった＞実は自分の問題<br>
実際の所は自分の問題と本が出てない問題のどちらなんですかね。両方な気もするけれど。</p>
<p>あと本に頼らない学びのパスは面白いかもしれない。公式文書はだいたいすでに他の技術を知っている前提で自身の技術を説明するので、新規に学ぶ人が難しくなっている気もしている。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>インターネットの声</title>
      <link>https://messagepassing.github.io/012-manycore/07-internet/</link>
      <pubDate>Fri, 07 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/07-internet/</guid>
      <description>インターネットで反応してくれた声を紹介します (morrita)
 OkHttp の HTTP/2 並列性 - 2021/05/02 – kanejaku.org
 Message Passing #12 で OkHttp がどうやって HTTP/2 の上にブロッキング API を作っているのか、という疑問が書いてあった。興味が出たので Android も Kotlin も分からないけれど少し調べてみた。 最初はコードを読んでいたのだけど途中でしっかりした説明があることに気づいた。ここに知りたいことは書いてあった。 &amp;hellip; 最近の趣味プロジェクトとして HTTP/2 サーバを自作している。
自作 HTTP/2 サーバも OkHttp と似たアプローチを取っている: ソケットからの読み込みは専用のタスク (tokio を使っているのでスレッドではなくタスク)を使う。
 Massively Multi-Core in Supercomputer - 雛形書庫
 僕は普段High-Performance Computing (HPC) の文脈でコアを使い切る活動をしていて、さきのshinhさんのポストからは、この分野ではわりとembarassingly parallelの色合いが強いのだなという気づきがあった。
 HPCぽい話と並列性の分類と
 HPC、とりあえず、スケールしない部分が足をひっぱらない程度にはバカパラに近くなってないと、なんともならないというのがあると思う。そこはなんか問題いじったりしてでもバカパラにするし、できないならスパコン使う必要とか無い、ということになるんだと思う
 </description>
      <content:encoded><![CDATA[<p>インターネットで反応してくれた声を紹介します (morrita)</p>
<hr>
<p><a href="https://kanejaku.org/posts/2021/05/2021-05-02/">OkHttp の HTTP/2 並列性 - 2021/05/02 – kanejaku.org</a></p>
<blockquote>
<p>Message Passing #12 で OkHttp がどうやって HTTP/2 の上にブロッキング API を作っているのか、という疑問が書いてあった。興味が出たので Android も Kotlin も分からないけれど少し調べてみた。
最初はコードを読んでいたのだけど途中でしっかりした<a href="https://github.com/square/okhttp/blob/f8fd4d08decf697013008b05ad7d2be10a648358/docs/concurrency.md">説明</a>があることに気づいた。ここに知りたいことは書いてあった。
&hellip;
最近の趣味プロジェクトとして HTTP/2 サーバを自作している。</p>
<p>自作 HTTP/2 サーバも OkHttp と似たアプローチを取っている: ソケットからの読み込みは専用のタスク (<a href="https://tokio.rs/">tokio</a> を使っているのでスレッドではなくタスク)を使う。</p>
</blockquote>
<p><a href="https://tl.hateblo.jp/entry/2021/04/30/154411">Massively Multi-Core in Supercomputer - 雛形書庫</a></p>
<blockquote>
<p>僕は普段High-Performance Computing (HPC) の文脈でコアを使い切る活動をしていて、さきのshinhさんのポストからは、この分野ではわりとembarassingly parallelの色合いが強いのだなという気づきがあった。</p>
</blockquote>
<p><a href="http://shinh.skr.jp/m/?date=20210506#p01">HPCぽい話と並列性の分類と</a></p>
<blockquote>
<p>HPC、とりあえず、スケールしない部分が足をひっぱらない程度にはバカパラに近くなってないと、なんともならないというのがあると思う。そこはなんか問題いじったりしてでもバカパラにするし、できないならスパコン使う必要とか無い、ということになるんだと思う</p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: 複雑さのはなし</title>
      <link>https://messagepassing.github.io/016-complexity/02-kzys/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/016-complexity/02-kzys/</guid>
      <description>昔に『人月の神話』は本を買って読んだはずだけど、手元には残っていないので、該当部分だけ O&amp;rsquo;Reilly Online Learning で読み直してみました。&amp;ldquo;Hopes for the Silver&amp;rdquo; という節に、世の中では銀の弾丸と目されているけれど、Brooks 自身はそこまでは思わない近年の技術的進歩が列挙されているんですが、Ada とその他の高級言語の発達、オブジェクト指向プログラミング、と時代を感じさせる並びの後に来るのがなんと人工知能! でもここで
 The techniques used for speech recognition seem to have little in common with those used for image recognition, &amp;hellip;
 教授! 我々はついにその2つを繋げられるなにかを見つけましたよ! というところで本題へ。
複雑さはどこから来るのか 複雑さには色々な場所からやってくる。
まずはドメインというか、解決するべき問題そのものから発生する複雑さ。いわゆる SE っぽい仕事の人々はこういう本を読んで、RDBMS のスキーマとかを延々と議論している、というのは私の偏見。金融とか医療とかにも、何かドメイン特有の複雑さがあるんだろうと思う。
ソフトウェアを書くプラットフォームから来る複雑さ。私は Android のフレームワークとしての良し悪しについて議論するほど Android アプリを書いていないけれど、Web アプリケーションは結構書いていて、HTML + CSS + JavaScript は、プラットフォームとしては格別に複雑だと思うし、* { Box-sizing: Border-box } FTW なんてのを見ると、複雑さの一部については偶発的なものといってもいいと思う。
もっと一般化すると、これは時間からくる複雑さともいえる。レガシーな仕様や実装が事態を複雑にすることは良くある。1900年の1月と2月を除いては。
クライアントサイドの、ソフトウェアが走る環境の多様性からくる複雑さ。Facebook の Year class: A classification system for Android なんかは、モバイル (といっても Web) をちょっとやっていた身としては、なるほどこういう手があったのかという感心があった。</description>
      <content:encoded><![CDATA[<p>昔に『人月の神話』は本を買って読んだはずだけど、手元には残っていないので、該当部分だけ O&rsquo;Reilly Online Learning で読み直してみました。&ldquo;Hopes for the Silver&rdquo; という節に、世の中では銀の弾丸と目されているけれど、Brooks 自身はそこまでは思わない近年の技術的進歩が列挙されているんですが、Ada とその他の高級言語の発達、オブジェクト指向プログラミング、と時代を感じさせる並びの後に来るのがなんと人工知能! でもここで</p>
<blockquote>
<p>The techniques used for speech recognition seem to have little in common with those used for image recognition, &hellip;</p>
</blockquote>
<p><a href="http://www.cs.unc.edu/~brooks/">教授</a>! 我々はついにその2つを繋げられる<a href="https://www.deeplearningbook.org/">なにか</a>を見つけましたよ! というところで本題へ。</p>
<h3 id="複雑さはどこから来るのか">複雑さはどこから来るのか</h3>
<p>複雑さには色々な場所からやってくる。</p>
<p>まずはドメインというか、解決するべき問題そのものから発生する複雑さ。いわゆる SE っぽい仕事の人々は<a href="https://www.shoeisha.co.jp/book/detail/9784798157382">こういう本</a>を読んで、RDBMS のスキーマとかを延々と議論している、というのは私の偏見。金融とか医療とかにも、何かドメイン特有の複雑さがあるんだろうと思う。</p>
<p>ソフトウェアを書くプラットフォームから来る複雑さ。私は Android のフレームワークとしての良し悪しについて議論するほど Android アプリを書いていないけれど、Web アプリケーションは結構書いていて、HTML + CSS + JavaScript は、プラットフォームとしては格別に複雑だと思うし、<a href="https://www.paulirish.com/2012/box-sizing-border-box-ftw/">* { Box-sizing: Border-box } FTW</a> なんてのを見ると、複雑さの一部については偶発的なものといってもいいと思う。</p>
<p>もっと一般化すると、これは時間からくる複雑さともいえる。レガシーな仕様や実装が事態を複雑にすることは良くある。<a href="https://www.joelonsoftware.com/2006/06/16/my-first-billg-review/">1900年の1月と2月を除いては</a>。</p>
<p>クライアントサイドの、ソフトウェアが走る環境の多様性からくる複雑さ。Facebook の <a href="https://engineering.fb.com/2014/11/06/android/year-class-a-classification-system-for-android/">Year class: A classification system for Android</a> なんかは、モバイル (といっても Web) をちょっとやっていた身としては、なるほどこういう手があったのかという感心があった。</p>
<p>そういえば Alexa 時代は、自然言語処理からくる複雑さに悩まされることが時折あった。基本的には <a href="https://developer.amazon.com/en-US/docs/alexa/custom-skills/create-intents-utterances-and-slots.html">Intent と Slot</a> という形に抽象化されていて、自分が機械学習っぽいことをする必要は無いのだけど、それでも抽象から複雑さが漏れていることはある。</p>
<p>こうやって振り返ってみると、今に自分がやっているサーバーサイド仕事は複雑さが、無いというと語弊があるけれど、あまり四方八方からくる感じはない。複雑さの多様性に欠けている。</p>
<p>自分のソフトウェアは基本的にはデータセンターの中で走るだけだし、プラットフォームとしての Linux は、ソフトウェアごとに違う設定ファイルにはうんざりしつつも、Web とは比べものにならないくらい単純。プロダクトマネージャーと話はするけれど、ドメインの専門家とユビキタス言語を作りましょう、というほどドメインに距離も複雑さもない。</p>
<p>大企業は専門化しがちなのかもしれないなあ。チームの規模として大小色々やっている karino2 さんはどうですか?</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>複雑さのはなし</title>
      <link>https://messagepassing.github.io/016-complexity/01-morrita/</link>
      <pubDate>Mon, 03 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/016-complexity/01-morrita/</guid>
      <description>本質的な複雑さ批判 森田が大ファンであるところの Dan Luu が「人月の神話」の Fred Brooks をディスる 記事を書いており、 痛快なのでみんなでこれ読んで与太話しようぜ、という回。(Dan Luu のページは Pocket か Instapaper 必須なのでみなインストールされたし。)
ここで批判されているのは Brook の Essential Complexity / Accidental complexity に関する記述。 極めて雑に復習すると、Brooks は「問題には &amp;ldquo;essential complexity&amp;rdquo; すなわち &amp;ldquo;本質的な複雑さ&amp;rdquo; というのがあるから、 プログラミング言語とかツールとか計算機性能の改善とかで &amp;ldquo;accidental complexity&amp;rdquo; / &amp;ldquo;偶発的な複雑さ&amp;rdquo; を減らしていっても限度があるよね、 ソフトウェア開発って難しいですね・・・という話だった。
Dan Luu はそんなわけねーとこの主張を一蹴し、自身の仕事から反例を二つ引き合いに出す。 森田に馴染みある方の例はこんなかんじ: オープンソースの分散 OLAP DB Presto に保存されている モニタリングのデータ相手に SQL を書き、結果を R で ggplot する。 Presto の性能、SQL の宣言的な簡潔さと ggplot の表現力は明らかに仕事を桁違いに簡単にして、問題の偶発的な複雑さを粉砕している。
一方で、と話は続く: Presto と ggplot が吹っ飛ばいた偶発的複雑さの量はすごいけど、一方でいま更に速いコンピュータがあったら 俺が遭遇した残りの偶発的複雑さも消し飛ばせるんだけどなーと愚痴タイムに突入し、 字数が足りないといいつつ Presto と ggplot の残念バグを次々に列挙してしていく（ここが一番楽しい）。</description>
      <content:encoded><![CDATA[<h2 id="本質的な複雑さ批判">本質的な複雑さ批判</h2>
<p>森田が大ファンであるところの Dan Luu が「人月の神話」の <a href="https://danluu.com/essential-complexity/">Fred Brooks をディスる</a> 記事を書いており、
痛快なのでみんなでこれ読んで与太話しようぜ、という回。(Dan Luu のページは <a href="https://getpocket.com/">Pocket</a> か <a href="https://www.instapaper.com/">Instapaper</a> 必須なのでみなインストールされたし。)</p>
<p>ここで批判されているのは Brook の Essential Complexity / Accidental complexity に関する記述。
極めて雑に復習すると、Brooks は「問題には &ldquo;essential complexity&rdquo; すなわち &ldquo;本質的な複雑さ&rdquo; というのがあるから、
プログラミング言語とかツールとか計算機性能の改善とかで &ldquo;accidental complexity&rdquo; / &ldquo;偶発的な複雑さ&rdquo; を減らしていっても限度があるよね、
ソフトウェア開発って難しいですね・・・という話だった。</p>
<p>Dan Luu はそんなわけねーとこの主張を一蹴し、自身の仕事から反例を二つ引き合いに出す。
森田に馴染みある方の例はこんなかんじ: オープンソースの分散 OLAP DB <a href="https://prestodb.io/">Presto</a> に保存されている
モニタリングのデータ相手に SQL を書き、結果を R で <a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a> する。
Presto の性能、SQL の宣言的な簡潔さと ggplot の表現力は明らかに仕事を桁違いに簡単にして、問題の偶発的な複雑さを粉砕している。</p>
<p>一方で、と話は続く: Presto と ggplot が吹っ飛ばいた偶発的複雑さの量はすごいけど、一方でいま更に速いコンピュータがあったら
俺が遭遇した残りの偶発的複雑さも消し飛ばせるんだけどなーと愚痴タイムに突入し、
字数が足りないといいつつ Presto と ggplot の残念バグを次々に列挙してしていく（ここが一番楽しい）。</p>
<p>話の肝はこうだ: Brooks は偶発的な複雑さを倒しても本質的な複雑さが立ちふさがるから無駄といったけど、
この問題なんてちょろい SQL を書く本質的な複雑さは皆無にも関わらず
Brooks 現役時代の 1986 年には偶発的な複雑さが桁違い過ぎて解こうとすら思われない類の問題でしょ、
テクノロジの進歩で解ける問題変わってるじゃん。</p>
<p>本質的な複雑さの占める割合ゆえに計算機が速くなって偶発的な複雑さを倒しても有り難みは薄いという Brooks は想像力を欠いていた。
1986 年の計算機は桁違いに遅かった。スクリプト言語も GC もメインストリームではなかった。
Brooks は計算機の遅さやテクノロジの未熟さに伴う偶発的な複雑さによって誰も解こうとしない類の問題が無限にある事実に目を向けるべきだった。
Brooks に限らず昔の人の話は想像力が足りてことがよくある。眉唾せよ。Dan Luu はそんなかんじで話を締めくくっている。</p>
<h2 id="複雑さの属性">複雑さの属性</h2>
<p>「人月の神話」の知名度を「本質的な複雑さ」なるフレーズが持つミームの強さが手伝い、
これを引き合いに出して偉そうなことを言う人はいまでも少しはいるだろう。
だから今更でも釘を差しておく Dan Luu はいい仕事をしたと思う。</p>
<p>とはいえ「人月の神話」とかさすがに大昔すぎて、この「本質的」「偶発的」の二項対立に付き合って話を続けるのも忍びない。
Dan Luu も脚注で「本質的と偶発的の区別とかあんまし意味ないよね」と Michael Feathers の Tweet を紹介している。
(最近 <a href="https://michaelfeathers.silvrback.com/">blog</a> 書いてないと思ったらソーシャルメディアで時間を溶かしていたのか Feathers! それより <a href="https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052">本</a>書いて！)</p>
<p>ここで一歩下がって考える:「本質的/偶発的」という切り口はいまいちだけれど、
眼の前の複雑さが持つ「属性」に目を向けて打ち手を選ぶのはそれなりに意味のあるヒューリスティクスに思える。</p>
<p>たとえば自分は複雑さの「局所性」について気にすることが多い。
局所的な複雑さ・・・たとえばこのアルゴリズムが難しい、このコンポーネントのコードがゴミすぎる・・・みたいのは、
割と個人の努力でやっつけられる。仕事で成果を出したいなら、
目についた複雑を局所性でソートして個人に力量で倒せそうないちばんでかいやつ、
つまりいちばん局所的でないやつ、に取り掛かるのが良い。</p>
<p>局所性の高い（同時に濃度も高い）複雑さは、少人数でやっつけられる割にやっつけるとかっこいい。なので Enginering blog などで華やかに語られがちである。局所性の低い複雑さはしんどい割に解決への道筋が地味なので、表舞台に現れない。放置も多い。</p>
<p>別の言い方をすると: 局所性の高い複雑さは目立つので、みな熱心に取り組む。だからただ指摘すればよい。誰かがやってくれる。
局所性の低すぎる、つまりコードベース全体にベローンと薄く広がっている複雑さは、組織の力がないと倒せない。下っ端には荷が重い。</p>
<p>だから局所性の両端は他人に譲り、自分は中間くらいにある仕事を探したい。</p>
<p>局所性の低い複雑さの例: 昔 C++ なブラウザの仕事をしていた頃、コードベースのスレッドの扱いにはいつも苦しめられていた。Controller ぽいクラスが複数のスレッドから参照されるのだが、いまいちどのメソッドがどのスレッドから呼ばれうるのかわからない。オブジェクトを <a href="https://source.chromium.org/chromium/chromium/src/+/master:base/bind.h">bind</a> して thread pool に投げるイディオムが、このマルチスレッドの壊れやすさを助長していた。もうちょっと message passing ぽく実装するなり immutable なオブジェクトを増やすなり手堅いマルチスレッドのコードを書くパターンは色々あるわけだが、少なくとも当時はそういう配慮はみられなかった。結果として森田はいつも race condition で苦しんでいた。(<a href="https://anemone.dodgson.org/2017/09/11/20150307-chrome-threading/">当時の愚痴</a>.)</p>
<p>今の仕事である Android アプリの Java コードはマルチスレッドだが、もうちょっと安全に書かれておりそこまで race の辛さはない。一方、何かとブロッキングの API を呼んだりロックを待ったりするので、同期にともなう性能劣化に苦しめられている。先のブラウザのコードは non-blocking なコードが支配的なのでこうした問題は起きにくい。</p>
<p>こういうプロジェクトに染み渡ったコーディングのパターンみたいのは局所性が低い。C++ でも Java でも非同期かつスレッドセーフなコードを書く方法は定番が広く知られているので、この問題を解決しても特にかっこよくはない。一方でこの複雑さを倒すにはコードをくまなく書き換え同時に新しいダメコードの発生を抑制する必要がある。しんどい。個人で戦える範囲を超えている。だからこういう問題には近づかず、心を無にしてやりすごすと決めている。大局的だと思っていた問題がクールな発明で局所的に解決できるケースも稀にあるが、加齢にともないそういう博打はしなくなった。こいつらを <a href="https://github.com/scylladb/seastar">ScyllaDB の Seastar</a> で書き直すぞ！スレッドセーフでノンブロッキングだ！とか言えればかっこいいんだけどさー。</p>
<p>というわけで「複雑さの局所性」を森田は割と気にしている。そういう empirical(与太話的) な複雑性の指標は誰もが持ってると思うんですけど、
<a href="/016-complexity/02-kzys/">和良さん</a>とかどうですか。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
事務連絡: 日付は 5 月になっていますが、一連の記事は 1 月に書かれたまま忘れ去られていたものです。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>インフォーマルな文章を書く楽しさ</title>
      <link>https://messagepassing.github.io/015-poems/06-secondlife/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/015-poems/06-secondlife/</guid>
      <description>皆さんはじめまして。ゲストとして呼ばれた、secondlife です。Tateno Culture といった形で以前森田さんが書いていたが、あれは Tateno Culture というよりは Hatena Culture の話だと思っています。なので、今回はインフォーマルな文章という主題とはずれるかもしれませんが、自分はなぜそんな感じの文章を書いていたのか、というのを当時のはてな時代を振り返り書いてみようと思います。
 はてな社に居た当時、これが皆さんの想定するインフォーマルな文章かはさておき、さまざまな社内向け文章を社内の全員、とは言わないまでも、7-8割の人がけっこう書いていた。
自分もしょっちゅう書いていたのだけど、なぜ書いていたのかを今更考えると、それはひとえに『楽しかったから』だった。
なぜ楽しかったのか 当時は2006年頭、自分は15人目の社員として会社にジョインした。入社すると hatenawiki なるはてなグループ(今で言う Qiita::Team や Esa、Kibela といった、Wiki と Blog が融合したようなサービス)に、エンジニア非エンジニア関係なく、ありとあらゆる様々な文章が投稿されていた。
サービスの思想や考え方、会社組織のあり方、人事評価、各種収益、新規サーバ構築方法、お菓子やジュース補充、といった会社全体の話から、日々の社内日記のような話題、新しくできた近くの店の定食が美味しかっただの、モンハン面白いから夜みんなぜやろうぜだの、この言語ならこの実装がこんなにきれいに書ける、などなど、制限など特に無く良くも悪くもありとあらゆる情報で溢れていた。取締役会の生音声なども公開されていて、具体的な年収といった個人の機微情報以外、ほとんどが公開されていたんじゃなかろうか。
そんな場だったので、入社したばかりの人も最初は戸惑いつつも、徐々に書くことに慣れ、みんな当たり前のように文章を書いて公開していってた。自分もその一人で、新規サービスの話だったり、全社で導入する新しい開発手法だったり、細かい技術Tipsだったり、サービスの批評だったり、ただの日記だったり、とりとめもなく様々なことを書いていた。全社での情報共有が～とか生産性が～など仕事としての価値向上を考えて書くというより、自分はただ楽しかったから書いていたのだと思う。
なぜ楽しかったのか。いくつかの要素に分解して考えてみる。
ポエムの読み書き ベンチャー初期において、何を目指してるのか、どんな世界にしたいのかというポエムというのは思想・カルチャーを作る上でも重要で、それを偉い人が発信する、それを読むだけでも楽しかった。
これは共有の場(はてなグループ)自体を毎日見ることにもつながっている。
限られた技術コンテキスト 技術関連の文章の場合、ほぼ全員がその技術を理解できるという、当時の技術コンテキストの狭さがあった。言語は Perl, JavaScript、RDB は MySQL、Linuxチョット、エディタは Vim か Emacs あたりが仕事で構成される技術の殆ど。Web アプリケーションは DB に CRUD して、HTMLに整形して出力するがほとんどの責務。今のように汎用化された様々な技術を目的や状況に応じて選択できる時代ではなかったので、話題の範囲が狭い。
つまるところ、みんながみんな理解できるネタで話せるので、他人の技術文章を理解しやすい、自分が書いた文章もほとんどの人が理解できる状況が生まれていた。そのため場の話を理解しやすい、理解してもらいやすかった。
適度なフィードバック 書いた文章に全く反応(フィードバック)がないとつまらない。もちろん仕事のためのドキュメンテーションは反応を期待して、というよりは後の自分や組織のために書くのでそれは別なのだけど、情報発信するモチベーションは殆どの場合、なんらか期待される反応とセットだ。
期待される反応はコメントやはてなスター(likeのようなもの)もあったが、何より大きかったのが「トラックバック」だったと思う。トラックバックは、文章内で URL を記載するとURL先のWikiやBlogの記事に、この文章から言及されてるというリンクが付く。
このトラックバックのちょうどよい距離感。パーソナルスペースである、自分が主体的に書いたWikiや自分がオーナーのblogから、相手のパーソナルスペースをほとんど汚さない形で通知し合うことができる。blog(他人) / wiki(共有) / blog(自分) と別れてはいるが、相互にゆるいつながりを生むことができる。
ポエム的な記事であれば自分もそれに対して共感や批評を書けるし、技術的なドキュメントや Tips であれば、それに対しての別の手法だったり Emacs の話に対してそれ Vim ならこうやれるよ、といったような返しなども、コメントというその記事スレッドに閉じられた空間ではなく、自分のblog記事として書くことができる。
また、今で言うメンションも id トラックバックという機能で実装されていたため、特定の人の話を聞きたい、みたいな記事も気軽に書くことが出来た。
この辺の適度なフィードバックがしょっちゅう行われていたため、なにか情報発信をすると、より良い意見、様々な意見が貰え、さらに何か書こうという楽しさが発生していた。id トラックバックも、ゆるく「話してよ」というのが伝わるため、あまり情報発信しない人でも定期的に発信が行われ、全員参加して場を作る、という一体感が生まれていたのだと思う。
小さな組織 自分が居たときは十数人〜40人程度の小さな組織だったため、全員が技術に限らず様々なコンテキストを共有しやすかったことも挙げられるだろう。また小さな組織だと、誰がなんのプロフェッショナルでどんなことをしているのかが解りやすく、そのため信頼関係を積みやすく、相互理解もしやすい。</description>
      <content:encoded><![CDATA[<p>皆さんはじめまして。ゲストとして呼ばれた、<a href="https://secon.dev/">secondlife</a> です。<a href="https://anemone.dodgson.org/2018/08/24/honoring-yuichi-tateno/">Tateno Culture</a> といった形で以前森田さんが書いていたが、あれは Tateno Culture というよりは Hatena Culture の話だと思っています。なので、今回はインフォーマルな文章という主題とはずれるかもしれませんが、自分はなぜそんな感じの文章を書いていたのか、というのを当時のはてな時代を振り返り書いてみようと思います。</p>
<hr>
<p>はてな社に居た当時、これが皆さんの想定するインフォーマルな文章かはさておき、さまざまな社内向け文章を社内の全員、とは言わないまでも、7-8割の人がけっこう書いていた。</p>
<p>自分もしょっちゅう書いていたのだけど、なぜ書いていたのかを今更考えると、それはひとえに『楽しかったから』だった。</p>
<h3 id="なぜ楽しかったのか">なぜ楽しかったのか</h3>
<p>当時は2006年頭、自分は15人目の社員として会社にジョインした。入社すると hatenawiki なるはてなグループ(今で言う Qiita::Team や Esa、Kibela といった、Wiki と Blog が融合したようなサービス)に、エンジニア非エンジニア関係なく、ありとあらゆる様々な文章が投稿されていた。</p>
<p>サービスの思想や考え方、会社組織のあり方、人事評価、各種収益、新規サーバ構築方法、お菓子やジュース補充、といった会社全体の話から、日々の社内日記のような話題、新しくできた近くの店の定食が美味しかっただの、モンハン面白いから夜みんなぜやろうぜだの、この言語ならこの実装がこんなにきれいに書ける、などなど、制限など特に無く良くも悪くもありとあらゆる情報で溢れていた。取締役会の生音声なども公開されていて、具体的な年収といった個人の機微情報以外、ほとんどが公開されていたんじゃなかろうか。</p>
<p>そんな場だったので、入社したばかりの人も最初は戸惑いつつも、徐々に書くことに慣れ、みんな当たり前のように文章を書いて公開していってた。自分もその一人で、新規サービスの話だったり、全社で導入する新しい開発手法だったり、細かい技術Tipsだったり、サービスの批評だったり、ただの日記だったり、とりとめもなく様々なことを書いていた。全社での情報共有が～とか生産性が～など仕事としての価値向上を考えて書くというより、自分はただ楽しかったから書いていたのだと思う。</p>
<p>なぜ楽しかったのか。いくつかの要素に分解して考えてみる。</p>
<h3 id="ポエムの読み書き">ポエムの読み書き</h3>
<p>ベンチャー初期において、何を目指してるのか、どんな世界にしたいのかというポエムというのは思想・カルチャーを作る上でも重要で、それを偉い人が発信する、それを読むだけでも楽しかった。</p>
<p>これは共有の場(はてなグループ)自体を毎日見ることにもつながっている。</p>
<h3 id="限られた技術コンテキスト">限られた技術コンテキスト</h3>
<p>技術関連の文章の場合、ほぼ全員がその技術を理解できるという、当時の技術コンテキストの狭さがあった。言語は Perl, JavaScript、RDB は MySQL、Linuxチョット、エディタは Vim か Emacs あたりが仕事で構成される技術の殆ど。Web アプリケーションは DB に CRUD して、HTMLに整形して出力するがほとんどの責務。今のように汎用化された様々な技術を目的や状況に応じて選択できる時代ではなかったので、話題の範囲が狭い。</p>
<p>つまるところ、みんながみんな理解できるネタで話せるので、他人の技術文章を理解しやすい、自分が書いた文章もほとんどの人が理解できる状況が生まれていた。そのため場の話を理解しやすい、理解してもらいやすかった。</p>
<h3 id="適度なフィードバック">適度なフィードバック</h3>
<p>書いた文章に全く反応(フィードバック)がないとつまらない。もちろん仕事のためのドキュメンテーションは反応を期待して、というよりは後の自分や組織のために書くのでそれは別なのだけど、情報発信するモチベーションは殆どの場合、なんらか期待される反応とセットだ。</p>
<p>期待される反応はコメントやはてなスター(likeのようなもの)もあったが、何より大きかったのが「トラックバック」だったと思う。トラックバックは、文章内で URL を記載するとURL先のWikiやBlogの記事に、この文章から言及されてるというリンクが付く。</p>
<p>このトラックバックのちょうどよい距離感。パーソナルスペースである、自分が主体的に書いたWikiや自分がオーナーのblogから、相手のパーソナルスペースをほとんど汚さない形で通知し合うことができる。blog(他人) / wiki(共有) / blog(自分)  と別れてはいるが、相互にゆるいつながりを生むことができる。</p>
<p>ポエム的な記事であれば自分もそれに対して共感や批評を書けるし、技術的なドキュメントや Tips であれば、それに対しての別の手法だったり Emacs の話に対してそれ Vim ならこうやれるよ、といったような返しなども、コメントというその記事スレッドに閉じられた空間ではなく、自分のblog記事として書くことができる。</p>
<p>また、今で言うメンションも id トラックバックという機能で実装されていたため、特定の人の話を聞きたい、みたいな記事も気軽に書くことが出来た。</p>
<p>この辺の適度なフィードバックがしょっちゅう行われていたため、なにか情報発信をすると、より良い意見、様々な意見が貰え、さらに何か書こうという楽しさが発生していた。id トラックバックも、ゆるく「話してよ」というのが伝わるため、あまり情報発信しない人でも定期的に発信が行われ、全員参加して場を作る、という一体感が生まれていたのだと思う。</p>
<h3 id="小さな組織">小さな組織</h3>
<p>自分が居たときは十数人〜40人程度の小さな組織だったため、全員が技術に限らず様々なコンテキストを共有しやすかったことも挙げられるだろう。また小さな組織だと、誰がなんのプロフェッショナルでどんなことをしているのかが解りやすく、そのため信頼関係を積みやすく、相互理解もしやすい。</p>
<h2 id="なぜ楽しかったのかまとめ">なぜ楽しかったのか・まとめ</h2>
<p>だらーっと色々書いてみたけど、まとめると読み応えがある文章が発信され、技術的に理解でき、統一された情報共有の場で適度なフィードバックが得られ、組織コンテキストが共有された信頼関係のある人達と働いている、といった様々な要素が組み合わされて総合的に楽しかったのだろう。これらの項目はお互いに相乗効果を生んでいた。そんな場自体が楽しかったので、自分もその場にのみ込まれる形で、楽しくインフォーマルな文章を書いていたのだ。</p>
<p>どんどん歳を取るにつれて、純粋に「楽しいから」インフォーマルな文章を書くということはなくなってしまった。組織作りの際にも「楽しいから」という項目は、生産性や目的達成といったもの比べるとどうしても優先順位を低く置きがちだ。昔を思い出すと、楽しいことも生産性や目的達成に通じていたなと改めて思ったので、今後また組織作りと情報発信に関わるとしたら、根源的な楽しさという視点からも、情報発信やインフォーマルな文章を書くことについて考えていきたいなぁ。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>楽しいってありますよねぇ。自分も気晴らしとか息抜きで書いている部分は大きい気がする。
言われてみるとなぜインフォーマルな方を強く好むかの理由の一つに、そっちの方が楽しいから、というのはある気がするなぁ。</p>
<p>楽しい方がたくさん書かれるので情報量が多くなって良い、という部分もある気がするし、
そもそも日常が楽しいのは重要な事ですよねぇ。</p>
<p>適度なフィードバックの元に好きに文章を書く楽しさ、というのは、
まさにこのMessage Passingなんてものをやっている理由でもある気がする。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>いわれてみれば、そういう「はてなカルチャー」みたいのに憧れてた時期があったなー。</p>
<p>使われてる書き物プラットフォームは社内でも議論が盛んというのはきっとあるんでしょうね。
Facebook も社内バージョンが活況で、たまに <a href="https://onezero.medium.com/the-big-shift-internal-facebook-memo-tells-employees-to-do-better-on-privacy-92cee35ba560">リークして</a>話題になるのを思い出しました。ある種の透明性は言論プラットフォーム企業ならではの unfair advantage なのかもしれない、というのは言い過ぎかな。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>あんまり考えてないよね</title>
      <link>https://messagepassing.github.io/014-reuse/04-jmuk/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/014-reuse/04-jmuk/</guid>
      <description>オープンソースなのにわりかし再発明しがち勢として @jmuk どうですか。
 というふうに（内部的に）話題をふられてしまった。再利用ねえ。あんまり考えてないよね。
Chromiumはモノリシックなコードベースだけど、もちろんいろんな他のライブラリを再利用している。だいたい third_party というところに、そういうのは押し込められている。再利用のためには、ソースコードをもってきて、自分たち用にビルドするという立場。システムに入っているライブラリ（DLL）を再利用する、みたいなことはやらない。バージョンの互換性とかABIの互換性とかがしんどすぎるから。まぁこれは普通か。
ChromiumはGNという独自のビルドシステムでビルドするが（ここがすでに独自なのかよ、というツッコミがあるかもしれませんがスルーしてください）、独自なのでこれをあらかじめサポートしている外部ライブラリというものは、事実上存在しない。なので外部ライブラリを利用するときは誰かがChromium用にGNを書かないといけない。誰かというか、だいたいはそのライブラリを使いたくてthird_partyに足したい人が自分で書くことになる。めんどうくさい。外部ライブラリはgit submodule的なものでリビジョンが指定されていて、uprevするときはGNファイルも微調整する必要がある。細かいビルドフラグの話などもあり、たまに妙な問題を引き起こしたりする（が、昔使われていたGYPよりはだいぶマシになった）。というように細々とした苦労があり、そこは別に乗り越えられていない。たんにたくさんの人がChromiumプロジェクトに雇用されているので、そのうちの誰かに頑張ってもらっているというだけ。
フレームワークという点でいうと、そういえば Chrome / ChromeOS は既存のGUIフレームワーク（gtk+とかWxとか）を使っていない。viewsという独自のGUIフレームワークが内部にあり、これを使ってUIは書かれている。viewsはバックエンドとして「ネイティブ」のUIとやりとりする部分があるが、ネイティブUIのことはあんまり使わず、たとえば全部描画するし入力イベントも自分でハンドルしている（あとChromeOSは「ネイティブ」レイヤが基本的には存在しないので、viewsのバックエンドのようなものを全部作っている）。viewsは、正直にいうとあんまり出来がよくなく、ChromeのUIで動くところしかきちんとできてなかったりということがよくある。が、自分としては一通りわかっていて（頻繁に変わるのでいつでも再確認しないといけないのだが）それなりに読んだり細かい修正をしてきたので愛着もある。内製なので好き勝手に変更できるのはメリットではある。そんなメリットは喧伝すべきかどうかわからないけど。
逆側の話、つまりChromiumそのものやその一部をライブラリ化したり再利用したい、みたいな話もあるけど、こちらもそうそう再利用していない。Chromiumのレンダリングエンジンであるblinkは、その前身であるWebKitと大きく異なり、ライブラリ化されていない。Chromiumについているcontent/というレイヤを介さない限りは使えない。結果として、WebKitベースのブラウザはありうるけど、blinkベースのブラウザというものはほとんどなく、Chromiumをベースにしたブラウザというものになっている。
また、Chromiumのbase/というディレクトリはなかなかいいように思うけど外部で利用できないか、というリクエストはたまにあったのだが、毎回にべもなく断っていた。Chromiumプロジェクトとしては自分たちの都合で好き勝手にいろいろ足したいし、後方互換性のこととかを考えたりしたくない、Chromiumのためのものなので他では勘弁な、という話になっている。これははっきりいって感じが良くないのだが、そういうことをしたくないという気持ちはよくわかる。汎用のライブラリを作ってるわけじゃないのにそんなことを要求されても困る、という話でもある。が、abseilができてからは、こういうリクエストはほぼなくなった気がする。C++も発展が進んだので、いまどきChromiumのbaseがほしい人間なんていやしないのだった。よかったよかった（？）
なおChromeOS側のサービスなどの実装のためにChromiumのbase相当のものがほしいという話が根強くあり、baseを勝手にコピーしてライブラリ化して使っている。一見再利用っぽく聞こえるかもしれないけれど、別にそういうわけでもない。勝手にコピーしてるだけだし。たまにChromiumの最新のものに更新するたびに大変な作業になっているつらさとかを垣間見るに、再利用を避けるポリシーを徹底したことの弊害が感じられないでもない。
というわけで、仕事のほうではあんまりちゃんと再利用していない昔ながらのプロジェクトをやっているので、それがどんな感じなのかを書いてみた。
この状況は、再利用がごくふつうな他の言語と比べるとかなり乖離があるが、そうなっていることにはそれなりに理由があるときもある。たとえばbaseが一般化されたライブラリになっていないのは、そういうことを指向していないからだ。専用のGUIフレームワークは、ChromeのUIで必要になりそうなところだけがよく書けていて、それ以外の部分は意外に雑なつくりになっていたりする。そういうものを使おうとすると、けっきょくそういう雑な部分を自分で書く必要が出てきたり、ということがよくある。これは残念なライブラリという見方もできるけれど、視点を変えれば、汎用のものは目指さない指向という意味では一貫している。
が……よく考えてみると、けっきょくこれは「C/C++では再利用が大変だ」という話の言い換えでしかないような気もする。再利用が大変であるがゆえに内製もしがちだし、パッケージとして公開するのもかんたんじゃないから公開しない。 後方互換性とかもべつに考えたくないけどそのための解決策もとくになかった。
他の言語だと、再利用が難しいとかできないっていうことは、みんなあんま考えてる気がしない。が、これはなんというか、パッケージシステムとかビルドシステムによって解決されてきた問題なような気がする。だいたいnpm installすればいいでしょ、go getすればいいでしょ、nuget&amp;hellip;cargo&amp;hellip;みたいな。C/C++にはこのレイヤの（デファクト）スタンダードがなんにもないから解決していない。しかしいまさらそんなのは望むべくもない。残念ですね、という話なような気がしてきた。
ところで逆な例でいえば、Node.js (NPM)とかを見ると「さすがに他人のコードに依存しすぎでしょ」という揺り戻しはたまに起きてる気がするし（たとえば文字列に空白を埋めるだけのライブラリが破綻を引き起こした事件とか）、lodashに依存するな問題とか、そういうのはある。もちろんこういうのは程度問題でしかなくて、再利用を一切しないっていうことはさすがに考えていないだろうけど、再利用しすぎの問題ってのも、それはそれで顕在化はしてると思う。
 morrita  ここがすでに独自なのかよ、というツッコミがあるかもしれませんがスルーしてください
 でもビルドシステムの揃っていなさはコミュニティとしての合意の無さのあらわれという気はする・・・。 Chromium はオープンソースでありながらあんなに再利用に不親切で、 その一方で互換ブラウザや Electron みたいのが沢山あって、興味深いですね。
あと Chrome/Chromium コードベース本体はともかく、Chrome 製品の一環として開発されているライブラリたちは割と広く使われているので、 捨てたものではない、かもしれない。(V8, Skia, Webp, PDFium&amp;hellip;)
  karino2 Electronなんかを見ていると、再利用をしてもらうのに一番大切なのは再利用をするに値する価値ある物を作る、という事なんだろうなぁ、と思う。
ネイティブのweb viewを使ったもっと小さなelectron alternativesの試み、いっぱいあっていろいろ評価してみたのだけれど、評価すればするほどChromium良く出来てるな、という思いを強くしただけだった。</description>
      <content:encoded><![CDATA[<blockquote>
<p>オープンソースなのにわりかし再発明しがち勢として @jmuk どうですか。</p>
</blockquote>
<p>というふうに（内部的に）話題をふられてしまった。再利用ねえ。あんまり考えてないよね。</p>
<p>Chromiumはモノリシックなコードベースだけど、もちろんいろんな他のライブラリを再利用している。だいたい <a href="https://chromium.googlesource.com/chromium/src.git/+/refs/heads/master/third_party/">third_party</a> というところに、そういうのは押し込められている。再利用のためには、ソースコードをもってきて、自分たち用にビルドするという立場。システムに入っているライブラリ（DLL）を再利用する、みたいなことはやらない。バージョンの互換性とかABIの互換性とかがしんどすぎるから。まぁこれは普通か。</p>
<p>Chromiumは<a href="https://gn.googlesource.com/gn/">GN</a>という独自のビルドシステムでビルドするが（ここがすでに独自なのかよ、というツッコミがあるかもしれませんがスルーしてください）、独自なのでこれをあらかじめサポートしている外部ライブラリというものは、事実上存在しない。なので外部ライブラリを利用するときは誰かがChromium用にGNを書かないといけない。誰かというか、だいたいはそのライブラリを使いたくてthird_partyに足したい人が自分で書くことになる。めんどうくさい。外部ライブラリはgit submodule的なものでリビジョンが指定されていて、uprevするときはGNファイルも微調整する必要がある。細かいビルドフラグの話などもあり、たまに妙な問題を引き起こしたりする（が、昔使われていたGYPよりはだいぶマシになった）。というように細々とした苦労があり、そこは別に乗り越えられていない。たんにたくさんの人がChromiumプロジェクトに雇用されているので、そのうちの誰かに頑張ってもらっているというだけ。</p>
<p>フレームワークという点でいうと、そういえば Chrome / ChromeOS は既存のGUIフレームワーク（gtk+とかWxとか）を使っていない。viewsという独自のGUIフレームワークが内部にあり、これを使ってUIは書かれている。viewsはバックエンドとして「ネイティブ」のUIとやりとりする部分があるが、ネイティブUIのことはあんまり使わず、たとえば全部描画するし入力イベントも自分でハンドルしている（あとChromeOSは「ネイティブ」レイヤが基本的には存在しないので、viewsのバックエンドのようなものを全部作っている）。viewsは、正直にいうとあんまり出来がよくなく、ChromeのUIで動くところしかきちんとできてなかったりということがよくある。が、自分としては一通りわかっていて（頻繁に変わるのでいつでも再確認しないといけないのだが）それなりに読んだり細かい修正をしてきたので愛着もある。内製なので好き勝手に変更できるのはメリットではある。そんなメリットは喧伝すべきかどうかわからないけど。</p>
<p>逆側の話、つまりChromiumそのものやその一部をライブラリ化したり再利用したい、みたいな話もあるけど、こちらもそうそう再利用していない。Chromiumのレンダリングエンジンであるblinkは、その前身であるWebKitと大きく異なり、ライブラリ化されていない。Chromiumについているcontent/というレイヤを介さない限りは使えない。結果として、WebKitベースのブラウザはありうるけど、blinkベースのブラウザというものはほとんどなく、Chromiumをベースにしたブラウザというものになっている。</p>
<p>また、Chromiumのbase/というディレクトリはなかなかいいように思うけど外部で利用できないか、というリクエストはたまにあったのだが、毎回にべもなく断っていた。Chromiumプロジェクトとしては自分たちの都合で好き勝手にいろいろ足したいし、後方互換性のこととかを考えたりしたくない、Chromiumのためのものなので他では勘弁な、という話になっている。これははっきりいって感じが良くないのだが、そういうことをしたくないという気持ちはよくわかる。汎用のライブラリを作ってるわけじゃないのにそんなことを要求されても困る、という話でもある。が、abseilができてからは、こういうリクエストはほぼなくなった気がする。C++も発展が進んだので、いまどきChromiumのbaseがほしい人間なんていやしないのだった。よかったよかった（？）</p>
<p>なおChromeOS側のサービスなどの実装のためにChromiumのbase相当のものがほしいという話が根強くあり、baseを勝手にコピーしてライブラリ化して使っている。一見再利用っぽく聞こえるかもしれないけれど、別にそういうわけでもない。勝手にコピーしてるだけだし。たまにChromiumの最新のものに更新するたびに大変な作業になっているつらさとかを垣間見るに、再利用を避けるポリシーを徹底したことの弊害が感じられないでもない。</p>
<p>というわけで、仕事のほうではあんまりちゃんと再利用していない昔ながらのプロジェクトをやっているので、それがどんな感じなのかを書いてみた。</p>
<p>この状況は、再利用がごくふつうな他の言語と比べるとかなり乖離があるが、そうなっていることにはそれなりに理由があるときもある。たとえばbaseが一般化されたライブラリになっていないのは、そういうことを指向していないからだ。専用のGUIフレームワークは、ChromeのUIで必要になりそうなところだけがよく書けていて、それ以外の部分は意外に雑なつくりになっていたりする。そういうものを使おうとすると、けっきょくそういう雑な部分を自分で書く必要が出てきたり、ということがよくある。これは残念なライブラリという見方もできるけれど、視点を変えれば、汎用のものは目指さない指向という意味では一貫している。</p>
<p>が……よく考えてみると、けっきょくこれは「C/C++では再利用が大変だ」という話の言い換えでしかないような気もする。再利用が大変であるがゆえに内製もしがちだし、パッケージとして公開するのもかんたんじゃないから公開しない。 後方互換性とかもべつに考えたくないけどそのための解決策もとくになかった。</p>
<p>他の言語だと、再利用が難しいとかできないっていうことは、みんなあんま考えてる気がしない。が、これはなんというか、パッケージシステムとかビルドシステムによって解決されてきた問題なような気がする。だいたいnpm installすればいいでしょ、go getすればいいでしょ、nuget&hellip;cargo&hellip;みたいな。C/C++にはこのレイヤの（デファクト）スタンダードがなんにもないから解決していない。しかしいまさらそんなのは望むべくもない。残念ですね、という話なような気がしてきた。</p>
<p>ところで逆な例でいえば、Node.js (NPM)とかを見ると「さすがに他人のコードに依存しすぎでしょ」という揺り戻しはたまに起きてる気がするし（たとえば<a href="https://qz.com/646467/how-one-programmer-broke-the-internet-by-deleting-a-tiny-piece-of-code/">文字列に空白を埋めるだけのライブラリが破綻を引き起こした事件</a>とか）、<a href="https://medium.com/@madhankumar028/dont-depend-on-lodash-when-javascript-has-the-same-part-1-52719420ee43">lodashに依存するな問題</a>とか、そういうのはある。もちろんこういうのは程度問題でしかなくて、再利用を一切しないっていうことはさすがに考えていないだろうけど、再利用しすぎの問題ってのも、それはそれで顕在化はしてると思う。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<blockquote>
<p>ここがすでに独自なのかよ、というツッコミがあるかもしれませんがスルーしてください</p>
</blockquote>
<p>でもビルドシステムの揃っていなさはコミュニティとしての合意の無さのあらわれという気はする・・・。
Chromium はオープンソースでありながらあんなに再利用に不親切で、
その一方で互換ブラウザや Electron みたいのが沢山あって、興味深いですね。</p>
<p>あと Chrome/Chromium コードベース本体はともかく、Chrome 製品の一環として開発されているライブラリたちは割と広く使われているので、
捨てたものではない、かもしれない。(V8, Skia, Webp, PDFium&hellip;)</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>Electronなんかを見ていると、再利用をしてもらうのに一番大切なのは再利用をするに値する価値ある物を作る、という事なんだろうなぁ、と思う。</p>
<p>ネイティブのweb viewを使ったもっと小さなelectron alternativesの試み、いっぱいあっていろいろ評価してみたのだけれど、評価すればするほどChromium良く出来てるな、という思いを強くしただけだった。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>社内の情報共有とか社内ソーシャルメディア</title>
      <link>https://messagepassing.github.io/015-poems/05-jmuk/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/015-poems/05-jmuk/</guid>
      <description>グーグル社内の情報共有とか社内ソーシャルメディアは、たぶんHow Google WorksとかWork Rules!といった本で軽く触れられていると思う。ちゃんと読み返してないけど、だいたい似たようなことが書かれていただろうと思う。
大昔の話をすると、wikiがあってそこで雑にいろいろ書かれていた時代というのがあった。そういうところで、仕事の情報も、そうじゃないカジュアルな情報共有も行われていたような気がする。ただ、wikiはだんだん使われなくなてきたような気がする。社員数の急増に対してスケールしなくなっていったのだろう。可視性の細かい制御とかができないのも、組織が大きくなってくると難しい話になってくるからかもしれない。
GoogleBuzz / Google+ GoogleBuzzというのは、もう覚えていない人も多いだろうけど、マイクロブログ的なソーシャルサービスで、一般サービスとしては一瞬で撤退してしまった。だが、ローンチより前には社内で使われており、社内ではそこそこ流行っていたと記憶している。Buzzの失敗の原因はいくつかあるとされているが、そのうちのひとつは社内でそこそこうまくいっていたことで誤解してしまったことだとされている。
その後のGoogle+も、社内では唯一のオフィシャルなソーシャルサービスなのでけっこう流行った。けっこういろんな長文投稿をする人もいた。rantを書く人もいたし、技術的な小ネタを書く人もいてけっこう面白かった。社内で書いたものは社外にはそのままでは共有できないようになっていたので、それなりに安全なソーシャルサービスになっていた気がする。UIが一緒なので、間違って社内向けrantをgmail.comのアカウントで投稿してしまうといった事件も発生したりしていたけど、裏を返せばそれぐらいには社内にオーディエンスがいたのだった。
ただし、社内Google+は次第に人気を失っていったように思う。決定的だったのは、一般公開Google+が終了したことか、それともCurrentsという名前にリブランドされたことか。いまでもたまに見ると投稿はちらほら見るけど、かつての賑わいは失われてしまったような気がする。
memegen もうひとつユニークなサービスがmemegenだ。memegenは社内向けの「インターネットミーム」の投稿サイトで、ミームというのは画像に好きなキャプションをかぶせたジョーク、といったものだ。これはめちゃくちゃ流行っていた。基本的に皮肉っぽく、社内のいろんなネタを笑い飛ばせるところが良かった。また、全社のTGIFでの発表なんかでも、おかしなことを投稿するとすぐ茶化されたりといったこともあった。人気を反映して真面目な問題提起がなされるようになったりしたし、会社の偉い人たちもこういうところで雰囲気をはかるようなところがあったりした。ただ、独自のカルチャーもあるし、奇妙な「お約束」もあったりした。皮肉っぽいカルチャーゆえに、妙に会社や（ほかのチームの）製品のクオリティに対する文句も増えてきている気がする。今でも人気はある気がするし、たまに見ると面白いんだけど、わたしはあんまり見なくなってしまった。あとmemegenは構造上、ジョークがメインであって、ソーシャルにはいいんだけど、メモとかそういう話ではない。
g3doc これも存在が明らかになっているみたいなので書いておくと、このごろはg3docにまとめておくという話もあるにはある。g3docは、社内用のgithub pagesのような仕組みであり、markdownで書いたファイルをコミットしておくと、ウェブサイトでいいかんじに表示してくれる、というもの。
これ自体はよくできていて、とくにオフィシャルなドキュメントの整備には向いている。チームの情報をまとめたり、といったことには広く使われている。が、ファイルをコミットしないといけないので、雑多なメモやら、カジュアルな情報共有にはあまり向いていない。痛し痒し。
Google Workplaces けっきょくのところ、いわゆるgSuite / Google Workplacesの製品が、いまではよく使われている気がする。たとえば、ちょっとしたノートやtipsならGoogle Docsに書く。チーム内のインフォーマルな情報共有にはGoogle Chatが使われるようになった。あとGmail。グーグルではメールが非常に頻繁に使われていて、わりとちょっとしたこともメールで書くことはある、気がする。意図的に雑談チャット風のメーリングリストを運用していて、ちょっとしたこと（たとえばツールやスクリプトのトラブルなど）の相談なんかは、そういうところで行われることもある。Google Sitesは……あんまり使わないかな……チームにもよるんだろうけど。
この分野、もうちょっとどうにかならないものかと思ってはいるけれど、なかなか丁度いいものというのは難しいんだなという気がする。あと意外とDocsはそこまで悪くはない。
 morrita 知らない人のために補足すると、うっかり公開されてしまった社内向けポストというのは &amp;ldquo;Steve Yagge Platform Rant&amp;rdquo; という名前で 10 年くらい前に話題になりました。思えばこの頃が Google+ 最盛期だったかもしれない。なおその後 Steve Yagge 氏は転職して Grab という会社で数年働き, いまはリタイアして趣味のオンラインゲーム開発をしているそうな。
個人的に社内ソーシャルメディアの衰退にとどめを刺したのは 数年前の超絶キナクサ案件 かなと思います。 自分はアンチソーシャルメディアなのでもともとそんなに書いてなかったけど、このあとは空気が悪すぎてほんとに書く気なくなった人が多いんじゃないかな。 そして社内の vocal な人たちは野(Twitter)に放たれ Tech Employee Activism の先駆けとなったり外資系ドヤり勢となったりしたのだった。 めでたしめでたし。
  </description>
      <content:encoded><![CDATA[<p>グーグル社内の情報共有とか社内ソーシャルメディアは、たぶん<a href="https://www.amazon.com/How-Google-Works-Eric-Schmidt/dp/1455582328">How Google Works</a>とか<a href="https://www.amazon.com/Work-Rules-Insights-Inside-Transform/dp/1455554790/">Work Rules!</a>といった本で軽く触れられていると思う。ちゃんと読み返してないけど、だいたい似たようなことが書かれていただろうと思う。</p>
<p>大昔の話をすると、wikiがあってそこで雑にいろいろ書かれていた時代というのがあった。そういうところで、仕事の情報も、そうじゃないカジュアルな情報共有も行われていたような気がする。ただ、wikiはだんだん使われなくなてきたような気がする。社員数の急増に対してスケールしなくなっていったのだろう。可視性の細かい制御とかができないのも、組織が大きくなってくると難しい話になってくるからかもしれない。</p>
<h2 id="googlebuzz--google">GoogleBuzz / Google+</h2>
<p>GoogleBuzzというのは、もう覚えていない人も多いだろうけど、マイクロブログ的なソーシャルサービスで、一般サービスとしては一瞬で撤退してしまった。だが、ローンチより前には社内で使われており、社内ではそこそこ流行っていたと記憶している。Buzzの失敗の原因はいくつかあるとされているが、そのうちのひとつは社内でそこそこうまくいっていたことで誤解してしまったことだとされている。</p>
<p>その後のGoogle+も、社内では唯一のオフィシャルなソーシャルサービスなのでけっこう流行った。けっこういろんな長文投稿をする人もいた。rantを書く人もいたし、技術的な小ネタを書く人もいてけっこう面白かった。社内で書いたものは社外にはそのままでは共有できないようになっていたので、それなりに安全なソーシャルサービスになっていた気がする。UIが一緒なので、間違って社内向けrantをgmail.comのアカウントで投稿してしまうといった事件も発生したりしていたけど、裏を返せばそれぐらいには社内にオーディエンスがいたのだった。</p>
<p>ただし、社内Google+は次第に人気を失っていったように思う。決定的だったのは、一般公開Google+が終了したことか、それともCurrentsという名前にリブランドされたことか。いまでもたまに見ると投稿はちらほら見るけど、かつての賑わいは失われてしまったような気がする。</p>
<h2 id="memegen">memegen</h2>
<p>もうひとつユニークなサービスがmemegenだ。memegenは社内向けの「インターネットミーム」の投稿サイトで、ミームというのは画像に好きなキャプションをかぶせたジョーク、といったものだ。これはめちゃくちゃ流行っていた。基本的に皮肉っぽく、社内のいろんなネタを笑い飛ばせるところが良かった。また、全社のTGIFでの発表なんかでも、おかしなことを投稿するとすぐ茶化されたりといったこともあった。人気を反映して真面目な問題提起がなされるようになったりしたし、会社の偉い人たちもこういうところで雰囲気をはかるようなところがあったりした。ただ、独自のカルチャーもあるし、奇妙な「お約束」もあったりした。皮肉っぽいカルチャーゆえに、妙に会社や（ほかのチームの）製品のクオリティに対する文句も増えてきている気がする。今でも人気はある気がするし、たまに見ると面白いんだけど、わたしはあんまり見なくなってしまった。あとmemegenは構造上、ジョークがメインであって、ソーシャルにはいいんだけど、メモとかそういう話ではない。</p>
<h2 id="g3doc">g3doc</h2>
<p>これも存在が明らかになっているみたいなので書いておくと、このごろは<a href="https://www.usenix.org/sites/default/files/conference/protected-files/srecon16europe_slides_macnamara.pdf">g3doc</a>にまとめておくという話もあるにはある。g3docは、社内用のgithub pagesのような仕組みであり、markdownで書いたファイルをコミットしておくと、ウェブサイトでいいかんじに表示してくれる、というもの。</p>
<p>これ自体はよくできていて、とくにオフィシャルなドキュメントの整備には向いている。チームの情報をまとめたり、といったことには広く使われている。が、ファイルをコミットしないといけないので、雑多なメモやら、カジュアルな情報共有にはあまり向いていない。痛し痒し。</p>
<h2 id="google-workplaces">Google Workplaces</h2>
<p>けっきょくのところ、いわゆるgSuite / Google Workplacesの製品が、いまではよく使われている気がする。たとえば、ちょっとしたノートやtipsならGoogle Docsに書く。チーム内のインフォーマルな情報共有にはGoogle Chatが使われるようになった。あとGmail。グーグルではメールが非常に頻繁に使われていて、わりとちょっとしたこともメールで書くことはある、気がする。意図的に雑談チャット風のメーリングリストを運用していて、ちょっとしたこと（たとえばツールやスクリプトのトラブルなど）の相談なんかは、そういうところで行われることもある。Google Sitesは……あんまり使わないかな……チームにもよるんだろうけど。</p>
<p>この分野、もうちょっとどうにかならないものかと思ってはいるけれど、なかなか丁度いいものというのは難しいんだなという気がする。あと意外とDocsはそこまで悪くはない。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>知らない人のために補足すると、うっかり公開されてしまった社内向けポストというのは &ldquo;<a href="https://www.google.com/search?q=steve+yegge+platforms+rant">Steve Yagge Platform Rant</a>&rdquo;
という名前で 10 年くらい前に話題になりました。思えばこの頃が Google+ 最盛期だったかもしれない。なおその後 Steve Yagge 氏は転職して <a href="https://steve-yegge.medium.com/get-that-job-at-grab-eea6de1d8421">Grab という会社で数年働き</a>, いまは<a href="https://steve-yegge.medium.com/saying-goodbye-to-the-best-gig-i-ever-had-a33736833c1e">リタイアして趣味のオンラインゲーム開発をしているそうな</a>。</p>
<p>個人的に社内ソーシャルメディアの衰退にとどめを刺したのは <a href="https://en.wikipedia.org/wiki/Google%27s_Ideological_Echo_Chamber">数年前の超絶キナクサ案件</a> かなと思います。
自分はアンチソーシャルメディアなのでもともとそんなに書いてなかったけど、このあとは空気が悪すぎてほんとに書く気なくなった人が多いんじゃないかな。
そして社内の vocal な人たちは野(Twitter)に放たれ
<a href="https://www.google.com/search?q=tech+employee+activism">Tech Employee Activism</a> の先駆けとなったり外資系ドヤり勢となったりしたのだった。
めでたしめでたし。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>もはや書く気おきない</title>
      <link>https://messagepassing.github.io/015-poems/04-morrita/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/015-poems/04-morrita/</guid>
      <description>全然書いてないですね。
書いてない理由は色々だけれど、ポエム/お気持ち表明系の話と技術的な度合いの高いメモでは空気が違うと思う。 かずよしさんの話 は主に前者という認識。 なので二つ別々に議論してみたい。
お気持ち表明系 まずはまじさんがポエムといっているようなやつ。
書いてない理由は、もちろん英語だから厳しいのはある。 がそれはさておくとして、チームによってポエムに対する温度差があると思う。 まわりの人が色々言っていると自分もそういうことを考えたり書いたりするようになる。 まわりに意見を表明する人がいないと、自分だけでは角が立つ気がしてわざわざ声を上げる気にはならない。 意見が多いチームにいた頃はたまになんか書いていた気がする。今はゼロ。
あと今の部署は文章より face to face を好んでいる。 割とエラ目の人が定期的に &amp;ldquo;office hour&amp;rdquo; という名の update+unconference みたいのを開催し、人々はそういう forum で意見を表明している。 でも、これだとほんとに英語的な厳しさがあるね。 Crucial Conversation を即興でやるとかムリ。これは自分だけでなく周りの non-native speaker も苦労しているように見える。 誰でも意見を言える環境の方が風通しは良いから、その点でいまの部署はイマイチなのだろう。 ただすごく不満というほどではない。チームの価値は風通しだけではないし。
あと大企業でそれなりに mature なチームだと、何か言ったくらいで変化を起こせる気がしない。 良くも悪くも企業や組織の文化は出来上がっていて、したっぱ平社員がどうこういう話でもない。
エンジニアリング的にいまいちだと思うところ、たとえばリリースプロセスとかも、 変えるのが大変なのはわかっている。自分のチームの TPM とか超優秀で Accelerate 的なリリースの理想系 はどう考えてもわかってる。そんな人がいまいちな現状に甘んじざるをえない困難は想像がつくから、 &amp;ldquo;DORA の調査によれば&amp;hellip;&amp;rdquo; とかさ、言えないよね。
こういう納得のいきやすい例だけでなく単に気に入らないものも色々あるけど、文句を言ったところで変わらないことに違いはない。 こういうのを変えたいと思ったら労力か権力か、あるいはその両方が必要。 口先だけの感じ悪い人にならず、しかしなんか書くだけで特に何もしない、という綱渡りをするには今の 5 倍くらい英語力/米国文化資本がないとムリ。
他人を educate するにしても、自分で書き下すより世の中なり社内の文章のほうが大抵よく書けている。それをリンクすれば済む。 「コミットログもうちょっとなんとかしてくれ・・・ほらこれ」 とか 「副作用のある部分は外に押し出して計算のとこだけテストかいてくれ・・・・ほらこれ」 とか 「目に優しく early return して flat にしてくれよーほらこれ」 とか、コードレビューでありがちなコメントの例。 あと、そもそも自分の opinion で他人を educate する authority もそんなに無い。下っ端だからね。</description>
      <content:encoded><![CDATA[<p>全然書いてないですね。</p>
<p>書いてない理由は色々だけれど、ポエム/お気持ち表明系の話と技術的な度合いの高いメモでは空気が違うと思う。
<a href="/015-poems/03-kzys/">かずよしさんの話</a> は主に前者という認識。
なので二つ別々に議論してみたい。</p>
<h2 id="お気持ち表明系">お気持ち表明系</h2>
<p>まずはまじさんがポエムといっているようなやつ。</p>
<p>書いてない理由は、もちろん英語だから厳しいのはある。
がそれはさておくとして、チームによってポエムに対する温度差があると思う。
まわりの人が色々言っていると自分もそういうことを考えたり書いたりするようになる。
まわりに意見を表明する人がいないと、自分だけでは角が立つ気がしてわざわざ声を上げる気にはならない。
意見が多いチームにいた頃はたまになんか書いていた気がする。今はゼロ。</p>
<p>あと今の部署は文章より face to face を好んでいる。
割とエラ目の人が定期的に &ldquo;office hour&rdquo; という名の update+unconference みたいのを開催し、人々はそういう forum で意見を表明している。
でも、これだとほんとに英語的な厳しさがあるね。
<a href="https://www.amazon.com/Crucial-Conversations-Talking-Stakes-Second/dp/1469266822">Crucial Conversation</a>
を即興でやるとかムリ。これは自分だけでなく周りの non-native speaker も苦労しているように見える。
誰でも意見を言える環境の方が風通しは良いから、その点でいまの部署はイマイチなのだろう。
ただすごく不満というほどではない。チームの価値は風通しだけではないし。</p>
<p>あと大企業でそれなりに mature なチームだと、何か言ったくらいで変化を起こせる気がしない。
良くも悪くも企業や組織の文化は出来上がっていて、したっぱ平社員がどうこういう話でもない。</p>
<p>エンジニアリング的にいまいちだと思うところ、たとえばリリースプロセスとかも、
変えるのが大変なのはわかっている。自分のチームの TPM とか超優秀で
<a href="https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">Accelerate</a> 的なリリースの理想系
はどう考えてもわかってる。そんな人がいまいちな現状に甘んじざるをえない困難は想像がつくから、
&ldquo;<a href="https://www.devops-research.com/research.html">DORA</a> の調査によれば&hellip;&rdquo; とかさ、言えないよね。</p>
<p>こういう納得のいきやすい例だけでなく単に気に入らないものも色々あるけど、文句を言ったところで変わらないことに違いはない。
こういうのを変えたいと思ったら労力か権力か、あるいはその両方が必要。
口先だけの感じ悪い人にならず、しかしなんか書くだけで特に何もしない、という綱渡りをするには今の 5 倍くらい英語力/米国文化資本がないとムリ。</p>
<p>他人を educate するにしても、自分で書き下すより世の中なり社内の文章のほうが大抵よく書けている。それをリンクすれば済む。
「コミットログもうちょっとなんとかしてくれ・・・ほら<a href="https://google.github.io/eng-practices/review/developer/cl-descriptions.html">これ</a>」
とか
「副作用のある部分は外に押し出して計算のとこだけテストかいてくれ・・・・ほら<a href="https://martinfowler.com/bliki/CommandQuerySeparation.html">これ</a>」
とか
「目に優しく early return して flat にしてくれよーほら<a href="https://blog.codinghorror.com/flattening-arrow-code/">これ</a>」
とか、コードレビューでありがちなコメントの例。
あと、そもそも自分の opinion で他人を educate する authority もそんなに無い。下っ端だからね。</p>
<h3 id="leadership-and-passion">Leadership and Passion</h3>
<p>一歩さがると、ポエムでお気持ち表明をするに至る経路は二つくらいあると思う。</p>
<p>ひとつ目は leadership としての自覚。つまり、自分は周りの人に影響を与えられると思っている。
あるいは周りの人が自分に意見を期待していると思っている。</p>
<p>言葉に棘を感じる人もいるかもしれないけれど、そういう意図はない。
我々はだいぶおっさんなので、順当にキャリアを重ねていれば程度の差はあれ指導的立場にあるはずで、つまり意見を期待されている。
意見をいうかどうかが問題ではなく、意見の良し悪しで評価される段階。
はまじさんやありのさんはこれに該当するんじゃないかな。
組織階層的な leadership はともかく実力者としての存在感はあるでしょう。</p>
<p>ふたつ目は passion の表出。愛社精神や製品愛みたいなやつ。
仕事のことをずっと考えていて、だから意見もあって、
その意見と現状の不一致に腹が立ったりして、まわりの期待とは無関係にそれを表現してしまう。</p>
<p>ここでも棘を見出す人がいるかもしれないけれど、そうじゃない。
愛社精神、ないよりあった方がいいじゃん。政治的正しさを脇に置くなら、これが若さってもんじゃん。
むかしの自分やかずよしさんはこれに該当したんじゃないですかね。もう覚えてないけど。</p>
<p>いまの自分はどうかというと、それほど順当にキャリアが進んでないので特に leadership もなく、
かつてほど愛社精神、製品愛といった passion もなく（ゼロじゃないよ）、
そんなことより眼の前の仕事をさっさと終わらせ子供を風呂に入れねば・・・みたいな日々。</p>
<p>そうそう、最近はポエムとか書いてる時間がないというのもある。降ってくる仕事を片付けるだけで精一杯。
そして就業後・家事子守後に仕事のことを考えたりもしない。そんなヒマがあったらこうして blog 書いたり podcast やったりしてる。
我ながらいかにも出世できなそうであることよ&hellip;</p>
<h2 id="技術メモ系">技術メモ系</h2>
<p>ポエムはおいといてもうちょっと技術的なメモとかないの、という話。</p>
<p>ない! これはツールが悪い。つまりここから先は仕事の愚痴なのだけれど、
勤務先には Confluence も Notion も無いのですよね。
Google Docs と Google Sites しかない。</p>
<p>Google Docs は Google Drive のフォルダくらいしか文書間のナビゲーションを表現する方法がなく、
書いたドキュメントは次々と電子の海の藻屑になっていく。
一方 Google Sites はホームページビルダーみたいな路線に進化してしまい、
ドキュメントレポジトリとしては終了してしまった。
これじゃ information を accessible and useful にできる気がしない。
なんとかならないかと年に一回くらい社内ツール事情を探っては絶望するのを繰り返した結果、
学習的無気力に陥ってしまった。</p>
<h3 id="g3docs">g3docs</h3>
<p>ただ最近は同じチームで三年も働いてしまった結果過剰にノウハウが蓄積されてしまった。
そのノウハウのせいでいらん仕事を引き寄せてしまう。
そんな仕事を<del>他人に押し付ける</del>属人性を廃しスケーラブルにすべく文書化を頑張ろうと、最近は少し心を改めた。
そこで再び社内事情を調べてみると <a href="https://www.usenix.org/conference/srecon16europe/program/presentation/macnamara">g3docs</a> という
Monorepo GitHub Pages みたいなツールがそれなりに使えるようになっていたので、
これで妥協しようかなとおもってます。変更のたびにコミットするとかかったるいけど、やむなし。
性能関係のチップスみたいのを整備していきたい。</p>
<p>なおこれを書こうと思ったきっかけは <a href="https://notes.dodgson.org/">自分のブログ</a>だった。
これ日本語で書くより同僚に読ませるべきなのでは・・・という。
なおこのブログは GitHub と Netlify でホストした Hugo で書いている。
だから g3docs をディスるのは不当で、結局は英語を書きたくないだけなのかもしれない。</p>
<p>でも英語はともかく、仕事は文章を書くヒマがあったらコードを書いて目に見える進捗を出したくなってしまうのだよねえ。</p>
<p>&hellip;</p>
<p>ちょっと話がフォーマルっぽい文書に傾きすぎてしまった。
会社のなかでのインフォーマルな会話はソーシャルメディアとか色々あるんだけど、
そのへんはむかいさんの方が詳しい気がする。どうですか &gt; <a href="/015-poems/05-jmuk/">jmuk</a></p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
<p>確かに、昔はお気持ち表明していたかも。</p>
<p>ちょっと読んだ (通読していない) &ldquo;The Manager&rsquo;s Path&rdquo; に「シニアになるにつれて、お前のマネージャーは問題の指摘じゃなくて、その解決を期待するようになるぞ!」というのがあって、お気持ち + 解決策 + その文脈、とやっていくと、まあ短い文章になってしまうのはあるかもしれない。</p>
<p>技術メモとはちょっと違うのですが、最近がんばって、<a href="https://github.com/kzys/firecracker-containerd/blob/architecture-diagram/docs/img/overview.svg">アーキテクチャ図</a>を書き直したりしました。近所のチームとのミーティングで使い回すつもり。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
職場でMorrita on Software書こうぜ。
でも部外者的には、それよりはポッドキャストとかMessage Passing書いてくれる方が嬉しいか。
</div>
</div></p>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>何かを書きたいとか何か言いたいという気持ちがないんですよね。そういうのは継続的にやってないと失われてしまう感情、欲望なんじゃないかな。あとまわりの同僚と個人的な近さを感じてないと書きにくいのもある気がする。自分は team bonding みたいのをさぼりがちなので。近しさを通じた心理的安全の確保が必要なのかもしれないなあ。</p>
<p>インフォーマルでもフォーマルでも、文章が短いのはいいと思うんだよね。文章が長いのは単に作文スキルが低いだけかもしれないし。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>コアを使い切るとかあんまり考えたことない</title>
      <link>https://messagepassing.github.io/012-manycore/06-jmuk/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/06-jmuk/</guid>
      <description>コア、使い切るとか考えたことないなぁ。
仕事ではOSのウィンドウマネージャとか、デスクトップUIとかを作る仕事をしているが、こういう部分のコードというのは、コアは使い切らないほうが良い。ユーザの主たる感心はアプリケーションであって、コアみたいなリソースはそっちに割り振られるべき。だから考えるべきなのは、所望するエフェクトを実現しつつ、きびきびと動作しつつコアのようなものは使わないようなやり方はどうなのか、っていうことだ。
結果的に検討しないといけない条件や、導入するべきテクニックや方法論は似通ってる。たとえば、ブロッキングを避ける。コアを専有しないように、無駄な計算は避けて、コアが渋滞しないように気をつける。UIスレッドはひとつだけなので、重くなる処理は別のスレッドに移譲したり。でもその結果としてCPUがストールしてても、そこは比較的どうでもいい。というかそんな重たい処理はあるべきではない、というべきか。
もちろんこれが全てではなく、コアを大量に使ってでもうまく動いてくれるとありがたい部分ていうのもあるだろうとは思う。たとえばログイン時とかはいろんな初期化が走るけど、こういうのはできるだけすぐ終わってほしいし、へんな初期化プロセスがコアを専有してそれがシステム全体を阻害してくれては困る。でもそこをすごくきちんと頑張ってコアを使い切る、といったことは意義がありそうだが（あんま詳しくないけど）ちゃんと達成できてはいない気もする。大量のサービスやプロセスが行き来して全体像は把握しづらいし。無駄にブロックしないとか、UIやアニメーションの足を引っ張るようなことはしない、ぐらいは気をつけているだろうけれど。
あと、仕事のレイヤが変わってカーネルレベルになれば、アプリケーションが各種走ったときにきちんとコアが使い切れてくれるか、といったスケジューリング的な意味での興味とかも、あったりするのかもしれない。そのへんも詳しくないのでよくわからないけど。
今はChromebookはたいがいしょぼいのでコアが少ないけど、今後どんどんコアが増えてきたら話はかわるだろうか？　そんな変わんないんじゃないか。どんなコアが増えても、シングルコア性能の伸びがサチっても、ウィンドウマネージャがマルチコアで複雑な計算をすることは、正直考えづらい。あとラップトップOSみたいな文脈では、単一のアプリケーションがコアを使い切れなくて余っても別にそんな困らないだろうという気がする。複数アプリが同時に動いても総合的にきびきび動くなら嬉しいし、仮にコアがあまったりしてもそれだけ消費電力が減り、利用時間が伸びるだけなので、それはそれでいいことのような気もする。かつまた、いつまでたってもローエンド機は居残り、ローエンドでもひどくならないような工夫は残るんじゃないかなあ。
各種のアクセラレータが搭載されることで、別種のパラレリズムが要求されるようなことはありそう。アクセラレータを利用するようなOSサービス（たとえばローカルで動く音声アシスタント機能とか）が増えて、きちんとタスクを分配して無駄なく協調動作させるにはどうしたらいいだろうか、みたいな問題。モバイルでこの問題は起こりつつあるという認識だけど、ラップトップOSだとどうだろうか。そんな特殊なアクセラレータが入ったデバイスは多くないから、まだまだ未来の話かなあ。
morrita OS がコア、に限らず余計な資源を使うべきでないというのはほんとにそうですね。 新品のデバイスでメモリやディスクの残量が妙にすくないのに気づいた時のがっかり感を思い出しました。   karino2 Chromebookって今何コアくらいあるもんなんですか？ちらっとググったらMediaTekのが8コア、PixelBookなんかは2コア4HTくらいと引っかかったけれど、ユーザーの手元にあるのはだいたい幾つくらいと思っておくと丼が合うのかしら。
OSの視点だと、コアをOSが使うというよりは、その上のアプリがちゃんと使えるような仕組みを提供出来ているのか？というのが本題のような気もするけれど、 そもそものChromeOSのコンセプトに対してコアを使い切るようなアプリがユーザーに望まれているのか、というのは良く分からないなぁ。
  jmuk  OSの視点だと、コアをOSが使うというよりは、その上のアプリがちゃんと使えるような仕組みを提供出来ているのか？
 その話はちょっと考えたんですが、ChromeOSはそのへんはなにも提供してないので（基本はシングルスレッドなウェブアプリなので）、書くことが思い浮かびませんでした。ChromeOS上のAndroidやLinux appは仮想環境なので、vCPUがどう見えてるかとかいろいろ話がある気がしますが全然くわしくない。
現実としてはウィンドウマネージャ＋デスクトップシステム＋各種OSサービスはけっこうリソースをくっていている気がしますが、具体的な数値はすぐは出てこないかな……。
  kzys OS の話はコンテナランタイムの話に近いなあ。脇役/裏方仲間。</description>
      <content:encoded><![CDATA[<p>コア、使い切るとか考えたことないなぁ。</p>
<p>仕事ではOSのウィンドウマネージャとか、デスクトップUIとかを作る仕事をしているが、こういう部分のコードというのは、コアは使い切らないほうが良い。ユーザの主たる感心はアプリケーションであって、コアみたいなリソースはそっちに割り振られるべき。だから考えるべきなのは、所望するエフェクトを実現しつつ、きびきびと動作しつつコアのようなものは使わないようなやり方はどうなのか、っていうことだ。</p>
<p>結果的に検討しないといけない条件や、導入するべきテクニックや方法論は似通ってる。たとえば、ブロッキングを避ける。コアを専有しないように、無駄な計算は避けて、コアが渋滞しないように気をつける。UIスレッドはひとつだけなので、重くなる処理は別のスレッドに移譲したり。でもその結果としてCPUがストールしてても、そこは比較的どうでもいい。というかそんな重たい処理はあるべきではない、というべきか。</p>
<p>もちろんこれが全てではなく、コアを大量に使ってでもうまく動いてくれるとありがたい部分ていうのもあるだろうとは思う。たとえばログイン時とかはいろんな初期化が走るけど、こういうのはできるだけすぐ終わってほしいし、へんな初期化プロセスがコアを専有してそれがシステム全体を阻害してくれては困る。でもそこをすごくきちんと頑張ってコアを使い切る、といったことは意義がありそうだが（あんま詳しくないけど）ちゃんと達成できてはいない気もする。大量のサービスやプロセスが行き来して全体像は把握しづらいし。無駄にブロックしないとか、UIやアニメーションの足を引っ張るようなことはしない、ぐらいは気をつけているだろうけれど。</p>
<p>あと、仕事のレイヤが変わってカーネルレベルになれば、アプリケーションが各種走ったときにきちんとコアが使い切れてくれるか、といったスケジューリング的な意味での興味とかも、あったりするのかもしれない。そのへんも詳しくないのでよくわからないけど。</p>
<p>今はChromebookはたいがいしょぼいのでコアが少ないけど、今後どんどんコアが増えてきたら話はかわるだろうか？　そんな変わんないんじゃないか。どんなコアが増えても、シングルコア性能の伸びがサチっても、ウィンドウマネージャがマルチコアで複雑な計算をすることは、正直考えづらい。あとラップトップOSみたいな文脈では、単一のアプリケーションがコアを使い切れなくて余っても別にそんな困らないだろうという気がする。複数アプリが同時に動いても総合的にきびきび動くなら嬉しいし、仮にコアがあまったりしてもそれだけ消費電力が減り、利用時間が伸びるだけなので、それはそれでいいことのような気もする。かつまた、いつまでたってもローエンド機は居残り、ローエンドでもひどくならないような工夫は残るんじゃないかなあ。</p>
<p>各種のアクセラレータが搭載されることで、別種のパラレリズムが要求されるようなことはありそう。アクセラレータを利用するようなOSサービス（たとえばローカルで動く音声アシスタント機能とか）が増えて、きちんとタスクを分配して無駄なく協調動作させるにはどうしたらいいだろうか、みたいな問題。モバイルでこの問題は起こりつつあるという認識だけど、ラップトップOSだとどうだろうか。そんな特殊なアクセラレータが入ったデバイスは多くないから、まだまだ未来の話かなあ。</p>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
OS がコア、に限らず余計な資源を使うべきでないというのはほんとにそうですね。
新品のデバイスでメモリやディスクの残量が妙にすくないのに気づいた時のがっかり感を思い出しました。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>Chromebookって今何コアくらいあるもんなんですか？ちらっとググったらMediaTekのが8コア、PixelBookなんかは2コア4HTくらいと引っかかったけれど、ユーザーの手元にあるのはだいたい幾つくらいと思っておくと丼が合うのかしら。</p>
<p>OSの視点だと、コアをOSが使うというよりは、その上のアプリがちゃんと使えるような仕組みを提供出来ているのか？というのが本題のような気もするけれど、
そもそものChromeOSのコンセプトに対してコアを使い切るようなアプリがユーザーに望まれているのか、というのは良く分からないなぁ。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>jmuk</div>
<div class='message-body'>
<blockquote>
<p>OSの視点だと、コアをOSが使うというよりは、その上のアプリがちゃんと使えるような仕組みを提供出来ているのか？</p>
</blockquote>
<p>その話はちょっと考えたんですが、ChromeOSはそのへんはなにも提供してないので（基本はシングルスレッドなウェブアプリなので）、書くことが思い浮かびませんでした。ChromeOS上のAndroidやLinux appは仮想環境なので、vCPUがどう見えてるかとかいろいろ話がある気がしますが全然くわしくない。</p>
<p>現実としてはウィンドウマネージャ＋デスクトップシステム＋各種OSサービスはけっこうリソースをくっていている気がしますが、具体的な数値はすぐは出てこないかな……。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
OS の話はコンテナランタイムの話に近いなあ。脇役/裏方仲間。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>書いていないなあ</title>
      <link>https://messagepassing.github.io/015-poems/03-kzys/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/015-poems/03-kzys/</guid>
      <description>インフォーマルなもの、書いていないなあ。
Design Docs の話のあとだと自分の書いているものを &amp;ldquo;Design Docs&amp;rdquo; とは言いにくいのですが、そういうフォーマルなものはそこそこ書いている。チケットが起点の調べものはチケットに書いていて、「これ読んでおいて」的なものはコードレビューでリンクを貼ることが多い。自分専用の雑多なメモとか TODO は、Quip という Google Docs みたいなものが社内で使えるので、それに書いたり、ローカルのテキストファイルに書いたりしている。エッセイは全然書いていない。
ちなみに、こういったインフォーマルな書き物をインターネットの人々が「ポエム」と呼ぶに至った経緯に関しては、昔に自分のブログに書きました。
私もミクシィで働いていたころは、Confluence のブログ機能を使って何か書いたりしていた記憶があって、あれは悪くなかった。morrita さんが以前に書いていた Tateno Culture も、はてなグループが起点だし、ミクシィも当時は人々が日記を書くサイトだった。そういう会社に集まる人々は、自分の考えを文章にまとめて、他人の読めるところに置いておくけれど、とりわけ「読んでね」と促すわけでもない、という行為と相性が良かったのかもしれない。
ただ、思いかえすと、これって「読んでね」と言わないことでどこかにエクスキューズを確保した、必要以上にインターネット的なコミュニケーションのとりかただったなあとも思う。社内なんだからもっと間合いを詰めても良かった。Slack の分報チャンネル (2005) にも同じような気持ちがある。読んでほしいことがあったら、チームの Slack チャンネルなりメーリングリストに送ればいいのでは? 気楽に書けるのが良いのはわかるけれど、私は気楽に書いたものはそこまで読みたくなくて、でもそれを明示してしまうと色々と角がたつのでちょっと&amp;hellip;
そういったわけで、ここ数年は、読んで欲しいものは「読んでね」と明言して、それなりに気合を入れて書く生活を送っている。行間とか空気を読んでもらうことを期待するより、書いてあることを読んでもらったほうが良い。また、shinh さんが冒頭で書いている
 スタートアップの社内プロジェクトの場合、読み手が少ないのでフォーマルなドキュメントを書くコストはペイしにくいと思っています
 と、逆向きの力が大企業だと働いていて、フォーマルな文章を書くコストはペイしてしまいがち、というのもある。
一方で、皆さんの話を読むと、自分が書き損ねているものについてはちょっと考えてしまう。自分の頭の中だけにあって、本当はちゃんとした文章にするべきだけど、とりあえず雑なかたちでもチームで共有するだけでも何かが改善できそうな情報、いくつかあるような気がするなあ。
 karino2 「読んでね」と「書かない」の２つだけ、というのは両極端な気がしますね。 フォーマルな文書には向いていないものも世の中にはいっぱいあるんじゃないかなぁ。   kzys そうですね。年をとるにつれて、雑なかたちで共有できそうなものを「もっとちゃんとしよう」とフィルタリングしてしまうの、ブログの更新が少なくなるのとも似ている気がします。   morrita Design Doc でない短めのフォーマルな書き物、N-pager みたいのを書く土壌があるのなら、インフォーマルな書き物の出番は減るのかもしれない。インフォーマルなものを頻繁に書いていた若かりし頃、逆にそういうフォーマルなものを書いてました？自分はぜんぜん書いてなかったな。   kzys 同じく書いてませんでした。「ちょっと文章にまとめてチームでレビューしましょう」というチームメンバーも (いま思い出せる範囲では) いなかったし、自分自身も、プログラミングの前に文章を書くことについて退避する気持ちがありました。Paul Graham かぶれというかなんというか。   shinh ポエムの経緯面白い。読み手が少ないどころか誰もいなくても、自分の思考の整理のツールになることもあるかもですね。今週自分が書いたコードをざつーに説明するスライド作って、結果としてリファクタリングが捗ったので思いました。グーグルにいた頃を思い出すと、大企業だとちゃんとレビューとかするので、思考も整理せずやった仕事なんてあまり残ってなかったかもなーとも思いましたが。   </description>
      <content:encoded><![CDATA[<p>インフォーマルなもの、書いていないなあ。</p>
<p>Design Docs の話のあとだと自分の書いているものを &ldquo;Design Docs&rdquo; とは言いにくいのですが、そういうフォーマルなものはそこそこ書いている。チケットが起点の調べものはチケットに書いていて、「これ読んでおいて」的なものはコードレビューでリンクを貼ることが多い。自分専用の雑多なメモとか TODO は、<a href="https://quip.com/">Quip</a> という Google Docs みたいなものが<a href="https://www.salesforce.com/video/3642926/">社内で使える</a>ので、それに書いたり、ローカルのテキストファイルに書いたりしている。エッセイは全然書いていない。</p>
<p>ちなみに、こういったインフォーマルな書き物をインターネットの人々が「ポエム」と呼ぶに至った経緯に関しては、<a href="https://blog.8-p.info/ja/2016/10/12/poem-history/">昔に自分のブログに書きました</a>。</p>
<p>私もミクシィで働いていたころは、Confluence のブログ機能を使って何か書いたりしていた記憶があって、あれは悪くなかった。morrita さんが以前に書いていた <a href="https://anemone.dodgson.org/2018/08/24/honoring-yuichi-tateno/">Tateno Culture</a> も、はてなグループが起点だし、ミクシィも当時は人々が日記を書くサイトだった。そういう会社に集まる人々は、自分の考えを文章にまとめて、他人の読めるところに置いておくけれど、とりわけ「読んでね」と促すわけでもない、という行為と相性が良かったのかもしれない。</p>
<p>ただ、思いかえすと、これって「読んでね」と言わないことでどこかにエクスキューズを確保した、必要以上にインターネット的なコミュニケーションのとりかただったなあとも思う。社内なんだからもっと間合いを詰めても良かった。Slack の<a href="https://craftsman-software.com/posts/56">分報チャンネル</a> (2005) にも同じような気持ちがある。読んでほしいことがあったら、チームの Slack チャンネルなりメーリングリストに送ればいいのでは? 気楽に書けるのが良いのはわかるけれど、私は気楽に書いたものはそこまで読みたくなくて、でもそれを明示してしまうと色々と角がたつのでちょっと&hellip;</p>
<p>そういったわけで、ここ数年は、読んで欲しいものは「読んでね」と明言して、それなりに気合を入れて書く生活を送っている。行間とか空気を読んでもらうことを期待するより、書いてあることを読んでもらったほうが良い。また、shinh さんが冒頭で書いている</p>
<blockquote>
<p>スタートアップの社内プロジェクトの場合、読み手が少ないのでフォーマルなドキュメントを書くコストはペイしにくいと思っています</p>
</blockquote>
<p>と、逆向きの力が大企業だと働いていて、フォーマルな文章を書くコストはペイしてしまいがち、というのもある。</p>
<p>一方で、皆さんの話を読むと、自分が書き損ねているものについてはちょっと考えてしまう。自分の頭の中だけにあって、本当はちゃんとした文章にするべきだけど、とりあえず雑なかたちでもチームで共有するだけでも何かが改善できそうな情報、いくつかあるような気がするなあ。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
「読んでね」と「書かない」の２つだけ、というのは両極端な気がしますね。
フォーマルな文書には向いていないものも世の中にはいっぱいあるんじゃないかなぁ。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
そうですね。年をとるにつれて、雑なかたちで共有できそうなものを「もっとちゃんとしよう」とフィルタリングしてしまうの、ブログの更新が少なくなるのとも似ている気がします。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
Design Doc でない短めのフォーマルな書き物、N-pager みたいのを書く土壌があるのなら、インフォーマルな書き物の出番は減るのかもしれない。インフォーマルなものを頻繁に書いていた若かりし頃、逆にそういうフォーマルなものを書いてました？自分はぜんぜん書いてなかったな。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
同じく書いてませんでした。「ちょっと文章にまとめてチームでレビューしましょう」というチームメンバーも (いま思い出せる範囲では) いなかったし、自分自身も、プログラミングの前に文章を書くことについて退避する気持ちがありました。Paul Graham かぶれというかなんというか。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
ポエムの経緯面白い。読み手が少ないどころか誰もいなくても、自分の思考の整理のツールになることもあるかもですね。今週自分が書いたコードをざつーに説明するスライド作って、結果としてリファクタリングが捗ったので思いました。グーグルにいた頃を思い出すと、大企業だとちゃんとレビューとかするので、思考も整理せずやった仕事なんてあまり残ってなかったかもなーとも思いましたが。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>インターネットの声</title>
      <link>https://messagepassing.github.io/011-designdocs/07-internet/</link>
      <pubDate>Sat, 03 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/07-internet/</guid>
      <description>エゴサーチをしていたら反応を書いてくれた人がいたのでみつけた順に紹介します (morrita)
 Message Passing 11 感想 - 2021/03/26 – kanejaku.org:
 Design のセクションの有用性は半々かなという印象を持っている。このセクションは Proof of Concept なコードをまず書いて、ある程度動く見通しを立ててから文章に落とし込んでいる部分が多い。ただ、alternatives を列挙しているトピックについてはパッチを書く前に合意をとるのに役立ったし、事前にフィードバックをもらうことで解決した問題もあった。
 Design doc所感 · osak.jp
 個人的には、半年くらい前まではDesign docに何を書けばいいのか今ひとつ分かっていなかったけど、最近になってこれらの事実に気が付いたので、BackgroundとMotivationの説明に時間をかけるようにして、他の部分は適当に済ませるような方針にしている。
 Design Docs への思い
 考えを整理する中で、私は自分のために Design Docs を書いていることが多いことに気づきました。そのためか Design Docs に対して悪い印象は持っていません。一方で読み手に対する配慮が欠けがちであることにも気づきました。
 </description>
      <content:encoded><![CDATA[<p>エゴサーチをしていたら反応を書いてくれた人がいたのでみつけた順に紹介します (morrita)</p>
<hr>
<p><a href="https://kanejaku.org/posts/2021/03/2021-03-26/">Message Passing 11 感想 - 2021/03/26 – kanejaku.org</a>:</p>
<blockquote>
<p>Design のセクションの有用性は半々かなという印象を持っている。このセクションは Proof of Concept なコードをまず書いて、ある程度動く見通しを立ててから文章に落とし込んでいる部分が多い。ただ、alternatives を列挙しているトピックについてはパッチを書く前に合意をとるのに役立ったし、事前にフィードバックをもらうことで解決した問題もあった。</p>
</blockquote>
<p><a href="https://osak.jp/posts/ja/what-i-feel-about-design-docs/">Design doc所感 · osak.jp</a></p>
<blockquote>
<p>個人的には、半年くらい前まではDesign docに何を書けばいいのか今ひとつ分かっていなかったけど、最近になってこれらの事実に気が付いたので、BackgroundとMotivationの説明に時間をかけるようにして、他の部分は適当に済ませるような方針にしている。</p>
</blockquote>
<p><a href="https://nhiroki.jp/2021/03/31/design-docs">Design Docs への思い</a></p>
<blockquote>
<p>考えを整理する中で、私は自分のために Design Docs を書いていることが多いことに気づきました。そのためか Design Docs に対して悪い印象は持っていません。一方で読み手に対する配慮が欠けがちであることにも気づきました。</p>
</blockquote>
]]></content:encoded>
    </item>
    
    <item>
      <title>誰かがどこかで使ってる</title>
      <link>https://messagepassing.github.io/012-manycore/05-morrita/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/05-morrita/</guid>
      <description>自分は仕事で電話機のカメラアプリ開発を手伝っている。 なのでカメラアプリから見るとどうかを中心に議論してみたい。
電話機の CPU はどのくらい使われているのか 電話機の CPU, 最近だと 8 コアくらいある。こいつらを活用したい。
わけだけれど、まず現実にはどのくらい活用されているのか実例を眺めてみる。 ちょっと前に自分のブログで Perfetto というトレーシングツール (プロファイラだと思ってください)を紹介した。 その中で実際にいくつかのアプリのトレースを集めた。手頃な実例になっている。
アプリの起動 このデータ をダウンロードして、ui.perfetto.dev から開いてほしい。 以下画面写真:
このトレースは Pixel 2 という電話機の上で TikTok というアプリの起動直後 5 秒間をキャプチャしている。 細かいところはわからなくていいけど、&amp;ldquo;CPU 0&amp;rdquo; から &amp;ldquo;CPU 7&amp;rdquo; までの行に細かい線が詰まっているのが見えると思う。
ちょっとズームインすると何がおきているかもう少しわかる。 これは起動 500ms 後くらい。
各 CPU がいつどのスレッドに使われているのか、時系列で可視化されているのがわかる。 隙間の空白は CPU が何もしていない瞬間を示している。
わかること: TikTok 起動の瞬間は CPU がそれなりに使われている。 目一杯限界まで使われているとは言わないけれど、半分以上は埋まってる。 自分は仕事でよく「起動が遅いのなんとかして」と送りつけられて来るトレースを睨む。 そういう「遅い起動」のトレースは CPU のタスクがもっとびっちり詰まっているのも珍しくない。 というかアプリの起動が遅い時、だいたい CPU は目一杯使われている。（みんな電話機酷使しすぎだよ・・・）
一体だれが CPU を使っているのか。Perfetto はそれも簡単に調べられる。 起動後二秒くらいを適当に切り出してプロセス単位の CPU 使用時間を眺めると&amp;hellip;
com.zhiliaoapp.musically が TikTok. たしかに一番 CPU を使っているけれど、 他にも Android のサービスをまるごとホストしたデーモンの system_server, Out-Of-Process された WebView, kthreadd(Linux カーネル) などもわりと熱心に活動されている。直前まで開いていた NYTimes のアプリもいる。 仕事でやっているカメラアプリだと、このほかに Camera HAL (ユーザランドのドライバみたいなものです) も コア 1-2 個分くらいなんかしてる。</description>
      <content:encoded><![CDATA[<p>自分は仕事で電話機のカメラアプリ開発を手伝っている。
なのでカメラアプリから見るとどうかを中心に議論してみたい。</p>
<h2 id="電話機の-cpu-はどのくらい使われているのか">電話機の CPU はどのくらい使われているのか</h2>
<p>電話機の CPU, 最近だと 8 コアくらいある。こいつらを活用したい。</p>
<p>わけだけれど、まず現実にはどのくらい活用されているのか実例を眺めてみる。
ちょっと前に自分のブログで Perfetto というトレーシングツール
(プロファイラだと思ってください)を<a href="https://notes.dodgson.org/android/perfetto-minimum/">紹介</a>した。
その中で実際にいくつかのアプリのトレースを集めた。手頃な実例になっている。</p>
<h3 id="アプリの起動">アプリの起動</h3>
<p><a href="https://storage.googleapis.com/morritanotes-files/perfetto-minimum/walleye_QQ3A200805001_20200923200328_tiktok.pftrace.gz">このデータ</a>
をダウンロードして、<a href="https://ui.perfetto.dev/#!/viewer">ui.perfetto.dev</a> から開いてほしい。
以下画面写真:</p>
<p><img src="/images/manycore-05-morrita-01.png" alt="TikTok launch"></p>
<p>このトレースは Pixel 2 という電話機の上で TikTok というアプリの起動直後 5 秒間をキャプチャしている。
細かいところはわからなくていいけど、&ldquo;CPU 0&rdquo; から &ldquo;CPU 7&rdquo; までの行に細かい線が詰まっているのが見えると思う。</p>
<p>ちょっとズームインすると何がおきているかもう少しわかる。
これは起動 500ms 後くらい。</p>
<p><img src="/images/manycore-05-morrita-02.png" alt="TikTok launch zoom"></p>
<p>各 CPU がいつどのスレッドに使われているのか、時系列で可視化されているのがわかる。
隙間の空白は CPU が何もしていない瞬間を示している。</p>
<p>わかること: TikTok 起動の瞬間は CPU がそれなりに使われている。
目一杯限界まで使われているとは言わないけれど、半分以上は埋まってる。
自分は仕事でよく「起動が遅いのなんとかして」と送りつけられて来るトレースを睨む。
そういう「遅い起動」のトレースは CPU のタスクがもっとびっちり詰まっているのも珍しくない。
というかアプリの起動が遅い時、だいたい CPU は目一杯使われている。（みんな電話機酷使しすぎだよ・・・）</p>
<p>一体だれが CPU を使っているのか。Perfetto はそれも簡単に調べられる。
起動後二秒くらいを適当に切り出してプロセス単位の CPU 使用時間を眺めると&hellip;</p>
<p><img src="/images/manycore-05-morrita-03.png" alt="TikTok launch CPU usage breakdown"></p>
<p><code>com.zhiliaoapp.musically</code> が TikTok. たしかに一番 CPU を使っているけれど、
他にも Android のサービスをまるごとホストしたデーモンの <code>system_server</code>, Out-Of-Process された WebView, <code>kthreadd</code>(Linux カーネル)
などもわりと熱心に活動されている。直前まで開いていた NYTimes のアプリもいる。
仕事でやっているカメラアプリだと、このほかに Camera HAL (ユーザランドのドライバみたいなものです) も コア 1-2 個分くらいなんかしてる。</p>
<p>なおここでいう「アプリの起動」にはマルチタスクでのアプリ切り替えも含まれている。
Android ではアプリ切り替えと launcher からのアプリ起動に大きな違いはない。
Social media addict 気味の人が複数アプリを zap したりするの、電話機的には割と過酷。</p>
<p>アプリの起動後しばらくすると背後の様々なノイズは収まって、
メインのアプリ(と、そのアプリが使っているサブシステム)が 8 コアのうち 6-7 コアくらいは専有できるようになる。
3-4 秒後くらいかな。</p>
<p>ただし WiFi や Cellular のネットワークが切り替わったり (geofencing) サーバから push が降ってきたりするとまた騒がしくなる。
電子書籍アプリの仕事をしていたときに「遅い」とよこされるトレースは、
だいたいネットワークが切り替わるタイミングに背後でもぞもぞしている奴らのせいだった。
(歩きスマホはご遠慮ください。)</p>
<p>そんなかんじで、少なくともアプリ起動直後の CPU は割と忙しい。
沢山のアプリを行ったり来たりするヘビーユーザーならコア数が倍になってもそれなりに使える気がする。
逆に言うと long tail のアプリの起動を速くしたいなら現状だと並列化はそんなに効かない。
背後の活動に押されて起動中のアプリ自体は CPU 2-3 個ぶんくらいしか使えないから。
あと本題とは関係ないけど I/O 律速なことも多い。</p>
<h3 id="レイテンシ重視と-heterogeneous-cores">レイテンシ重視と Heterogeneous Cores</h3>
<p>Android での性能改善では起動および画面遷移の時間短縮と Jank-free すなわちコマ落ちしないことに重点がある。
実際のアプリではネットワークリクエストのレイテンシ最適化が一番大切だろうけど、それはコアの話に直接関係ないので置いておく。</p>
<p>起動ではまあまあコアを使い切れているのは先に書いたとおり。画面遷移は起動の小規模版という風情。</p>
<p>Jank はどうか。というと、レンダリングのパイプラインはそれほど並列化されてない。
もちろん「パイプライン」というくらいなのでステージへの分割は一定程度されている。
たとえばレイアウトのち描画を指示するメインスレッドと、描画の指示に従って実際に GL の API を呼ぶ RenderThread はわかれているし、
描画結果の画像を画面に合成する SurfaceFlinger も別プロセス。
画面に貼り付ける JPEG のデコードもワーカーでやる。React Native とかだとレイアウトも別スレッド。
ただこういうタスク並列には限度がある、並列化原理主義者の思い描く manycore 超並列の理想からは遠い。
しかもパイプラインが深くなるとユーザの入力から画面表示までのレイテンシが長くなる上、同期にしくじって stall とかも起きやすい。
速いコアの上で直列化されたクリティカルパスがピリっと動いてくれるに越したことはない。
ぶっちゃけ今でもだいたい UI スレッドが支配的。</p>
<p>実例として <a href="https://notes.dodgson.org/android/trace-processor/">Twitter と Instagram の UI スレッドを比較する記事</a>を前に書いたので参照されたし。
以下はスクロールしている Twitter アプリのトレースから活発なスレッドを集めた様子:</p>
<p><img src="/images/manycore-05-morrita-04.png" alt="Twitter scrolling"></p>
<p>スレッド単位に行があり、緑色の部分で実際にスレッドが走っている。一番上が UI スレッド、一番下が RenderThread で、あとはそれ以外。
わりとがんばって複数スレッド使ってるけど、UI スレッドが詰まり気味なのが見て取れる。次が RenderThread. あとはスカスカ。
別に Twitter アプリの出来が特別悪いわけではなく、Android アプリというのは普通につくるとこうなる。</p>
<p>電話機のアーキテクチャもそうした甘えた気持ちを反映している。
最新のハイエンドチップセット <a href="https://www.anandtech.com/show/16271/qualcomm-snapdragon-888-deep-dive">Snapdragon 888</a> は
すごい速い Cortex-X1 の &ldquo;prime core&rdquo; が一つ、 Cortex-A78 の &ldquo;big core&rdquo; が 3 つ、Cortex-A55 の &ldquo;little core&rdquo; が 4 つ。
これらのコアは動作クロック数も違うし、パイプラインの構成もキャッシュサイズも違う。シリコン上での専有面積も全然違う。
雑なイメージとして big と little は倍くらい性能が違う。
Prime と big も、よくわかんないけどたぶん数割は速さに差がある気がする。</p>
<p>つまり Snapdragon は 6+4 の 10 コアとかにするかわりに 1+3+4 = 8 コアの構成を選んだ。
お前ら manycore 並列化とかできないだろうから割は悪いけどクロック上げてキャッシュ積んでやんよ、みたいな。
なお iPhone は 2+4 の 6 コア。なのに速い。そういうことです。</p>
<p>ソフトウェアも過激な並列化よりでかいコアをいかす方にがんばりがち。
Android だと Linux の cpuset を使って手前のアプリ(とシステム)に<a href="https://source.android.com/devices/tech/power/performance#exclusive_core">速いコアを専有させている</a>。
がんばって並列度を上げても余っているのはしょぼいコアばかり。しかも専有できないせいで混み合ってる。
下手に並列化して CPU を使い切ってもスケジューラがコアの間でタスクをたらい回すせいでキャッシュミスして遅くなるだけ。
盛り上がらない。</p>
<p>この構成はプログラマの甘えだけが原因でなく、
電話機のように画面がある個人向けデバイスがスループットではなくレイテンシを重視しているせいでもあると思う。
サーバサイドでバッチ処理をするようなユースケースではレイテンシを犠牲にしてスループットを上げると嬉しいことも多い。
そういうトレードオフが許されるなら並列化の選択肢も増える。
でも電話機にスループットを上げたい場面、たとえば沢山のアプリを同時にレンダリングするみたいなの、あんまりない。画面も狭いし。
スループット無視のレイテンシ重視だとタイミング調整の自由度が低く、できることが限られる。</p>
<h3 id="並列化ヘビーな計算とバカパラ開拓">並列化ヘビーな計算とバカパラ開拓</h3>
<p>カメラアプリでいちばん CPU を酷使するのは起動でも画面の表示でもなく、写真の現像。
一例として <a href="https://research.google/pubs/pub45586/">HDR+ とよばれる現像アルゴリズム</a>は
複数の RAW 画像を気の利いた方法でマージするみたいな計算をする。
データ並列な画像処理を記述できる <a href="https://halide-lang.org/">Halide</a> という DSL を使うなど、CPU は全力で使う。
アクセラレータも使う。</p>
<p>ただこいつらも 8 コアを全部使ってきちんと速くなるのかというと、キャッシュとかの都合で微妙なラインっぽい。
データ並列じゃないコードパスも結構ある。
仮に 16 コアの電話機が登場しても、写真一枚の現像処理がそれを生かしきれるのかはあまり自明でない。
自分はアルゴリズムの詳細は理解せず傍からプロファイラやトレースの出力を眺めてるだけなので実情はわからないけれど。</p>
<p>一方、アプリの利用統計などからユーザはシャッターボタンを連打しがちであることが知られている。
シャッターの連打によって複数の現像処理が並列に走ると CPU は簡単に埋め尽くされる。
全てのユーザが連打をするわけではないとはいえ、
ユーザに代わって連打相当の画像を用意してあげる <a href="https://www.youtube.com/watch?v=ZgB9dhxe9hI">TopShot</a> みたいな機能は
コアが沢山あれば普通に嬉しい。今はすごい複雑なコードで無理やり実装している（のでよくバグって以下愚痴省略）ところを、
もっと素朴、富豪的、あるいははまじさんのいう「バカパラ」的に実装できるようになる。</p>
<p>これは示唆的な事例だと思う。
つまり既存の機能を並列化して増えたコアを使い切ろうとするより、
増えたコアでバカパラ的に実現できる新しい機能/UX を模索する方が有意義なのではないか。
昔からあるソフトウェアの機能というのはそんなにコアがない時代に考えられたものなわけで、並列性がなくても仕方ない。
新しいハードウェアには新しい使い方があるはずで、それを開拓した方が差別化や競争力に繋げやすいんじゃないかなあ。
決められた問題を解くのって、パズルとしては exciting かもしれないけど縛りプレイっぽいとこないですか。</p>
<h3 id="コア数増加の見通し">コア数増加の見通し</h3>
<p>ところでコア数、増えるんですかね。ありのさんは 16 コアは現実で 32 コアあるかもと言っているけれど、
モバイル機器に限るとそんなに増えないという説を自分は買っている。</p>
<p>これは<a href="https://www.amazon.com/Computer-Architecture-Quantitative-Approach-Kaufmann-dp-0128119055/dp/0128119055/">ヘネパタ</a>に書いてある文字通り教科書的な見通しで、
別にユニークな洞察ではない。
ヘネパタでは <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore&rsquo;s Law</a> が終わる前に <a href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a> が
終わってしまい困ったねという話をしている。要するに (Moore&rsquo;s Law の残りカスによって) 半導体の集積度はジリジリあがっていくが、
昔は集積度によらず単位面積あたり一定だった消費電力が (Dennard scaling がおわったせいで) 集積度が増える分だけ増えていく。</p>
<p>CPU, 電話機だと SoC は、チップは小さいままでもどんどん電力を使うようになっていく。
でも電力予算はそんなに増えないので, チップのうちごく一部の回路しか同時に使われず、大半は寝かせて節電する。
この寝ている回路を <a href="https://en.wikipedia.org/wiki/Dark_silicon">Dark silicon</a> という。
沢山の回路を同時に使いたい時は動作周波数を下げて節電する。</p>
<p>集積度アップにあわせて同一面積内の CPU のコア数を増やしかつ CPU を使い切ると、dark な部分がないため消費電力は増えてしまう。
モバイルでこれは NG. 動作周波数を下げればある程度乗り切れる (Intel の CPU は過去にそれをやった) けど、
先に書いたレイテンシ要件の厳しいモバイルで許さるだろうか。画面描画 120fps とかフレーム毎の deadline が半分になるわけで、いかにも CPU の単体性能に依存してるじゃん。</p>
<p>こういう電力の縛りがあるせいで manycore はそんなにこさそうとヘネパタは書いている。
かわりにどうするかというと、
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">TPU</a> みたいな特定用途向けのアクセラレータ
(Domain Specific Architecture) を色々積むのが良いという。
今やボトルネックは回路の集積度ではなく電力なのだから、そのぶんだぶつく回路を生かして節電しようや、みたいな話。
じっさい電話機の SoC のうち CPU が占める面積は既にだいぶ小さい。 インターネットの分析を信じるなら 1/4 未満だと思う(<a href="https://semianalysis.com/apple-a14-die-annotation-and-analysis-terrifying-implications-for-the-industry/">A14 の例</a>)
。</p>
<p>こういう流れはモバイルだけかと思っていたら、
ちょっと前に Google Cloud が <a href="https://cloud.google.com/blog/topics/systems/the-past-present-and-future-of-custom-compute-at-google">Intel から大物を引き抜いたから今後は SoC つくってくぞ</a> とアナウンスしており、サーバサイドも似たようなものなかもしれない。
(自分はクラウド部門の内情は何も知らないので誤解かもしれない。)
AWS も SoC は知らないけれど Nitro という名前で<a href="https://aws.amazon.com/ec2/nitro/">色々アクセラレータ</a>を作っている。</p>
<p>というわけで、自分は電話機やタブレットはしばらくは 8 コアで、 10 年たってもせいぜい 12 コアくらいじゃないかなとおもってます。
ラップトップも 16 コアが限度じゃないのかなあ。高い Macboook とかそのくらいあるけど、壁から電源とらないと使い物にならないよねきっと。
壁に繋ぐ計算機向けのソフトウェアは、皆様がんばってください。この文章も壁の電源で書いてますので。</p>
<p>CPU 屋でバイトしてたありのさんには釈迦に説法な気がしてけど、そんなかんじです。</p>
<h2 id="android-は-reactive-なのか">Android は Reactive なのか</h2>
<p>にわか業界通のしったかぶりみたいな話ばかり書いて心が痛んできた。
以下ではもうちょっとプログラマっぽいことも書いて detox したい。</p>
<p>Android は reactive なのか。スレッドプールに future で async でヒャッホイなのだろうか。
<a href="https://kotlinlang.org/docs/flow.html">Kotlin の Flow</a> とかあるので表面的にはそういう雰囲気だけど、個人的には信じてない・・・というか、できたらいいけど道は遠いよねと思っている。</p>
<p>Reactive な世界ではコア数にあわせてをスレッドつくると先に書いた。
現実と照らし合わせるべく先の TikTok アプリのスレッド数を数えてみる。答えを見る前に予想した数字を思い浮かべてほしい。カンでいいです。 8? 16? 32?</p>
<p>Perfetto UI の SQL コンソールから以下の SQL を実行する:</p>
<pre><code>SELECT COUNT(*), process.name
FROM thread, process
WHERE thread.upid = process.upid
  AND process.name = &quot;com.zhiliaoapp.musically&quot;
</code></pre><p>答え: Drumroll タララララララララ&hellip;&hellip;.. &hellip;&hellip; &hellip;.. &hellip;. &hellip; .. . -&gt; 255</p>
<p>これは別に TikTok が異常なわけではなく、たとえば今数えたら Twitter は 180 くらい、NYTimes は 280 くらいあった。
(補足としてとしてこれは短命スレッドも数えている。でも短命スレッドとかさ、やめろ。)
しかもサーバサイドと違ってこういうアプリが 10 とか 20 とか生きてるわけです。
いくら Linux CFS が O(1) だからって現代人としていいのかこれは。8 コアしかないんだよ?</p>
<p>この数字だけで試合終了したくなるけど、歯を食いしばり事情を説明して参ります。</p>
<h3 id="ブロッキングコールの偏在">ブロッキングコールの偏在</h3>
<p>Android, 色々なものがブロッキングコールである。</p>
<p>まず IPC の <a href="https://source.android.com/devices/architecture/hidl/binder-ipc">Binder</a>.
Android のプロセス間通信は基本ぜんぶこれです。でもね、ちょうブロックする。しかも勝手にプロセス内にスレッドプールをつくる。あなたのアプリにもこっそり binder スレッドができてます。
そしてプロセス間通信なんてそんなにないと思っているかもしれないけれど、すごい沢山ある。
たとえばちょっと画面の解像度を読もうかなと Plaform の API を呼ぶと息をするように IPC する。
これは <a href="https://chromium.googlesource.com/chromium/src/+/master/mojo/README.md">Chrome の IPC</a> が基本ぜんぶ async なのとは対照的である。</p>
<p>ただし Binder が遅いかと言われるとかならずしもそうとは言えず、
<a href="https://android.googlesource.com/kernel/common.git/+/android-3.18/drivers/staging/android/binder.c">カーネルドライバ</a>とかでいろいろ小細工していて遅くはない。
でもブロッキングが基本であることに代わりはない。<a href="https://source.android.com/devices/architecture/hidl/threading#oneway">oneway</a> という仕組みで非同期にできるが、
名前のとおり一方通行で値を返せないため使用範囲は限定的。</p>
<p>こういう platform の機能だけでなく、サードパーティのライブラリもブロックする。
Android で一番広く使われている HTTP ライブラリ <a href="https://square.github.io/okhttp/">OkHttp</a> はブロッキングである。
HTTP/2 みたいな多重化プロトコルをどうやってブロッキングで実装しているのかよくわからない(たぶんコネクション単位でスレッドがある)が、とにかくブロックする。
つまりこの上に作られている REST の data binding みたいなライブラリたちは、たとえば表面的に非同期でもスタックのどこかではブロックしている。
表面的にすら非同期でないものも多い。そんなのいくら Flow をつかってもすぐスレッドプール詰まっちゃうのでは・・・。</p>
<p>Android で動くノンブロッキングの HTTP 実装は少ない。サーバサイドのデファクトである Netty が Android をサポートしたのは <a href="https://netty.io/wiki/new-and-noteworthy-in-4.1.html">4.1 以降</a>。しかもテストはないからよろしくとか書いてある。実際に使われてるのは見たことがない。
Chrome の HTTP スタックを切り出した <a href="https://developer.android.com/guide/topics/connectivity/cronet">Cronet</a> もあり、
これは Play Services についてくるので最近はそこそこ使いやすくなった。とはいえそれなりに覚悟を要する。
<a href="https://envoy-mobile.github.io/">Envoy-Mobile</a> とかなおさら要覚悟。</p>
<p>一応ちょっとだけ擁護すると、
サーバサイドの人からするとネットワークスタックを非同期にできないなら一体何を非同期にするのか疑問に思うかもしれないけれど、まあそれなりにあります。
画像のデコードみたいな重い計算がぼちぼちあるので。あと Binder IPC は HTTP の REST call に比べると当たり前だけど圧倒的に速い。
空の呼び出しなら 1ms もしない。10us とかそういう雰囲気だった記憶。なので常に問題になるわけではない。とはいえすごく遅いものもあり、そういうのがブロックすると厳しい。</p>
<h3 id="ネイティブコードと-java-コードの混在">ネイティブコードと Java コードの混在</h3>
<p>Android はアプリは基本的に Java/Kotlin で書くが、platform の中は割と C++ が使われている。
あと最近の AI 系のライブラリや、それ以外でも C/C++ の資産を持ってきて使うことが多い。</p>
<p>最初の問題として、 C/C++ ネイティブコードは基本的に非同期とか気の利いたことしないのでブロッキングしがち。
C++ の残念さからこのスレがはじまったのを思い出してほしい。</p>
<p>スレッドプール分断の問題もある。
Java には <a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Executor.html"><code>Executor</code></a> や
<a href="https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ScheduledExecutorService.html"><code>ScheduledExecutorService</code></a> という
標準スレッドプール API があるのでこれを使うことが多い。しかしこれは pure Java なので C/C++ から使えない。
結果として C/C++ レイヤと Java レイヤで別々にスレッドプールをつくるという無駄が生まれる。</p>
<p>Kotlin や RxJava などにも似た問題があり、こいつらは Java 標準とは別のスレッドプール API を持っている。
がんばれば interop できるけど、現実的には誰も頑張らない。こうしてまた別のスレッドプールが作られる。</p>
<h3 id="conways-law-of-thread-pool">Conway&rsquo;s Law of Thread Pool</h3>
<p>先の RxJava  / Kotlin の独自 thread pool API は、より大きな問題の一角でしかない。
より大きな問題: いくつものサードパーティライブラリたちがみな勝手に自分のスレッドプールを作る。
しかもそれぞれが何も考えず CPU のコア数だけスレッドを作ったりする。
CPU は! お前らだけのものじゃ!! ないんだぞ!!! わかってんのか!!!!
ライブラリは <code>Executor</code> なりその factory なりを外からさせるようにしてほしい。ほんとに。</p>
<p>これがサードパーティのライブラリだけならまだいいが、同一組織内でもスレッドプールを統一できてないケースがあり、
というかわたくしめのところでございますが、よく性能部門の監査人に怒られてる。俺のせいじゃねー。</p>
<p>先に挙げたブロッキングコールの偏在がこの解決を難しくしている: みな自分のスレッドプールを詰まらせたくない。
だから得体のしれない他人とスレッドプールを共有したがらない。基盤の不在による信頼の欠如。つらい。
ブロッキングコールが詰まる心配は杞憂ともいえず、森田はこれまでに二回 binder を介したデッドロックを報告のうえ直してもらったことがある。
どちらのケースもプールから余剰スレッドが枯渇していた。</p>
<h3 id="handler">Handler</h3>
<p>Android platform の API はなにかと <a href="https://developer.android.com/reference/android/os/Handler"><code>Handler</code></a> オブジェクトを要求する。
<code>Handler</code> というのはイベントループの抽象である。イベントループというのはスレッドプールのシングルスレッド版である(語弊あり)。
だからある意味で <code>Handler</code> は <code>Executor</code> みたいなものだと言える。
でもスレッドは一つだけ。そのせいで N スレッドを M (&gt;N) クライアントで共有するのがやりにくい。結果として人々は自分のコードでこっそり
<a href="https://developer.android.com/reference/android/os/HandlerThread"><code>HandlerThread</code></a> をつくったりしがち。
オレオレスレッドつくるのやめてくれませんかね・・・。</p>
<h3 id="platform-の雑さ">Platform の雑さ</h3>
<p>Platform の API を呼ぶと勝手に短命スレッドを作ることがよくある。なぜかというと昔からあるコードの実装が雑だからである。
Sigh.</p>
<h2 id="road-ahead">Road Ahead</h2>
<p>こういうのほんとなんとかしてほしいんだけど、今の所なんともなってない。</p>
<p>他人の実装は気にせず自分の書くコードでは Kotlin Flow なりなんなりをつかって小奇麗に書き、
それで満足しておくのは一つの態度だと思う。たぶんその方が精神衛生に良い。
でも自分はトレースをじっとみつめるお仕事をしている都合で、ランタイムの不都合な現実から文字通り目を逸らせない。
なのでいらないスレッドをちまちま削る泥臭い仕事を、精神衛生とのバランスを鑑みつつしたりしなかったりしている。</p>
<p>かずよしさんはそういうのはプログラマが頑張る<a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/">のではなく</a>ランタイムに任せたほうがいいという。
でも Android は Go 言語じゃないからねえ・・・とかおもっていたら、
長期的には Android の問題も Go 的に解決されるかもしれないとおもわせるニュースがいくつかあった。</p>
<p>一つは Java の <a href="https://blogs.oracle.com/javamagazine/going-inside-javas-project-loom-and-virtual-threads">Project Loom</a>:
Java のスレッドを Go の軽量スレッド (fiber) みたいにしようという実験的なプロジェクトを Oracle が開発している。
実験的すぎて OpenJDK にマージすらされておらず、そもそも Android の Java は OpenJDK ではなく別実装の ART なので
Android ART のスレッドが fiber になる日がくる見込みはそんなにないが、Java エコシステムがそっちに舵を切ったら逆らえない気もして、
長い目で淡い期待を抱いている。</p>
<p>もう一つは <a href="https://www.scs.stanford.edu/~dm/blog/c++-coroutines.html">C++20 の coroutine</a>。
Project Loom みたいなことが C++ にもおこる・・・というと雑すぎるけど Folly Future みたいのは諦めてユーザ空間に軽量な
coopretive context switch を入れる。レガシー人材/コードの reactive 化という点で現実的かもしれない。</p>
<p>どちらも先の話なのですぐさま影響はないけれど、人類に async は早すぎたのかもと自分の中の reactive 信仰をみつめなおすきっかけにはなった。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
<p>このトレースはガーンと殴られた感じというか、自分の認識のずれを恥じる感じでした……！こんなにちゃんとマルチコア使ってるんですねえ。表に出てるアプリ以外のサービスやらなんやらもなんかやってるのはわかるんですが、こんなに見えるほど CPU 時間使っているのですね。 Perfetto 僕たちも使ってるんですが、こっちのはシンプルではるかに読みやすいですね</p>
<p>Snapdragon は 855 から 1+3+4 の3段階構成で、 Pixel 4 とかも使っていて、ある程度の歴史があると思うんですが、なんかアプリ側でも明示的な使いわけをしている感じなのですかね？システムで affinity を調整するのはなるほどやはりそういうことするのね、という感じだったのですが、カメラアプリ的には特有の処理とかあるのかな？とか気になりました</p>
<blockquote>
<p>スケジューラがコアの間でタスクをたらい回す</p>
</blockquote>
<p>これ、数年前に<a href="https://github.com/google/kati/pull/112#issuecomment-282195635">linux kernel は意味もなく違う NUMA ノードに動かすけど Mac は動かないなあ</a>、と思った記憶があります。今もそうなんですねえ</p>
<p>単なる感想文ですが、この文章は全体的に、とても楽しく読んだ文章でした。やっぱ並列は楽しいトピックですねえ。</p>
<blockquote>
<p>増えたコアでバカパラ的に実現できる新しい機能/UX を模索する方が有意義なのではないか</p>
</blockquote>
<p>とかとても良いと思いました。なんかあるかなあ</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>これは大量にコメントつけたくなるような面白い話が山盛りですねぇ。ぐっとこらえてタブレット周りの話だけ。</p>
<p>iPadはGarage BandやPhotoshopといったアプリがiPad上でも既にかなりヘビーに使われている。
一方でスマホの方でCPUインテンシブな作業というのは、、、ゲームくらい？そんなには無い気もする。
すると「スマホでもコアを使い切ってパワフルなアプリを！」とはならないかも？</p>
<p>でもそれだと、シングルスレッド性能を上げる方はそんなに先は無いので、新機種の新しさを見せるのはだんだん難しくなりそうだけど。<a href="https://android-developers.googleblog.com/2017/05/here-comes-treble-modular-base-for.html">プロジェクトTreble</a>みたいなのは既に難しくなっている事の裏返し…という訳でも無いか。
そもそも自分のスマホはギャラノ3で4コア、LinageOS入れて使っていて、もう一年くらいこれでいいかなぁ、と思っているので、既に自分は新機種の新しさをあまり感じてないのかもしれない。</p>
<p>Androidも、大きな画面のタブレットではCPUインテンシブな作業をいろいろやる方向に行くのが自然と思うのだけど、Androidタブレットのためだけにプロフェッショナルユースなアプリを作る気になるか？というのは問題としてあるかもしれない。
Macbookに対応するものがなんか無いと。
Chrome Bookはハイエンド路線では無いし、プロフェッショナルユースとしてCPUインテンシブなアプリが使われている訳では無い。
まぁタブレットとハイエンドノートPCはAppleに譲ってAndroidはAppleとは違うタブレットの道を模索すれば良いのかもしれない。
KotlinとJetpackComposeでバリバリアプリ書けるクールなノートPC環境出たら面白いとは思うけれど（流行らせるのは難しいだろうけれど）。</p>
<p>以上から、自分はiPadのコアは増えると予想する。Androidのコアは分からない。数年後にこのエントリを見直してどう思うか、楽しみですね。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
<p>AWS だと機械学習専用チップに <a href="https://aws.amazon.com/machine-learning/inferentia/">AWS Inferentia</a> と <a href="https://aws.amazon.com/machine-learning/trainium/">AWS Trainium</a> というのがありますね。しかし Android 荒野すぎる&hellip;。</p>
<blockquote>
<p>ライブラリは Executor なりその factory なりを外からさせるようにしてほしい。ほんとに。</p>
</blockquote>
<p>サーバーだと、<a href="https://logging.apache.org/log4j/2.x/manual/thread-context.html">MDC</a> にリクエスト ID とかいれて取り回しているのが、ライブラリの中に隠れている ExecutorService を通ると消えてしまって、それで困った記憶があります。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>shinh: Perfetto 使ってるんですか。Perfetto チームの人に教えてあげると大変喜ぶとおもうので、ぜひブログの一つも書いてあげてください。
データが見やすいのは、ひとつはアクセラレータの情報が全然ないからかもしれないですね。GPU とか HVX とか見えてほしいんだけど。</p>
<p>アプリのレイヤで CPU を選ぶことはしてないです。考えたことはありますが、OS の中の人に「やめろ」と釘を刺されました。
まあアプリ全体を固めてしまうリスクとかもあるので Android として公式にサポートしてもらえるまでは遠慮するとおもいます。</p>
<p>karino2: 自分がコア数が増えないと思うのはユースケースよりフォームファクターに依存する電力予算の上限が理由です。
ああかつての Intel のように Apple も資本主義の力で物理法則を歪めアカデミアの予想を打ち破る可能性は、あるかもですね。
<a href="https://anemone.dodgson.org/2019/09/14/how-its-been-ending-1/">前に書いたブログ</a> をみると、
Intel Macbook は 2006 年に 2 コア (4HT), 2019 年に 8 コア (16HT) だから 13 年で x4. だたしフォームファクタも 13 から 16 インチに増えてる。
M1 Macbook は <a href="https://www.macworld.co.uk/news/m1x-mac-3801943/">M1X というチップで 12 コアになる</a> という噂記事がありました。</p>
<p>kzys: Executor を挟むと trace とかの propagation が消えてしまうの、サーバサイドあるあるっぽい良い話。
Java は伝統的にはブロッキング言語だというのをよく伝える事例だと思います。その点 JavaScript は偉かった。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>再利用の 15 年くらい</title>
      <link>https://messagepassing.github.io/014-reuse/03-morrita/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/014-reuse/03-morrita/</guid>
      <description>ソフトウェアの再利用が難しい・・・というか難しかったというのは歴史的には事実で, たとえば ICSR / International Conference on Software Reuse とかいう学会がある。 どんな論文が書かれていたのか検索すると 2005 年の Software Reuse Research: Status and Future という論文が 950 citation くらい。もっと引用されている同系統の論文もないではないけど古すぎるので割愛し、 この論文をざっと眺めてみると・・・そういうのあったわーという単語がいっぱい出てくる。COM とかね。 (知らない人向けに補足すると COM というのは C++ で Java みたいなことをしたくて色々苦し紛れにがんばったテクノロジだとご理解ください。）
この頃のソフトウェア再利用、色々厳しい雰囲気が論文をチラ見するだけで伝わってくる。 今から考えるとムリっぽい暗黙の前提があると思う。三つくらいに分けて雑に整理してみたい。
ひとつ目の前提: ソースコードが非公開。 この頃はまだコードは出さないのが普通。
コードが見られなかったらそりゃ再利用大変でしょ。 エラーがおきても原因を調べられないし、ワークアラウンドもできないじゃん。
しかも形態が共有ライブラリだったりする。HTTP でプロセス境界を切ったりしない。 いちおう分散コンピューティングはあったが EJB とか CORBA とか DCOM とかの分散オブジェクトがマインドシェアを持っていた。 こいつらはマジ密結合で厳しく、SOAP だなんだと退化して結局 REST くらいに落ち着いたのを我々は事後的に知っている。
ふたつ目の前提: 再利用に課金したい。 ソフトウェア、仕事で書いてるので再利用したらちゃんと現金で対価をで払ってほしいと思っていた。
でもね、ライブラリでカネとるとか相当大変。現代でも数少ない例外を除き基本的にはできていない。 金をとりたいからひとつ目のソースコード非公開が必要なのだけれど、 使う側からするとそんなブラックボックスにわざわざ金払ってロックインされたくない。悪循環。 (じっさい成功しているライブラリ業者はソースコードも提供していることが多い。)
しかも昔はライブラリを作る側も使う側もソフトウェアのリリース・デプロイが頻繁じゃなかったので、 課金も subscription based ではなく買い切りだった。なので質が高いほど継続的な集金が難しい。 純粋な技術的障壁だけでなく、ビジネスモデルが辛い。
みっつ目の前提: 方法論があればなんとかなる。 2000 年代前半って、ソフトウェア工学といえばプロセス、開発方法論というような雰囲気があった(例: RUP)。 方法論というとちょっと限定的すぎで、たとえば形式化手法とか標準化とか、そういうやつね。 良い方法論と、そのためのツールを整備すれば再利用含め色々なことが上手くいく・・・といいな・・・と人々は期待していた。 先の論文でも chapter 6 によくわかんない methodology が列挙されている。(著者のバイアスな気もするが・・・)</description>
      <content:encoded><![CDATA[<p>ソフトウェアの再利用が難しい・・・というか難しかったというのは歴史的には事実で,
たとえば <a href="https://dblp.org/db/conf/icsr/index.html">ICSR / International Conference on Software Reuse</a> とかいう学会がある。
どんな論文が書かれていたのか検索すると 2005 年の <a href="https://scholar.google.com/scholar?cluster=16619599721629954424&amp;hl=en&amp;as_sdt=2005&amp;sciodt=0,5">Software Reuse Research: Status and Future</a>
という論文が 950 citation くらい。もっと引用されている同系統の論文も<a href="https://scholar.google.com/scholar?q=software+reuse">ないではない</a>けど古すぎるので割愛し、
この論文をざっと眺めてみると・・・そういうのあったわーという単語がいっぱい出てくる。<a href="https://docs.microsoft.com/en-us/windows/win32/com/component-object-model--com--portal">COM</a> とかね。
(知らない人向けに補足すると COM というのは C++ で Java みたいなことをしたくて色々苦し紛れにがんばったテクノロジだとご理解ください。）</p>
<p>この頃のソフトウェア再利用、色々厳しい雰囲気が論文をチラ見するだけで伝わってくる。
今から考えるとムリっぽい暗黙の前提があると思う。三つくらいに分けて雑に整理してみたい。</p>
<h2 id="ひとつ目の前提-ソースコードが非公開">ひとつ目の前提: ソースコードが非公開。</h2>
<p>この頃はまだコードは出さないのが普通。</p>
<p>コードが見られなかったらそりゃ再利用大変でしょ。
エラーがおきても原因を調べられないし、ワークアラウンドもできないじゃん。</p>
<p>しかも形態が共有ライブラリだったりする。HTTP でプロセス境界を切ったりしない。
いちおう分散コンピューティングはあったが EJB とか CORBA とか DCOM とかの分散オブジェクトがマインドシェアを持っていた。
こいつらはマジ密結合で厳しく、SOAP だなんだと退化して結局 REST くらいに落ち着いたのを我々は事後的に知っている。</p>
<h2 id="ふたつ目の前提-再利用に課金したい">ふたつ目の前提: 再利用に課金したい。</h2>
<p>ソフトウェア、仕事で書いてるので再利用したらちゃんと現金で対価をで払ってほしいと思っていた。</p>
<p>でもね、ライブラリでカネとるとか相当大変。現代でも数少ない例外を除き基本的にはできていない。
金をとりたいからひとつ目のソースコード非公開が必要なのだけれど、
使う側からするとそんなブラックボックスにわざわざ金払ってロックインされたくない。悪循環。
(じっさい成功しているライブラリ業者はソースコードも提供していることが多い。)</p>
<p>しかも昔はライブラリを作る側も使う側もソフトウェアのリリース・デプロイが頻繁じゃなかったので、
課金も subscription based ではなく買い切りだった。なので質が高いほど継続的な集金が難しい。
純粋な技術的障壁だけでなく、ビジネスモデルが辛い。</p>
<h2 id="みっつ目の前提-方法論があればなんとかなる">みっつ目の前提: 方法論があればなんとかなる。</h2>
<p>2000 年代前半って、ソフトウェア工学といえばプロセス、開発方法論というような雰囲気があった(例: <a href="https://en.wikipedia.org/wiki/Rational_Unified_Process">RUP</a>)。
方法論というとちょっと限定的すぎで、たとえば形式化手法とか標準化とか、そういうやつね。
良い方法論と、そのためのツールを整備すれば再利用含め色々なことが上手くいく・・・といいな・・・と人々は期待していた。
先の論文でも chapter 6 によくわかんない methodology が列挙されている。(著者のバイアスな気もするが・・・)</p>
<p>しかしなかなかヒット作は生まれなかった。
Scrum とか良くも悪くもヒット作だけど、ソフトウェアの再利用は助けてくれそうにない。</p>
<h2 id="オープンソースの台頭">オープンソースの台頭</h2>
<p>こういう問題を解決したのがオープンソースである。
というか先の ICSR 論文が書かれた 2005 年の時点で UNIX の上ではオープンソースの C 言語のライブラリが割と再利用されたいた。
C 言語での再利用、現代の水準からみると大したことなく見えるけれど、C という言語の圧倒的しょぼさを考えるとめちゃ再利用されている。</p>
<p>オープンソースは先に書いたような伝統的再利用願望に潜む前提をぜんぶひっくりかえしている。</p>
<p>まず by definition でソースコードにアクセスできる。
だからドキュメントが多少しょぼくてもなんとかなるし、手元で自分の都合にあわせて直すことも、やりたくはないができる。</p>
<p>課金も、基本的にはしない。
オープンソースのソフトウェアを売って仕事にしようという個人/企業は Red Hat をはじめ今も昔も一定数いるけれど、
総体としてはオープンソース開発者のうちコードから直接の収益を挙げているのは少数派だと思う。
それでも色々な時代の力でコードが書かれ、使われている。</p>
<p>C 言語の再利用はさすがにだいぶ原始的で厳しかった。
でもかずよしさんのいうように後発のモダン言語では CPAN のようなパッケージマネージャが当たり前になり、
ソースコードあり・基本無料というオープンソースの強さをひきだすインフラができた。</p>
<p>しばらくは「ライブラリの再利用はできてもフレームワークは難しいですよね」とか言う人もいたが、
Rails を皮切りに何をするにもまずはフレームワーク探しから、みたいに風向きが変わった。
ウェブ以外ではここまで極端じゃないけれど、そうはいってもフレームワークだって再利用できるよね。コードが読めれば。</p>
<h3 id="github-の台頭">GitHub の台頭</h3>
<p>オープンソースすばらしいけど現実には報酬がないと続かないですよね <a href="https://www.amazon.com/Just-Fun-Story-Accidental-Revolutionary/dp/0066620732">just for fun</a> とはいえ・・・という問題も、段階的に解消された。</p>
<p>一つの解決は、企業が <a href="https://www.gwern.net/Complement">補完材をコモディティ化</a> するためにオープンソースをやる事例。
つまりハードウェア企業がそのハードウェアを上手に使うためのソフトウェアをオープンソースにするだとか、
広告企業がトラフィックの入り口をオープンソースにするとか、
広く使ってもらうことで間接的に利益があるソフトウェアをオープンソースで開発する企業が現れた。
もともとは草の根だったプロジェクトも、それを補完材にできる企業がスポンサーしてくれたりする。
これがゼロ年代。</p>
<p>もう一つの解決は、プログラマや企業の名声をオープンソースに紐付けること。
つまりオープンソースで書いたソフトウェアが有名になれば開発者の実力は広く知れ渡り、
会社員やフリーランスであれば雇用や契約につながるし、企業であればプログラマ採用の糧になる。</p>
<p>名声や関心をソフトウェアの対価にするこうした流れはゼロ年代から少しはあったけれど、
2010 年代以降 GitHub によって大きく後押しされた。
今では GitHub のアカウントがレジュメにないとかっこ悪いみたいな水準に至っている。
(なお森田の GitHub は今年に入ってからちょっと緑っぽくなってきたけどぜんぶ Message Passing なのだった。プログラマとしての成果ゼロ。リクルータよ騙されるな！)</p>
<h2 id="クラウドの台頭">クラウドの台頭</h2>
<p>オープンソース以外にもソフトウェアの再利用を推し進めたものがある。それはクラウド。
クラウド、最初は VM やストレージなど仮想化されたハードウェアを貸し出すビジネスという触れ込みで始まった。
人々はハードウェアに金を払うのは当たり前だと思っているので、
本来なら一括で大金を払わないと買えないハードウェアを従量課金で借りられるクラウドには大喜びで金を払った。</p>
<p>その後クラウド業者は VM やストレージのように比較的プリミティブな部品の上に段々と付加価値のあるサービスを積み増して行った。
今はもうサーバーレスとか言ってる。
(このレイヤリングが圧倒的に見事な AWS については <a href="https://queue.acm.org/detail.cfm?id=3434573">CTO のありがたいお言葉</a>を読んでみんなで感心しよう。)</p>
<p>ソフトウェアの再利用という視点で見ると、
クラウド業者は再利用可能なソフトウェアをハードウェアと抱き合わせて売ることに成功した。
純粋なソフトウェアには金を払わない人々も、ハードウェアと抱き合わせるとそれなりに納得して買ってくれる。
しかも買い切りじゃなくて毎月金を払ってくれる。</p>
<p>クラウドにはハードウェアだけでなく運用もついてくる。
というか現代的な価値観だとクラウドからは運用を買っている感覚のほうが強い気がする。
ソフトウェアやシステムの運用は昔から重要ではあったけれど、
ほぼ全てのソフトウェアに運用が伴うようになったのはインターネット以降。
だから「再利用可能なソフトウェアと運用を抱き合わせて売る」というモデルも、それなりに新しい現象だと言える。</p>
<p>そして運用が必要で再利用可能なソフトウェア、いわゆるインフラのソフトウェアはライブラリでもフレームワークでもないことが多い。
データベース&hellip;は昔からあるとして、CI, CDN, キュー、Functions&hellip;
これらを「再利用する」感覚は、2005 年にはそんなになかったんじゃないかな。</p>
<p>冒頭の残念な三つの前提に立ち戻ると、クラウドは主に三個目の前提「方法論がなんとかしてくれる」に答えをくれた。
必要だったのは形式化手法でも標準でもなく、売る側も買う側もソフトウェアをインターネットに載せることだった。</p>
<p>まあインターネットは技術標準なので TCP/IP/HTTP/TLS/JSON が偉かったと言ってもそんなに間違ってはいないかもしれない。</p>
<h2 id="積み残し">積み残し</h2>
<p>こうしてみると、ソフトウェア開発は随分遠くまで来たなと思う。
「ソフトウェアは再利用できない」とはもう誰も思ってないからね。</p>
<p>もちろん再利用が常に簡単とは言えず、
たとばバージョニングのような構成管理の問題もあるし、
クラウド業者へのロックインも場合によっては気になる。
オープンソースプロジェクトの持続可能性はいつだって心配。</p>
<p>とはいえもう時代が逆戻りするとも思えない。
15 年後に振り返って「いやー当時は他人のコードに依存しすぎだったねワッハッハ」とか言うこと、なさそうだよねえ。</p>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
RUP といえば、最近に読んだ <a href="https://buttondown.email/hillelwayne/archive/why-uml-really-died">Why UML &ldquo;Really&rdquo; Died</a> が面白かったので、そちらもどうぞ。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>なんとかなってる</title>
      <link>https://messagepassing.github.io/012-manycore/04-shinh/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/04-shinh/</guid>
      <description>たぶん WebKit のミーティングに行った時に、 GPU rendering のトピックがとても盛り上がっていて、 morita さんが「GPUとか「ちょっとオレも一言言わせろ」って感じで盛り上がっちゃうテーマだよね」と言っていて、不思議なくらいなるほどーと思った記憶があります。何が言いたいかというと、並列とかそういうテーマですよね、と。ということで、一言というか、色々と言いたいことがあるのです。
バカパラサイコーという話 Embarassingly parallel をバカパラと訳したの、どなたが考えたのか知らないけど、とても好き。ほぼ独立したタスク群であれば自明にコアを使い切れるし、その数だけ速度がスケールする、という話。 MapReduce の mapper 、ピクセルシェーダ、並列ビルド、深層学習モデルのデータパラレルもそう。普通同じタスクが違うデータに対して動く時にバカパラと言う気もするけど、独立しているから並列化可能、という意味で並列ビルドも同じ箱に入れて考えている。 kzys さんの話しているようなクラウドのケースも、そもそも物理 CPU を切り売りしていて、コンテナごとに完全に独立なので、これも僕はバカパラ、くらいの認識でいる。
プログラムもとても簡単。プロセス並列でいいなら shell script で
for i in `seq 10`; do ./my_command $i &amp;amp; done wait とかで十分だし、 OpenMP 使うなら #pragma omp parallel つければいいし、適当なスレッドプールを使うのも、自分で作るのも、そんなに難しくない。
並列プログラムは難しい、でもなんとかなってる気がする バカパラ以外のケースは、並列 reduce などのよく知られたケースを除くと、なかなか大変なことが多いように思う。特に個々に別々の役割を持ったスレッド・プロセスが協調して動いてるようなやつ。サーバサイドだと、フロントエンドのリクエストを受けて、バックエンドにリクエスト投げたりキャッシュしたりゴチャゴチャやってからレスポンスを返す、ミドルエンド的なやつが大変だった記憶がある（例）。あとは Chrome もなんだかたくさんプロセスもスレッドもあって、大変なところはとても大変な印象だった。 Chrome はブラウザというよりはユーザランドで動いてるマイクロカーネルという認識をしているので、カーネルとかもそうなんだろうなーと思っている。
ここで言う大変というのはバグっていないプログラムを書くのが大変ということで、この手のスレッドプログラミングは、書くのもレビューするのもデバッグするのも難しい。ただ、難しいんだけど、個人的には人類はなんとかなりそうな道具を揃えられたんじゃないかな、と思っている。
morita さんや karino2 さんが紹介していた Future/Promise や、 Go のチャンネルのように、 mutex のような古いプリミティブよりバグりにくい、新しい抽象が出てきたのがひとつ。 Rust のように型レベルでスレッドのバグをコンパイルタイム時に検出する言語もあるし、よく使うロックフリーデータ構造とかのライブラリも整ってきているので、難しい atomic op を直接使う理由はあまり無いと思う。あと何より、その手のものを一切使ってなくても、 ThreadSanitizer が割とバグを見つけてくれる。余談だけど、 sanitizer の類は C++ という言語の寿命を延命させているように感じている。</description>
      <content:encoded><![CDATA[<p>たぶん WebKit のミーティングに行った時に、 GPU rendering のトピックがとても盛り上がっていて、 morita さんが「GPUとか「ちょっとオレも一言言わせろ」って感じで盛り上がっちゃうテーマだよね」と言っていて、不思議なくらいなるほどーと思った記憶があります。何が言いたいかというと、並列とかそういうテーマですよね、と。ということで、一言というか、色々と言いたいことがあるのです。</p>
<h2 id="バカパラサイコーという話">バカパラサイコーという話</h2>
<p><a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">Embarassingly parallel</a> をバカパラと訳したの、どなたが考えたのか知らないけど、とても好き。ほぼ独立したタスク群であれば自明にコアを使い切れるし、その数だけ速度がスケールする、という話。 MapReduce の mapper 、ピクセルシェーダ、並列ビルド、深層学習モデルのデータパラレルもそう。普通同じタスクが違うデータに対して動く時にバカパラと言う気もするけど、独立しているから並列化可能、という意味で並列ビルドも同じ箱に入れて考えている。 kzys さんの話しているようなクラウドのケースも、そもそも物理 CPU を切り売りしていて、コンテナごとに完全に独立なので、これも僕はバカパラ、くらいの認識でいる。</p>
<p>プログラムもとても簡単。プロセス並列でいいなら shell script で</p>
<pre><code>for i in `seq 10`; do
  ./my_command $i &amp;
done
wait
</code></pre><p>とかで十分だし、 OpenMP 使うなら <code>#pragma omp parallel</code> つければいいし、適当なスレッドプールを使うのも、自分で作るのも、そんなに難しくない。</p>
<h2 id="並列プログラムは難しいでもなんとかなってる気がする">並列プログラムは難しい、でもなんとかなってる気がする</h2>
<p>バカパラ以外のケースは、並列 reduce などのよく知られたケースを除くと、なかなか大変なことが多いように思う。特に個々に別々の役割を持ったスレッド・プロセスが協調して動いてるようなやつ。サーバサイドだと、フロントエンドのリクエストを受けて、バックエンドにリクエスト投げたりキャッシュしたりゴチャゴチャやってからレスポンスを返す、ミドルエンド的なやつが大変だった記憶がある（<a href="https://chromium.googlesource.com/infra/goma/client/+/refs/heads/master/client/threadpool_http_server.cc">例</a>）。あとは Chrome もなんだかたくさんプロセスもスレッドもあって、大変なところはとても大変な印象だった。 Chrome はブラウザというよりはユーザランドで動いてるマイクロカーネルという認識をしているので、カーネルとかもそうなんだろうなーと思っている。</p>
<p>ここで言う大変というのはバグっていないプログラムを書くのが大変ということで、この手のスレッドプログラミングは、書くのもレビューするのもデバッグするのも難しい。ただ、難しいんだけど、個人的には人類はなんとかなりそうな道具を揃えられたんじゃないかな、と思っている。</p>
<p>morita さんや karino2 さんが紹介していた Future/Promise や、 Go のチャンネルのように、 mutex のような古いプリミティブよりバグりにくい、新しい抽象が出てきたのがひとつ。 Rust のように型レベルでスレッドのバグをコンパイルタイム時に検出する言語もあるし、よく使うロックフリーデータ構造とかのライブラリも整ってきているので、難しい atomic op を直接使う理由はあまり無いと思う。あと何より、その手のものを一切使ってなくても、 <a href="https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/35604.pdf">ThreadSanitizer</a> が割とバグを見つけてくれる。余談だけど、 <a href="https://github.com/google/sanitizers">sanitizer の類</a>は C++ という言語の寿命を延命させているように感じている。</p>
<h2 id="苦労して書いたコードがスケールしない悲しさ">苦労して書いたコードがスケールしない悲しさ</h2>
<p>ただ、それがスケールするかというと、別の話。別々の役割を持ったスレッドがたくさんあるようなプログラムは、理想的な状況でも役割の数以上にコアを使うことはない。クラウドだったら kzys さんのおっしゃる通り、確保する論理コアの数を必要な数程度に減らせばいいだけと思っているけど、クライアントサイドのプログラムでは、 karino2 さんの問題意識のように、単にコアを使いこなせてない、という状況になってしまう。</p>
<p>実際、これは既に起きている問題だと思っている。ハイエンドスマホのコア数が 8 とか越えたのは、もう5年以上前だと思うけど、その後はずっと横這いだと思う。バカパラな用途があるハイエンドはともかく、ミドルエンド PC のコア数もそんなに増えていないと思う。アプリケーションが使わないから、リソースを他に回していると理解している。スマホのコア数競争の当事者であった Qualcomm の人が<a href="https://www.phonearena.com/news/Off-the-record-Qualcomm-sees-octa-core-chips-as-meaningless-marketing-play-committed-to-fewer-cores_id75804">「コア数増やすのって単に広告競争で、意味ないよねー」と言っていた</a>、という話もある。一方で最初から用途がバカパラのアクセラレータは際限なくコア数を増やしていっている。</p>
<p>コアを使い切れていない時にどうすれば良いかというと、今シングルスレッドで動いている部分にバカパラ並列性を見出せるとてっとり早い。ただ、これができるなら既にやられているはずで、難しいから、意味がないからまだやられていないという可能性も高い。例としてコンパイラを考えてみると、パースに文脈依存がない言語であれば、ここは割と並列化できそうな気がするけど、その後の意味解析などはかなり難しそうだ。シングルスレッドの部分が残るのであれば、そこが律速するので部分的に並列化するうまみは少ない。</p>
<p>別のアイデアとして、細粒度マルチタスクのようなものも考えられる。タスクの依存関係を実行していく、 make みたいなやつってすごくうまく並列化できるので、プロセス内に細かいタスクを大量に作って、依存が解決されたものからスレッドプールに投げ込めば綺麗に並列性を使い切れるのでは、という考えかた。これは頭で考えると、とてもうまくいきそうな気がするんだけど、実際にはあまりうまくいかないことが多いと思う。というのは、タスクを細かく切りすぎると、同期のコストが高くなるのと、データを別のコアに転送するコストがどうしても高くなってしまう。</p>
<h2 id="メニーコア時代到来ってずっと言ってる気がするよね">メニーコア時代到来！ってずっと言ってる気がするよね</h2>
<p>同期の方はさまざまな工夫で減らす余地があるのだけど、高速化したいプログラムって本質的にたくさんのデータを扱うものが多いわけで、 NUMA ノードを越えてデータを運ぶ方が計算そのものより時間がかかる、というケースは多い。僕個人としても、複数のスレッドがそれなりに忙しく動いているプログラムにも関わらず、 <code>taskset -c 0</code> で一つのコアにはりつけた方が速かった、とか、フェーズが複数あるプログラムの各フェーズを別スレッドにしてパイプラインにしてもたいして速くならなかった、みたいな経験はちょくちょくある。</p>
<p>コア数が増えた時に遠いメモリが遅くなるのは、これは物理的にどうしようもない問題だと思うので（この世界に空間が5次元くらいあったらだいぶ伸びしろが残るんだろうけどなあ、とか考えるのは楽しい）、バカパラから遠い並列プログラムはメニーコアを使い切るのは不可能だし、今後コアが増えるとするとますます余っていくと思っている。例えば、ブラウザが 100 コアを効率良く使う未来を僕は想像できない。</p>
<p>というわけで、この世にはバカパラで高速化できるアプリケーションと、あまりたくさんコアを使えないアプリケーションがあり、それに応じてコア数も二極化するんじゃないかな、と思っている。なんかメニーコア時代とか10年以上言ってるわりにはご家庭のコア数は増えてなくて、既にそうなっている気もするけど。なんにでも深層学習が使われている、みたいな状況になると少しは変わるかもしれないけど……なんかそれは CPU よりはアクセラレータにやらせる流れだとは思うし。</p>
<p><a href="https://www.computerworld.com/article/2534312/the--640k--quote-won-t-go-away----but-did-gates-really-say-it-.html">ビルゲイツが「メインメモリは 640kB で十分だよ」と言った話</a>のように、 8 コアもあれば十分と言ってたアホがいる、と笑い話になるかもしれないけどね。</p>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>8コアになったのは最近なのでは？と言ったら、<a href="https://www.itmedia.co.jp/mobile/articles/1502/04/news059.html">snapdragon 810は2015年だ</a>と教えてもらった。
モバイルと一口にいってもiPad ProとAndroidのスマホでは大分状況は違うのかもしれないけれど、
でもAndroidのスマホだってコア使い切る方がいいような気もするなぁ。
自分はAndroidの8コア端末、未だに持っていないのだけれど。</p>
<p>メニーコアが来る来る詐欺（？）というかずっと言っているのは自分もそう思っているのだけれど、
一方で本当に自分が困ったのは去年が初めてなので、
5年前と今では大分状況は変わってきた気はする。</p>
<p>在野のアプリ屋としてはアクセラレータよりは自由に使えるコアが増えて欲しいなぁ、と思うのだけれど、
iPad Proが16、32コアと増やしてくか、それともシリコンの面積をアクセラレータ系に割いていくだけでコアは増やさないのか、興味深い所ですね。自分はコアを増やすと思っているが、それほど自信は無い。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>意識したことない</title>
      <link>https://messagepassing.github.io/012-manycore/03-kzys/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/03-kzys/</guid>
      <description>私はあんまりコアを意識したことないなあ。
これは、どのくらい CPU がボトルネックになる処理を行うかという、ソフトウェアの中身によるところと、karino2 さんが作っているような、デスクトップやモバイルで前面に出てくるようなソフトウェアと、私が作っているような、いわゆるサーバーサイドかつクラウド上のソフトウェアという環境の違いからきているところがあると思う。
まず、ソフトウェアの中身として、ネットワークのどこかにあるサービスをコールをして、その結果を待つようなものだと、そこまで CPU がボトルネックになるようなことはない。
それに加えて、
 リクエストは並列にやってくるし、リクエストの間で共有しつつ書き換えるデータはそこまでないので、1リクエストでたくさんのコアを使い切らなくても、他のリクエストが使ってくれる (はず)。 新しい世代の XL なインスタンス、例えば t3.xlarge や t4g.xlarge でも4コアしかないので、そもそも8コアも存在しない。デスクトップ/モバイルと違って、サーバーのスペックは自分で選ぶものなので、コアを使いきれなかったら安いインスタンスに変えても良い。 AZ (availability zone) 単位の障害に statically stable に対応するために、サーバーの処理能力はは 1AZ が消失してもなんとかなるように余裕をもって用意する。全部のコアを文字通り 100% 使っていると負荷が高すぎ。  という理由で、頼んでもいないのに8コア来た! 使いきれない! 困った! という気持ちになったことはあまり無い。
もちろん、色々サービスコールをして、その結果を待つようなものでも、結果を待っている間はその処理をコアから下ろして&amp;hellip;みたいな処理を、例えば Java だったら CompletableFuture を使って頑張ることもできる。ただこれも、Go みたいなランタイムが代わりに頑張ってくれる言語を使えば、自分が書くコードからは追い出せる。
私の関わっている仕事のうち、containerd とか firecracker-containerd といったオープンソースソフトウェアは、クラウド上の自分達が管理するインスタンスではなくて、世界のどこかにあるメニーコアのマシンで運用されている可能性はある。ただ、これらはコンテナのランタイムという性格上、余っているコアはコンテナが使ってくれればいいので、これもまた自分でコアを使い切る必要はないのだった。オープンソースのリレーショナルデータベースエンジンを開発していたりすると違うのかなあ。でもこれも CPU よりは IO がボトルネックになりそう。
karino2 CPUをどれだけ有効活用するかとCPUリソースにどれくらい余裕をもたせるかは別の話なのでは…と思ったのだけれど、 結果として現れる現象が運用費をもうちょっと安く出来るのか、 ユーザーの手元の端末で遅いアプリを提供するハメになるのか、 と大きく違うんだな、と理解した。 運用費を下げるという点では別にCPUだけ特別扱いする理由も無いですしね。   </description>
      <content:encoded><![CDATA[<p>私はあんまりコアを意識したことないなあ。</p>
<p>これは、どのくらい CPU がボトルネックになる処理を行うかという、ソフトウェアの中身によるところと、karino2 さんが作っているような、デスクトップやモバイルで前面に出てくるようなソフトウェアと、私が作っているような、いわゆるサーバーサイドかつクラウド上のソフトウェアという環境の違いからきているところがあると思う。</p>
<p>まず、ソフトウェアの中身として、ネットワークのどこかにあるサービスをコールをして、その結果を待つようなものだと、そこまで CPU がボトルネックになるようなことはない。</p>
<p>それに加えて、</p>
<ul>
<li>リクエストは並列にやってくるし、リクエストの間で共有しつつ書き換えるデータはそこまでないので、1リクエストでたくさんのコアを使い切らなくても、他のリクエストが使ってくれる (はず)。</li>
<li>新しい世代の XL なインスタンス、例えば t3.xlarge や t4g.xlarge でも4コアしかないので、そもそも8コアも存在しない。デスクトップ/モバイルと違って、サーバーのスペックは自分で選ぶものなので、コアを使いきれなかったら安いインスタンスに変えても良い。</li>
<li>AZ (availability zone) 単位の障害に <a href="https://aws.amazon.com/builders-library/static-stability-using-availability-zones/">statically stable</a> に対応するために、サーバーの処理能力はは 1AZ が消失してもなんとかなるように余裕をもって用意する。全部のコアを文字通り 100% 使っていると負荷が高すぎ。</li>
</ul>
<p>という理由で、頼んでもいないのに8コア来た! 使いきれない! 困った! という気持ちになったことはあまり無い。</p>
<p>もちろん、色々サービスコールをして、その結果を待つようなものでも、結果を待っている間はその処理をコアから下ろして&hellip;みたいな処理を、例えば Java だったら <a href="https://docs.oracle.com/javase/jp/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a> を使って頑張ることもできる。ただこれも、Go みたいなランタイムが代わりに頑張ってくれる言語を使えば、自分が書くコードからは追い出せる。</p>
<p>私の関わっている仕事のうち、<a href="https://containerd.io/">containerd</a> とか <a href="https://github.com/firecracker-microvm/firecracker-containerd">firecracker-containerd</a> といったオープンソースソフトウェアは、クラウド上の自分達が管理するインスタンスではなくて、世界のどこかにあるメニーコアのマシンで運用されている可能性はある。ただ、これらはコンテナのランタイムという性格上、余っているコアはコンテナが使ってくれればいいので、これもまた自分でコアを使い切る必要はないのだった。オープンソースのリレーショナルデータベースエンジンを開発していたりすると違うのかなあ。でもこれも CPU よりは IO がボトルネックになりそう。</p>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
CPUをどれだけ有効活用するかとCPUリソースにどれくらい余裕をもたせるかは別の話なのでは…と思ったのだけれど、
結果として現れる現象が運用費をもうちょっと安く出来るのか、
ユーザーの手元の端末で遅いアプリを提供するハメになるのか、
と大きく違うんだな、と理解した。
運用費を下げるという点では別にCPUだけ特別扱いする理由も無いですしね。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Coreを使い切る苦労</title>
      <link>https://messagepassing.github.io/012-manycore/02-karino2/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/02-karino2/</guid>
      <description>前の記事がめっちゃ良くまとまっていて、 自分の動画（以後「並列プログラムの動画」と呼ぶ）なのに自分が語る資格があるのだろうか、とか考えてしまう。 相対的に一発撮りで何も考えずに作った自分の動画の粗が目立ってしまったが、メッセージ自体には価値はあると思いたい所。 なお、なんでいまさらC++？は、おっさんだからです…
歴史的な事とかコンテキストの説明には特に訂正したり付け足す事も無いので、自身の話をしてみます。
目の前のターゲットはiPad ProとMac Book まず並列プログラムの動画を録っていた時、自分が頭で思い浮かべていた環境はなんだったのか。自分の目の前の開発のターゲットは、iPad ProとMacBook用アプリでした。特にメインはiPad Pro。
iPadでは、既にプロフェッショナルユースの制作に使うような物をユーザーがいろいろ激しく使い込んでいて、もっと大きなデータでもっと速く動いてほしいと強く思われている。 そうしたアプリはMac版もある場合が結構あって、iPadのアプリをMacBookでの動きと比較している。 新しいiPadを買ったら、よりMacBookに近づいて欲しいという期待がある。
そんなMacBookの方は16コアというか16HTで、プログラムから見れば16コア。 iPadは8コア。4コア+遅い4コア を8と呼ぶのはどうなのか、という向きもあるだろうけれど、 コーディングの難しさという視点では立派に8コア。
そもそもそういう用途で使うなら 4コア+遅い4コアという構成はどうなの？とか言いたい事はあるのかもしれないけれど、 ユーザーの期待は16HTにどこまで近づけるか、という事なので、アプリ開発者の我々は、与えられた物を最大限に使うしか無い、 というか使っても足りていない。
対応すべきコア数という観点では、現時点で8と16、近い将来にも動くと期待すると32コアも無いとは言えないくらいのゾーンに居ると思っているので、 今からアプリを作る時にはそのくらいの範囲はadaptiveに対応出来るように作る必要がある、と思っている。
4コアと8コアの違い 4コアまでは、Concurrentなプログラムの延長で書いても、それほどコアを無駄にしている感じは無かった。 何かOSが1.5コアくらい使って、自分たちが２コアくらい使って、たまに1コア余る事もあるけれど、使っているのは3/4だ。まぁそんなもんだろう、みたいな。 大きくあいた所をちょっと再構成してキュッキュッと重そうな物を裏にやれば、だいたい埋まっている感じにはなる。 よくよく見るとまだ結構詰められるのだけど、見なかった事にしてまぁいいか、という気分でいた。 morritaさんの普段の仕事の話を見ているともっと頑張って詰めてそうなので立場に依るのだろうけれど。
4コア時代の主な関心は、いわゆる「ジャンク」を取る事、つまりフレームレートを出す事だったと言えると思う。 実際2コアでジャンクを取り切るのは厳しかった事からも、4コア時代の関心事として割と妥当な所だった。
でも「8コア使ってMacBookに近づいたパフォーマンスをプロフェッショナルに届けよ」とか言われるようになると、もうちょっとCPUインテンシブな事もやっていかないといけない。
でも、8コア使い切るにはConcurrentにちょっと毛がはえたくらいでは厳しい。 8個って結構多くて、コードの構成が最初からそういう前提じゃないとすぐやる事が無いコアが出てきてしまって、全然スケールしてくれない。 リアルにアムダールの法則状態というか。
「iPadが8コアになった」というのは、自分的には大きなニュースで、 morritaさんが言ってた所のSEDA的にプログラムを変えなきゃいけない、 という大きなジャンプを強制された訳です。
この4コアと8コアのギャップみたいなのって、皆はどう思っていますかね？ ビルドの時にninjaが全部使ってくれれば、他は気にしてないっすよ、とかそんな感じだったりします？
自分たちはどうしているか的な話 教科書的な話はまぁいいだろう、という事で、実際に自分がどうしているかの話も少し。
まず、もともと簡単に並列化出来る所はスレッドで並列化してある所が結構ある。 関数の外から見て区別無い形で並列化出来て、それなりにパフォーマンス的に重要な所は、結構頑張って並列化してある。 内部はまぁまぁスレッド同士で依存があるような物を、いろいろと工夫してちゃんとパフォーマンスを出している。
これまではそうやっていたのだけれど、最近は関数単位で閉じた形での並列化が難しい大物がだんだんと目立つようになってきて、 これをどうにかしていかないとなぁ、というのがプロジェクトを始めた時に置かれていた状況。 やはり8コア時代はもうちょっと真面目にやらないといけないと結論づけて、道具を頑張って揃える所から始めている。
道具立ての基礎となるライブラリはfuture-promise。 基本的には、follyのfuture-promiseを真似ているがもうちょっと単純化したものを自分たちでスクラッチから実装していて、これを基本に並列化を進めていっている。 現在は他と依存が少ない新規コードでfuture化したコードを書いていって、ちゃんとパフォーマンスが出る事を確認していっている段階。
下のスレッドプールはQtとかWindowsはシステムのものを、iOSはGCDを、それ以外はとりあえず現在はpthreadで自前実装した物につなげている。 STLじゃなくてpthreadなのは完全に歴史的事情で、STLに直してもいいんだけどなぁ、と思いながらpthreadを使っている。 スレッドプールのAPIはGCDを真似ているけれどもうちょっと単純な感じにしていて、コア数全部使うキューと、シリアルな事が保証されているキューがある感じにしている。 この辺はいろんな環境のいろんなスレッドプール事情を調べて、どれにもつなげられるように作ったつもり。
ちょっとモバイルが特殊なのはGUIスレッドが特別扱いな所。 自分たちはfutureを最終的にGUIスレッドで待てるようにしていて、 この待っている時にプログレスバーを回したり、イベントループに戻せるシステムでは戻したりしている。 他のスレッドからもworkitem的な物をポスト出来るようにはなっていて、待っている時にwork itemが来た場合はGUIスレッドで処理出来るような仕組みはある。 この辺はGUI環境ごとにいろいろあるので、うまくそれらに合わせらるように頑張ってはいる。
Android以外はシステムのスレッドプールがあるのでいいのだけれど、Androidはどうするもんですかねぇ。 AndroidもJava側には十分その辺の道具は揃っているのだけれど、JNI側ではどうするのがいいのだろうか。 あんまりボトルネックになってないので自作の奴でこのまま行くのでもいいのだけれど、この令和の時代に自作のスレッドプール使うのもなぁ…
みんなって意外とみんなじゃなかった そんな訳でiPadとMacBookを頭に浮かべつつ「並列プログラムの動画」を作ったつもりなのだけれど、そうはいってもだいたい「みんな」が対象となるだろう、と思っていた。
最近8コアになった、というのはモバイル特有の事情であって、 サーバーなどでは8コアなんてはるか昔に通った所だ。 morritaさんのポストの最初の方に挙がってるような例で、8コア時代をどうすべきかなんてとっくに結論も出ている。 動画はモバイル向けに作ったものではあるけれど、基本的なアイデアはサーバー時代の結論を元にしているので、サーバーサイドの人でもそう違った事は考えていないんじゃないか、と。</description>
      <content:encoded><![CDATA[<p><a href="https://messagepassing.github.io/012-manycore/01-morrita/">前の記事</a>がめっちゃ良くまとまっていて、
<a href="https://karino2.github.io/2021/03/05/future_for_parallel.html">自分の動画</a>（以後「並列プログラムの動画」と呼ぶ）なのに自分が語る資格があるのだろうか、とか考えてしまう。
相対的に一発撮りで何も考えずに作った自分の動画の粗が目立ってしまったが、メッセージ自体には価値はあると思いたい所。
なお、なんでいまさらC++？は、おっさんだからです…</p>
<p>歴史的な事とかコンテキストの説明には特に訂正したり付け足す事も無いので、自身の話をしてみます。</p>
<h3 id="目の前のターゲットはipad-proとmac-book">目の前のターゲットはiPad ProとMac Book</h3>
<p>まず並列プログラムの動画を録っていた時、自分が頭で思い浮かべていた環境はなんだったのか。自分の目の前の開発のターゲットは、iPad ProとMacBook用アプリでした。特にメインはiPad Pro。</p>
<p>iPadでは、既にプロフェッショナルユースの制作に使うような物をユーザーがいろいろ激しく使い込んでいて、もっと大きなデータでもっと速く動いてほしいと強く思われている。
そうしたアプリはMac版もある場合が結構あって、iPadのアプリをMacBookでの動きと比較している。
新しいiPadを買ったら、よりMacBookに近づいて欲しいという期待がある。</p>
<p>そんなMacBookの方は16コアというか16HTで、プログラムから見れば16コア。
iPadは8コア。4コア+遅い4コア を8と呼ぶのはどうなのか、という向きもあるだろうけれど、
コーディングの難しさという視点では立派に8コア。</p>
<p>そもそもそういう用途で使うなら 4コア+遅い4コアという構成はどうなの？とか言いたい事はあるのかもしれないけれど、
ユーザーの期待は16HTにどこまで近づけるか、という事なので、アプリ開発者の我々は、与えられた物を最大限に使うしか無い、
というか使っても足りていない。</p>
<p>対応すべきコア数という観点では、現時点で8と16、近い将来にも動くと期待すると32コアも無いとは言えないくらいのゾーンに居ると思っているので、
今からアプリを作る時にはそのくらいの範囲はadaptiveに対応出来るように作る必要がある、と思っている。</p>
<h3 id="4コアと8コアの違い">4コアと8コアの違い</h3>
<p>4コアまでは、Concurrentなプログラムの延長で書いても、それほどコアを無駄にしている感じは無かった。
何かOSが1.5コアくらい使って、自分たちが２コアくらい使って、たまに1コア余る事もあるけれど、使っているのは3/4だ。まぁそんなもんだろう、みたいな。
大きくあいた所をちょっと再構成してキュッキュッと重そうな物を裏にやれば、だいたい埋まっている感じにはなる。
よくよく見るとまだ結構詰められるのだけど、見なかった事にしてまぁいいか、という気分でいた。
morritaさんの普段の仕事の話を見ているともっと頑張って詰めてそうなので立場に依るのだろうけれど。</p>
<p>4コア時代の主な関心は、いわゆる「ジャンク」を取る事、つまりフレームレートを出す事だったと言えると思う。
実際2コアでジャンクを取り切るのは厳しかった事からも、4コア時代の関心事として割と妥当な所だった。</p>
<p>でも「8コア使ってMacBookに近づいたパフォーマンスをプロフェッショナルに届けよ」とか言われるようになると、もうちょっとCPUインテンシブな事もやっていかないといけない。</p>
<p>でも、8コア使い切るにはConcurrentにちょっと毛がはえたくらいでは厳しい。
8個って結構多くて、コードの構成が最初からそういう前提じゃないとすぐやる事が無いコアが出てきてしまって、全然スケールしてくれない。
リアルにアムダールの法則状態というか。</p>
<p>「iPadが8コアになった」というのは、自分的には大きなニュースで、
morritaさんが言ってた所のSEDA的にプログラムを変えなきゃいけない、
という大きなジャンプを強制された訳です。</p>
<p>この4コアと8コアのギャップみたいなのって、皆はどう思っていますかね？
ビルドの時にninjaが全部使ってくれれば、他は気にしてないっすよ、とかそんな感じだったりします？</p>
<h3 id="自分たちはどうしているか的な話">自分たちはどうしているか的な話</h3>
<p>教科書的な話はまぁいいだろう、という事で、実際に自分がどうしているかの話も少し。</p>
<p>まず、もともと簡単に並列化出来る所はスレッドで並列化してある所が結構ある。
関数の外から見て区別無い形で並列化出来て、それなりにパフォーマンス的に重要な所は、結構頑張って並列化してある。
内部はまぁまぁスレッド同士で依存があるような物を、いろいろと工夫してちゃんとパフォーマンスを出している。</p>
<p>これまではそうやっていたのだけれど、最近は関数単位で閉じた形での並列化が難しい大物がだんだんと目立つようになってきて、
これをどうにかしていかないとなぁ、というのがプロジェクトを始めた時に置かれていた状況。
やはり8コア時代はもうちょっと真面目にやらないといけないと結論づけて、道具を頑張って揃える所から始めている。</p>
<p>道具立ての基礎となるライブラリはfuture-promise。
基本的には、follyのfuture-promiseを真似ているがもうちょっと単純化したものを自分たちでスクラッチから実装していて、これを基本に並列化を進めていっている。
現在は他と依存が少ない新規コードでfuture化したコードを書いていって、ちゃんとパフォーマンスが出る事を確認していっている段階。</p>
<p>下のスレッドプールはQtとかWindowsはシステムのものを、iOSはGCDを、それ以外はとりあえず現在はpthreadで自前実装した物につなげている。
STLじゃなくてpthreadなのは完全に歴史的事情で、STLに直してもいいんだけどなぁ、と思いながらpthreadを使っている。
スレッドプールのAPIはGCDを真似ているけれどもうちょっと単純な感じにしていて、コア数全部使うキューと、シリアルな事が保証されているキューがある感じにしている。
この辺はいろんな環境のいろんなスレッドプール事情を調べて、どれにもつなげられるように作ったつもり。</p>
<p>ちょっとモバイルが特殊なのはGUIスレッドが特別扱いな所。
自分たちはfutureを最終的にGUIスレッドで待てるようにしていて、
この待っている時にプログレスバーを回したり、イベントループに戻せるシステムでは戻したりしている。
他のスレッドからもworkitem的な物をポスト出来るようにはなっていて、待っている時にwork itemが来た場合はGUIスレッドで処理出来るような仕組みはある。
この辺はGUI環境ごとにいろいろあるので、うまくそれらに合わせらるように頑張ってはいる。</p>
<p>Android以外はシステムのスレッドプールがあるのでいいのだけれど、Androidはどうするもんですかねぇ。
AndroidもJava側には十分その辺の道具は揃っているのだけれど、JNI側ではどうするのがいいのだろうか。
あんまりボトルネックになってないので自作の奴でこのまま行くのでもいいのだけれど、この令和の時代に自作のスレッドプール使うのもなぁ…</p>
<h3 id="みんなって意外とみんなじゃなかった">みんなって意外とみんなじゃなかった</h3>
<p>そんな訳でiPadとMacBookを頭に浮かべつつ「並列プログラムの動画」を作ったつもりなのだけれど、そうはいってもだいたい「みんな」が対象となるだろう、と思っていた。</p>
<p>最近8コアになった、というのはモバイル特有の事情であって、
サーバーなどでは8コアなんてはるか昔に通った所だ。
morritaさんのポストの最初の方に挙がってるような例で、8コア時代をどうすべきかなんてとっくに結論も出ている。
動画はモバイル向けに作ったものではあるけれど、基本的なアイデアはサーバー時代の結論を元にしているので、サーバーサイドの人でもそう違った事は考えていないんじゃないか、と。</p>
<p>モバイルとサーバーサイド両方って言ったらもう「みんな」と言っていいんじゃないか？
GPUを使いまくる機械学習とか一部の分野は違うだろうけれど、それらは例外という事で。こんな風に考えていた。</p>
<p>でも、「Switch買ってよ！みんな持ってるよ！」とオカンに言うと、「みんなって誰よ！？」と問い詰められるものです。
動画を挙げた時も「どこの環境向けの話？」というフィードバックを受けました。
「そんなのみんなだろう」と思ったのだけれど、具体的に「みんな」とは誰かをまじめに考えてみると、
実はそれほど「みんな」でも無い気がしてきた。</p>
<p>パフォーマンスを突き詰めていけばサーバーサイドもモバイルもだいたい同じ話になる、
という認識は今でも変わってないけれど、パフォーマンスを突き詰めていく、
というのが、言われてみるとそれほど一般的では無い気もしてきた。
その辺が重要になってくるのは勝負がついた後の話であって、
一番重要なバリバリ競争をしているフェーズでは、まだProcessExecutorでお茶をにごしたりコンテナ増やして対応したりで凌いだりするよなぁ。</p>
<p>クラウドなんかだとグルーコード的なのが多かったり、Dataflowとか…はそんな詳しくないけれど、
自分の知ってるMapReduce世代を振り返るとシャッフルやReduceで詰まらないようにとかMapでなるべく各ノードで済ますとか、そういう頑張りの方が主で、そんなにコアを使い切るという話にはなってなかった気がする（突き詰めればなるはずだけれど）。</p>
<p>また機械学習も、例外と切り捨てるほどマイナーな分野とも言い切れない。
C++でクロスプラットフォームなライブラリ書いてアプリ作ってる人よりは多いかもしれない…</p>
<p>一方でサーバーサイドでRustとか流行るのは意外とCPUリソースが希少なのでは？という気もするのでこの辺の感覚は全然わからないのだけど、どうなんですかね？</p>
<p>なんにせよ、あまり対象外の分野を、どんどん「それは例外な分野だ」として切り離していくと、例外の方が多いんじゃないか、という気分になってきました。あんまりコアを使い切るのに悩むのは一般的では無いのかもしれない。</p>
<p>という事で最初の動画の対象は、大規模アクセスをさばく複雑なロジックを持つサービスと、
プロフェッショナル向けのiPad Proハイエンドアプリくらいなのかもしれない。</p>
<h3 id="普通のプログラマ視点の-gpu-vs-cpu">普通のプログラマ視点の GPU vs CPU</h3>
<p>Parallelな話というとすぐGPUの話になりがちに思うのだけれど、その辺には結構不満がある。
熱とか電力とかも含めた計算能力という点では、GPUの勝利で勝負は随分昔に済んでいて、
使えるならGPUを有効活用する方が、CPUコアを使い切るよりも断然良い、という事に異論は無いのですが。</p>
<p>でも、一アプリプログラマとして見た時には、自分のアプリでGPUを活用するのは、なかなかに難しい。
いろいろなデバイスで動く汎用のアプリで、ユーザーから様々なデータがやってくる状況で、
GPUを有効活用する、というのは、
業界全体のグランドチャレンジというか、出来たらいい夢の話ではあるが、自分の手には余る。
なんとかしたいとは思っているのだけれど…</p>
<p>一方で、CPUのコアは複雑なアプリであればだいたい使い切る余地があるし、
自分程度の腕でも頑張ればちゃんと使い切れる。
そういう点ではCPUコアを使い切るのは今目の前にある現実であって、
日々の仕事の話と思っている。</p>
<p>コンペとかベンチとかではGPUがメインになっちゃうけれど、ユーザーが使う実際のアプリではやっぱりCPUがメインなんじゃないの？
と思ってしまう。
GPUを有効活用出来ているゲームとか機械学習も、有効活用出来るまでにはいろいろな困難を乗り越えて来たのだろうけれど、
それでもやはりそれらの分野限定なんじゃないか。まぁうまく解決した人が居ると、もともとそういう分野だったからに見えるものですが。</p>
<p>とにかく、現状ではまずCPUコア使い切る方向で頑張るのが現実的なんじゃないか。
だから僕ら普通のプログラマの現代的な課題として、もっと普段からこのトピックの話を見かけてもいいのになぁ、と思うのだけれど。</p>
<p>その辺、皆はどう思いますかね？</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
余談だけれど Mac(book) も <a href="https://www.apple.com/mac/m1/">M1</a> とかがでて今後は iPad みたいなハードウェアアーキテクチャに近づいていきそうですねえ。
クライアントサイドで Intel の存在感はどんどんなくなっていきそう。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
ソフトウェアもSwiftUIで結構統一されつつあるし、ハードウェアもiPadと近づいているし、
iPadとMacBookがプロフェッショナルユース、
という感じには、かなりうまく進められているんじゃないか。
無理して一気にやらない所がうまいですよね、Apple。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ポエム</title>
      <link>https://messagepassing.github.io/015-poems/02-shinh/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/015-poems/02-shinh/</guid>
      <description>ちょくちょくポエムと呼ぶようなインフォーマル書きものするので、よく僕がやる通りの形式で、よく書くような感じのメモを殴り書きしてみました。 karino2 さんが大作感があったので、箸休めにどうぞ。
 スタートアップの社内プロジェクトの場合、読み手が少ないのでフォーマルなドキュメントを書くコストはペイしにくいと思っています どういう種類があるかなと考えてみると、以下のようなものを思いつきました  新しいことやる人にこういうの考慮に入れるのではという思いつきを共有する種類のメモ 自分がやった作業を引き継ぐ人に、現状の課題を説明して、何をすれば再現できるか、本当はどうあった方が良いと思っているか、などを共有するメモ ちょっと複雑なものを書いた時に、自分の備忘録も兼ねて、ざっくりとした実装の説明 問題だと思っていることの報告   1 と 2 は、口頭のミーティングの前に準備しておいて、それでトピック思い出して口頭で情報を補いつつ、補った有用と思われる情報はミーティング中にメモに追記していったりします コンポーネントのからみあいとかの説明は、口頭では伝わりにくいので、文章を細かめにしておいて、わからないところあれば slack でお願いします、とかでいいのかなと 1 は思想の共有というか、こういうコンポーネントがあると良いのでは、みたいな、アイデアの共有みたいな話をする時にも似たようなスタイルになるかも 3 は本当に読み手が存在するか謎なので、未来の自分が読める程度にしていて、他の人から見れば謎の文章かもです 4 は自分のよく知らない領域に問題が起きていて、込みいった相談がしたい時ですね 書いてる時間がもったいないので、なんというか雑ですね なぜか箇条書き使うことが多いですね。意味的には &amp;lt;li&amp;gt; が適切ではない使いかたなのだけど  後からこういう感じでメモを追加できるのは良さではある   英語の reading/writing は苦手だがそんなに苦でない、と思ってたんですけど、最近しみじみ思うのは、やっぱこういうの日本語でできるとむっちゃラクですね  ちょっとした調整で良くなったり悪くなったりするアルゴリズムがあって、「なんかこの PR で速くなってるんですが、この PR のおかげではなく、桶屋だと思います」とか言っていたりして、この桶屋みたいなのが気軽に使えて通じるのがね   これ草稿の段階で美文章滅すべし を kzys さんに教えてもらったのですが、これ僕がこのスタイル好きな理由をとても良く説明してくれていますね。  英語のことちょっと書きましたが、グーグル時代はこういうのはあまり書かなかったですね。でも、全く書かなかったかというと、メールに長めの返事をする時は結構これ的な箇条書きも多かったな、と思いました。 &amp;ldquo;Interesting idea! My random thoughts:&amp;rdquo; みたいな感じで始めて、あとは箇条書き、というような。むしろ英語だから美文章書けない苦肉の策として、自分の中で定着していった定石なのかもです。
他の外資系大企業陣営はどんなもんでしょうか？
 shinh そういえば2ヶ月ほど前に書いたやつが、あまり社内事情とか関係なくて、そのまま出して問題なさそうなので、サンプルとして紹介してみます。普段はこのノリで技術的な内容書くことが多い感じ: https://docs.google.com/document/d/1v_EoYtnMY9-jBuGME6uQMNIQ6XIIkrO8uPO2Lc9M1zs/edit   morrita 箇条書きって書く側に optimize されてますよね。箇条書きで省かれている論理構造を読む側で補う前提がある。それで良いかどうかは「読み」という需要と「書き」という供給のバランスで決まると思うけど、読まれたいコンテンツを持っている人はばんばん箇条書きした方が良いのだろうなあ。あるいは「本当に読み手が存在するか謎」でも書ける余剰があればいいのかな。メールの返事とかは明らかに自分の返事に需要があるので、自分もよく箇条書きしてる気がする。   </description>
      <content:encoded><![CDATA[<p>ちょくちょくポエムと呼ぶようなインフォーマル書きものするので、よく僕がやる通りの形式で、よく書くような感じのメモを殴り書きしてみました。 karino2 さんが大作感があったので、箸休めにどうぞ。</p>
<ul>
<li>スタートアップの社内プロジェクトの場合、読み手が少ないのでフォーマルなドキュメントを書くコストはペイしにくいと思っています</li>
<li>どういう種類があるかなと考えてみると、以下のようなものを思いつきました
<ol>
<li>新しいことやる人にこういうの考慮に入れるのではという思いつきを共有する種類のメモ</li>
<li>自分がやった作業を引き継ぐ人に、現状の課題を説明して、何をすれば再現できるか、本当はどうあった方が良いと思っているか、などを共有するメモ</li>
<li>ちょっと複雑なものを書いた時に、自分の備忘録も兼ねて、ざっくりとした実装の説明</li>
<li>問題だと思っていることの報告</li>
</ol>
</li>
<li>1 と 2 は、口頭のミーティングの前に準備しておいて、それでトピック思い出して口頭で情報を補いつつ、補った有用と思われる情報はミーティング中にメモに追記していったりします</li>
<li>コンポーネントのからみあいとかの説明は、口頭では伝わりにくいので、文章を細かめにしておいて、わからないところあれば slack でお願いします、とかでいいのかなと</li>
<li>1 は思想の共有というか、こういうコンポーネントがあると良いのでは、みたいな、アイデアの共有みたいな話をする時にも似たようなスタイルになるかも</li>
<li>3 は本当に読み手が存在するか謎なので、未来の自分が読める程度にしていて、他の人から見れば謎の文章かもです</li>
<li>4 は自分のよく知らない領域に問題が起きていて、込みいった相談がしたい時ですね</li>
<li>書いてる時間がもったいないので、なんというか雑ですね</li>
<li>なぜか箇条書き使うことが多いですね。意味的には <code>&lt;li&gt;</code> が適切ではない使いかたなのだけど
<ul>
<li>後からこういう感じでメモを追加できるのは良さではある</li>
</ul>
</li>
<li>英語の reading/writing は苦手だがそんなに苦でない、と思ってたんですけど、最近しみじみ思うのは、やっぱこういうの日本語でできるとむっちゃラクですね
<ul>
<li>ちょっとした調整で良くなったり悪くなったりするアルゴリズムがあって、「なんかこの PR で速くなってるんですが、この PR のおかげではなく、桶屋だと思います」とか言っていたりして、この桶屋みたいなのが気軽に使えて通じるのがね</li>
</ul>
</li>
<li>これ草稿の段階で<a href="https://scrapbox.io/shokai/%E7%BE%8E%E6%96%87%E7%AB%A0%E6%BB%85%E3%81%99%E3%81%B9%E3%81%97">美文章滅すべし</a> を kzys さんに教えてもらったのですが、これ僕がこのスタイル好きな理由をとても良く説明してくれていますね。</li>
</ul>
<p>英語のことちょっと書きましたが、グーグル時代はこういうのはあまり書かなかったですね。でも、全く書かなかったかというと、メールに長めの返事をする時は結構これ的な箇条書きも多かったな、と思いました。 &ldquo;Interesting idea! My random thoughts:&rdquo; みたいな感じで始めて、あとは箇条書き、というような。むしろ英語だから美文章書けない苦肉の策として、自分の中で定着していった定石なのかもです。</p>
<p>他の外資系大企業陣営はどんなもんでしょうか？</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
そういえば2ヶ月ほど前に書いたやつが、あまり社内事情とか関係なくて、そのまま出して問題なさそうなので、サンプルとして紹介してみます。普段はこのノリで技術的な内容書くことが多い感じ:
<a href="https://docs.google.com/document/d/1v_EoYtnMY9-jBuGME6uQMNIQ6XIIkrO8uPO2Lc9M1zs/edit">https://docs.google.com/document/d/1v_EoYtnMY9-jBuGME6uQMNIQ6XIIkrO8uPO2Lc9M1zs/edit</a>
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
箇条書きって書く側に optimize されてますよね。箇条書きで省かれている論理構造を読む側で補う前提がある。それで良いかどうかは「読み」という需要と「書き」という供給のバランスで決まると思うけど、読まれたいコンテンツを持っている人はばんばん箇条書きした方が良いのだろうなあ。あるいは「本当に読み手が存在するか謎」でも書ける余剰があればいいのかな。メールの返事とかは明らかに自分の返事に需要があるので、自分もよく箇条書きしてる気がする。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>インフォーマルなドキュメント</title>
      <link>https://messagepassing.github.io/015-poems/01-karino2/</link>
      <pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/015-poems/01-karino2/</guid>
      <description>Design Docの話を書いていて思ったが、自分はそれよりもWikiとかインフォーマルなドキュメントを書く方が好きなんですよね。 という事でその辺の話を書いてみる。
Wikiに何書いているの？ Wikiはインフォーマルにいろいろ書いていて、インフォーマルゆえに「これ」というのは難しいのだけれど、 皆が何書いているかを知りたいので自分のやっている事もなんとなく言語化してみる。
コーディングにまつわる、直近のTODOの書き出し まずやらなくてはいけない事が複数あってなんか手が動かない、みたいな時に、やらなきゃいけない事を箇条書きで書き出したりする。 箇条書きに書き出して、それを眺めて考えたり、散歩してきたりして、やらなきゃいけない事を考えていく。
自分の場合、何か手が動かない理由の半分くらいは何をやるかが自分の中で明確になってないケースなので、 そういう場合はWikiに書き出してそれを眺めて考える、というのは結構有効に機能している（そうじゃない場合は結局手は動かないのだけれど）。
簡単なものはローカルのテキストファイルに書いているのだが、手強い物で考える必要があるものをWikiに書いて考えている気がする。
曳光弾にまつわる事 何を作りたいかが曖昧で、いわゆる曳光弾を打つ時にもよくWikiを書いている。 何が曖昧なのか、よく分からないと思っている事はなんなのか、をぼんやりと書いて、 その辺をもう少しマシにする為こんな感じの曳光弾を打とうと思ってる、とか書く。 で、実際に実装していく過程で考えてたのは全然違っていて、実際の曳光弾は全然別の物になって、分からないと思っていた事や曖昧と思っていた事も全然違う所が曖昧だった、 みたいな事が判明したりするのだが、そういう事も追記していく。
あと実装が終わったあとにどうだったか、は良く書いている。分かった事、新たに生まれた分からない事、当初考えていた事がどこが間違いだったか、など。
最初に思っていた事はだいたいいつも間違いなのだが、最初に書いた事は訂正はせずにそのまま残している事が多い。 あとに追記した事だけでは意味をなさず、でもその前の記述は間違っている、というような状態にはなりがちで、これについては歴史改変のあたりで後述する。
自分マイルストーンにまつわる事 やろうとしている事が壮大過ぎて何から手を付けていいかよく分からない、という事がある。
そういう時にはやりたい事を適当に分割した、自分マイルストーンを勝手に定義して、それにバージョン番号を降って開発を進めていく。 Ver 0.1ではXXXをやる、Ver 0.2ではYYYYをやる、みたいな事をだらだらと書き出す。 次にやる事はまぁまぁ詳しく、次の次にやる事はぼんやりと、その先は妄想みたいなのが一行書かれてるだけなのが並ぶ、みたいな形が多い。
始まりは前述のTODOの書き出しの一種だが、その後各自分マイルストーンのサブセクションが成長していく所がちょっと違う。 また各バージョンと先述の曳光弾との違いは曖昧。
自分マイルストーンはチケットも切って、Wikiとは相互リンクを貼っている。
壮大な事はだいたいうまく行かないので、なんでうまく行かないのか、みたいな記述が増えていって当初考えていたところまでたどり着かず、どこかでピボットする事になる、というのもありがち。 そういう軌跡が曖昧に残る感じになる。
設計的なこと 設計的な事を書く事もある。ARCHITECURE.mdみたいにあとから書く事もあるし、 作る前になんとなく思っている事を書き出す事もある。 レイヤリングとか、本当はこうしたいんだがこういう理由でこうしている、といった言い訳とかそういうのも書く事はある。
基本的にはソースコードやコメントやコミットログやUnitTestで設計意図は読み解けるように書いているつもりで、それが望ましいとは思っている。 特に設計的な事はなるべくコメントに書くようにしている。
でもWikiにも書いてあるな。どう違うんだろう？ Wikiはファイルをまたがる全体的な事や補助的な情報を書いている気がするが、今見直すとdoc stringに書く方がいいな、と思う事もある…
feature flagとか技術的に知られているイディオム的な解説 何かを実装した時に、それが業界で良く知られたアイデアに基づいている事がある。feature flagの仕組みとか。 そういう、実装した事に関わる、一般常識ではあるが知らない人も居るような背景知識を、Wikiで解説したり、further readingを紹介したりする。 また、参考にしてはいるが違うものになっている場合は、その理由というか裏話的な事も書いている。
調査関連 調査する時はWikiに調査する内容とか調査のモチベーションとか読んだ記事とか動画とかのリンクとかを書いたりする。調査はissueにする事もあり、その辺の使い分けは曖昧。 外部技術に関する調査で公式ドキュメントとか動画を読んでいくようなのはWikiが多いかなぁ。 逆にパフォーマンス調査とか自分たちのコードベースの特定の側面とかを調査するものはissueにする事が多い。issueとの使い分けについてはあとでも触れる。
karino2 on software 何か意見を言ったり何かフィードバックを返す時に、背景が膨大で全部その場では説明出来ない、という事がある。 例えばslackでバグの報告とか質問があった時に、Issue trackerに上げてもらう。 そういう実際の行動はその場でお願いしたりすれば良いのだけれど、何故そうした方がいいのか、というような背景とかについては、 その場ではあまり説明出来ない。
そういう時に、そもそもIssue Trackerを使う意義とは何か、とか、どういうissueの記載が望ましいのか、とか、 そうした背景の説明をエッセイとして書くというのをやっている。
そういう「直接はチームの決定には関係しないが、背景となるようなソフトウェア開発に関わるエッセイ」は、 Joel on softwareオマージュとしてkarino2 on softwareというタイトルにしてWikiに書いている。</description>
      <content:encoded><![CDATA[<p><a href="https://messagepassing.github.io/011-designdocs/">Design Docの話</a>を書いていて思ったが、自分はそれよりもWikiとかインフォーマルなドキュメントを書く方が好きなんですよね。
という事でその辺の話を書いてみる。</p>
<h2 id="wikiに何書いているの">Wikiに何書いているの？</h2>
<p>Wikiはインフォーマルにいろいろ書いていて、インフォーマルゆえに「これ」というのは難しいのだけれど、
皆が何書いているかを知りたいので自分のやっている事もなんとなく言語化してみる。</p>
<h3 id="コーディングにまつわる直近のtodoの書き出し">コーディングにまつわる、直近のTODOの書き出し</h3>
<p>まずやらなくてはいけない事が複数あってなんか手が動かない、みたいな時に、やらなきゃいけない事を箇条書きで書き出したりする。
箇条書きに書き出して、それを眺めて考えたり、散歩してきたりして、やらなきゃいけない事を考えていく。</p>
<p>自分の場合、何か手が動かない理由の半分くらいは何をやるかが自分の中で明確になってないケースなので、
そういう場合はWikiに書き出してそれを眺めて考える、というのは結構有効に機能している（そうじゃない場合は結局手は動かないのだけれど）。</p>
<p>簡単なものはローカルのテキストファイルに書いているのだが、手強い物で考える必要があるものをWikiに書いて考えている気がする。</p>
<h3 id="曳光弾にまつわる事">曳光弾にまつわる事</h3>
<p>何を作りたいかが曖昧で、いわゆる曳光弾を打つ時にもよくWikiを書いている。
何が曖昧なのか、よく分からないと思っている事はなんなのか、をぼんやりと書いて、
その辺をもう少しマシにする為こんな感じの曳光弾を打とうと思ってる、とか書く。
で、実際に実装していく過程で考えてたのは全然違っていて、実際の曳光弾は全然別の物になって、分からないと思っていた事や曖昧と思っていた事も全然違う所が曖昧だった、
みたいな事が判明したりするのだが、そういう事も追記していく。</p>
<p>あと実装が終わったあとにどうだったか、は良く書いている。分かった事、新たに生まれた分からない事、当初考えていた事がどこが間違いだったか、など。</p>
<p>最初に思っていた事はだいたいいつも間違いなのだが、最初に書いた事は訂正はせずにそのまま残している事が多い。
あとに追記した事だけでは意味をなさず、でもその前の記述は間違っている、というような状態にはなりがちで、これについては歴史改変のあたりで後述する。</p>
<h3 id="自分マイルストーンにまつわる事">自分マイルストーンにまつわる事</h3>
<p>やろうとしている事が壮大過ぎて何から手を付けていいかよく分からない、という事がある。</p>
<p>そういう時にはやりたい事を適当に分割した、自分マイルストーンを勝手に定義して、それにバージョン番号を降って開発を進めていく。
Ver 0.1ではXXXをやる、Ver 0.2ではYYYYをやる、みたいな事をだらだらと書き出す。
次にやる事はまぁまぁ詳しく、次の次にやる事はぼんやりと、その先は妄想みたいなのが一行書かれてるだけなのが並ぶ、みたいな形が多い。</p>
<p>始まりは前述のTODOの書き出しの一種だが、その後各自分マイルストーンのサブセクションが成長していく所がちょっと違う。
また各バージョンと先述の曳光弾との違いは曖昧。</p>
<p>自分マイルストーンはチケットも切って、Wikiとは相互リンクを貼っている。</p>
<p>壮大な事はだいたいうまく行かないので、なんでうまく行かないのか、みたいな記述が増えていって当初考えていたところまでたどり着かず、どこかでピボットする事になる、というのもありがち。
そういう軌跡が曖昧に残る感じになる。</p>
<h3 id="設計的なこと">設計的なこと</h3>
<p>設計的な事を書く事もある。ARCHITECURE.mdみたいにあとから書く事もあるし、
作る前になんとなく思っている事を書き出す事もある。
レイヤリングとか、本当はこうしたいんだがこういう理由でこうしている、といった言い訳とかそういうのも書く事はある。</p>
<p>基本的にはソースコードやコメントやコミットログやUnitTestで設計意図は読み解けるように書いているつもりで、それが望ましいとは思っている。
特に設計的な事はなるべくコメントに書くようにしている。</p>
<p>でもWikiにも書いてあるな。どう違うんだろう？
Wikiはファイルをまたがる全体的な事や補助的な情報を書いている気がするが、今見直すとdoc stringに書く方がいいな、と思う事もある…</p>
<h3 id="feature-flagとか技術的に知られているイディオム的な解説">feature flagとか技術的に知られているイディオム的な解説</h3>
<p>何かを実装した時に、それが業界で良く知られたアイデアに基づいている事がある。feature flagの仕組みとか。
そういう、実装した事に関わる、一般常識ではあるが知らない人も居るような背景知識を、Wikiで解説したり、further readingを紹介したりする。
また、参考にしてはいるが違うものになっている場合は、その理由というか裏話的な事も書いている。</p>
<h3 id="調査関連">調査関連</h3>
<p>調査する時はWikiに調査する内容とか調査のモチベーションとか読んだ記事とか動画とかのリンクとかを書いたりする。調査はissueにする事もあり、その辺の使い分けは曖昧。
外部技術に関する調査で公式ドキュメントとか動画を読んでいくようなのはWikiが多いかなぁ。
逆にパフォーマンス調査とか自分たちのコードベースの特定の側面とかを調査するものはissueにする事が多い。issueとの使い分けについてはあとでも触れる。</p>
<h3 id="karino2-on-software">karino2 on software</h3>
<p>何か意見を言ったり何かフィードバックを返す時に、背景が膨大で全部その場では説明出来ない、という事がある。
例えばslackでバグの報告とか質問があった時に、Issue trackerに上げてもらう。
そういう実際の行動はその場でお願いしたりすれば良いのだけれど、何故そうした方がいいのか、というような背景とかについては、
その場ではあまり説明出来ない。</p>
<p>そういう時に、そもそもIssue Trackerを使う意義とは何か、とか、どういうissueの記載が望ましいのか、とか、
そうした背景の説明をエッセイとして書くというのをやっている。</p>
<p>そういう「直接はチームの決定には関係しないが、背景となるようなソフトウェア開発に関わるエッセイ」は、
Joel on softwareオマージュとしてkarino2 on softwareというタイトルにしてWikiに書いている。</p>
<p>この手のエッセイは、全員に読んでもらう事は期待してない。ただし何かをslackで説明してる時などに必要になったらリンクを貼る事はある。
だいたい読んでほしい人は読んでくれないが、関係ないチームの若者とかに人気になったりする。</p>
<h3 id="未実装なモジュールのモックアップとして">未実装なモジュールのモックアップとして</h3>
<p>相互に依存するモジュールがあって、片方が無いともう片方が考えられない、みたいな事がある。</p>
<p>例えば、Domain SpecificなBitCodeとVMを設計したい、みたいな時（Domain側の知識は十分にあるとして）。
BitCodeの設計がVMの構造を決め、VMのロードとか実行時の構造がBitCodeの設計を決める、みたいな相互依存があり、
でも最初に両方を一気に考えるにはそれぞれ手強くて難しい。</p>
<p>こういう相互依存があってどちらもそれなりに大きい時は、片方、例えばVM側を、自然言語で曖昧に書いた物で代用して、BitCode側のコーディングを進めたりする。
まずVMについてぼんやり思っている事を言葉にして書き出す。
それを元にBitCode側を考えながらコンパイラを書いていく。</p>
<p>こういう時には、ぼんやり思っている事はだいたいちゃんとは言葉に出来ないので、文章が途中で止まる。
例えば以下みたいな日本語の途中で止まった文章が書かれる。</p>
<blockquote>
<p>このVMの基本構造はスタック型マシンである。ただしfor文の所では</p>
</blockquote>
<p>ここまで書いていたら、良くわからなくなってきた、という時に、文章の途中で止まる。</p>
<p>こういう良くわからなくなった所で止めておいて、そこまでを眺めて考えたり、とりあえず分かってる範囲の知識を元にBitCode側のコードを書いてみたりする。</p>
<p>両方がある程度出来てくればコーディングの中でデザインを行っていく方が良いと思うけれど、最初のブートストラップとしてハリボテを作るのにインフォーマルな自然言語はなかなか良い事がある。</p>
<h3 id="図を含めたコードのコメントの代わりとして">図を含めたコードのコメントの代わりとして</h3>
<p>コードのコメントで図を含めたい時に、その代替としてWikiに図入りの説明を書いてリンクをコメント側に入れたりする。
ただWikiは失われてコードが残る事は（残念ながら）良くあるので、コード側だけでも理解出来るようには気をつけている。</p>
<h2 id="準時系列とか更新の話">準時系列とか更新の話</h2>
<p>実態と合わなくなった情報をどう扱うか、みたいなのはインフォーマルなドキュメンテーションで割と重要なトピックと思うので、
自分がどうしているのかの話を。皆はどうしてますかね？</p>
<h3 id="準時系列な追記とstaleになるメカニズム">準時系列な追記と、staleになるメカニズム</h3>
<p>「自分マイルストーン」の所とかでも書いたけれど、
自分は、項目ごとに時系列に追記していくスタイルで書いているものが幾つかある。</p>
<p>セクションは時系列じゃないんだが、サブセクションは時系列に追記していく、みたいな。
そうした時系列に追記していく物は、基本的に前に書いた事と、あとに書いた事に整合性が無い。</p>
<p>例えば何かを書き出して、それに基づいて実装をすると、書き出した事の勘違いに気づいたりする。
そういう時に、その勘違いをWikiには反映させずに、その次に詰まった時に詰まった事とかをWikiに書く。</p>
<p>すると詰まった時点での理解を元に追記された内容と、その理解の以前の良く分かってない時に書いた考えている事はつながらない。
こういう時に、「基本的には」前に書いてある誤りは直さない事にしている。</p>
<h3 id="更新や歴史改変とその方針">更新や歴史改変とその方針</h3>
<p>基本的には前を直さずに追記をしていくのだけれど、一定まで行くと問題が出てくる。</p>
<p>目に入れて考える時に、間違った事が多すぎるとかえって考える邪魔になってくる。
残す情報としても、実態と乖離している割合が多すぎて、かえって有害だな、と感じるようになる。</p>
<p>そういう時は、多少手を入れている。
手を入れる方針としては、時系列的に一番最後の内容がちゃんと意味をなすように、そこと関連ある場所だけ遡って直す、という事をしている。遡って直すのを歴史改変と読んでいる。</p>
<p>例えば「XXXを考えてYYYという作業をやる」という記述があった時に、「XXXを考えて」を、当時は実際には考えてなかったがあとに分かった事に直したり、当初考えていた間違った所を削除したりして、続きの追記内容とのギャップを無くす。その代わり、そのブロック内での整合性は無くなって事実でもなくなる。だが、全部をちゃんと直すのは面倒で続かないので最後の記述以外が変になるのは受け入れている。</p>
<p>こうする事で、たまにその時点での正しい記述になるチェックポイントのような物を設けている。
ある日何らかの理由で突然更新しなくなっても、割と最後の方の記述は意味を成すように出来る。トラックナンバー的な考えですね。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>オフトピだが入れられずにはいられない関連ツールなどの話題を。</p>
<h2 id="他のツールとの使い分け">他のツールとの使い分け</h2>
<p>他というと際限が無いのだけれど、関連が深そうだけど別種のツールとの使い分けとか。</p>
<h3 id="考えるツールという側面">考えるツールという側面</h3>
<p>他の用途の物と比較するにあたり、まずWikiなどのインフォーマルなドキュメント側の事をちょっと考えてみたい。</p>
<p>Wikiなどのインフォーマルなドキュメントの一つの重要な側面として、「眺めて考える」というのがある。
それをぼんやりと見ながら考える。他のツールとの使い分けを考える時に、書きかけを見て考える、という事が多い場合はだいたいWikiを使っている。
上記の例でも幾つか、「眺めて考える」というような意味の記述がある。</p>
<p>考えるツールとして何が必要か、みたいな事をあんまり長々と書くのは好きでは無いのだけれど、</p>
<ul>
<li>「かなり高い確率ですぐ書き直す」という事を書くため、変更が簡単であって欲しい</li>
<li>分類の間とかはみ出たあたりに重要な事が出る事があるからそういう余地を残したい</li>
<li>分類の統合、分離、前後の入れ替えなどの再構成が頻繁に起こるので簡単にできて欲しい</li>
</ul>
<p>くらいの期待を満たして欲しい。</p>
<p>また、すぐ書き直すつもりが意外とそのまま残ったりする事もあるので、こういう試行錯誤はローカルのテキストファイルとかでは無くてチームで見える場所でやりたいな、と思っている。</p>
<h3 id="docsとの使い分け">Docsとの使い分け</h3>
<p>Docsの場合、文書の境界を変更するのが手間がかかるが、
逆にそういう境界をはっきりさせたい時にdocsを使うこともある。
前回のDesign Docsの話でもあったように、合意とかフィードバックを目的に、あるミーティングの前に、参加者に必ず読んでもらうことを前提にしたい時とか。</p>
<p>あと、データが膨大なテーブル関連はスプレッドシートを使う事もある。パフォーマンス関連のデータとか。
現在使っているWikiはGitHubのWikiなのでテーブル周りが貧弱なので、あんまり大きなテーブルをここで編集したりはしたくない。Confluenceはもうちょっと頑張れるんだけどなぁ。</p>
<p>あと、そのままで残す意思を込めてdocsで書くものもある。
キックオフにあたりこのプロジェクトで達成したいと思っている事とか、どうしてこのプロジェクトが今まさにやるべき事なのか、とか。</p>
<p>Docsで書いたものはなるべくWikiからリンクを貼るようにしている。</p>
<h3 id="issue-trackerとの使い分け">Issue trackerとの使い分け</h3>
<p>Issue trackerもインフォーマルな情報を残す目的にも使っていて（本来の使い方とかもしている）、使い分けはまぁまぁ曖昧。</p>
<ul>
<li>書いた物がすぐに書き直されると思っている場合はWiki</li>
<li>前後関係とか、複数のセクションをマージしたり、をあとから頻繁にやりたいくなりそうな物はWiki</li>
<li>普段目に入れたくないが必要になった時に見たい、というものはissue（IRのダンプとかパフォーマンスの計測結果とか）</li>
<li>時系列性が高いものはissue</li>
<li>コミットと関連度が高いものはissue</li>
<li>画像を良く入れるものはissue</li>
</ul>
<p>最後の画像は、単純に今使っているGitHubのWikiの制約であって、ツール次第ではWikiでもいいのになぁ、と思っている。
Cookpad時代は <a href="https://gyazo.com/ja">Gyazo</a> があったのでissueじゃなくても良い気はしていた。Gyazo、凄く良いと思うのでもっと標準装備になって欲しいなぁ。</p>
<h3 id="slackの分報との使い分け">Slackの分報との使い分け</h3>
<p>時系列なログとしてはSlackで自分の分報チャンネルを作って、そこでも書いている。</p>
<p>とりあえず何やるかとかとかは分報でつぶやく訳だが、こちらはあまり考える、という事はしていない気がする。
分報でつぶやいていって、何か考えが必要になったらWikiに書く、みたいな事が多い。
そういう時には最初は分報からコピペして編集する事から始めたりもする。</p>
<p>あと分報には「やった、終わった」とか「なかなか良く出来ているな」とか、そうした思いをつぶやいたりする事は多い。</p>
<h3 id="フリーハンドのノート">フリーハンドのノート</h3>
<p>ツリーの構造を考える時とか、バイナリフォーマットで何ビット目から何ビット目までがどうとか、
そのほか図を書きながら考えたい時にはフリーハンドのノートを使っている。
ただ図を描きながら考える時でも、自然言語の記述が長く必要で、それの頻繁な編集が必要な場合はWikiやIssueに移行したりする。</p>
<p>紙のノートとボールペン、タブレットPCとOneNote、GalaxyNote3とLayerPaintなどいろいろと渡りあるているが、
現在はBOOX Note3付属のノートアプリを使っている。だいたいBOOX Note3の付属のノートアプリは紙のノートを置き換え出来たな、とは思っている。</p>
<p>ここで書いたものを共有するのがかったるい、は最近の悩み。現在のプロジェクトでも、OneNoteとDocLibみたいな感じになればいいのになぁ。</p>
<h2 id="同種のツールいろいろ">同種のツールいろいろ</h2>
<p>なんとなくこのトピックに関連するツールというかサービスについて、自分が経験した物についての印象を書いてみる。
触った時期もバラバラで触った度合いもバラバラなので、ツールの説明というよりは自分の考えをもとにした自分の説明。</p>
<h3 id="sharepoint">SharePoint</h3>
<p>自分はもともとSharePointというソフトウェアを開発していたエンジニアなので、当然SharePointが最高ですよ、といいたい所だが、別にそうでも無い。
しかも最近のSharePointは知らない。自分が知っているのは2013まで。</p>
<p>ただ、DocLibは非常に良く出来ていて、OneNoteとの組み合わせは最高だった。Wordとかとの親和性が高いので、そういう物を中心にしつつインフォーマルなものを補助的に組み合わせたい、という時にはなかなか良いとは思う。
あと、もと中の人なのでCAMLとかWebParts書くのは慣れていて、カスタマイズは好きに出来るから、大規模開発で使いたいならいろいろカスタマイズして使っていける。でも今更そんな事はやりたくないな。</p>
<p>Issue tracker的なのは無いですね。</p>
<h3 id="githubのwikiとissue">GitHubのWikiとIssue</h3>
<p>今のプロジェクトはこれ。</p>
<p>GitHubのWikiは、GitHubを使っていれば導入がしやすいのが良い。
Wikiは必要最低限で、嬉しくは無いが、生きてはいける、という印象。</p>
<p>一方、Issue trackerはなかなか良く出来ている。画像も貼りやすいし。
サブチケットとか作れないが、そういう余計な機能が無いのも哲学を感じる所で、良さでもある。
Wikiがもうちょっと良ければなぁ。</p>
<h3 id="jiraとconfluence">JiraとConfluence</h3>
<p>何故か業界標準感のあるJiraとConfluene。
別にこれじゃなきゃいけない理由はそんなに無いと思うのだが、必要な物は一通り入っていて、出来もなかなか良く、これが使えれば自分は不満は無い。
こんないろいろ出来なくてもいいが、これで不満は無い、という感じ。</p>
<p>Jiraはサブチケット切れるので管理はやりやすい。マイクロマネージメント好きな人が居るとうんざりだけど、居なければ悪くない。</p>
<p>Confluenceもテーブル周りのUIとかJiraとの連携とか、ちょこちょこGitHubのWikiよりいいな、という事はある。
この手のツールはそういうものの積み重ねが結構重要だよな、とか思ったりする。</p>
<h3 id="その他いろいろ">その他いろいろ</h3>
<p>Tracを使ってるチームで開発した事もある。そんな不満は無かった。Jira+ConfluenceとGitHubの間くらいの印象。
Tracくらいでいいのでは…という思いはちょっとある。</p>
<p>勉強会でNotionをちょっと使った事はある。そこではあまり有効活用されなかったが、ツール自体は良さそうなので、そのうちちゃんと使ってみたい。</p>
<p>自分が触った事無いので良さそうなのもいろいろありますよね。ここに居る人のそうした体験とかは知りたい気がする（業者の宣伝とかはうんざりなので広く聞きたい気はしない）。</p>

</div>
</div>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
随分いろいろ書いて共有してますね。逆に書くけど共有しないメモとかあるんですか？
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
日報と週報的な箇条書きを書いているけれど、これを共有してないです。
共有してもいいのだけれど、やる気が出ないので午後はお休み、
とか書いてたりするので、共有してないのかな（別にサボるのを隠す必要も無いのだけれど）。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>非同期と並列</title>
      <link>https://messagepassing.github.io/012-manycore/01-morrita/</link>
      <pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/01-morrita/</guid>
      <description>karino2 が 並列プログラムから見たFuture というビデオを作って公開していたので、引っ越しの荷造りをしながら眺めた。
 長いのでここにざっくりとした主張をまとめると:
 Future/Promise (およびその後釜の async/await) は非同期プログラミングで callback hell にならない発明という見方をされているが、 そもそもなぜ callback hell が必要だったかの時代背景が十分に理解されていない。 背景の一つはブラウザ JavaScript のプログラミングモデルにシングルスレッド・ノンブロッキング(イベントループ)という制限があったから。 これは(特にフロントエンド開発者の間では)よく理解されている。 もう一つの視点は SEDA みたいなマルチスレッド・ノンブロッキング環境の必要性で、 こっちはいまいち広く理解されていないように思える。 結果としてサーバやデスクトップなどで C++ (なんで?) を書いているプログラマに Fuure/Promise の重要性を説明する良い資料がない。 なぜ Twitter が Finable を、 Facebook が Folly Future を、 Netflix が ReactiveX を、 Apple が Dispatch を、 Google が ListenableFuture を (一個だけダサいのが混じってるぞ!) 持っているのかが伝わらない。  ので俺が説明してやんよ、という内容。
いいたいことに大きな異論はないのだけれど、 先のビデオは準備不足なのか色々わかりにくい部分もあって議論を続けるのが難しい。 そこでまずは話を整理し、そのあと仕事のコードとかだと実際どうなんですかと人々に聞いてみる回です。
20 年前のデスクトップ: スレッドは雑に作る。UI スレッドはブロックする。 というわけでおっさんの昔話から始まるのだよ・・・。
スレッドの使い方という点でいちばんしょうもない例を見るには、15-25 年くらい前のデスクトップアプリを見ると良い。 この世界ではみんな基本的にシングルスレッドでコードを書いている。 のみならず、UI スレッドをブロックしないという現代の常識すらあまり守られていない。 容赦なくダイアログボックスとかを表示して UI スレッドを止める。 厳密にいうと UI スレッド (イベントループ) は止まっておらず、かわりにネストしている。 ただ細かいことなのでブロックしていると思っておけばだいあいあってる。</description>
      <content:encoded><![CDATA[<p>karino2 が
<a href="https://karino2.github.io/2021/03/05/future_for_parallel.html">並列プログラムから見たFuture</a>
というビデオを作って公開していたので、引っ越しの荷造りをしながら眺めた。</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/eaduJdlCamQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>長いのでここにざっくりとした主張をまとめると:</p>
<ul>
<li>Future/Promise (およびその後釜の async/await) は非同期プログラミングで callback hell にならない発明という見方をされているが、
そもそもなぜ callback hell が必要だったかの時代背景が十分に理解されていない。</li>
<li>背景の一つはブラウザ JavaScript のプログラミングモデルにシングルスレッド・ノンブロッキング(イベントループ)という制限があったから。
これは(特にフロントエンド開発者の間では)よく理解されている。</li>
<li>もう一つの視点は <a href="http://www.sosp.org/2001/papers/welsh.pdf">SEDA</a> みたいなマルチスレッド・ノンブロッキング環境の必要性で、
こっちはいまいち広く理解されていないように思える。</li>
<li>結果としてサーバやデスクトップなどで C++ (なんで?) を書いているプログラマに Fuure/Promise の重要性を説明する良い資料がない。
なぜ Twitter が <a href="https://twitter.github.io/finagle/">Finable</a> を、
Facebook が <a href="https://engineering.fb.com/2015/06/19/developer-tools/futures-for-c-11-at-facebook/">Folly Future</a> を、
Netflix が <a href="http://reactivex.io/">ReactiveX</a> を、
Apple が <a href="https://developer.apple.com/documentation/DISPATCH">Dispatch</a> を、
Google が <a href="https://github.com/google/guava/wiki/ListenableFutureExplained">ListenableFuture</a> を (一個だけダサいのが混じってるぞ!)
持っているのかが伝わらない。</li>
</ul>
<p>ので俺が説明してやんよ、という内容。</p>
<p>いいたいことに大きな異論はないのだけれど、
先のビデオは準備不足なのか色々わかりにくい部分もあって議論を続けるのが難しい。
そこでまずは話を整理し、そのあと仕事のコードとかだと実際どうなんですかと人々に聞いてみる回です。</p>
<h2 id="20-年前のデスクトップ-スレッドは雑に作るui-スレッドはブロックする">20 年前のデスクトップ: スレッドは雑に作る。UI スレッドはブロックする。</h2>
<p>というわけでおっさんの昔話から始まるのだよ・・・。</p>
<p>スレッドの使い方という点でいちばんしょうもない例を見るには、15-25 年くらい前のデスクトップアプリを見ると良い。
この世界ではみんな基本的にシングルスレッドでコードを書いている。
のみならず、UI スレッドをブロックしないという現代の常識すらあまり守られていない。
容赦なくダイアログボックスとかを表示して UI スレッドを止める。
厳密にいうと UI スレッド (イベントループ) は止まっておらず、かわりにネストしている。
ただ細かいことなのでブロックしていると思っておけばだいあいあってる。</p>
<p>非同期なはずの JavaScript の世界で <code>alert()</code> とかがブロックするのは、
こういうプログラミングモデルを前提としたデスクトップ OS の API を使って実装されていたから。
(逆にそういう前提を捨てたモダンブラウザの実装をみると <code>alert()</code> をはじめとする blocking call 周辺はかなりの mess になっている。)</p>
<p>20 年くらいの PC も高いやつだと CPU は 2-4 コアくらいあったので、
すごく時間のかかる計算はスレッドを作って並列化されていた。
ただスレッドの使い方はアドホック。必要なときに新しいスレッドを欲しいだけ作って、タスクを動かして、おしまい。</p>
<h2 id="同時代のサーバサイド-1-リクエスト-1-スレッド">同時代のサーバサイド: 1 リクエスト 1 スレッド</h2>
<p>同じ時代、Web サーバのようなサーバサイドのソフトウェアも同じように素朴だった。
クライアントのリクエストを <code>accept()</code> するスレッドがいて、そのスレッドがリクエストを受け取るたびに新しいスレッドを作り、
ソケットを渡して処理を任せる。
<a href="https://docs.python.org/3/howto/sockets.html">ソケット入門</a>みたいな記事は今でもそういう説明をすることが多いと思う。
概念的にわかりやすいからね。</p>
<p>ただ現実のサーバーでリクエスト単位に新しいスレッドを作るとオーバーヘッドがでかいなど色々と都合が悪いので、
一度作ったスレッドは使いまわすのが普通。 スレッドプールというやつ。
この「都合の悪さ」や「オーバーヘッド」は karino2 の議論で重要なトピックなのだけれど、
今はスルーして先に進もう。</p>
<h2 id="ノンブロッキングサーバ-シングルスレッド">ノンブロッキングサーバ: シングルスレッド</h2>
<p>リクエスト単位でスレッドをつくるアプローチの対極に、一つのスレッドで全てのリクエストをさばくアプローチもある。
こうしたサーバはノンブロッキング I/O の API, 古いところだと <code>select()</code> とか、を使って書かれている。
これだとスレッドが一個しかないので、スレッドを沢山つくる「オーバーヘッド」がない。</p>
<p>この「オーバーヘッド」がなんなのかはやはり議論の余地があるが、
シングルスレッド・ノンブロッキングなサーバではそもそもスレッドが一つしかないので気にしなくていい。
オーバーヘッドの少なさ、並列プログラミングの難しさ（ロックとか）を避けられるある種の単純さもあって、
特にコネクションの寿命が長いチャットみたいなアプリのサーバとして伝統的に割と人気。</p>
<p>一方でマルチコアの CPU では２つ目以降のコアを使い切れない欠点もあり、そのへんは工夫を要する。</p>
<h2 id="がんばるサーバ-seda">がんばるサーバ: SEDA</h2>
<p>リクエスト単位でスレッドを作るかシングルスレッドか。
上で議論したこのトレードオフはどう考えても雑すぎで、
実際はノンブロッキングだけどマルチスレッドにできるのが望ましい。
そういう実装は色々あるが、中でも <a href="https://scholar.google.com/scholar?cluster=6145791245667108590">SEDA</a>
という 2001 年の研究が有名だと思う。
SEDA は I/O を待つメインスレッドもワーカーも全部ノンブロッキングにしてメッセージキューでやり取りする。
具体的にはタスク (&ldquo;Stage&rdquo;) 毎にスレッドプールを作り、そのスレッドプール同士をメッセージキューで繋ぐ。
ノンブロッキングにできない処理(Linux だとファイルの読み書きとか)は、ブロッキング専用のスレッドプールをつくって閉じ込める。</p>
<p>ステージ間の通信に使うキューに小細工することで、従来なら OS のスケジューラががやっていた仕事の一部を
アプリケーションで実装できるようになる。おかげで OS の制限、すなわちオーバーヘッドを避けられるし、
スケジューリングにアプリの都合を加味できる。だから良い。
それが SEDA の主張 (をかなり雑に解釈したもの) である。</p>
<h2 id="スレッド数--コア数">スレッド数 = コア数</h2>
<p>SEDA のデザインは、ある意味では現在でも割と生き延びている。
つまり、用途に応じたスレッドプールを事前に用意し、アプリケーションのコードはみなでそれを使う。
ブロッキングコールは遠慮する。</p>
<p>SEDA では複数のスレッドプールをつくりスループットを調整していたが、そこまでがんばるケースは少ない。
CPU のコア数ぶんだけスレッドがあるデフォルトのスレッドプールをひとつだけ用意するほうが普通。
おまけでファイル操作のようなブロッキング IO 用のスレッドプールがついてくる場合もある。
<a href="https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-dispatchers/index.html">Kotlin の Dispatchers</a>,
<a href="https://kotlin.github.io/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-dispatchers/index.html">RxJava の Schedulers</a>,
<a href="https://docs.rs/tokio/1.4.0/tokio/#cpu-bound-tasks-and-blocking-code">Tokio</a>,
<a href="https://golang.org/pkg/runtime/#GOMAXPROCS">GOMAXPROCS</a>,
などなど。</p>
<h2 id="がんばるデスクトップアプリ">がんばるデスクトップアプリ</h2>
<p>karino2 のビデオでは、二千ゼロ年代中盤の巨大な Windows アプリの開発が同様の問題（OS スレッドのスケーラビリティ不足）にぶつかり、
同様の解決に至った経緯を紹介している。すなわちコア数にあわせたスレッドプールをつくってノンブロッキングにがんばる。</p>
<p>ゼロ年代の世の中は割とウェブ全盛で、クライアントサイドというかフロントエンドの人々は
多くがシングルスレッドなブラウザの JS で暮らしていた。けれどデスクトップネイティブ勢はがんばっていたらしい。
言われてみると C# は async/await をメインストリームにもってきた最初の言語だし、
<a href="https://github.com/dotnet/reactive">RX(Reactive Extension)</a> も Microsoft 生まれ。
Windows は色々やっていたのだろう。</p>
<h2 id="ノンブロッキングスレッドプールという合意">ノンブロッキング・スレッドプールという合意</h2>
<p>こうしてマルチコア環境での高性能、高並列アプリケーションの実行モデルはだいたい合意ができた:
OS のスレッドはコア数ぶんだけしかつくらず、スケジューリングとかはユーザ空間でがんばろうではないか。</p>
<p>もちろん OS 自体も進化しており、昔の「オーバーヘッド」の常識は当てはまらない。
たとえば SEDA の書かれた 2001 年に Linux CFS はなかった。
(<a href="https://en.wikipedia.org/wiki/Completely_Fair_Scheduler">Wikipedia によれば 2010 年くらいに有効化されたらしい</a>。)
そんなモダン実装 OS のスレッドに頼ってばんばんブロッキングコールをする作る人々もいる。
たとえ Hadoop のようなバッチ分散コンピューティングはスレッドをじゃんじゃかつくる印象。
伝統的なデータベースの実装も割と OS のスレッドだのみな気がする。
ファイル I/O がブロックするときに非同期とか言われてもやりようがないせいだろうか。</p>
<p>そんなわけで「ノンブロッキング・スレッドプール」が唯一の正解というわけではない。
とはいえメインストリームの一つになったのは間違いない。
プログラミング・ポップカルチャーでは &ldquo;Reactive&rdquo; という呼び名を獲得した。
厳密に Reactive がなんなのかには色々<a href="https://www.reactivemanifesto.org/">議論の余地がある</a>けれど、近似としてはあってると思う。</p>
<h2 id="よりよい抽象を求めて">よりよい抽象を求めて</h2>
<p>ノンブロッキングのコード、高性能なのはいいけれど書くのがだいぶかったるい問題があった。
かったるさの代表例としては JS の <a href="http://callbackhell.com/">calback hell</a> がよく知られている。
でも JS のように first class function がある言語はまだマシで、lambda が入る前の Java や C++ とかマジだるかった。</p>
<p>今でも相変わらずシングルスレッドな JS だけれど
(<a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers">Web Workers</a> とか他の言語からみたら冗談みたいなもんです)
ノンブロッキング、非同期プログラミングのよりよいプログラミングモデルを幅広いプログラマに届けたのも JS だった。
つまり <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Using_promises">Promise</a> と
<a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await">async/await</a> である。
どちらも JS 以前からあったといえばあったとはいえ、さほどメジャーでなかった。
一方 JS (というか ES6) 以降の世代の言語は、だいたい似たような仕組みをもっている。</p>
<p>しかし&hellip; と karino2 は言う。こういう素敵な抽象の恩恵を受けそびれているプログラマがいる。
それは、本来こういう素敵抽象の恩恵を一番うけてしかるべき高性能システム/アプリを書き続けてきた苦難の C++ プログラマたちである。</p>
<p>C++ に限らず他の言語、たとえば Java とかでも非同期の世界に行きそびれてしまった人はそれなりにいる。
とはいえ C++ はそもそも標準にスレッドプールすらないので、広く使われる抽象を作りようがない。
一方で Facebook のように体力のある会社は独自に Future を実装している。なんたる格差社会。
そうしたかわいそうな一部プログラマを啓蒙すべく karino2 は冒頭のビデオを作った。</p>
<h2 id="where-is-the-free-lunch">Where Is The Free Lunch</h2>
<p>ところでここまでの議論は問題領域が intrinsic な平行性をもっている前提だった。
サーバなり大規模デスクトップなり、彼らは平行して処理するタスク(リクエストとか)が多すぎて困っていた。</p>
<p>ゼロ年代の同じ頃、あまり平行でない世の中の別の場所で、人々が別の問題に頭を悩ませていた:
最近の CPU はコアばかり増えてシングルスレッド性能が上がらない！なんとかコードを並列化して最新 CPU を活用しなければ！
そうした声のなかでたぶん一番有名なのが 2005 年に書かれた
&ldquo;<a href="http://www.gotw.ca/publications/concurrency-ddj.htm">The Free Lunch Is Over</a>&rdquo;
という記事。当時はまだ割と元気だった C++ の有名人が世間を煽っている。</p>
<p>この頃からなんとか手元のコードを並列化したい人々の努力が始まり、
たとえば &hellip; 例をあげるとキリがないけど色々なライブラリ、フレームワーク、ツール、言語などなどがでてきた。
わかりやすいところだと
<a href="https://docs.scala-lang.org/overviews/parallel-collections/overview.html">Scala の Parallel Collection</a>
とかね。<a href="https://www.erlang.org/">Erlang</a> がもてはやされはじめたのも同じ頃だった記憶。</p>
<p>更に同じ頃別の場所で、手元にあるすごい速いチップ&hellip; つまり GPU &hellip;を持て余している人たちが <a href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units">GPGPU</a> というのをはじめた。
GPU をうまくつかうのは CPU 以上に難しいが、上手く使うと CPU が足元にもおよばない速さで計算できる。
そんなんじで CUDA が登場したのは 2007 年らしい (<a href="https://en.wikipedia.org/wiki/CUDA">Wikipedia</a> 調べ)。</p>
<h2 id="で最近どうしてる">で、最近どうしてる?</h2>
<p>というかんじで 10 年くらい前に並列や並列ってすごい活発に議論されてたのを、
karino2 のビデオをみたおっさんである森田は思い出したのだった。</p>
<p>今の計算機、たしかにまあまあマルチコアになってる。
ラップトップも 4-16 論理コア/HT くらいあるし、スマホは 8 コア。
クラウドのサーバとか仮想化されてて見えないけど bare-metal なら<a href="https://aws.amazon.com/ec2/instance-types/m5/">高いやつだと 96 vCPU</a> とかある。
AI 人材は暗号通貨人材と GPU を奪い合っている。</p>
<p>そんなコア余りっぽい昨今、みなさんちゃんとコア使ってる？余ってる？足りない？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>いけすかなさの出処</title>
      <link>https://messagepassing.github.io/011-designdocs/06-morrita/</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/06-morrita/</guid>
      <description>Design docs への温度感も、design docs といって想定するものも、けっこう個人差があるのがわかった。
自分は Google がもてはやされていた時代に会社の外からさぞかし良いものに違いないと眺めていた時間が長く、 そのときの印象を拭いきれていないのかもしれない。 会社カルチャーの宣伝を真に受けない大人になったのは、もうちょっとあとなのだった。
ただ design docs への高い期待値はテンプレートにも織り込まれている面がある。 テンプレートを無視すればいいとかずよしさんは言う。じっさい自分は無視しているけれど、 他の人が使う限り冗長で読みにくい design docs が回覧されてきてしまう事実は変わらないんじゃないかな。
Writing Culture むかいさんのいう Chrome の design docs は テンプレート も含め社内のものとは独立して公開されており、これは Chrome 用でサーバサイドからのバイアスとかはない。それに比較的簡素。
一歩さがってみると、チームはそれぞれが必要に応じ自分自身の documentation / writing の (sub)culture をきちんと育てていく必要があって、 そうしないと外側の、自分たちには不似合いな mainstream に飲み込まれてしまう。あるいは文化不在の荒野になってしまう。 自分の不満はそうした不在から来ているのかもしれない。
そして他人が書くものをどうこうしたいと期待するのは不毛だし横柄。 自分はべつに change agent になりたいわけではない。現状は受け入れ、自分が書くものがどうあるべきかに考えを向ける。
説得としての Design Docs かずよしさんやはまじさんのはなしを読んで振り返るに、この手の high-level writing は 具体的なデザインの詳細より問題の分析や説明に労力を割くべきなのだろう。 よくコードのコメントは How ではなく Why を書けとかいうけれど、 それと似ている。自分が書いたものを振り返ると、その点がいまいちだった。
こうした反省を踏まえて最近 push-back されてしまった自分の design docs を時間をかけて書き直し、計画も見直した。 いざミーティング！事前に回覧する時間がなかったので口頭でさっと説明すると、いいんじゃない、みたいなかんじで素通し。 あれ、がんばって書いた渾身の problem analsys とか読んでよ・・・とおもったが、 計画をだいぶ scale down したため人々の警戒が解けたらしい。</description>
      <content:encoded><![CDATA[<p>Design docs への温度感も、design docs といって想定するものも、けっこう個人差があるのがわかった。</p>
<p>自分は Google がもてはやされていた時代に会社の外からさぞかし良いものに違いないと眺めていた時間が長く、
そのときの印象を拭いきれていないのかもしれない。
会社カルチャーの宣伝を真に受けない大人になったのは、もうちょっとあとなのだった。</p>
<p>ただ design docs への高い期待値はテンプレートにも織り込まれている面がある。
テンプレートを無視すればいいとかずよしさんは言う。じっさい自分は無視しているけれど、
他の人が使う限り冗長で読みにくい design docs が回覧されてきてしまう事実は変わらないんじゃないかな。</p>
<h2 id="writing-culture">Writing Culture</h2>
<p>むかいさんのいう <a href="https://www.chromium.org/developers/design-documents">Chrome の design docs</a> は
<a href="https://docs.google.com/document/d/14YBYKgk-uSfjfwpKFlp_omgUq5hwMVazy_M965s_1KA/edit">テンプレート</a>
も含め社内のものとは独立して公開されており、これは Chrome 用でサーバサイドからのバイアスとかはない。それに比較的簡素。</p>
<p>一歩さがってみると、チームはそれぞれが必要に応じ自分自身の documentation / writing の (sub)culture をきちんと育てていく必要があって、
そうしないと外側の、自分たちには不似合いな mainstream に飲み込まれてしまう。あるいは文化不在の荒野になってしまう。
自分の不満はそうした不在から来ているのかもしれない。</p>
<p>そして他人が書くものをどうこうしたいと期待するのは不毛だし横柄。
自分はべつに <a href="https://www.amazon.com/Fearless-Change-Patterns-Introducing-paperback/dp/0134395255">change agent</a>
になりたいわけではない。現状は受け入れ、自分が書くものがどうあるべきかに考えを向ける。</p>
<h2 id="説得としての-design-docs">説得としての Design Docs</h2>
<p>かずよしさんやはまじさんのはなしを読んで振り返るに、この手の high-level writing は
具体的なデザインの詳細より問題の分析や説明に労力を割くべきなのだろう。
よく<a href="https://blog.codinghorror.com/code-tells-you-how-comments-tell-you-why/">コードのコメントは How ではなく Why を書け</a>とかいうけれど、
それと似ている。自分が書いたものを振り返ると、その点がいまいちだった。</p>
<p>こうした反省を踏まえて最近 push-back されてしまった自分の design docs を時間をかけて書き直し、計画も見直した。
いざミーティング！事前に回覧する時間がなかったので口頭でさっと説明すると、いいんじゃない、みたいなかんじで素通し。
あれ、がんばって書いた渾身の problem analsys とか読んでよ・・・とおもったが、
計画をだいぶ scale down したため人々の警戒が解けたらしい。</p>
<p>でも、そのほうが良い。Design docs で他人の説得が必要なくらい規模のある作業は、できればやりたくない。
インクリメンタルにちまちま進められる仕事がしたい。
むかいさんは design docs を各所との調整が求められる大規模開発の税金だという。
言われてみればそのとおりで、自分は調整とかが全然得意でなく、
その事実も design docs への怨嗟を高めていた気がする。</p>
<h2 id="where-is-the-design">Where Is The Design?</h2>
<p>Design docs が実際は説得 docs なのだと考えると、色々腑に落ちる。</p>
<p>たとえば自分がこのごろ気になっている <a href="https://rahulramchandani.com/writing-culture-at-amazon/">Amazon Narrative</a> も、
説得(すなわちミーティングで approval を得るため)のプロセスの話だった。
これじゃあ使いみちは限られているとがっかりしてたけど、design docs も似たようなものだとしたら学べることは多い。</p>
<p>ありのさんのいう design docs のデザイン力過信問題も、説得の方法によってはある程度は緩和できるのではないか。
つまり合意を得る過程で重要なのはまず問題認識(Why)を揃えることで、デザインの細部には踏み込まない方が良い。
雑な first sketch をいくつか示し「これがどのくらい上手く行きそうか試して、よさそうなら進めるしダメそうなら違うの試してまたアップデートしますね」
くらいにしておく。</p>
<p>逆にいうと、この段階で詳しいデザインを議論しなければいけないとしたら、
それは戦略の失敗かもしれない。どうしても詳しい議論をしたいなら、試作で裏付けを取る。</p>
<p>デザインの自由度をある程度担保しつつ説得 docs で問題認識を揃え協力をとりつける。
細かいデザインは、仕事が進むなかでインクリメンタルにアップデートしていく。
決まってない部分はムリに決まったフリをしない。きまった分は必要に応じて事後的に書く。
世の中の多くの design doc がこう書かれているとは思わないし、
これはもはや design doc と呼べるのかもわからない（というか呼べない）けれど、
自分の仕事はそうやって進めるべきな気がしてきた。
Design docs は、もういいです。みんなすきにしてちょうだい。</p>
<p>これだとバーンと大きくなにかを変える仕事はできない。
それは別に design docs や writing culture の問題ではなく、
どちらかというと今の自分の限界なのだろうな。
組織圧に負けず、
プログラマの筋肉をつけて仕事のインクリメントの歩幅を増やし、
視力を高めて調整のいらない道筋を見つけ出し、
バーンとせずとも遠くへ行けるようになりたいものです。
勤務先で楽しく働いているのはそういう人たちな気がする。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>jmuk</div>
<div class='message-body'>
コードのコメントにはwhyを書け、という話でいうと、design docに求められているのはwhyよりはwhy notだと思うんですよね。alternatives consideredは自分はけっこう大事だなーと思っています。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>そんないろいろ言うもんかな</title>
      <link>https://messagepassing.github.io/011-designdocs/05-jmuk/</link>
      <pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/05-jmuk/</guid>
      <description>わたしはかずよしさんと近いところがある。design doc、あると便利なときもたくさんあると思っていて、そんないろいろ言うもんかな、という気がする。ただ自分が書くのは苦手。書くのは正直気が重いが、他の誰かがなにかしてるなら「おいおい軽くでいいからdesign doc書いてくれよ」などと思う。うーん身勝手。
実際のところ、自分が書いたものは mini design doc という程度の規模が多いと思う。クライアント側の機能としてそこまで複雑化はしなかったり、テンプレートのなかに意味のない項目がたくさんあったりということはままある。でもalternativesをいろいろ並べてみて検討してみて、自分がそこまで詳しくないエリアの人から「ここは実はこうなんだけど、それだとうまくいかないんじゃない？」みたいなツッコミを受けられることには意味があるように思う。
期待値の高さ もりたさんの文章を改めて読んでみると、design docというものに対する期待値の高さを感じる。そんなにすごいものだったっけ？　いや、そうやって喧伝されてきたことはあったのかもしれないけれど、今どきもうそこまでのものじゃないんじゃないか。書かれたdesign docをあとから参照せよみたいになることってのも、今どきほとんどないんじゃない？　書かれているように、あとでも読むようなドキュメントは別個にいろんな形態で書かれていて、design docはproposalをつくるのに特化していることも多いんじゃないか。つまり、いろんな面ですでに解体は進んでるんじゃないかなぁ。これはそのチームのカルチャーにもよるような気がするけれど。
もりたさんも私も、サーバサイドのしごとをしていないので、いわば「本流」と離れたところにあるので、本流の側ではどうなのかは、じつはわたしもあんまりよくわからないんだけど。
design docのデメリット ありのさんが言うようなデメリットは、自分は正直あんまり感じたことがない。たとえば、design docが大量発生しても、それはそれでべつに大した問題だとは思わない。そういう人が生産的かというとそうでもない気もするが、design docはそれ自体で成果なわけでもないので、そこにだけ血道を上げる人というのは、そこまで多い気がしない。
design docで書いたことと、じっさいにコードとして書いたことが乖離してしまうこと、これはまあ、けっこうある（こないだもちょっとした提案のドキュメントを書いたが、そこに書いたコードスニペットと最終的にコミットされたものはわりと違うものになった）。でも、だからといって意味がないというわけでもない。問題領域を広く共有して、alternativesを検討してみるというのはそれなりに意味のあるプロセスでもあるし、そこから自分の知らなかったような依存関係や考えないといけなかったディティールを教えてもらったり、ということは実際のところそれなりにあるように思う。
けっきょくのところ要は、変更1個でおわるようなものじゃないなら、いきなりコードを送りつけるんじゃなくて何をしたいのか、どういうことを考えてやったことなのか教えてくれ、という話なんではないか。また、数あるアプローチのうちなぜこのアプローチを採用したか自明でないなら、その理由が知りたくもなる。issueでもいいんだけど、issueはそこまで長々といろいろ検討したりする場でもないし。
design docは大規模開発のためのものか いろいろ検討するとか、レビューするとか、コメントをもらうとか、いろいろ自分の書いていたことから考えて見るに、design docというのは大規模開発に特有のなにかなのではないか、という気がする。design docの主要な役割っていうのは、つまるところ「関係者各位と話を通しておく」というようなことでしかない。
ソフトウェアが複雑化するとすべてを把握するのは大変なので、「この機能、こっちのコンポーネントと関係すると思うけどそっちの人にきいてみたら？　なんか地雷あったら教えてくれるよ」であったりとか、「それこっちのコンポーネント使ったらすぐできるよ」であったりとか、そういうことがままある。「この機能を実現するためにこういうRPCを足して、するとこうなる」みたいな構想でいたところ「いやその方針はやめてほしい。こういうのはどう」みたいな提案があったり、というのも実際に見たことがある。もしかしたらミーティングでもいいのかもしれないけれど、毎回いちから話すのはかったるいし大変だし、記録に残さないとすべて忘れてしまうので、なんらかのテキストを書いてそれをシェアして回るみたいなことになる。そういうものとしてdesign docは生まれた。というのはどうか。
はまじさんがkatiを作った体験談はめちゃくちゃおもしろいが、うかいさんとおおむね二人で新しいものを作ったという話なわけで、たしかにこういうものならdesign docも必要ないだろう。ちょっと口頭で話せば済むので。GNU make知っている人とか、android.mkに詳しいAndroidビルドインフラの人であるとかに聞いてみるというのは、もしかしたら意味のあることだったかもしれないけれど、現実的にはそんなに意味のあることだという感じもしない。そういうふうに始まったプロジェクトのように、ことのおこりにはdesign docがない、みたいなことはありがちなのかもしれない。たとえばChromeそれ自体のdesign docなんてものは、まあないだろう、たぶん。でもChromeのしごとをしていて、新しい機能を提案したかったら今なら軽くdocを書いてシェアしてもらったほうがいいことはたぶん多いはず、みたいにして世の中はまわっているような、そんな気もする。
 shinh そう、まあ必要に応じて書いたらいい、くらいのものですよね。なんか過剰に良い文明扱いされている感がある。 OKR とかもそうだけど、便利な時は使うツール、くらいで良い気がしますね。
ところで Chrome の Design Doc 、見たような気がする（そして「グーグルでブラウザ作ってうまくいくわけないやろ」って笑っていた）けど、単に社内 Wiki に Google Browser という感じのページがあっただけかもしれない。
  karino2 必要に応じて書いたらいい、は自分も思う所で、たぶんそこまではここに居る全員の同意が得られそうかしら？
必要になる頻度が「だいたいのケースで必要」と思うか、「だいたいのケースでは要らない」と思うかという所で、仕事の環境や性質とかカルチャーの違いが出てくるのでは無いかな。
  jmuk そうまあ必要に応じてという話で、そこはたしかに誰もが同意できそう。「だいたいのケースで必要」と「だいたいのケースで不要」はどっちも極論な気がしていて、自分としてはその中間ぐらい。あると便利なこともそこそこあるでしょ、というぐらいかな。で、カルチャーとか仕事の性質のほかにも、チームの規模（人数）とかにもよるんだろうなーとは思いますね。</description>
      <content:encoded><![CDATA[<p>わたしはかずよしさんと近いところがある。design doc、あると便利なときもたくさんあると思っていて、そんないろいろ言うもんかな、という気がする。ただ自分が書くのは苦手。書くのは正直気が重いが、他の誰かがなにかしてるなら「おいおい軽くでいいからdesign doc書いてくれよ」などと思う。うーん身勝手。</p>
<p>実際のところ、自分が書いたものは mini design doc という程度の規模が多いと思う。クライアント側の機能としてそこまで複雑化はしなかったり、テンプレートのなかに意味のない項目がたくさんあったりということはままある。でもalternativesをいろいろ並べてみて検討してみて、自分がそこまで詳しくないエリアの人から「ここは実はこうなんだけど、それだとうまくいかないんじゃない？」みたいなツッコミを受けられることには意味があるように思う。</p>
<h2 id="期待値の高さ">期待値の高さ</h2>
<p>もりたさんの文章を改めて読んでみると、design docというものに対する期待値の高さを感じる。そんなにすごいものだったっけ？　いや、そうやって喧伝されてきたことはあったのかもしれないけれど、今どきもうそこまでのものじゃないんじゃないか。書かれたdesign docをあとから参照せよみたいになることってのも、今どきほとんどないんじゃない？　書かれているように、あとでも読むようなドキュメントは別個にいろんな形態で書かれていて、design docはproposalをつくるのに特化していることも多いんじゃないか。つまり、いろんな面ですでに解体は進んでるんじゃないかなぁ。これはそのチームのカルチャーにもよるような気がするけれど。</p>
<p>もりたさんも私も、サーバサイドのしごとをしていないので、いわば「本流」と離れたところにあるので、本流の側ではどうなのかは、じつはわたしもあんまりよくわからないんだけど。</p>
<h2 id="design-docのデメリット">design docのデメリット</h2>
<p>ありのさんが言うようなデメリットは、自分は正直あんまり感じたことがない。たとえば、design docが大量発生しても、それはそれでべつに大した問題だとは思わない。そういう人が生産的かというとそうでもない気もするが、design docはそれ自体で成果なわけでもないので、そこにだけ血道を上げる人というのは、そこまで多い気がしない。</p>
<p>design docで書いたことと、じっさいにコードとして書いたことが乖離してしまうこと、これはまあ、けっこうある（こないだもちょっとした提案のドキュメントを書いたが、そこに書いたコードスニペットと最終的にコミットされたものはわりと違うものになった）。でも、だからといって意味がないというわけでもない。問題領域を広く共有して、alternativesを検討してみるというのはそれなりに意味のあるプロセスでもあるし、そこから自分の知らなかったような依存関係や考えないといけなかったディティールを教えてもらったり、ということは実際のところそれなりにあるように思う。</p>
<p>けっきょくのところ要は、変更1個でおわるようなものじゃないなら、いきなりコードを送りつけるんじゃなくて何をしたいのか、どういうことを考えてやったことなのか教えてくれ、という話なんではないか。また、数あるアプローチのうちなぜこのアプローチを採用したか自明でないなら、その理由が知りたくもなる。issueでもいいんだけど、issueはそこまで長々といろいろ検討したりする場でもないし。</p>
<h2 id="design-docは大規模開発のためのものか">design docは大規模開発のためのものか</h2>
<p>いろいろ検討するとか、レビューするとか、コメントをもらうとか、いろいろ自分の書いていたことから考えて見るに、design docというのは大規模開発に特有のなにかなのではないか、という気がする。design docの主要な役割っていうのは、つまるところ「関係者各位と話を通しておく」というようなことでしかない。</p>
<p>ソフトウェアが複雑化するとすべてを把握するのは大変なので、「この機能、こっちのコンポーネントと関係すると思うけどそっちの人にきいてみたら？　なんか地雷あったら教えてくれるよ」であったりとか、「それこっちのコンポーネント使ったらすぐできるよ」であったりとか、そういうことがままある。「この機能を実現するためにこういうRPCを足して、するとこうなる」みたいな構想でいたところ「いやその方針はやめてほしい。こういうのはどう」みたいな提案があったり、というのも実際に見たことがある。もしかしたらミーティングでもいいのかもしれないけれど、毎回いちから話すのはかったるいし大変だし、記録に残さないとすべて忘れてしまうので、なんらかのテキストを書いてそれをシェアして回るみたいなことになる。そういうものとしてdesign docは生まれた。というのはどうか。</p>
<p>はまじさんがkatiを作った体験談はめちゃくちゃおもしろいが、うかいさんとおおむね二人で新しいものを作ったという話なわけで、たしかにこういうものならdesign docも必要ないだろう。ちょっと口頭で話せば済むので。GNU make知っている人とか、android.mkに詳しいAndroidビルドインフラの人であるとかに聞いてみるというのは、もしかしたら意味のあることだったかもしれないけれど、現実的にはそんなに意味のあることだという感じもしない。そういうふうに始まったプロジェクトのように、ことのおこりにはdesign docがない、みたいなことはありがちなのかもしれない。たとえばChromeそれ自体のdesign docなんてものは、まあないだろう、たぶん。でもChromeのしごとをしていて、新しい機能を提案したかったら今なら軽くdocを書いてシェアしてもらったほうがいいことはたぶん多いはず、みたいにして世の中はまわっているような、そんな気もする。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
<p>そう、まあ必要に応じて書いたらいい、くらいのものですよね。なんか過剰に良い文明扱いされている感がある。 OKR とかもそうだけど、便利な時は使うツール、くらいで良い気がしますね。</p>
<p>ところで Chrome の Design Doc 、見たような気がする（そして「グーグルでブラウザ作ってうまくいくわけないやろ」って笑っていた）けど、単に社内 Wiki に Google Browser という感じのページがあっただけかもしれない。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>必要に応じて書いたらいい、は自分も思う所で、たぶんそこまではここに居る全員の同意が得られそうかしら？</p>
<p>必要になる頻度が「だいたいのケースで必要」と思うか、「だいたいのケースでは要らない」と思うかという所で、仕事の環境や性質とかカルチャーの違いが出てくるのでは無いかな。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>jmuk</div>
<div class='message-body'>
そうまあ必要に応じてという話で、そこはたしかに誰もが同意できそう。「だいたいのケースで必要」と「だいたいのケースで不要」はどっちも極論な気がしていて、自分としてはその中間ぐらい。あると便利なこともそこそこあるでしょ、というぐらいかな。で、カルチャーとか仕事の性質のほかにも、チームの規模（人数）とかにもよるんだろうなーとは思いますね。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>あまり感情を持ってない</title>
      <link>https://messagepassing.github.io/011-designdocs/04-shinh/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/04-shinh/</guid>
      <description>僕は Design Doc に対して、あまり感情を持ってない。「Design Doc は最高です！」みたいな話を聞くと鼻白むものもあるけど、有用なケースもあると思う。ただ好悪は置いておいて、めんどくさいから書きたくない。実際のところ、ほぼ書いたことがない。
よりよい未来のため Design Doc は未来の失敗を回避するために有用なのはわかる。特にグーグルのサーバサイドの文化という気がするんだよなあ。グーグルは共有のインフラがすごく多くて、共有のライブラリもものすごく多くて、全てを把握してから開発に入るのは不可能。ひょっとしたら同じものあるかも、と思いつつも Design を書いたら、それは XX でできるよ、ということはありそう。
あと、グーグルの Design Doc のテンプレートには privacy concerns や security concerns という項目があって、こういうのはプロダクトのデザインをひっくり返す可能性がある割に専門家が少なく、前もって相談しておくのは有用だろう。それと最初の方の Background とか Motivation も地味に重要な項目だと思っていて、「それってそもそもやる意味ある？」と実装してからなってしまうのを防ぐ効果もあるように思う。単に自分が解きたいから、解けるから、という理由で存在しない問題に取り組んでしまう人というのが、一定数存在すると思っている。（これはかなりブーメランである）
というわけで、自分より特定領域を知ってる人がいる時に相談する手段としては、まあ割と良いのではないでしょうか。知らんけど……
過去を自分語りする楽しさと、有益さ 設計と言ってもハイレベルから細かいとこまで色々で、ハイレベルなところでは割と有用なんじゃないかな、というのが前段で言いたかったことかもしれない。例えば使うコンポーネント選択とか RPC の流れレベルのハイレベルな決定には有用そうな気がする。 それより細かい話になってくると、 morita さんの「不確実性の軽視」や karino さんの「Design力が過大評価」の話になると思うんだけど、正直実装を書いてるうちにそのレベルの設計はガンガン変わってくるよね、となる気がする。 どうせ実装やってる間に細かい設計はガンガン変わっていくのだから……という意味で、 kzys さんの「デザインの前にプロトタイプ作ります」とかすごく僕は好みの考え方。ホントそれでいいと思うなあ。やってみてわかることってやっぱり多いと思うし。前段で批判した「存在しない問題を解いたけど誰も困ってなかったらから誰も幸せにならなかった」的な状況でさえ、何もしてないよりは成長が得られるだろうし。その様子をハタで見てると「それ事前に相談しておいてくれればもう少し筋の良い提案ができたのに……」となることもあるだろうけど。
グーグルでは一応 Design Doc を現状の design と一致するように更新することが推奨されていた……と思ってたけど、 morita さんがそう言っていないので、あまり自信はない。いずれにせよ多くの Design Doc は実装以降アップデートされてないので、 morita さんの「「古くなってるけどだいたい合ってるよね」という感じで読まれる想定がある」はそのとおりだったと思うし、そこらへんに読むのですらだるくなってしまう理由があるのだと思う。「なんで後で間違ってると判明したかもしれない設計を熱心に読まないとダメなんだ？」ってなりそう。 そんな理由で、細かめの設計は、なんかむしろ事前に書くより後で書くのがよいのかもしれないな、と思った。 morita さんの言及していた ARCHITECTURE.md のように。事前に書くより実際のコードの設計と一致してる可能性が高いので後から参照された時の有用性も高そうだし。僕は割と自分語りが好きというか、ドヤりたい性分なので、そういうのは割と書いたりする。
僕の好みのスタイルと、 kati の例と というわけで、事前段階ではモチベーションの確認、他プロジェクトとの関連性、大枠のデザインに激しく影響する部分だけ必要なら Design Doc なりなんなりで議論して、さっさと実装して、うまくいったら ARCHITECTURE.md を書いてドヤる、というのが僕としては好みなのかな、と思った。ところで、この文章も特に考えをまとめてから書いてないので、この章を書き始めたあたりで、「僕は考えをまとめながら進めるのが好きなのだなあ」と自分の嗜好を自覚した状態。
これを書く前の事前の相談で kati とか Design Doc とかどうしたの？と聞いてもらったのだけど、ちょうどそういう、あまり事前に相談せず後で説明を書くスタイルだった気がするので書いてみる。</description>
      <content:encoded><![CDATA[<p>僕は Design Doc に対して、あまり感情を持ってない。「Design Doc は最高です！」みたいな話を聞くと鼻白むものもあるけど、有用なケースもあると思う。ただ好悪は置いておいて、めんどくさいから書きたくない。実際のところ、ほぼ書いたことがない。</p>
<h2 id="よりよい未来のため">よりよい未来のため</h2>
<p>Design Doc は未来の失敗を回避するために有用なのはわかる。特にグーグルのサーバサイドの文化という気がするんだよなあ。グーグルは共有のインフラがすごく多くて、共有のライブラリもものすごく多くて、全てを把握してから開発に入るのは不可能。ひょっとしたら同じものあるかも、と思いつつも Design を書いたら、それは XX でできるよ、ということはありそう。</p>
<p>あと、グーグルの Design Doc のテンプレートには privacy concerns や security concerns という項目があって、こういうのはプロダクトのデザインをひっくり返す可能性がある割に専門家が少なく、前もって相談しておくのは有用だろう。それと最初の方の Background とか Motivation も地味に重要な項目だと思っていて、「それってそもそもやる意味ある？」と実装してからなってしまうのを防ぐ効果もあるように思う。単に自分が解きたいから、解けるから、という理由で存在しない問題に取り組んでしまう人というのが、一定数存在すると思っている。（これはかなりブーメランである）</p>
<p>というわけで、自分より特定領域を知ってる人がいる時に相談する手段としては、まあ割と良いのではないでしょうか。知らんけど……</p>
<h2 id="過去を自分語りする楽しさと有益さ">過去を自分語りする楽しさと、有益さ</h2>
<p>設計と言ってもハイレベルから細かいとこまで色々で、ハイレベルなところでは割と有用なんじゃないかな、というのが前段で言いたかったことかもしれない。例えば使うコンポーネント選択とか RPC の流れレベルのハイレベルな決定には有用そうな気がする。
それより細かい話になってくると、 morita さんの「不確実性の軽視」や karino さんの「Design力が過大評価」の話になると思うんだけど、正直実装を書いてるうちにそのレベルの設計はガンガン変わってくるよね、となる気がする。
どうせ実装やってる間に細かい設計はガンガン変わっていくのだから……という意味で、 kzys さんの「デザインの前にプロトタイプ作ります」とかすごく僕は好みの考え方。ホントそれでいいと思うなあ。やってみてわかることってやっぱり多いと思うし。前段で批判した「存在しない問題を解いたけど誰も困ってなかったらから誰も幸せにならなかった」的な状況でさえ、何もしてないよりは成長が得られるだろうし。その様子をハタで見てると「それ事前に相談しておいてくれればもう少し筋の良い提案ができたのに……」となることもあるだろうけど。</p>
<p>グーグルでは一応 Design Doc を現状の design と一致するように更新することが推奨されていた……と思ってたけど、 morita さんがそう言っていないので、あまり自信はない。いずれにせよ多くの Design Doc は実装以降アップデートされてないので、 morita さんの「「古くなってるけどだいたい合ってるよね」という感じで読まれる想定がある」はそのとおりだったと思うし、そこらへんに読むのですらだるくなってしまう理由があるのだと思う。「なんで後で間違ってると判明したかもしれない設計を熱心に読まないとダメなんだ？」ってなりそう。
そんな理由で、細かめの設計は、なんかむしろ事前に書くより後で書くのがよいのかもしれないな、と思った。 morita さんの言及していた ARCHITECTURE.md のように。事前に書くより実際のコードの設計と一致してる可能性が高いので後から参照された時の有用性も高そうだし。僕は割と自分語りが好きというか、ドヤりたい性分なので、そういうのは割と書いたりする。</p>
<h2 id="僕の好みのスタイルと-kati-の例と">僕の好みのスタイルと、 kati の例と</h2>
<p>というわけで、事前段階ではモチベーションの確認、他プロジェクトとの関連性、大枠のデザインに激しく影響する部分だけ必要なら Design Doc なりなんなりで議論して、さっさと実装して、うまくいったら ARCHITECTURE.md を書いてドヤる、というのが僕としては好みなのかな、と思った。ところで、この文章も特に考えをまとめてから書いてないので、この章を書き始めたあたりで、「僕は考えをまとめながら進めるのが好きなのだなあ」と自分の嗜好を自覚した状態。</p>
<p>これを書く前の事前の相談で kati とか Design Doc とかどうしたの？と聞いてもらったのだけど、ちょうどそういう、あまり事前に相談せず後で説明を書くスタイルだった気がするので書いてみる。</p>
<p><a href="https://github.com/google/kati">kati</a> というのは数年前に書いた、 GNU make の Android のための中途半端な別実装。 make がクッソ遅いというあからさまな問題があり、 motivation は明快だった。 drop-in-replacement を指向していたので、関連プロジェクトもない。というわけで Design Doc とかは一切書いてない。その前のプロジェクトの都合もあり、 Android.mk という GNU make の上で構築されたビルドシステムが何をしてるからはだいたいわかっていたので、なにかをキャッシュすれば速くなる、とは思っていたと思う。</p>
<p>それ以上のことは何も設計してないし、まさに「デザインの前にプロトタイプ作ります、うまいこといったらそのまま本番ということで」スタイルの進行だった。 GNU make 、ユーザとしてはある程度知ってるつもりだったし、一緒にやっていた <a href="http://ukai.jp/">ukai さん</a>も僕も簡単な言語処理系くらいならサックリ書けるでしょ、くらいの自信はあった。でも、実装を書いてみると知らないことがたくさんあり、 ukai さんと二人で理解を深める手段として実装を書いていったような感じだったと思う。普通に考えてこういう処理してるでしょ、みたいな予想を GNU make が次々と外してくるので、激しくお互いのコードを書き直しまくってたいたように思う。関係ないけど、思い出すにこれも含めて ukai さんとの作業は楽しかったなあ。また機会があれば、と思う。</p>
<p>「なにかをキャッシュする」ことにより劇的に速くなる予定だったので、たぶん Go でいいでしょ、と書いていて、そのまま本番で使うつもりで実装をしていた（ukai さんが Go ファンなので、リクルートする口実になるという事情もあった）。だけど、そのうちに、これでは速度的に気に入らないなあ、と C++ で書き直したので、事後的に最初に書いていた実装はプロトタイプだった、ということになった。 C++ の再実装も、 Go の経験があるぶんやり直しは少なかったけど、後になって判明した必要な機能で全体をいじったり、高速化のためのアレコレを入れたり、割と最後の方で make の drop-in-replacement という方針を放棄して ninja を生成する方針に切り替えたせいで設計が少し変わったり、割と有機的に変化を続けていた。</p>
<p>このへんは Design Doc で事前相談してたら防げていた出戻りだったんだろうか。そんな気がする部分もあるけど、深く考えず実装を進めていったからこそ気付いた問題もある気がしている。このいきあたりばったりとしか言いようがないワチャワチャやってる時に、信頼してるのかダメ元なのか、とにもかくにも猶予をくれていた当時のマネージャの懐の広さには感謝している。僕なら止めるし、僕はマネージャの類になってはならない、と思う所以でもある。</p>
<p>こんな感じでやけに長く経緯を書くことから分かる通り、僕は自分がうまくやったことを語りたいタイプであり、自分が面白い、ここは変だ、工夫した、頑張った、など書くのは楽しく、ポエムを書いた。日本語だと<a href="http://shinh.hatenablog.com/entry/2015/09/24/005803">これ</a> で英語だと<a href="https://github.com/google/kati/blob/master/INTERNALS.md">これ</a> 。これは割と ARCHITECTURE.md 的な役割を果たしたのかもしれない。 kati はその後 US の人がメンテしていてくれて、ごくまれにグーグル外の人も話題にしてくれているのを見るのだけど、ここに書いたようなことはわかっている前提で会話していてくれるような気がしていて、ひょっとしたら書いた意味があったのかなあ、などと思っている。まあでもおおむね自己満足という意味合いが強い気がする。</p>
<p>逆に失敗談も書いておくと、 kati の直後にやった <a href="https://docs.google.com/document/d/1eRSNE352rA6ocyoFljHQW2ySdhg9oKN8CHj2ljrlKX0/edit">Dependency Sanitizer</a> というやつは、プロトタイプもよく動いていたし、
名前もかっこいいし、自分が書いたドキュメントでは最も Design Doc に近い体裁だったと思っているんだけど、びっくりするほど全く人の興味を得られず、悲しい感じで立ち消えていってしまった。今でも良いコンセプトだったと思ってるので、何が悪かったんだろうなあ……と時々思い返している。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
Ukai-san といえば、自分が Design doc という名前を初めて耳にしたのは Ukai-san の techtalk だった気がする。<a href="https://www.youtube.com/watch?v=pc-IQkVmOdI">これ</a>かな？
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
結局ninja生成するようになった、というあたりはいい話ですね。
そういう事は多いと思うんだよなぁ。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>不安とコード</title>
      <link>https://messagepassing.github.io/010-wced/05-morrita/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/05-morrita/</guid>
      <description>皆の話を読んで、 自分の「仕事の成果を出すためにいつもコードを書く」論は現実というより願望なのだと気づいた。 仕事で成果を出したいならコードを書く以外にもやるべきことは色々あって、 そういうのはさぼらずやったほうが成果はでる。調査とか説得とか協議とか。ただやりたくない。
同じように「よく考える」みたいな曖昧で前の見えない時間の使い方にも不安を感じ、 コードという tangible な存在に頼ってしまう。 コードを頼りに考えを進められるからコードを書く・・・と言えればかっこいいけれど、 自分は必ずしもそういう類のコードを優先しているとは言えない。
一歩下がると、コードを書かずにいる不安が根にある。
会社員プログラマ、偉くなるとコードを書かなくなるのはよく知られた事実だけれど、 偉くない平社員でもあんまりコードを書かない人はいる。 それでも意味のある貢献はできる。組織がでかいと特に。 自分は厳密には会社員プログラマではなく会社員ソフトウェア・エンジニアで、 広義のソフトウェア・エンジニアリングはプログラミング以外にも割と色々ある。 自分が「雑用」と読んでいる仕事たちの裾野は広い。
一方で、コードを書かないでいるとプログラミングができなくなってしまう、 「雑用」の人になってしまうのではと気が気でない。 だからコードを書いて雑用だけでない自分を確かめたい。 向井さんがいう「マネージャの趣味的なコード書き」に通じるものがある。
以前はまじさんが難しいコードを家で書けばいいと言っていた。 これはコード全般にいえるのかもしれない。 コードを書きたい不満や書いていない不安は仕事の外で晴らしておき、仕事は成果にフォーカスする。
自分は残念ながらそこまでストイックでなく、家ではコードを書くのかわりに ブログを書いたりインターネットしたりしちゃってる。 家でもっとコード書くぞ！・・・と宣言するガッツはないけれど、 今日こうして不安の存在に気づけたのはよかった。</description>
      <content:encoded><![CDATA[<p>皆の話を読んで、
自分の「仕事の成果を出すためにいつもコードを書く」論は現実というより願望なのだと気づいた。
仕事で成果を出したいならコードを書く以外にもやるべきことは色々あって、
そういうのはさぼらずやったほうが成果はでる。調査とか説得とか協議とか。ただやりたくない。</p>
<p>同じように「よく考える」みたいな曖昧で前の見えない時間の使い方にも不安を感じ、
コードという tangible な存在に頼ってしまう。
コードを頼りに考えを進められるからコードを書く・・・と言えればかっこいいけれど、
自分は必ずしもそういう類のコードを優先しているとは言えない。</p>
<p>一歩下がると、コードを書かずにいる不安が根にある。</p>
<p>会社員プログラマ、偉くなるとコードを書かなくなるのはよく知られた事実だけれど、
偉くない平社員でもあんまりコードを書かない人はいる。
それでも意味のある貢献はできる。組織がでかいと特に。
自分は厳密には会社員プログラマではなく会社員ソフトウェア・エンジニアで、
広義のソフトウェア・エンジニアリングはプログラミング以外にも割と色々ある。
自分が「雑用」と読んでいる仕事たちの裾野は広い。</p>
<p>一方で、コードを書かないでいるとプログラミングができなくなってしまう、
「雑用」の人になってしまうのではと気が気でない。
だからコードを書いて雑用だけでない自分を確かめたい。
向井さんがいう「マネージャの趣味的なコード書き」に通じるものがある。</p>
<p>以前はまじさんが<a href="https://messagepassing.github.io/006-hitech/03-shinh/">難しいコードを家で書けばいい</a>と言っていた。
これはコード全般にいえるのかもしれない。
コードを書きたい不満や書いていない不安は仕事の外で晴らしておき、仕事は成果にフォーカスする。</p>
<p>自分は残念ながらそこまでストイックでなく、家ではコードを書くのかわりに
ブログを書いたりインターネットしたりしちゃってる。
家でもっとコード書くぞ！・・・と宣言するガッツはないけれど、
今日こうして不安の存在に気づけたのはよかった。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>毎日は書いてないが、言わんとする事は分かる</title>
      <link>https://messagepassing.github.io/010-wced/04-karino2/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/04-karino2/</guid>
      <description>WCEDという物自体を今回初めて知ったし、 毎日コードを書く事は意識していなかったし、WCEDしてない。
自分の仕事でのコード書きはどんな感じか オリジナルのWCEDとmorritaさんの話は既に結構違う所なので、 仕事でどうなの？という事だと思うのだけれど、 自分は毎日は書いていないと思う。 そもそも毎日働いてはいないのもあるが（今は60%稼働の契約なので週休4日）、 稼働日も毎日はコードを書いてはいない。
今回の仕事は、大雑把には「今から作るプロダクトが業界でNo.1になるのに必要な機能を作ってくれ、何を作るかは好きに決めてくれ（意訳）」みたいな仕事だ。 何を作るかも自分で勝手に考える（相談はするが）し、割と綺麗に切れている大きめの機能をスクラッチから単独で数ヶ月かけて実装するものが多い。 チームが小さすぎてレビューを頼める相手が居ない事情もあり、 レビュー待ちとかミーティングとかはほぼゼロ。コードを書く以外の仕事は無い。
だいたい2週間くらい何かを調査し、3ヶ月〜半年くらい掛けて実装するみたいなのが多い。 調査期間の2週間くらいはほとんどコードを書いていなくて、 実装期間である三ヶ月〜半年の間はほぼ毎稼働日コードを書いていると思う。
ただ実装期間でもたまに一日以上調査が必要になる事もあって、 完全に毎日という訳では無く、たまに空く日はある。 でもこれはそんなに頻度は多く無いかな。数週間に一回とかのレベル。 これはmorritaさんの言う２つ目のパターンですね。jmukが言っているのも同じ感じに思う。
一日の稼働日のほぼすべてが調査とコーディングだけ。それ以外の時間はほぼ無い。 実際は一日中コード書くのは大変なので、午前中だけの日とか夜だけの日ともある。一週間ではだいたい3稼働日くらいの労働量という形態になっている。
だから毎日書いてはいないけれど、コードを書く量に関しては結構な量書けていて、コードとしてのアウトプットにはまぁまぁ満足している。
コードを書く事、前に一歩進む事 自分はmorritaさんのエントリを見て、Joelの射撃しつつ前進の話を思い出した。
メールとか経費精算とかミーティングとかで、コード書きになかなか取りかかれない。 そんななか毎日ちょっとでも、FogBUGZのカラースキームを改良することだけでも、 とにかくコードを書けていればOKだ・・・という話。
雑用と、パフォーマンス計測とかで時間を溶かすのとは違う気もするけれど、 なんとかコーディングの時間を捻出してそれにしがみつくのが大切な事なのでは？ というのは似た話に感じた。
もともとmorritaさんの言っているバグレポート解析とかコードレビューとか性能問題の分析というのは、 無駄な雑用という訳でも無いし、それ自体コードを書くより価値がある場合もある。 メールとかはだいたい無駄な気もするけれど、これだって必要と思っているから書いているはず。
でも、あとで振り返った時に、そうした活動があまり価値を生んでないように感じる事はあるんだよなぁ。 四半期を振り返って「あれ？これだけしかやってないのはどうなんだ？」というような。 そしてこの感覚はだいたい正しいとも思う。
コードを書くという選択 ソフトウェア開発の仕事でも、なるべくコードを書かないで済ますのが重要な仕事とか、 人の仕事を助けるような形でチーム全体のアウトプットを増やすのが重要な仕事とか、 いろんな形態がある。 コードを書くというのがいつも前に一歩進んでいる事で、それ以外がいつも無駄という訳では無い。
一方でコードを書く事で前進するような仕事はあるし、 「自分の今の仕事はそういう物でありたい」という希望の元に日々頑張ってコードを書く選択をすることもあると思う。 コードを書く事が一歩進む事であるというよりは、コードを書く事が一歩になるような仕事をするという。
自分は今は「コードを書く事が重要な仕事」を選んで受けている。 Individual Contributorとして、自分１人で書くコードでシニアとしての存在価値を示すのを最近の自分のテーマとしている。 仕事を選ぶ段階で「コードを書くという事が前進となっている仕事」を選択している。
結局我々はプログラムが好きなので、そういう選択をするのもまぁ当然ではあるよなぁ。
余談だけど、Individual Contributorって日本語ではなんて言うんですかね？
 morrita 射撃しつつ前進! そうかも。潜在意識で影響受けてそう。ジョエル世代というやつですねえ。
IC は自分は語弊があるのは承知で「平社員」と意訳することが多いかな。 Senior engineer だと「一人前の平社員」でそれより偉いと「できる平社員」。
  karino2 その分類だとたぶん「できる平社員」は結構ラダー高いICですよね。 めちゃくちゃ凄い人なのに言葉から漂うゆるふわ感（笑）</description>
      <content:encoded><![CDATA[<p>WCEDという物自体を今回初めて知ったし、
毎日コードを書く事は意識していなかったし、WCEDしてない。</p>
<h3 id="自分の仕事でのコード書きはどんな感じか">自分の仕事でのコード書きはどんな感じか</h3>
<p>オリジナルのWCEDとmorritaさんの話は既に結構違う所なので、
仕事でどうなの？という事だと思うのだけれど、
自分は毎日は書いていないと思う。
そもそも毎日働いてはいないのもあるが（今は60%稼働の契約なので週休4日）、
稼働日も毎日はコードを書いてはいない。</p>
<p>今回の仕事は、大雑把には「今から作るプロダクトが業界でNo.1になるのに必要な機能を作ってくれ、何を作るかは好きに決めてくれ（意訳）」みたいな仕事だ。
何を作るかも自分で勝手に考える（相談はするが）し、割と綺麗に切れている大きめの機能をスクラッチから単独で数ヶ月かけて実装するものが多い。
チームが小さすぎてレビューを頼める相手が居ない事情もあり、
レビュー待ちとかミーティングとかはほぼゼロ。コードを書く以外の仕事は無い。</p>
<p>だいたい2週間くらい何かを調査し、3ヶ月〜半年くらい掛けて実装するみたいなのが多い。
調査期間の2週間くらいはほとんどコードを書いていなくて、
実装期間である三ヶ月〜半年の間はほぼ毎稼働日コードを書いていると思う。</p>
<p>ただ実装期間でもたまに一日以上調査が必要になる事もあって、
完全に毎日という訳では無く、たまに空く日はある。
でもこれはそんなに頻度は多く無いかな。数週間に一回とかのレベル。
これは<a href="https://messagepassing.github.io/010-wced/01-morrita/">morritaさんの言う２つ目のパターン</a>ですね。<a href="https://messagepassing.github.io/010-wced/03-jmuk/">jmukが言っているの</a>も同じ感じに思う。</p>
<p>一日の稼働日のほぼすべてが調査とコーディングだけ。それ以外の時間はほぼ無い。
実際は一日中コード書くのは大変なので、午前中だけの日とか夜だけの日ともある。一週間ではだいたい3稼働日くらいの労働量という形態になっている。</p>
<p>だから毎日書いてはいないけれど、コードを書く量に関しては結構な量書けていて、コードとしてのアウトプットにはまぁまぁ満足している。</p>
<h3 id="コードを書く事前に一歩進む事">コードを書く事、前に一歩進む事</h3>
<p>自分はmorritaさんのエントリを見て、Joelの<a href="https://megalodon.jp/ref/2011-0824-1248-00/japanese.joelonsoftware.com/Articles/FireAndMotion.html">射撃しつつ前進</a>の話を思い出した。</p>
<p>メールとか経費精算とかミーティングとかで、コード書きになかなか取りかかれない。
そんななか毎日ちょっとでも、FogBUGZのカラースキームを改良することだけでも、
とにかくコードを書けていればOKだ・・・という話。</p>
<p>雑用と、パフォーマンス計測とかで時間を溶かすのとは違う気もするけれど、
なんとかコーディングの時間を捻出してそれにしがみつくのが大切な事なのでは？
というのは似た話に感じた。</p>
<p>もともとmorritaさんの言っているバグレポート解析とかコードレビューとか性能問題の分析というのは、
無駄な雑用という訳でも無いし、それ自体コードを書くより価値がある場合もある。
メールとかはだいたい無駄な気もするけれど、これだって必要と思っているから書いているはず。</p>
<p>でも、あとで振り返った時に、そうした活動があまり価値を生んでないように感じる事はあるんだよなぁ。
四半期を振り返って「あれ？これだけしかやってないのはどうなんだ？」というような。
そしてこの感覚はだいたい正しいとも思う。</p>
<h3 id="コードを書くという選択">コードを書くという選択</h3>
<p>ソフトウェア開発の仕事でも、なるべくコードを書かないで済ますのが重要な仕事とか、
人の仕事を助けるような形でチーム全体のアウトプットを増やすのが重要な仕事とか、
いろんな形態がある。
コードを書くというのがいつも前に一歩進んでいる事で、それ以外がいつも無駄という訳では無い。</p>
<p>一方でコードを書く事で前進するような仕事はあるし、
「自分の今の仕事はそういう物でありたい」という希望の元に日々頑張ってコードを書く選択をすることもあると思う。
コードを書く事が一歩進む事であるというよりは、コードを書く事が一歩になるような仕事をするという。</p>
<p>自分は今は「コードを書く事が重要な仕事」を選んで受けている。
Individual Contributorとして、自分１人で書くコードでシニアとしての存在価値を示すのを最近の自分のテーマとしている。
仕事を選ぶ段階で「コードを書くという事が前進となっている仕事」を選択している。</p>
<p>結局我々はプログラムが好きなので、そういう選択をするのもまぁ当然ではあるよなぁ。</p>
<p>余談だけど、Individual Contributorって日本語ではなんて言うんですかね？</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>射撃しつつ前進! そうかも。潜在意識で影響受けてそう。ジョエル世代というやつですねえ。</p>
<p>IC は自分は語弊があるのは承知で「平社員」と意訳することが多いかな。
Senior engineer だと「一人前の平社員」でそれより偉いと「できる平社員」。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
その分類だとたぶん「できる平社員」は結構ラダー高いICですよね。
めちゃくちゃ凄い人なのに言葉から漂うゆるふわ感（笑）
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>半分くらいわかる</title>
      <link>https://messagepassing.github.io/011-designdocs/03-kzys/</link>
      <pubDate>Thu, 11 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/03-kzys/</guid>
      <description>morrita さん、karino2 さんのいう嫌さは半分くらいわかるかなあ。
「Design Doc 書いてください」というのが、設計が終わったあとに実装がはじまる直線的なソフトウェア開発や、設計が難しい/偉くて実装はそうでもないという、上流工程偏重な職業感を想起させるというのはわかる。無駄な Design Doc が書かれがちなのもわかる。文章がないことに文句を言う人は多いけれど、文章があることに文句を言う人は少ない。でもまあ、無駄な実装よりは無駄な Design Doc の方がマシかなあ。
あと、Design Doc を書かなくてはいけないときは、それなりに大手術になってしまう変更を入れるときで、それは初期の設計のダメさであるとか、機能のつけすぎの現れじゃないか、と思うこともある。炎上プロジェクトには、それを消火してくれるヒーローが現れるように、柔軟性のない巨大ソフトウェアには、それを乗り切るための Design Doc が必要なんじゃないか。
一方で、テンプレートが新規のサーバーサイドのシステムを開発するのを想定しているとか、将来に誰かに読まれそうな期待というのはよくわからない。あわないテンプレートは無視すればいいし、昔に書かれた Design Doc を参照するのは自己責任で、書き手がそれを意識する必要はなくない?
Is it that Design Doc? morrita さんのテンプレートの話や、karino2 さんの
 Design Docは形式が広く知られているし、書く時に気をつけるべき事なども良く語られていて、しかも比較的それらの説明は短い。
 あるいは、Design Docs at Google の
 The sweet spot for a larger project seems to be around 10-20ish pages. If you get way beyond that, it might make sense to split up the problem into more manageable sub problems.</description>
      <content:encoded><![CDATA[<p>morrita さん、karino2 さんのいう嫌さは半分くらいわかるかなあ。</p>
<p>「Design Doc 書いてください」というのが、設計が終わったあとに実装がはじまる直線的なソフトウェア開発や、設計が難しい/偉くて実装はそうでもないという、上流工程偏重な職業感を想起させるというのはわかる。無駄な Design Doc が書かれがちなのもわかる。文章がないことに文句を言う人は多いけれど、文章があることに文句を言う人は少ない。でもまあ、無駄な実装よりは無駄な Design Doc の方がマシかなあ。</p>
<p>あと、Design Doc を書かなくてはいけないときは、それなりに大手術になってしまう変更を入れるときで、それは初期の設計のダメさであるとか、機能のつけすぎの現れじゃないか、と思うこともある。炎上プロジェクトには、それを消火してくれるヒーローが現れるように、柔軟性のない巨大ソフトウェアには、それを乗り切るための Design Doc が必要なんじゃないか。</p>
<p>一方で、テンプレートが新規のサーバーサイドのシステムを開発するのを想定しているとか、将来に誰かに読まれそうな期待というのはよくわからない。あわないテンプレートは無視すればいいし、昔に書かれた Design Doc を参照するのは自己責任で、書き手がそれを意識する必要はなくない?</p>
<h2 id="is-it-that-design-doc">Is it that Design Doc?</h2>
<p>morrita さんのテンプレートの話や、karino2 さんの</p>
<blockquote>
<p>Design Docは形式が広く知られているし、書く時に気をつけるべき事なども良く語られていて、しかも比較的それらの説明は短い。</p>
</blockquote>
<p>あるいは、<a href="https://www.industrialempathy.com/posts/design-docs-at-google/">Design Docs at Google</a> の</p>
<blockquote>
<p>The sweet spot for a larger project seems to be around 10-20ish pages. If you get way beyond that, it might make sense to split up the problem into more manageable sub problems. It should also be noted that it is absolutely possible to write a 1-3 page “mini design doc”.</p>
</blockquote>
<p>とかを読むと、人々が Design Doc といって想起するものには結構ばらつきがある気がする。私が好んでいるものは、ここでいう mini design doc というか、もっというと単なる &ldquo;doc&rdquo; なのかもしれない。メール やSlackで五月雨式に質問したり、ミーティングで口頭で話したり、突然コードレビューで大作を送ってくるのはやめて、全体像を文章でまとめて送ってくれませんか?</p>
<p>ここで私が読みたいのは、問題の背景、複数の実装案の良し悪しと、結果として著者が良いと思っている実装案くらい。そんなの実装みたらわかるじゃない、と思うこともあるけれど、実装し終わったものをコードレビューで「これはそもそもがダメなのでやめましょう」というのは気分的にも締め切り的にも難しいことが多く、手をつけるまえに全体像を見れたほうがいい。そのためのツールとして文章に一回まとめるのは良いですよ、という話。</p>
<h2 id="プロトタイプ力">プロトタイプ力</h2>
<p>というわけで、私は Design Doc に関してはそこまで問題意識がないのだった。私の周りの人々が私の書く Design Doc に問題意識を持っている可能性はなくもないので、今度聞いてみてもいいかもしれない。でもなー、初回のミーティングでみんなが納得、コメントなしとなると、それはそれで不安になりそう。</p>
<p>ところで、Design Doc と同じような、実装まえにやると良いこととしてあげられがちなものに、プロトタイプ作りがある。個人的には、文章の説得力をあげていくよりは、プロトタイプをさっと作る方向に力を割きたいと思っている。Design Doc を書いてレビューしてみると良さそうだけど、作ってみるとダメなものってあるはずで、やっぱりちょっとはコードを書きながらデザインしたい。</p>
<p>ただ、画面のあるもののプロトタイプ作りは、ペーパープロトタイピングから <a href="https://www.figma.com/prototyping/">Figma</a> や <a href="https://www.sketch.com/docs/prototyping/">Sketch</a> みたいなものまで色々と方法論やツールがあるけれど、画面のないもののプロトタイプを人々がどう作っているのか、というのはよくわからない。</p>
<p>karino2 さんがリンクしている、Paul Graham の<a href="https://practical-scheme.net/trans/hp-j.html">ハッカーと画家</a>には、</p>
<blockquote>
<p>これはプログラミング言語は柔軟でなければならないということを意味する。 プログラミング言語はプログラムを考えるためのものであって、 既に考えたプログラムを書き下すためのものじゃない。 それはペンではなく鉛筆であるべきなんだ。 静的な型付けは、私が大学で教わったようにプログラムするなら良い考えだと 思う。でも私の知るハッカー達はそんなふうにはプログラムしない。 我々に必要なのは、落書きしたりぼかしたり塗りつぶしたりできる 言語であって、型の紅茶茶碗を膝に置きながら 厳しいコンパイラおばさんと丁寧な会話をするような言語じゃない。</p>
</blockquote>
<p>静的型に対する批判があるけれど、じゃあ最終的に静的型のついたプログラミング言語で書くものも、プロトタイプでは Ruby/Python で書くかというと、私はそこまで動的型に愛はないなあと思う。似た話に、遅い言語で書いてホットスポットだけ速くすればいいというのがあるけれど、これも <a href="https://blog.nelhage.com/post/reflections-on-performance/">Reflections on software performance</a> あたりを読むと、ちょっと楽観的すぎるんじゃないかと思う。</p>
<p>あるいはコーナーケースをどれだけ無視するかとか、一番難しいユースケースから挑むべきなのか、一番簡単なユースケースから挑むべきなのかもよくわからない。気分的には簡単なところから挑みたいけれど、これは結果として簡単なことだけできる中途半端なソフトウェアが量産されがちで、一番に難しい問題が手付かずになりがちだとも思う。</p>
<p>そもそも、プロトタイプじゃなくて本番向けの実装を最初から書けばいいじゃん、という気もするけれど「デザインの前に実装します」より「デザインの前にプロトタイプ作ります」のほうが角がたたない感じがしませんか。日和すぎ?</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
枝葉末節: ハッカーと画家は 2003 年に書かれたものなので、この頃の静的型付言語は現在とはだいぶ印象が違うんじゃないかな。REPL のできる静的型付言語とかなかったと思うし。
いずれにせよ Paul Graham は<a href="http://paulgraham.com/worked.html">リタイアして Lisp を書いている</a> ガチ Lisper なので、そこは間引いて考えてよいのではないでしょうか。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
型のある無しみたいなさすがに何周目だよ、って話題はスルーして欲しい所だけど、「プログラミング言語はプログラムを考えるためのものであって、 既に考えたプログラムを書き下すためのものじゃない。」はなかなか古びていない新鮮さを保っていると思う。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>毎日コードを書く理由</title>
      <link>https://messagepassing.github.io/010-wced/03-jmuk/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/03-jmuk/</guid>
      <description>わたしはコードはわりと毎日書いている気がする……仕事では（趣味ではとても毎日は続かない）。といってもべつにgithubを使っているわけじゃないから草が生えるわけでもないし、そういう可視化を励みにしているというわけでもない（むかし、Chromiumコードベース全体のコミット数ランキングの社内ダッシュボードみたいのがあったことがあり、そこではそこそこ上位になっていて嬉しかったということはある）。ただ、どっちかというと自分の趣味嗜好のようなものとして、結果的にそうなっているという方が近い気がする。
もちろんコードを書く＝コミットをマージするというわけでもない（コードレビューなどのプロセスもるから）し、実際には本当に文字通り毎日というわけでもないだろう。ずーっとデバッグだけして何も成果がないときもあるし。でも実際に自分のコードレビュー履歴 を見てみると、まあまあそれなりにちょこちょこ書いていることが多い気がする。
ただ、仕事においてWCEDがいいかというと、現実的になって振り返るとデメリットのほうが大きいとは思う。細かい雑用みたいな小さな仕事に手を付けがちで、大きな問題を放置してしまいがちになってしまう。もりたさんの書くような、雑用がみるみるうちに片付いてやることがなくなってしまった、なんていうのはある意味成功事例かな、という気がする。無限に雑用が湧いてくるようなタイプのプロジェクトの場合、いつまでたっても細かい雑用しかせず、結果的に大した成果もないし出世もしない、みたいな話になりがちなのがいちばん危なくて、バランスを取る必要がある。
もちろんプロジェクトのフェーズによっては、難しい問題について考えたり、考えをドキュメントにまとめたり、他人のドキュメントやコードをレビューすることで忙しくなってしまう、ということはある。それでも自分の場合は、他人にレビューコメントを送って返事がくるまでの間に細かいバグを直したり、みたいにしてコードを書く時間を設けていることが多いかなと思う。そのままバグの分析に熱中してしまってメインの大きな仕事がおろそかになってしまうことも、まああるのだけど……。
やっぱり個人的にはWCEDは自分の精神の安定性とか、満足度とか、楽しさとかのためにあるように思っている。小さな成果が積み重なっていく感じがあって満足度も高いし、ちょっとした達成感もある。ただやりたいのでやっているというぐらい。いってみれば趣味というようなものなので、そちらに行きすぎないようにうまくバランスをとらないといけないのだろう。あんまり自分がバランス取れている気もしないので、そこは大きな問題な気もする。
少し話はそれるけど、10年ほど前の上司の上司がdirectorに昇進したとき（directorっていうのは日本語だとなんなんだろう、部長、ぐらい？）、俺はdirectorになるけどコードは書くぜ！といった意気込みを示したことがあった。それからしばらくしたある日、私がちょっと遅い時間に仕事をしているとそのdirectorが私の席までやってきて、真剣な顔でちょっといいか、ききたいことがあるんだが……と言う。これはやばい話かもしれない、と戦々恐々としつつdirectorの席までついていくと、画面にeclipseが開いてあって「この関数をテストしたいんだけどさ……」というのであった（その部分は自分は詳しくなかったのであんまりきちんと答えられなかった。残念）。このdirectorは、その後更に出世したしさすがに今ではコードは書く時間もないだろうけれど、当時でもめちゃくちゃ忙しかったであろう合間をぬってでも細かい雑用みたいなコード書いていたのだった。これは偉いというかすごいと思った。が、今思えばあれはなんというか、この話と似たような趣味的な活動だったのかもしれない。every dayでないにせよ、定期的にコードを書いていたいというような。まあそれでいてその人は出世できてるんだからやっぱりすごい偉いという話でもあるんだが。
 shinh それた話題に喰いつきますが、マネージャーが全力でコード書いてるのはアンチパターンな気がするけど、十分に偉いリーダーがコード書いてると心を鷲掴みにされるもんがありますよね。実際 report のやってることを解像度良く把握するのに有効な気もするし……   </description>
      <content:encoded><![CDATA[<p>わたしはコードはわりと毎日書いている気がする……仕事では（趣味ではとても毎日は続かない）。といってもべつにgithubを使っているわけじゃないから草が生えるわけでもないし、そういう可視化を励みにしているというわけでもない（むかし、Chromiumコードベース全体のコミット数ランキングの社内ダッシュボードみたいのがあったことがあり、そこではそこそこ上位になっていて嬉しかったということはある）。ただ、どっちかというと自分の趣味嗜好のようなものとして、結果的にそうなっているという方が近い気がする。</p>
<p>もちろんコードを書く＝コミットをマージするというわけでもない（コードレビューなどのプロセスもるから）し、実際には本当に文字通り毎日というわけでもないだろう。ずーっとデバッグだけして何も成果がないときもあるし。でも実際に<a href="https://chromium-review.googlesource.com/q/owner:mukai%2540chromium.org">自分のコードレビュー履歴</a> を見てみると、まあまあそれなりにちょこちょこ書いていることが多い気がする。</p>
<p>ただ、仕事においてWCEDがいいかというと、現実的になって振り返るとデメリットのほうが大きいとは思う。細かい雑用みたいな小さな仕事に手を付けがちで、大きな問題を放置してしまいがちになってしまう。もりたさんの書くような、雑用がみるみるうちに片付いてやることがなくなってしまった、なんていうのはある意味成功事例かな、という気がする。無限に雑用が湧いてくるようなタイプのプロジェクトの場合、いつまでたっても細かい雑用しかせず、結果的に大した成果もないし出世もしない、みたいな話になりがちなのがいちばん危なくて、バランスを取る必要がある。</p>
<p>もちろんプロジェクトのフェーズによっては、難しい問題について考えたり、考えをドキュメントにまとめたり、他人のドキュメントやコードをレビューすることで忙しくなってしまう、ということはある。それでも自分の場合は、他人にレビューコメントを送って返事がくるまでの間に細かいバグを直したり、みたいにしてコードを書く時間を設けていることが多いかなと思う。そのままバグの分析に熱中してしまってメインの大きな仕事がおろそかになってしまうことも、まああるのだけど……。</p>
<p>やっぱり個人的にはWCEDは自分の精神の安定性とか、満足度とか、楽しさとかのためにあるように思っている。小さな成果が積み重なっていく感じがあって満足度も高いし、ちょっとした達成感もある。ただやりたいのでやっているというぐらい。いってみれば趣味というようなものなので、そちらに行きすぎないようにうまくバランスをとらないといけないのだろう。あんまり自分がバランス取れている気もしないので、そこは大きな問題な気もする。</p>
<p>少し話はそれるけど、10年ほど前の上司の上司がdirectorに昇進したとき（directorっていうのは日本語だとなんなんだろう、部長、ぐらい？）、俺はdirectorになるけどコードは書くぜ！といった意気込みを示したことがあった。それからしばらくしたある日、私がちょっと遅い時間に仕事をしているとそのdirectorが私の席までやってきて、真剣な顔でちょっといいか、ききたいことがあるんだが……と言う。これはやばい話かもしれない、と戦々恐々としつつdirectorの席までついていくと、画面にeclipseが開いてあって「この関数をテストしたいんだけどさ……」というのであった（その部分は自分は詳しくなかったのであんまりきちんと答えられなかった。残念）。このdirectorは、その後更に出世したしさすがに今ではコードは書く時間もないだろうけれど、当時でもめちゃくちゃ忙しかったであろう合間をぬってでも細かい雑用みたいなコード書いていたのだった。これは偉いというかすごいと思った。が、今思えばあれはなんというか、この話と似たような趣味的な活動だったのかもしれない。every dayでないにせよ、定期的にコードを書いていたいというような。まあそれでいてその人は出世できてるんだからやっぱりすごい偉いという話でもあるんだが。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
それた話題に喰いつきますが、マネージャーが全力でコード書いてるのはアンチパターンな気がするけど、十分に偉いリーダーがコード書いてると心を鷲掴みにされるもんがありますよね。実際 report のやってることを解像度良く把握するのに有効な気もするし……
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>曖昧な立場</title>
      <link>https://messagepassing.github.io/011-designdocs/02-karino2/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/02-karino2/</guid>
      <description>Design Doc、自分は無駄なケースが多いと思っているけれど、書いて欲しい場合もある、 という曖昧な立場で、読んでもスッキリしない感じになるかもしれないが、 そういう立場の人も多いと思うので書いてみる。
コミュニケーションの手段としてのDesign Docの有用性は高い（事がある） 設計について相手が考えている事を知りたい時に、Design Docを見せて欲しいと思う事がある。
特にこれから作ろうとしている物に明らかに幾つかの選択肢があって、 それぞれ長所短所があってどれが最善か良くわからない時、 相手が選んだ選択の理由を知りたい。（当然その選択が自分に関係ある場合。）
プロジェクトにはいろいろな背景事情があって、 その結果そのデザインが選ばれたと思う。 でも背景とかの事情には必要な事以外あまり興味が無く関係ある事だけ知りたい時、 Design Docとそのレビュー結果を見たい。
技術的にどちらが良いのかわからない重要な選択のうち、 なぜ一方を選んだのか、その意思決定には多くの情報が含まれる。 それを読む事で背後にあるいろいろな関連する事情も想像出来るようになる。 そこから芋づる式に必要な事を追加で質問していくのは、 最初から重要な所だけにフォーカス出来て効率が良い。
またあまり背景知識が無い状態では、何の準備も無く顔をあわせて説明を受けたり質問をしたりするよりも、 片方が考えている事を一通り書いてもらい、それを読んでから顔をあわせて質問したりする方がコミュニケーションの質が良い。 そういう時に何を書いて欲しいかを示す時、良く知られているDesign Docの形式は便利だ。 トレードオフや代替案などにフォーカスするスタイルは、良い切り口である事は多い。
その結果として残る物にもそこそこ価値があるので、 無駄なミーティングをへらす為のコミュニケーション手段としてもDesign Docはなかなか良いと思う事がある。
設計について話し合うテンプレートとしてのDesign Docのスタイル 設計について考えて話し合いたいとき、とりあえずコードを書いてきただけの経験の浅い若手などは何を話していいかわからない事がある。 特に入社からずっと１人チームとかで他のチームのベテランと話した事とか無いんですが・・・・みたいな人。 ちょっとこれから作るものはベテランの意見をちゃんと取り入れて欲しい、みたいなときに困る。
そういう時に「設計について考える」ことに期待される内容を伝える際、 Design Docを書いてレビューをしてもらう形式は提示しやすい。 それを元に議論してもらえば自然とやって欲しい事をやってもらえて、 そのやり方にはそれなりに有効性もある気がしている。
Design Docは形式が広く知られているし、書く時に気をつけるべき事なども良く語られていて、しかも比較的それらの説明は短い。自習もしやすい。 だから企業文化の違う相手にとりあえずやってくれと要求しやすい。 また相手がベテランなら、好き嫌いはおいといてだいたいは慣れ親しんでいるので、 何をして欲しいのかを簡単に伝えられる。
自分もそういう形式に慣れているおかげで、 Design Docとレビューのフィードバックを見れば、 どういう話し合いをしたかがだいたい後から分かる。 もっと言うと、どういう話し合いを「していないのか」も分かり、こちらの情報が重要な事も多い。 漫然とした打ち合わせと結論のよくわからないふにゃふにゃした議事録よりは、 Design Docとレビューを中心とした議論の方が周りからも分かりやすい。
無駄なDesign Docが大量に書かれがち そんな訳で有用なことはあると思っていて、書いてほしいと依頼する事もあるのだけれど、一方で好きになれない事も多い。 一番好きになれない所は、明らかに誰も読まないようなDesign Docが大量に量産されがちな所。
morrita氏が最初にリンクを貼ったDesign Docs at Googleでは「Design Docを書くべきでは無い時」という話が書かれているが、こういう時にもいかにも書かれがちに思う。 また、上記ではdesign problemに曖昧性があれば書くのが有効に読めるけれど、そういう場合でも有効でない事はあると思う（後述）。
Desig Docが有効で無いそういう状況でも、 Design Docを書いてレビューをもらうスタイルが浸透すると、Design Docを書いてしまいがちだ。 有効で無いDesign Docは負担が多く利益が少ない。</description>
      <content:encoded><![CDATA[<p>Design Doc、自分は無駄なケースが多いと思っているけれど、書いて欲しい場合もある、
という曖昧な立場で、読んでもスッキリしない感じになるかもしれないが、
そういう立場の人も多いと思うので書いてみる。</p>
<h2 id="コミュニケーションの手段としてのdesign-docの有用性は高い事がある">コミュニケーションの手段としてのDesign Docの有用性は高い（事がある）</h2>
<p>設計について相手が考えている事を知りたい時に、Design Docを見せて欲しいと思う事がある。</p>
<p>特にこれから作ろうとしている物に明らかに幾つかの選択肢があって、
それぞれ長所短所があってどれが最善か良くわからない時、
相手が選んだ選択の理由を知りたい。（当然その選択が自分に関係ある場合。）</p>
<p>プロジェクトにはいろいろな背景事情があって、
その結果そのデザインが選ばれたと思う。
でも背景とかの事情には必要な事以外あまり興味が無く関係ある事だけ知りたい時、
Design Docとそのレビュー結果を見たい。</p>
<p>技術的にどちらが良いのかわからない重要な選択のうち、
なぜ一方を選んだのか、その意思決定には多くの情報が含まれる。
それを読む事で背後にあるいろいろな関連する事情も想像出来るようになる。
そこから芋づる式に必要な事を追加で質問していくのは、
最初から重要な所だけにフォーカス出来て効率が良い。</p>
<p>またあまり背景知識が無い状態では、何の準備も無く顔をあわせて説明を受けたり質問をしたりするよりも、
片方が考えている事を一通り書いてもらい、それを読んでから顔をあわせて質問したりする方がコミュニケーションの質が良い。
そういう時に何を書いて欲しいかを示す時、良く知られているDesign Docの形式は便利だ。
トレードオフや代替案などにフォーカスするスタイルは、良い切り口である事は多い。</p>
<p>その結果として残る物にもそこそこ価値があるので、
無駄なミーティングをへらす為のコミュニケーション手段としてもDesign Docはなかなか良いと思う事がある。</p>
<h2 id="設計について話し合うテンプレートとしてのdesign-docのスタイル">設計について話し合うテンプレートとしてのDesign Docのスタイル</h2>
<p>設計について考えて話し合いたいとき、とりあえずコードを書いてきただけの経験の浅い若手などは何を話していいかわからない事がある。
特に入社からずっと１人チームとかで他のチームのベテランと話した事とか無いんですが・・・・みたいな人。
ちょっとこれから作るものはベテランの意見をちゃんと取り入れて欲しい、みたいなときに困る。</p>
<p>そういう時に「設計について考える」ことに期待される内容を伝える際、
Design Docを書いてレビューをしてもらう形式は提示しやすい。
それを元に議論してもらえば自然とやって欲しい事をやってもらえて、
そのやり方にはそれなりに有効性もある気がしている。</p>
<p>Design Docは形式が広く知られているし、書く時に気をつけるべき事なども良く語られていて、しかも比較的それらの説明は短い。自習もしやすい。
だから企業文化の違う相手にとりあえずやってくれと要求しやすい。
また相手がベテランなら、好き嫌いはおいといてだいたいは慣れ親しんでいるので、
何をして欲しいのかを簡単に伝えられる。</p>
<p>自分もそういう形式に慣れているおかげで、
Design Docとレビューのフィードバックを見れば、
どういう話し合いをしたかがだいたい後から分かる。
もっと言うと、どういう話し合いを「していないのか」も分かり、こちらの情報が重要な事も多い。
漫然とした打ち合わせと結論のよくわからないふにゃふにゃした議事録よりは、
Design Docとレビューを中心とした議論の方が周りからも分かりやすい。</p>
<h2 id="無駄なdesign-docが大量に書かれがち">無駄なDesign Docが大量に書かれがち</h2>
<p>そんな訳で有用なことはあると思っていて、書いてほしいと依頼する事もあるのだけれど、一方で好きになれない事も多い。
一番好きになれない所は、明らかに誰も読まないようなDesign Docが大量に量産されがちな所。</p>
<p>morrita氏が最初にリンクを貼った<a href="https://www.industrialempathy.com/posts/design-docs-at-google/">Design Docs at Google</a>では「Design Docを書くべきでは無い時」という話が書かれているが、こういう時にもいかにも書かれがちに思う。
また、上記ではdesign problemに曖昧性があれば書くのが有効に読めるけれど、そういう場合でも有効でない事はあると思う（後述）。</p>
<p>Desig Docが有効で無いそういう状況でも、
Design Docを書いてレビューをもらうスタイルが浸透すると、Design Docを書いてしまいがちだ。
有効で無いDesign Docは負担が多く利益が少ない。</p>
<p>だから有効でないケースを強調しないDesign Docの話（文書の書き方の話も）には、反発を覚えてしまう。</p>
<p>morrita氏も「過剰な期待」という言葉を使っているのは、不適切な用途で書かれているケースがあるという感覚を共有しているんじゃないかなぁ、と思う。</p>
<h2 id="design-docのdesign力が過大評価されがち">Design DocのDesign力が過大評価されがち</h2>
<p>Design Docには「実際に実装をしてみるよりも前の段階でフィードバックを得て修正をする事が出来る」という前提がある気がする。
一方で自分はこれが正しくない場合も多いと思っている。</p>
<p>自分のデザインについての考えは、かなりの部分<a href="https://practical-scheme.net/trans/hp-j.html">ハッカーと画家</a>のデザインの話と一致している。
コーディングはスケッチに近い物で、そこから着想を得てデザインができる。
コーディングからのフィードバックはデザインを考える上で最重要であり、
さらに言えばデザインプロセスの中心だと思っている。
コーディングの前に文書でこれができるというのは間違った前提だと思っている。</p>
<p>コーディングによる着想がどんなときでもすごく重要とは思ってないので、Design Docが有効に機能するケースはあると思う。
でもそのケースは割と少なくて、その少ない有効なケースの時にだけDesign Docは使われるべき、と思っている。</p>
<p>でもDesign Docのメリットの話はこの「デザインするという行為がそもそもにコーディングに根付いている」という前提を無視している事が多い。
文書が有効で無いケースに誤って文書が書かれてしまうケースを十分に警戒していない。</p>
<p>Design Docが有効でないけれど「デザインする」行為が必要なケースはすごく多く、
そういう時まずDesign Docを書くのは「デザインする」行為を邪魔する。
こういうときのDesign Docはコーディングを先にするよりも早く軌道を修正して正しい方向にコスト少なく導くものでは決して無い。
そういうケースでDesign Docが最初に書かれてしまう事例をたくさん見てきた。
morrita氏の欠点3の「不確実性の軽視」も同じような話に見えるので、似たような感覚を共有しているんじゃないか。</p>
<p>よくわかってない事に関して、形だけ代替案を列挙して、ほとんど意味の無い形だけの検討を行ってもそれっぽい体裁は作れてしまうが、そんな物に全く意味は無い。
でもそういう過ちは冒されやすい。</p>
<p>デザインは重要であり、それはコーディングと不可分であり、それを前もって文書で検討する事は出来ない。
我々はコーディングによるフィードバックという最大の武器を自分から捨ててはいけない。</p>
<p>Design Docが有効でないケースは多いと思っている。それは強く強調していきたい。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Design Docs のいけすかなさ</title>
      <link>https://messagepassing.github.io/011-designdocs/01-morrita/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/01-morrita/</guid>
      <description>Design docs というのが昔からあまり好きでない。読むのも書くのも好きでない。 仕事で文書を書くのはやぶさかではないけど Design docs はなんとなくいや。 せっかくなのでこのイヤさを言語化してみたい。
Design Docs とはなにか 自分が想定している Design docs は この文章が説明しているようなものだ。 なにかそれなりの規模があるものを作る時に設計やそのトレードオフをざっと文書化する文書。 もっというと一般名詞の design docs ではなく、リンク先に書いてあるような自分の勤務先固有の The Design Docs 文化が好きでない。
「設計やそのトレードオフをざっと文書化する。」 それだけ聞くと割と良いもののような気がして、自分もある時期までは良いものだと思っていた。 「ドキュメンテーション」というのは、プログラミングのポップカルチャーにおいては伝統的に嫌われものである。 そんななか Design docs は旧来のドキュメンテーションが持つ官僚的、形式的なイメージを覆し、 必要最低限の情報をインフォーマルに伝える手段として新風を吹き込んだ・・・気がしていた。十年以上前、具体的な実装を見るまでは。
しかし実際に仕事で Design docs を読んだり書いたりしてみると色々と欠点も見えてくる。
欠点 1: 想定されている問題領域の狭さ Design docs は、ある規模のものを「新規に」開発する暗の想定がある。 ついでにそこで想定されているのはサーバサイドのシステムみたいなやつである。 社内に用意されているテンプレートはこうした想定を強く織り込んでいる。 けれどモバイルアプリのコードをリファクタリングをしたり UI を増改築したり性能改善をしたり奇妙なバグを直したりに 大半の時間を費やしているしている自分にとって、この想定は他人事。
先にリンクした文書では、インクリメンタルで比較的規模の小さい仕事には “mini design doc” を書くと良いといってるけど、 その書き方については特に論じず、簡潔にしとけよ、オーバーヘッドでかいだろ、とかいうだけ。この無関心さが暗黙の想定を裏付けている。 実際、あたらしいシステムをバンバン設計なさっている立派な皆様ほど Design docs を好まれる。
欠点 2: 期待されている守備範囲の広さ Design docs の主目的はなにか大きなものをつくる前に重要な意思決定 (アーキテクチャといってもよい) をレビューすることである。 つまりレビューが済んだら基本的には用済みだ。にも関わらず、 Design docs は部外者や新参者が既存のソフトウェアのデザインを読み解くための文書としても使われている。 「古くなってるけどだいたい合ってるよね」という感じで読まれる想定がある。</description>
      <content:encoded><![CDATA[<p>Design docs というのが昔からあまり好きでない。読むのも書くのも好きでない。
仕事で文書を書くのはやぶさかではないけど Design docs はなんとなくいや。
せっかくなのでこのイヤさを言語化してみたい。</p>
<h2 id="design-docs-とはなにか">Design Docs とはなにか</h2>
<p>自分が想定している Design docs は
<a href="https://www.industrialempathy.com/posts/design-docs-at-google/">この文章</a>が説明しているようなものだ。
なにかそれなりの規模があるものを作る時に設計やそのトレードオフをざっと文書化する文書。
もっというと一般名詞の design docs ではなく、リンク先に書いてあるような自分の勤務先固有の The Design Docs 文化が好きでない。</p>
<p>「設計やそのトレードオフをざっと文書化する。」
それだけ聞くと割と良いもののような気がして、自分もある時期までは良いものだと思っていた。
「ドキュメンテーション」というのは、プログラミングのポップカルチャーにおいては伝統的に嫌われものである。
そんななか Design docs は旧来のドキュメンテーションが持つ官僚的、形式的なイメージを覆し、
必要最低限の情報をインフォーマルに伝える手段として新風を吹き込んだ・・・気がしていた。十年以上前、具体的な実装を見るまでは。</p>
<p>しかし実際に仕事で Design docs を読んだり書いたりしてみると色々と欠点も見えてくる。</p>
<h2 id="欠点-1-想定されている問題領域の狭さ">欠点 1: 想定されている問題領域の狭さ</h2>
<p>Design docs は、ある規模のものを「新規に」開発する暗の想定がある。
ついでにそこで想定されているのはサーバサイドのシステムみたいなやつである。
社内に用意されているテンプレートはこうした想定を強く織り込んでいる。
けれどモバイルアプリのコードをリファクタリングをしたり UI を増改築したり性能改善をしたり奇妙なバグを直したりに
大半の時間を費やしているしている自分にとって、この想定は他人事。</p>
<p>先にリンクした文書では、インクリメンタルで比較的規模の小さい仕事には “mini design doc” を書くと良いといってるけど、
その書き方については特に論じず、簡潔にしとけよ、オーバーヘッドでかいだろ、とかいうだけ。この無関心さが暗黙の想定を裏付けている。
実際、あたらしいシステムをバンバン設計なさっている立派な皆様ほど Design docs を好まれる。</p>
<h2 id="欠点-2-期待されている守備範囲の広さ">欠点 2: 期待されている守備範囲の広さ</h2>
<p>Design docs の主目的はなにか大きなものをつくる前に重要な意思決定 (アーキテクチャといってもよい) をレビューすることである。
つまりレビューが済んだら基本的には用済みだ。にも関わらず、
Design docs は部外者や新参者が既存のソフトウェアのデザインを読み解くための文書としても使われている。
「古くなってるけどだいたい合ってるよね」という感じで読まれる想定がある。</p>
<p>この想定は Design docs を冗長にするし、焦点を滲ませる。
レビューをするであろうチームメイト相手なら共有しているコンテクストを頼りに「全体像はだいたいいつものかんじ」と省略して本題に入り
議論すべき論点を絞れるはずなのに、読み手が知っている話をダラダラと書きがち。
ミーティングでレビューされた日には眠くなってしまう。</p>
<h2 id="欠点-3-不確実性の軽視">欠点 3: 不確実性の軽視</h2>
<p>Design docs は、暗にデザインの確度の高さを期待している。つまり「これでできるはず」という態度をとりがちである。
先にリンクした文書では, エンジニアリングの問題なんて多くは &ldquo;set of known problem&rdquo; でしょと書いているけれど、
そうはいっても相対的と未知/不安な要素はあるはず。だからこそレビューしてもらうんじゃないの？</p>
<p>それらの不安要素こそレビューを通じて議論したいポイントのはずなのだから強調されてしかるべきだが、
そういう率直さを感じられる Design docs を見かけることは少ない。
しいていえば問題のスコープや non-goal 語る際に風呂敷を小さめにすることで目配せを送るくらい。</p>
<p>実際に巨大なコミットメントが発生し権力者の approval が必要な重要プロジェクトの初期デザインとかは
現実問題としてある程度の確度は必要だろうし調査や試作にも時間をかけるだろう。
Design doc も自信作ができるまで iterate すればよい。
が、それを日常に持ち込まないでほしい。テンプレに draft/ready-to-review/approved とか入れないでくれ。
書かれる文書の 90% は最後まで draft じゃん。</p>
<h2 id="過剰な期待と後光">過剰な期待と後光</h2>
<p>こうした Design docs の残念さは、現実には Design docs でないテキストの不在として理解する方が腑に落ちる気がする。
Design docs が生まれた 15-20 年くらい前というのは agile movement が台頭しはじめた頃で、
世の中ではまだ巨大な「仕様書」が幅を利かせていた。</p>
<p>当時まだわりかしスタートアップだったであろう Google にはそういう官僚的ソフトウェア開発への反骨精神があり、
一方で事前の設計や議論の必要性もあり、最低限必要このくらいはやろうね、と生まれたのが Design docs &hellip; なんじゃないかな。
ついでにいうと開発されているソフトウェアも既存コードベースの拡張より新しいものをバンバンつくるフェーズだったに違いない。</p>
<p>月日は流れ、会社はでかくなり、コードもでかくなり、コードベースの寿命も伸びた。
同時に世の中はインターネット・ソフトウェアの開発に伴う様々な性質、たとえば連続的で、漸近的で、実験的で、運用と一体化していること、への理解を深めた。
ソフトウェア開発の流儀もかわり、沢山のイノベーションがあって、
<a href="https://research.swtch.com/vgo-eng">ソフトウェア・エンジニアリングはプログラミングの時間積分</a>になった。</p>
<p>Design docs はそうした進歩を織り込めていない。</p>
<p>別に Design docs 自体が進歩を織り込まなくてもいんだけど、その周辺にもあまり進歩がない&hellip;というのはちょっと言いすぎて、
たとえば <a href="https://learning.oreilly.com/library/view/software-engineering-at/9781492082781/">Software Engineering at Google</a>
という本では &ldquo;Design Docs&rdquo; の他に &ldquo;Reference Documentation&rdquo;, &ldquo;Tutorials&rdquo;, &ldquo;Conceptual Documentation&rdquo;, &ldquo;Landing Pages&rdquo;
といった種別を議論している。世の中でもそうした議論は沢山あることだろう。
けれどこういう最近のドキュメンテーションに関する議論は Design docs が一部の人に対して持っているマインドシェア/後光を上書きできていない。
キャッチーさが足りない。</p>
<h2 id="足りていないもの">足りていないもの</h2>
<p>そんなわけで誰か Design docs をやっつける、というか肩の荷をおろしてあげる、
キャッチーでモダーンなドキュメンテーションのやり方を考えてくれないかなあとぼんやり思いつつ早幾年。</p>
<p>まず「ドキュメンテーション」というのは若干 stigmatized に思えるので「テキスト」とでも呼んでおこう。
モダンなソフトウェア開発にテキストはどうあるべきか。大きな軸は二つあると思う。</p>
<p>まず議論、意思決定のためのテキストと解説のためのテキストを分離。Design docs はこれを混同して簡潔さを欠きがちだと先に書いた。
モダンテキストはそういう問題を乗り越えていってほしい。</p>
<p>そして小規模化と高頻度化。長いのよくない。ソフトウェア開発はインクリメンタルになったんだから、テキストもそれを織り込んでほしい。
かわりにもうちょっと頻繁に書いてほしい。というかメールとかバグトラッカーのコメントとかコードレビューのスレッドとかに書いている
ランダムなテキスト、もうちょっと名前と構造と発見可能性を与えてくれ！もう Gmail の検索で探すとか嫌なんだ！！</p>
<h2 id="目についたよさげな事例たち">目についたよさげな事例たち</h2>
<p>実際のところモダンテキストの試みはそれなりにある。</p>
<p>特にオープンソース・コミュニティの成熟化にともない「解説」の方は割と充実してきている。
ぱっと良い資料がみつからないけれど、たとえばこの <a href="https://diataxis.fr/">The  Diátaxis Documentation System</a> によれば
Tutorials, HOW-TO Guides, Explanation, Reference という軸があるとしている。なるほど。</p>
<p>最近だと <a href="https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html">ARCHITECTURE.md というのを書くと良いよ</a>
という話があって、これもなるほどなと思う。</p>
<p>勢い余って悪口を書いてしまった Google にも良いアイデアはあって、たとえば Codelabs。
要するにチュートリアルなんだけど、ステップバイステップで手を動かすのに特化したフォーマットを持つ。
(<a href="https://developer.android.com/courses/fundamentals-training/toc-v2">Android の例</a>)
こうやってフォーマットが構造化されていると書く方も迷いがないし、読む側の期待値もはっきりする。</p>
<p>もうひとつは &ldquo;Life of X&rdquo; というフォーマットのレクチャー。
目的は先の ARCHITECTURE.md に似ていて、プロジェクトの新入りがソフトウェアの概要を理解するために用意される。
一番よく知られているのは &ldquo;Life of A Query&rdquo; というやつで、ウェブ検索でワードを入力すると
そのクエリがどんなサーバに飛んでいってどこをどうたらい回された果てに結果が返ってくるのか、ロードバランサからフロントエンド、
バックエンドまで含めウォークスルーする。視点を動かしながらデザインを描き出すところがよい。</p>
<p>今はどうだか知らないけどその昔 Life of A Query は新入社員研修のヒトコマで、説明のわかりやすさとシステムの複雑さの両方に関心したのを覚えている。
&ldquo;Life of X&rdquo; は Codelabs よりハイレベルで書き手/話し手に求められるクリエイティビティも高い。
そのため残念ながら数はそれほど多くない。でもでかいチームには用意されている傾向。
たとえば:
Youtube が使っていた(まだ使ってるのかな?) MySQL クラスタマネージャ <a href="https://github.com/vitessio/vitess/blob/master/doc/LifeOfAQuery.md">Vittes の Life of A Query</a>,
Chrome の <a href="http://bit.ly/lifeofapixel">Life of A Pixel</a> (<a href="https://www.youtube.com/watch?v=PwYxv-43iM4">ビデオ</a>).</p>
<h2 id="あまり目につかないもの">あまり目につかないもの</h2>
<p>一方で議論と意思決定のためのテキストは、仕事での必要性は高いわりに自分はあまり良いスタイルを見つけられていない。
風のうわさに伝え聞く Amazon の narrative/6-pager というやつがよさそうだが、外からは実体がよくわからない。
だから中の人が書いたブログなどを(<a href="https://blog.riywo.com/2021/01/how-to-write-high-quality-technical-doc/">こういうの</a>とか<a href="https://writingcooperative.com/the-anatomy-of-an-amazon-6-pager-fc79f31a41c9">こういうのとか</a>)目を皿のようにして読んじゃう。
（<a href="https://www.amazon.com/Working-Backwards-Insights-Stories-Secrets/dp/1250267595">最近でたインサイダー本</a>も聴き始めました。)</p>
<p>Design docs を倒す・・・じゃなくて弱体化するにはこの議論のためのテキストに発明が必要だと思うんだけど、
なんかいいのないですかねえ。どうですか皆様。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>パッケージマネージャー世代</title>
      <link>https://messagepassing.github.io/014-reuse/02-kzys/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/014-reuse/02-kzys/</guid>
      <description>何故プログラムの再利用というのが難しかったのか、という話をしていたら、「えっ？別に難しくないですよね？」とkzysに言われて、ちょっとその辺の話をしてみたくなった。
 我ながら若者らしい発言。
ただ C/C++ でも、Linux だと pkg-config　や so ファイルの名前づけルール、apt-get とかのパッケージマネージャーのおかげである程度ビルド周りの話は解決していて、結果として他ライブラリを色々使うソフトウェアがあった気がする。GNOME なアプリを入れたら依存で色々入ったりしませんか? クロスプラットフォームだと確かに大変そう。
私は、アルバイトじゃない最初の仕事がミクシィで、ソーシャルネットワーキングサービスのミクシィはいわゆる LAMP (Linux + Apache + MySQL + Perl) スタック、そのあとも全体的に C/C++ とかは使わず、Linux だけを気にするサーバーサイド仕事が多かったので「再利用できない」という感覚はあまりない。MySQL や memcached みたいなオープンソースなミドルウェアと、CPAN ないし、その言語についてるパッケージマネージャーからダウンロードできるライブラリを組み合わせてソフトウェアを作るのが普通。
ライブラリの再利用と、フレームワークの再利用 ミクシィ世代の会社には、それでも自社 Web アプリケーションフレームワークというものを見かける機会がまだあって、オープンソースになっているものだと、例えばライブドアには Sledge, はてなには Ridge, GREE には、これは CTO の藤本さんがもともと開発していたものなので、自社フレームワークと呼ぶのは語弊があるけれど、Ethna があった。
その後のクックパッド世代になると、Rails や Django といった既製のフルスタックなフレームワークを使うのが普通になってしまって、Web アプリケーションフレームワークを自作するのは、よっぽどわかっているか、よっぽどわかっていないか、どちらかじゃないとやらない、普通じゃない選択肢になってしまったという感がある。
とはいえこれも一昔前の話で、最近のモバイルアプリとシングルページアプリケーション世代の「サーバーで生成するのは JSON だけでいいですよ」という人々が何を使っているのかというと、うーん、なんなんだろう。私はここらへんの仕事をしたことがないのでコメントは控えます。
最近にみかけた再利用 自分のいまの仕事の周辺でいうと、例えば containerd には ttrpc というオレオレ RPC を使っているんだけど、これはセマンティクスは gRPC で、IDL もそのまま proto3 を再利用している。Firecracker の API は RPC ではなく REST だけど、IDL は OpenAPI で定義されている。みんな色々と再利用できていてえらいなーという感じ。</description>
      <content:encoded><![CDATA[<blockquote>
<p>何故プログラムの再利用というのが難しかったのか、という話をしていたら、「えっ？別に難しくないですよね？」とkzysに言われて、ちょっとその辺の話をしてみたくなった。</p>
</blockquote>
<p>我ながら若者らしい発言。</p>
<p>ただ C/C++ でも、Linux だと pkg-config　や so ファイルの名前づけルール、apt-get とかのパッケージマネージャーのおかげである程度ビルド周りの話は解決していて、結果として他ライブラリを色々使うソフトウェアがあった気がする。GNOME なアプリを入れたら依存で色々入ったりしませんか? クロスプラットフォームだと確かに大変そう。</p>
<p>私は、アルバイトじゃない最初の仕事が<a href="https://mixi.jp/">ミクシィ</a>で、ソーシャルネットワーキングサービスのミクシィはいわゆる LAMP (Linux + Apache + MySQL + Perl) スタック、そのあとも全体的に C/C++ とかは使わず、Linux だけを気にするサーバーサイド仕事が多かったので「再利用できない」という感覚はあまりない。MySQL や memcached みたいなオープンソースなミドルウェアと、<a href="https://www.cpan.org/">CPAN</a> ないし、その言語についてるパッケージマネージャーからダウンロードできるライブラリを組み合わせてソフトウェアを作るのが普通。</p>
<h3 id="ライブラリの再利用とフレームワークの再利用">ライブラリの再利用と、フレームワークの再利用</h3>
<p>ミクシィ世代の会社には、それでも自社 Web アプリケーションフレームワークというものを見かける機会がまだあって、オープンソースになっているものだと、例えばライブドアには <a href="https://github.com/livedoor/Sledge">Sledge</a>, はてなには <a href="https://github.com/hatena/Ridge">Ridge</a>, GREE には、これは <a href="https://japan.cnet.com/article/20088792/">CTO の藤本さんがもともと開発していたものなので</a>、自社フレームワークと呼ぶのは語弊があるけれど、<a href="http://ethna.jp/doc/">Ethna</a> があった。</p>
<p>その後のクックパッド世代になると、Rails や Django といった既製のフルスタックなフレームワークを使うのが普通になってしまって、Web アプリケーションフレームワークを自作するのは、よっぽどわかっているか、よっぽどわかっていないか、どちらかじゃないとやらない、普通じゃない選択肢になってしまったという感がある。</p>
<p>とはいえこれも一昔前の話で、最近のモバイルアプリとシングルページアプリケーション世代の「サーバーで生成するのは JSON だけでいいですよ」という人々が何を使っているのかというと、うーん、なんなんだろう。私はここらへんの仕事をしたことがないのでコメントは控えます。</p>
<h3 id="最近にみかけた再利用">最近にみかけた再利用</h3>
<p>自分のいまの仕事の周辺でいうと、例えば <a href="https://github.com/containerd/containerd">containerd</a> には <a href="https://github.com/containerd/ttrpc">ttrpc</a> というオレオレ RPC を使っているんだけど、これはセマンティクスは gRPC で、IDL もそのまま proto3 を再利用している。<a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a> の API は RPC ではなく REST だけど、<a href="https://github.com/firecracker-microvm/firecracker/blob/master/src/api_server/swagger/firecracker.yaml">IDL</a> は OpenAPI で定義されている。みんな色々と再利用できていてえらいなーという感じ。</p>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>自分の所でちょっと触れてるけれど、CMake+conanはもっといい線行ってる感じですよ＞apt-getとかより</p>
<p>VS+vcpkgの組み合わせではvcpkgも結構使われている。世の中は進んではいるのだけれど…</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
C++ が解決していると言われると、「ウッ現在進行形で苦労している俺達って……」という感じに。まあ「お願いだから .so 作る時は <code>-fvisibility=hidden</code> つけてくれ！」「グローバルコンストラクタで難しいことすんな！」「libtorch は <code>_GLIBCXX_USE_CXX_ABI=0</code> つけるのいい加減やめてくれ！」と叫ばせてください
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
この話題で C と C++ をひとまとめにして扱うのは雑すぎました。<a href="https://github.com/itanium-cxx-abi/cxx-abi">C++ ABI</a> はいつ来るんだろう&hellip;
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>再利用のはなし</title>
      <link>https://messagepassing.github.io/014-reuse/01-karino2/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/014-reuse/01-karino2/</guid>
      <description>何故プログラムの再利用というのが難しかったのか、という話をしていたら、「えっ？別に難しくないですよね？」とkzysに言われて、ちょっとその辺の話をしてみたくなった。
個人的にソフトウェアの再利用が一般的と感じられるようになったのは、JavaでJakartaが有用なライブラリを揃え始めた頃からだ。 再利用される方の話は現代の普通の話なので良いと思う。 ではそれ以前の何が難しかったのか、と思うと、CやC++の難しさが多い気がしてきた。
C++の再利用が何故難しいのか、という話をすると長くなる上に今更なので、 今のプロジェクトでさしあたってうまく行かないと感じる、今、目の前の問題だけを書いてみたい。
共通のプリミティブが無い難しさ 例えばスレッド周りの何かのライブラリを再利用したい、と考えたとする。 この時、Win32 APIの同期プリミティブとQtの同期プリミティブとSTLの同期プリミティブとpthreadの同期プリミティブは、同じ機能を提供するが、相互に取り替えて動く保証が無い（あるかもしれないし幾つかの組み合わせはある事も知っているが、一般にあるか無いかを判定するのはかなり難しいし、幾つかの組み合わせは怪しいのも知っている）。 QtでGUIとタイトに相互作用するような所で使いたい場合、 Qtの並列プリミティブで無いと困ってしまう。
その結果、いろいろな環境で動く、スレッドプールを前提としたノンブロッキングなFuture、 みたいなライブラリを作るのは、なかなか難しい。STLのスレッド前提のものは作れるのだけれど。
Win32 APIやQtが、現在のSTLを元に作られていれば、こういう問題はなかったとは思う。 でもどちらもSTLのスレッドより以前から作られていた物だし、そういう物はまだまだ世の中多い。
STLにまだ入ってない物も多い。今更filesystem周りが入った、という事からもそれがわかる。
Javaや.NETなどの環境や、pythonなどの普通のLLには、 ベースと出来る範囲がずっと広く、それらに依存した物は普通にどこでも動く。 言語の標準となる機能の範囲がC++は狭い。特にどの環境でも使えるC++のバージョンに限定すると、さらに狭い。
歴史をなかなか無かった事に出来ない そろそろVSもXcodeもNDKもQtもすべての環境がCMakeになって、 最初からconanをサポートして、 最新のSTLにあるものはSTLを、boostにあるものはboostを使ってくれて、 STLのスレッドや並列周りもfollyの奴くらいにいい感じのになってくれればいいのでは、 という気はするのだけれど、今からそうはなってくれない。（なってくれていいのよ？）
過去の歴史はそのままに、CMakeでもプロジェクトファイルが生成出来ます、 みたいなのだと、どうしてもバージョンアップなどのトラブルで後手に回ってしまう。 残念な事にC++が相手にするような環境のうちの幾つかは十分なサポートがされてなく、 自分たちでどうにかせざるをえない事も多い。 こういう時に何かが一段その環境のネイティブな仕組みの間に挟まってると、 メンテがすごく大変になる。 公式の側がCMakeになってくれればそういう問題も無いのだが…
手元のコードベースの側も、過去のいろいろなプラットフォーム上での様々な固有事情を踏まえたプロジェクトファイルやらビルドの仕組みを内包していて、全てを新しい仕組みに移動するのもなかなか大変。
本来は最新版だけがきっちりサポートされてればいいはずなのだけど、メジャーバージョンアップをするとめちゃくちゃ不安定になって特定のバージョンで止めなきゃいけないみたいなくされ環境があり、 その環境がサポートしているコンパイラはちょっと古くて最新のC++機能が使えなかったりとかがあり、 いろいろな事情でVC2008もサポートしないと駄目とかがあり、 内輪の事情で特定のRHELでビルド出来ないと駄目とかもあり… みたいな、プロジェクト固有の事情からもなかなか脱却出来ず、 「本来はこうあるべき」という姿になかなか出来ない。
他への依存をみんなしたがらない おのおのが歴史を持ったプロジェクトに使ってもらう事を考えると、ライブラリ作者は使う側のビルド環境などを想定出来ないので、他のライブラリへの依存の仕方も難しい。 「このライブラリを動かす為には、ライブラリAとライブラリBとライブラリCを適切に設定してパスをXXXで通るようにしてください」 みたいな事をお願いすると、使ってもらうのもきびしい。
なので複数のライブラリに依存したライブラリを使ってもらうのはすごく大変。
結果として、STLとboostのヘッダオンリーな物あたりだけに依存したライブラリくらいしか使いたくない。
コデックとかflatbuffersとか他への依存が少ない小粋なライブラリは使えるのだけれど、 ノンブロッキングなfutureを返すhttpのライブラリ、 とか、ノンブロッキングなfutureを返すノンブロッキングioなファイル周りのライブラリ、 のように、他の結構大きな物に依存するライブラリは全然ない。
そもそもライブラリが言うほど無い 「iOSならGCD、WindowsやQtならシステムのスレッドプール、 AndroidならSTLあたりで書かれた自前実装のスレッドプールを使ったExecutor」程度のライブラリも存在しない。
Windowsのフルな機能にアクセス出来る、Direct2DあたりをベースにしたモダンなGUIライブラリ、程度のものも無い（xi-editor retrospectiveでも、There is no such thing as native GUIと言っている）。WTLをforkして自前で作るか？と思うくらい無い。
WindowsのAsync IOとOS XのDispatch SourceとLinuxのepoll周りを吸収してよ、くらいでも普通に無い（このくらいなら頑張って探せばあるかもしれない、自分は見つけられなかったが）。
「インテリセンスを壊さない」UnitTestライブラリ、程度でも見つけられなかった（仕方ないので自作した）。
みんな似たような物作っているくせに、全然再利用出来るものが無い。
kzys  WindowsのAsync IOとOS XのDispatch SourceとLinuxのepoll周りを吸収してよ、くらいでも普通に無い（このくらいなら頑張って探せばあるかもしれない、自分は見つけられなかったが）。</description>
      <content:encoded><![CDATA[<p>何故プログラムの再利用というのが難しかったのか、という話をしていたら、「えっ？別に難しくないですよね？」とkzysに言われて、ちょっとその辺の話をしてみたくなった。</p>
<p>個人的にソフトウェアの再利用が一般的と感じられるようになったのは、JavaでJakartaが有用なライブラリを揃え始めた頃からだ。
再利用される方の話は現代の普通の話なので良いと思う。
ではそれ以前の何が難しかったのか、と思うと、CやC++の難しさが多い気がしてきた。</p>
<p>C++の再利用が何故難しいのか、という話をすると長くなる上に今更なので、
今のプロジェクトでさしあたってうまく行かないと感じる、今、目の前の問題だけを書いてみたい。</p>
<h3 id="共通のプリミティブが無い難しさ">共通のプリミティブが無い難しさ</h3>
<p>例えばスレッド周りの何かのライブラリを再利用したい、と考えたとする。
この時、Win32 APIの同期プリミティブとQtの同期プリミティブとSTLの同期プリミティブとpthreadの同期プリミティブは、同じ機能を提供するが、相互に取り替えて動く保証が無い（あるかもしれないし幾つかの組み合わせはある事も知っているが、一般にあるか無いかを判定するのはかなり難しいし、幾つかの組み合わせは怪しいのも知っている）。
QtでGUIとタイトに相互作用するような所で使いたい場合、
Qtの並列プリミティブで無いと困ってしまう。</p>
<p>その結果、いろいろな環境で動く、スレッドプールを前提としたノンブロッキングなFuture、
みたいなライブラリを作るのは、なかなか難しい。STLのスレッド前提のものは作れるのだけれど。</p>
<p>Win32 APIやQtが、現在のSTLを元に作られていれば、こういう問題はなかったとは思う。
でもどちらもSTLのスレッドより以前から作られていた物だし、そういう物はまだまだ世の中多い。</p>
<p>STLにまだ入ってない物も多い。今更filesystem周りが入った、という事からもそれがわかる。</p>
<p>Javaや.NETなどの環境や、pythonなどの普通のLLには、
ベースと出来る範囲がずっと広く、それらに依存した物は普通にどこでも動く。
言語の標準となる機能の範囲がC++は狭い。特にどの環境でも使えるC++のバージョンに限定すると、さらに狭い。</p>
<h3 id="歴史をなかなか無かった事に出来ない">歴史をなかなか無かった事に出来ない</h3>
<p>そろそろVSもXcodeもNDKもQtもすべての環境がCMakeになって、
最初からconanをサポートして、
最新のSTLにあるものはSTLを、boostにあるものはboostを使ってくれて、
STLのスレッドや並列周りもfollyの奴くらいにいい感じのになってくれればいいのでは、
という気はするのだけれど、今からそうはなってくれない。（なってくれていいのよ？）</p>
<p>過去の歴史はそのままに、CMakeでもプロジェクトファイルが生成出来ます、
みたいなのだと、どうしてもバージョンアップなどのトラブルで後手に回ってしまう。
残念な事にC++が相手にするような環境のうちの幾つかは十分なサポートがされてなく、
自分たちでどうにかせざるをえない事も多い。
こういう時に何かが一段その環境のネイティブな仕組みの間に挟まってると、
メンテがすごく大変になる。
公式の側がCMakeになってくれればそういう問題も無いのだが…</p>
<p>手元のコードベースの側も、過去のいろいろなプラットフォーム上での様々な固有事情を踏まえたプロジェクトファイルやらビルドの仕組みを内包していて、全てを新しい仕組みに移動するのもなかなか大変。</p>
<p>本来は最新版だけがきっちりサポートされてればいいはずなのだけど、メジャーバージョンアップをするとめちゃくちゃ不安定になって特定のバージョンで止めなきゃいけないみたいなくされ環境があり、
その環境がサポートしているコンパイラはちょっと古くて最新のC++機能が使えなかったりとかがあり、
いろいろな事情でVC2008もサポートしないと駄目とかがあり、
内輪の事情で特定のRHELでビルド出来ないと駄目とかもあり…
みたいな、プロジェクト固有の事情からもなかなか脱却出来ず、
「本来はこうあるべき」という姿になかなか出来ない。</p>
<h3 id="他への依存をみんなしたがらない">他への依存をみんなしたがらない</h3>
<p>おのおのが歴史を持ったプロジェクトに使ってもらう事を考えると、ライブラリ作者は使う側のビルド環境などを想定出来ないので、他のライブラリへの依存の仕方も難しい。
「このライブラリを動かす為には、ライブラリAとライブラリBとライブラリCを適切に設定してパスをXXXで通るようにしてください」
みたいな事をお願いすると、使ってもらうのもきびしい。</p>
<p>なので複数のライブラリに依存したライブラリを使ってもらうのはすごく大変。</p>
<p>結果として、STLとboostのヘッダオンリーな物あたりだけに依存したライブラリくらいしか使いたくない。</p>
<p>コデックとかflatbuffersとか他への依存が少ない小粋なライブラリは使えるのだけれど、
ノンブロッキングなfutureを返すhttpのライブラリ、
とか、ノンブロッキングなfutureを返すノンブロッキングioなファイル周りのライブラリ、
のように、他の結構大きな物に依存するライブラリは全然ない。</p>
<h3 id="そもそもライブラリが言うほど無い">そもそもライブラリが言うほど無い</h3>
<p>「iOSならGCD、WindowsやQtならシステムのスレッドプール、
AndroidならSTLあたりで書かれた自前実装のスレッドプールを使ったExecutor」程度のライブラリも存在しない。</p>
<p>Windowsのフルな機能にアクセス出来る、Direct2DあたりをベースにしたモダンなGUIライブラリ、程度のものも無い（<a href="https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html">xi-editor retrospective</a>でも、There is no such thing as native GUIと言っている）。WTLをforkして自前で作るか？と思うくらい無い。</p>
<p>WindowsのAsync IOとOS XのDispatch SourceとLinuxのepoll周りを吸収してよ、くらいでも普通に無い（このくらいなら頑張って探せばあるかもしれない、自分は見つけられなかったが）。</p>
<p>「インテリセンスを壊さない」UnitTestライブラリ、程度でも見つけられなかった（仕方ないので<a href="https://karino2.github.io/2020/04/15/nfiftest.html">自作した</a>）。</p>
<p>みんな似たような物作っているくせに、全然再利用出来るものが無い。</p>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
<blockquote>
<p>WindowsのAsync IOとOS XのDispatch SourceとLinuxのepoll周りを吸収してよ、くらいでも普通に無い（このくらいなら頑張って探せばあるかもしれない、自分は見つけられなかったが）。</p>
</blockquote>
<p><a href="https://libuv.org/">libuv</a> どうですか?</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>ネットワークのライブラリというイメージだったがFileもあるんですね。
どうなんですかね？</p>
<p>ぱっと見GCDにすら依存してないような姿勢に見えるしgetenvとか呼び始めるコードがちょこちょこあるのでLinux以外ではあんまり使う気にならなさそうだけど、外部のスレッドプールと混ぜるのとかどのくらい出来るのかなぁ。
iOSとかQtのスレッドプールと混ぜて使えないと「共通のプリミティブが無い難しさ」の結果として再利用が出来ない実例になってしまいそうだけど。</p>
<p>こういうのは結構ちゃんと調べてみないと良く分からなくて、それがまさに再利用のコストが他より高い事を表している気もしますな。</p>
<p>興味はあるので、次Fileまわりを書き直す時にはもうちょっと真面目に調べてみます。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>毎日を細切れにされるのはきつい</title>
      <link>https://messagepassing.github.io/010-wced/02-kzys/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/02-kzys/</guid>
      <description>仕事に WCED は無理があったのか、それとも自分の仕事の仕方がよくないのか。 みんな仕事で毎日コードかいてんの？どうなの？
 Write Code Every Day してないなあ。毎週はなにか書いていると思うけれど、毎日といわれると怪しい。
仕事の外での Write Code Every Day は How the GitHub contribution graph is harmful (2016) という話があって、実際に GitHub からも連続日数表示が消えてからはや5年たつ2021年に目指すものではないと思うけれど、仕事でも毎営業日コードを書いてはいない。
理由は morrita さんと大体同じで、人にブロックされることとか、難しめの仕事とか。さらにいうと、後者には大抵「設計を文章にまとめて人々に相談してみる」すなわちミーティングの主催も含まれがちで、そうするとミーティングの日まで人にブロックされることになる。
毎日コードを書けないのはいいけど・・・ というわけで、毎日コードを書けないのは、個人的には許容している。コードを書く前に立ち止まって考えたほうがいいことは、立ち止まって考えたらいいじゃない。一方で、毎日をミーティングで埋められて、かつその合間が30分とか1時間なのはつらい。
そういうのが散見されるときは、自分のカレンダーを自分の予定で事前に埋めるというのを実践していて、適当な時間に2時間程度の長さの予定を入れている。ミーティングを入れるソフトウェアは一般にダブルブッキングを避けてくれるものなので、ここで難しい仕事とか、やらないといけない仕事にちょっと進捗を出す。2時間程度の連続した時間がとれない日には、人々の仕事をがんばって手伝ったということにして、自分の仕事が進まなくてもあまり気にしない。
メールは夕方4時まで読みません、というのは会社員にはちょっと厳しいと思うけれど、オフィスにちょっと早めに来て、仕事の最初の1時間くらいはメールを読まない、というのは一時期やっていた。最近やっていないのは、なんでだっけ? また再開してもよさそう。メールも Slack も、他人の TODO が高速に飛んでくるメディアという側面があるので、あんまり貼り付いているのは良くない。
毎日コードが書けないのが許容できて、ミーティングで時間を細切れにされるのを許容できないのは、多分自分の仕事の多くは「考えること」で、難しいことを1時間程度で考えることはできないと思っているからだと思う。訓練を積んだら出来るようになるのかもしれないけど、あまりに大企業最適化すぎるので出来るようになりたいかというと微妙な気持ち。</description>
      <content:encoded><![CDATA[<blockquote>
<p>仕事に WCED は無理があったのか、それとも自分の仕事の仕方がよくないのか。 みんな仕事で毎日コードかいてんの？どうなの？</p>
</blockquote>
<p>Write Code Every Day してないなあ。毎週はなにか書いていると思うけれど、毎日といわれると怪しい。</p>
<p>仕事の外での Write Code Every Day は <a href="https://web.archive.org/web/20161019123609/http://erik.io/blog/2016/04/01/how-github-contribution-graph-is-harmful/">How the GitHub contribution graph is harmful</a> (2016) という話があって、実際に <a href="https://github.blog/2016-05-19-more-contributions-on-your-profile/">GitHub からも連続日数表示が消えてから</a>はや5年たつ2021年に目指すものではないと思うけれど、仕事でも毎営業日コードを書いてはいない。</p>
<p>理由は morrita さんと大体同じで、人にブロックされることとか、難しめの仕事とか。さらにいうと、後者には大抵「設計を文章にまとめて人々に相談してみる」すなわちミーティングの主催も含まれがちで、そうするとミーティングの日まで人にブロックされることになる。</p>
<h3 id="毎日コードを書けないのはいいけど">毎日コードを書けないのはいいけど・・・</h3>
<p>というわけで、毎日コードを書けないのは、個人的には許容している。コードを書く前に立ち止まって考えたほうがいいことは、立ち止まって考えたらいいじゃない。一方で、毎日をミーティングで埋められて、かつその合間が30分とか1時間なのはつらい。</p>
<p>そういうのが散見されるときは、<a href="https://maketime.blog/article/start-with-a-full-calendar/">自分のカレンダーを自分の予定で事前に埋める</a>というのを実践していて、適当な時間に2時間程度の長さの予定を入れている。ミーティングを入れるソフトウェアは一般にダブルブッキングを避けてくれるものなので、ここで難しい仕事とか、やらないといけない仕事にちょっと進捗を出す。2時間程度の連続した時間がとれない日には、人々の仕事をがんばって手伝ったということにして、自分の仕事が進まなくてもあまり気にしない。</p>
<p><a href="https://www.calnewport.com/blog/2020/12/23/andrew-gelmans-4-pm-rule-a-knowledge-work-reverie/">メールは夕方4時まで読みません</a>、というのは会社員にはちょっと厳しいと思うけれど、オフィスにちょっと早めに来て、仕事の最初の1時間くらいはメールを読まない、というのは一時期やっていた。最近やっていないのは、なんでだっけ? また再開してもよさそう。メールも Slack も、他人の TODO が高速に飛んでくるメディアという側面があるので、あんまり貼り付いているのは良くない。</p>
<p>毎日コードが書けないのが許容できて、ミーティングで時間を細切れにされるのを許容できないのは、多分自分の仕事の多くは「考えること」で、難しいことを1時間程度で考えることはできないと思っているからだと思う。訓練を積んだら出来るようになるのかもしれないけど、あまりに大企業最適化すぎるので出来るようになりたいかというと微妙な気持ち。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Write Code Every Day At Work</title>
      <link>https://messagepassing.github.io/010-wced/01-morrita/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/01-morrita/</guid>
      <description>去年一年の仕事を振り返っていて、いまいちコードを書いていないことに気づいてしまった。
プログラマの下っ端がコードを書かずに何をしているかというと、 バグのたらい回し、バグレポートの解析、コードレビュー、メールとか報告とかの自然言語書き、バグのたらい回しとか。 下っ端には下っ端の雑用があり、特に性能問題の分析は無限に時間を溶かしがち。去年はだいぶ溶かしてしまった。
その反省からもうちょっとコードを書こうと、去年のおわりくらいから午前中は雑用をすべてすっぽかしコードを書くことにしてみた。 いわゆる Write Code Every Day (WCED)。
やってみると腰が重くて放置していた積み残しの仕事たちがあれよあれよと片付き、コードも書けて満足度も高く、 なぜこれをやっていなかったのか（答: 色々な圧力があったから）不思議なくらい捗った。のだけれど、ここ一週間くらい行き詰まってきた。 というのも、即座にコードの書ける仕事が手元からなくなってしまった。
１つ目のパターンは、誰かを待つ必要がある仕事。わかりやすいのだとコードレビューとか。 あとは人のコードベースに踏み込んでなんかやるために方針を相談するとか。 話がつくまでそのあとの作業ができない。 まあこれは自分にとって付き合いの長い問題なので、並列化とかでそれなりに乗り切れる。
２つ目のパターンは、真面目に考えないといけないむずかし目の仕事。 うーんと考える。既存のコードやインフラのドキュメントを読む。方針とかを書き出して関係者の反応を見る・・・など、 コードを書くためのコード以外の準備がそれなりに必要なもの。
個人的にはこの２つ目に手強さを感じている。 自分は考え事や調査に時間を溶かしがち。しかも考え事をするとコードを書く勢いが止まってしまう不安がある。 気がつくとまた雑用の引力に引き込まれてしまうんじゃないか。
そんな気の重さに負け、つい優先度の低い細かいリファクタリングやバグ修正を優先してしまったりする。 でもそういうことをしていると大事な問題が前に進まない。
世の中の WCED 体験談にも、似たような意見を見かけることがある。 WCED はもともと課外活動のためのアイデアなので、それなら WCED を目的にして手段を調整すればいいといえばいい。 課外活動の WCED はそうやって問題を回避している。たとえば coding quiz や教材を優先する、みたいな。 でも自分は仕事をはかどらせるのが目的なので、同じ方法は使えない。
仕事に WCED は無理があったのか、それとも自分の仕事の仕方がよくないのか。 みんな仕事で毎日コードかいてんの？どうなの？</description>
      <content:encoded><![CDATA[<p>去年一年の仕事を振り返っていて、いまいちコードを書いていないことに気づいてしまった。</p>
<p>プログラマの下っ端がコードを書かずに何をしているかというと、
バグのたらい回し、バグレポートの解析、コードレビュー、メールとか報告とかの自然言語書き、バグのたらい回しとか。
下っ端には下っ端の雑用があり、特に性能問題の分析は無限に時間を溶かしがち。去年はだいぶ溶かしてしまった。</p>
<p>その反省からもうちょっとコードを書こうと、去年のおわりくらいから午前中は雑用をすべてすっぽかしコードを書くことにしてみた。
いわゆる <a href="https://johnresig.com/blog/write-code-every-day/">Write Code Every Day</a> (WCED)。</p>
<p>やってみると腰が重くて放置していた積み残しの仕事たちがあれよあれよと片付き、コードも書けて満足度も高く、
なぜこれをやっていなかったのか（答: 色々な圧力があったから）不思議なくらい捗った。のだけれど、ここ一週間くらい行き詰まってきた。
というのも、即座にコードの書ける仕事が手元からなくなってしまった。</p>
<p>１つ目のパターンは、誰かを待つ必要がある仕事。わかりやすいのだとコードレビューとか。
あとは人のコードベースに踏み込んでなんかやるために方針を相談するとか。
話がつくまでそのあとの作業ができない。
まあこれは自分にとって付き合いの長い問題なので、並列化とかでそれなりに乗り切れる。</p>
<p>２つ目のパターンは、真面目に考えないといけないむずかし目の仕事。
うーんと考える。既存のコードやインフラのドキュメントを読む。方針とかを書き出して関係者の反応を見る・・・など、
コードを書くためのコード以外の準備がそれなりに必要なもの。</p>
<p>個人的にはこの２つ目に手強さを感じている。
自分は考え事や調査に時間を溶かしがち。しかも考え事をするとコードを書く勢いが止まってしまう不安がある。
気がつくとまた雑用の引力に引き込まれてしまうんじゃないか。</p>
<p>そんな気の重さに負け、つい優先度の低い細かいリファクタリングやバグ修正を優先してしまったりする。
でもそういうことをしていると大事な問題が前に進まない。</p>
<p>世の中の WCED 体験談にも、似たような意見を見かけることがある。
WCED はもともと課外活動のためのアイデアなので、それなら WCED を目的にして手段を調整すればいいといえばいい。
課外活動の WCED はそうやって問題を回避している。たとえば coding quiz や教材を優先する、みたいな。
でも自分は仕事をはかどらせるのが目的なので、同じ方法は使えない。</p>
<p>仕事に WCED は無理があったのか、それとも自分の仕事の仕方がよくないのか。
みんな仕事で毎日コードかいてんの？どうなの？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re^3: 読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/04-karino2/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/04-karino2/</guid>
      <description>皆の話を見て、自分はどうしているかなぁ、と今BooxのInstapaperとPocketを眺めてみたのだが、なかなか雑多な経路から入っていて端的に言うのがなんか難しい。 とりあえず個別に話してから雑感的な事を述べてみよう。
RSS関連 RSSは長らく既読にするだけという感じだったのだけれど、Booxを買ってから最近また活用するようになった。
7割くらいは読まずにarchiveになっていて、無駄だなぁ、とは思っている。一時的にオフに出来たらいいかもなぁ。 ちょっとオフトピだが、天文とか経済学とかが、最近は読まずにarchiveする比率が高い。 こういうのを読む気分じゃないのは一時的な物なので、アンフォローしたい訳でも無いのですよねぇ。 仕事やめて星を見る機会が増えたらまた見たいのだけれど。
RSSリーダーはInoreader使ってます。
読み方としてはざっとRSSリーダー上で確認して、気になったのはInstapaperに送る。以前はPocketに送ってたが、最近Instapaperに乗り換えを検討してて評価中。 後述するけれど、長いものは意図的に読む比率を上げています。 Instapaperに長いのを送るようになってからRSSを読む楽しさが増した気がするのでBooxは偉大だ。 なお今見直したら、送った奴はだいたい読んでいる模様。ちょっと意外。
友人知人と企業とかの区別は特に無く適当に加えてます。 昔はフォルダ分けとかしてたが最近はしてないので形骸化したフォルダが残ってて不便。
subscribeしている中で、割と良く読むブログを、読む率の高さ順で紹介しておく。
 Official Kotlin Blog  Kotlinの話は結構読んでいる気がする。事例紹介とかは飛ばす事も多いが、ここからリンクをたどって気になったのを読むケースも結構多い。これが一番真面目に読んでいるかな。
 Android Developers Blog  これも結構読んでいる。
 The Old New Thing  Microsoftの人のC++とかWindows関連のブログ。 最初はC++関連でググってたどり着いたが、Windowsの話とかもたまに見ている。読まないで飛ばす率も高い。C++の話の時は結構読んでる。
 2ality – JavaScript and more  以前Exploring ES6という本を読んで、なかなか良かったので、その後著者であるこのサイトをsubscribeしている。 JS関連はそこまで興味ある訳でも無いので飛ばす事も多いが、眺めるくらいはしているかなぁ。
 Google Developers Blog  TensorFlowとか興味がある奴だけ読んでる。これも飛ばす率は高い。
あと、kzysブログとshinhブログからリンクされている技術系の記事は結構読んでる気がする。
その他統計とか機械学習系はsubscribeしているが最近は全然読んでない。そっちの界隈に復帰したらまた読みはじめるかも。
TwitterとかMessage Passingとか RSS以外だと、Twitterで流れてきたのをInstapaperに送ってるのと、Message Passingでkzysとかが紹介しているのをInstapaperに送ったりとかはしている。 SNSは技術系の流入はだいたいTwitterからかなぁ。 自分の中ではTwitterからの流入とMessage Passingからの流入は割と同じカテゴリに入っている気がする。
自分は結構SNSやってる方だとは思うが、バズってる話題とかには極力近づかないようにしていて、そういうリンクは意識的に踏まないように心がけている。見てしまうと反応したくなるので。 だからSNSでつぶやいている量から想像されるよりは、Twitterからの流入は多くない。流入としてはRSSの1/3以下くらいかなぁ。
Message Passingからの流入の方がSNSからよりは気もち多い気もする。
ググった物 Instapaperを見ていて思うのは、単発の技術記事の多さ。どこから入ってきたかなぁ、と思うと、ググって見た物と、そこからリンクされてた物、みたいなのが多い。
例えばThe Rise of ``Worse is Better&#39;&#39;とか、Basics of the Unix Philosophyとか、LWN.</description>
      <content:encoded><![CDATA[<p>皆の話を見て、自分はどうしているかなぁ、と今BooxのInstapaperとPocketを眺めてみたのだが、なかなか雑多な経路から入っていて端的に言うのがなんか難しい。
とりあえず個別に話してから雑感的な事を述べてみよう。</p>
<h3 id="rss関連">RSS関連</h3>
<p>RSSは長らく既読にするだけという感じだったのだけれど、Booxを買ってから最近また活用するようになった。</p>
<p>7割くらいは読まずにarchiveになっていて、無駄だなぁ、とは思っている。一時的にオフに出来たらいいかもなぁ。
ちょっとオフトピだが、天文とか経済学とかが、最近は読まずにarchiveする比率が高い。
こういうのを読む気分じゃないのは一時的な物なので、アンフォローしたい訳でも無いのですよねぇ。
仕事やめて星を見る機会が増えたらまた見たいのだけれど。</p>
<p>RSSリーダーは<a href="https://www.inoreader.com/">Inoreader</a>使ってます。</p>
<p>読み方としてはざっとRSSリーダー上で確認して、気になったのはInstapaperに送る。以前はPocketに送ってたが、最近Instapaperに乗り換えを検討してて評価中。
後述するけれど、長いものは意図的に読む比率を上げています。
Instapaperに長いのを送るようになってからRSSを読む楽しさが増した気がするのでBooxは偉大だ。
なお今見直したら、送った奴はだいたい読んでいる模様。ちょっと意外。</p>
<p>友人知人と企業とかの区別は特に無く適当に加えてます。
昔はフォルダ分けとかしてたが最近はしてないので形骸化したフォルダが残ってて不便。</p>
<p>subscribeしている中で、割と良く読むブログを、読む率の高さ順で紹介しておく。</p>
<ul>
<li><a href="https://blog.jetbrains.com/kotlin/">Official Kotlin Blog</a></li>
</ul>
<p>Kotlinの話は結構読んでいる気がする。事例紹介とかは飛ばす事も多いが、ここからリンクをたどって気になったのを読むケースも結構多い。これが一番真面目に読んでいるかな。</p>
<ul>
<li><a href="https://android-developers.googleblog.com">Android Developers Blog</a></li>
</ul>
<p>これも結構読んでいる。</p>
<ul>
<li><a href="https://devblogs.microsoft.com/oldnewthing/">The Old New Thing</a></li>
</ul>
<p>Microsoftの人のC++とかWindows関連のブログ。
最初はC++関連でググってたどり着いたが、Windowsの話とかもたまに見ている。読まないで飛ばす率も高い。C++の話の時は結構読んでる。</p>
<ul>
<li><a href="https://2ality.com/">2ality – JavaScript and more</a></li>
</ul>
<p>以前Exploring ES6という本を読んで、なかなか良かったので、その後著者であるこのサイトをsubscribeしている。
JS関連はそこまで興味ある訳でも無いので飛ばす事も多いが、眺めるくらいはしているかなぁ。</p>
<ul>
<li><a href="https://developers.googleblog.com">Google Developers Blog</a></li>
</ul>
<p>TensorFlowとか興味がある奴だけ読んでる。これも飛ばす率は高い。</p>
<p>あと、<a href="https://blog.8-p.info/en/">kzysブログ</a>と<a href="https://shinh.skr.jp/m/">shinhブログ</a>からリンクされている技術系の記事は結構読んでる気がする。</p>
<p>その他統計とか機械学習系はsubscribeしているが最近は全然読んでない。そっちの界隈に復帰したらまた読みはじめるかも。</p>
<h3 id="twitterとかmessage-passingとか">TwitterとかMessage Passingとか</h3>
<p>RSS以外だと、Twitterで流れてきたのをInstapaperに送ってるのと、Message Passingでkzysとかが紹介しているのをInstapaperに送ったりとかはしている。
SNSは技術系の流入はだいたいTwitterからかなぁ。
自分の中ではTwitterからの流入とMessage Passingからの流入は割と同じカテゴリに入っている気がする。</p>
<p>自分は結構SNSやってる方だとは思うが、バズってる話題とかには極力近づかないようにしていて、そういうリンクは意識的に踏まないように心がけている。見てしまうと反応したくなるので。
だからSNSでつぶやいている量から想像されるよりは、Twitterからの流入は多くない。流入としてはRSSの1/3以下くらいかなぁ。</p>
<p>Message Passingからの流入の方がSNSからよりは気もち多い気もする。</p>
<h3 id="ググった物">ググった物</h3>
<p>Instapaperを見ていて思うのは、単発の技術記事の多さ。どこから入ってきたかなぁ、と思うと、ググって見た物と、そこからリンクされてた物、みたいなのが多い。</p>
<p>例えば<a href="https://web.stanford.edu/class/cs240/old/sp2014/readings/worse-is-better.html">The Rise of ``Worse is Better''</a>とか、<a href="https://homepage.cs.uri.edu/~thenry/resources/unix_art/ch01s06.html">Basics of the Unix Philosophy</a>とか、<a href="https://lwn.net/Articles/706404/">LWN.net: The Ninja build tool</a>とか、ググって引っかかった物を結構読んでる。
LWN.netはこの他にもちょくちょく読んだ記憶があるので、購読しても良いかもしれない。</p>
<p>昔読んだ物とか興味を持ったテクノロジーとかが多いかなぁ。ただ企業ブログとかもググって引っかかった物を単発で読む、というのは結構多い。
そこで気に入ったら目次に行って、幾つか気になりそうなのだけInstapaperに送って、subscribeまではしないが幾つかは読む、みたいなのとか。
ググって引っかかったものの、周囲2〜3リンクくらいを読む、みたいな感じでちょっと人力で周辺を見てみて、気になったのをInstapaperに加えたりしている。</p>
<p>こういうアドホックな流入が意外と多く、InstapaperにはRSS経由と同じくらいか、それよりも多いくらいある。
RSSはリーダー上で読んでいる物も多いから比較としては公平では無いが、それでもSNSから流れてくる物よりは大分多く、「読むものさがし」というトピックとしては自分の中で重要度が高そう。</p>
<p>自分から探しに行く、というのは古めかしい気もするけれど、流れてくるよりも自分で探した物を読むのに時間を使うのは正しい気もする。</p>
<h3 id="雑感">雑感</h3>
<p>Twitterに関しては自分はたぶんこの中では一番やってる人だと思う。
ただ技術系の情報の流入という点ではあまり価値が無いと思っていて、しかも近年その価値は急速に低下した気がしている。
その辺の感覚はmorritaさん、kzysさんと近いんじゃないか。
友人が興味を持った物には関心はあっても、友人がバズった物に反応しているのには距離をおきたいと思っている。</p>
<p>以前webの長い技術文書をあまり読まなくなっている事に気づいて、これではいかんと思って以後、長くてブラウザバックしてしまいそうな記事を意識的に踏みとどまってInstapaperに送るようにしている。
長いものを優先的に読むと意識してからは、新しい技術的な話題が入ってきやすくなった気がする。結構いい感じに機能しているのでオススメ。</p>
<p>RSSはいまいちsubscribeしたものを読む率が低いので、もう少し改善できんもんか…と思っている。
購読した時の興味が持続していないからそうなってしまうのかなぁ。
RSSが自分的には向こうから流れてくる類の情報の主力なのだけれど、義務というか溜まって消化している感じも強く、
気に入ったものをInstapaperで読んでる時の楽しさと比較するともうちょっとなんとかしたい。</p>
<p>昔はRSSからの流入はもっといい感じに機能していた気がするんだけどなぁ。
Web日記的なフィードが減ったからですかね。うーん。
ただTwitterからよりはずっと良い気がしているので、Twitterで流れてくるリンクを踏むよりはRSSを読むように意識はしている。</p>
<p>Hacker Newsletterとかも購読しているけれど、ほとんど読まずにArchiveしている。たまーに見るけれど。
こちらもやはりうまく機能していない気がする。流れてくるのは向いていないのかなぁ。</p>
<p>ググって引っかかったものとかの周辺を自分でちらっと見てInstapaperに送る、という方がRSSよりうまく行っている気もしているのだけれど、これだと量を増やすのが難しいんですよねぇ。
もうちょっとこの方向でさらなる進歩があるといいのかも。
我らがMessage Passingは読む物を知るには結構いい試みとは思っている。もうちょっとこういうのが他にも増えたらいいのかなぁ。</p>
<p>InstapaperとBooxの組み合わせは結構気に入ってます。やっぱりPCよりは専用デバイスの方が読む気になる。</p>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>自分から探して読む方が良いというのは、忘れがちだけど本当にそうですね。
自分だと探すきっかけみたいなものが不足しがちなので、ある程度ランダムな余暇プロジェクトとかをやるのが良いのかもしれない。
むかしブログを熱心に書いていた頃は「書くために読む」面があって、そこには良さもあったのを思い出しました。
Message Passing でもそういう書物ができるといいんだけど、どうかな。</p>
<p>LWN.net は自分も良いと思って一時期<a href="https://lwn.net/subscribe/Info">購読</a>していました。
ただ Linux の専門家でもないので毎週最新情報を読むより探して古い記事に出くわす方が多く、
有り難みが薄くていつからか解約しちゃったな。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>それは自分も一緒そうだなぁ＞最新情報が欲しいほどでも無い</p>
<p>お金を払ってもいいな、と思うのだけど、購読するほどじゃないんですよね。投げ銭出来るくらいがちょうどいいのになぁ。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: 読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/03-kzys/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/03-kzys/</guid>
      <description>自分は morrita さんと jmuk さんの間だと、morrita さんよりかなあ。ソーシャル少なめ。RSS 多め。
読みはじめたもの: ニュースレター 近頃流行りのニュースレター。私は Cindy Sridharan さんがニュースレターをはじめるというので、彼女のものを皮切りにいくつか購読している。いまのところ楽しみに読んでいるのは、Nelson Elhage の Musing in Computer Systems と、Hillel Wayne の Computer Things。
Nelson Elhage さんは、以前もふれた Sorbet の初期開発者の一人であり、Accidentally Quadratic の編者でもあった人。「コードレビューについて」みたいな平和なものから「Clang がこれを最適化しないのは変だと思ったんだけど、Alive2 っていう形式手法を使ったやつがあってさあ」みたいなマニアすぎるものまで話題が幅広く面白い。
Hillel Wayne さんは、こちらも以前にふれた &amp;ldquo;Practical TLA+&amp;rdquo; の著者の人。この人はブログもちゃんと更新されていて、その紹介の日もあれば、ニュースレター専用のエッセイもある。
形式手法の人だと思っていたら、ブログでは「ソフトウェアエンジニアはエンジニアと呼べるのか?」というたまに見かける話題に対して、実際に他分野のエンジニアにインタビューしたりしていて、なかなか手広い。
ずっと読んでいるもの: ブログ ブログは Feedly で読んでいる。livedoor Reader 時代は多読傾向があったのだけど、最近は控えめ (50前後)。セコンさんとか、Julia Evans さんとか、インターネットスターを追いがちで、いま見返すと仕事に直接関係あるものは少ない。
読まないつもりのもの: ニュース ニュースは、Hacker News, Lobsters, はてなブックマークあたりを見ていたんだけど、2021年はニュース消費を減らすつもりでいて、LeechBlock で土曜日以外はアクセスできないようにしている。
Cal Newport の &amp;ldquo;Digital Minimalsim&amp;rdquo; (邦訳『デジタル・ミニマリスト』) の影響、と言いたいところだけど、ニュースを読まないという話は、どちらかというと &amp;ldquo;Make Time&amp;rdquo; (邦訳『時間術大全』) の影響かもしれない。著者の一人である John Zeratsky の Why I Ignore the Daily News は、要するに「毎日ニュース読まなくていいでしょ。かわりに、毎週 The Economist 読んでるよ。」という話で、まあ私は The Economist も読んでいないんだけど&amp;hellip;</description>
      <content:encoded><![CDATA[<p>自分は morrita さんと jmuk さんの間だと、morrita さんよりかなあ。ソーシャル少なめ。RSS 多め。</p>
<h3 id="読みはじめたもの-ニュースレター">読みはじめたもの: ニュースレター</h3>
<p>近頃流行りのニュースレター。私は <a href="https://twitter.com/copyconstruct">Cindy Sridharan</a> さんが<a href="https://copyconstruct.substack.com/">ニュースレター</a>をはじめるというので、彼女のものを皮切りにいくつか購読している。いまのところ楽しみに読んでいるのは、<a href="https://nelhage.com/">Nelson Elhage</a> の <a href="https://buttondown.email/nelhage/archive">Musing in Computer Systems</a> と、<a href="https://www.hillelwayne.com/">Hillel Wayne</a> の <a href="https://buttondown.email/hillelwayne/archive">Computer Things</a>。</p>
<p>Nelson Elhage さんは、以前もふれた <a href="https://sorbet.org/">Sorbet</a> の初期開発者の一人であり、<a href="https://accidentallyquadratic.tumblr.com/">Accidentally Quadratic</a> の編者でもあった人。「コードレビューについて」みたいな平和なものから「Clang がこれを最適化しないのは変だと思ったんだけど、Alive2 っていう形式手法を使ったやつがあってさあ」みたいなマニアすぎるものまで話題が幅広く面白い。</p>
<p>Hillel Wayne さんは、こちらも以前にふれた &ldquo;Practical TLA+&rdquo; の著者の人。この人はブログもちゃんと更新されていて、その紹介の日もあれば、ニュースレター専用のエッセイもある。</p>
<p>形式手法の人だと思っていたら、ブログでは「ソフトウェアエンジニアはエンジニアと呼べるのか?」というたまに見かける話題に対して、実際に他分野のエンジニアにインタビューしたりしていて、なかなか手広い。</p>
<h3 id="ずっと読んでいるもの-ブログ">ずっと読んでいるもの: ブログ</h3>
<p>ブログは <a href="https://feedly.com/">Feedly</a> で読んでいる。livedoor Reader 時代は多読傾向があったのだけど、最近は控えめ (50前後)。<a href="https://secon.dev/">セコンさん</a>とか、<a href="https://jvns.ca/">Julia Evans さん</a>とか、インターネットスターを追いがちで、いま見返すと仕事に直接関係あるものは少ない。</p>
<h3 id="読まないつもりのもの-ニュース">読まないつもりのもの: ニュース</h3>
<p>ニュースは、<a href="https://news.ycombinator.com/">Hacker News</a>, <a href="https://lobste.rs/">Lobsters</a>, <a href="https://b.hatena.ne.jp/">はてなブックマーク</a>あたりを見ていたんだけど、2021年はニュース消費を減らすつもりでいて、<a href="https://www.proginosko.com/leechblock/">LeechBlock</a> で土曜日以外はアクセスできないようにしている。</p>
<p><a href="https://www.calnewport.com/">Cal Newport</a> の &ldquo;Digital Minimalsim&rdquo; (邦訳『デジタル・ミニマリスト』) の影響、と言いたいところだけど、ニュースを読まないという話は、どちらかというと <a href="https://maketime.blog/">&ldquo;Make Time&rdquo;</a> (邦訳『時間術大全』) の影響かもしれない。著者の一人である John Zeratsky の <a href="https://maketime.blog/article/why-i-ignore-the-daily-news/">Why I Ignore the Daily News</a> は、要するに「毎日ニュース読まなくていいでしょ。かわりに、毎週 The Economist 読んでるよ。」という話で、まあ私は The Economist も読んでいないんだけど&hellip;</p>
<p>あとは、<a href="https://www.blog.google/products/assistant/hey-google-tell-me-something-good/">Hey Google, tell me something good</a> で紹介されている「従来のジャーナリズムは問題にフォーカスしすぎであって、人々がその問題にどう対応しているのかが抜けがちで、我々はそれを変えていくよ」という <a href="https://www.solutionsjournalism.org/">Solutions Journalism</a> というアイデアがあって、私はこれを知ってから、ちゃんとした報道機関によるニュースについても「自分は問題の話ばかりを読んでいないかな」とちょっと一歩ひいて考えるようになっている。</p>
<p>morrita さんは Hacker News 読んでます?</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<blockquote>
<p>morrita さんは Hacker News 読んでます?</p>
</blockquote>
<p>Hacker News 読んでますよ。News として読むというよりは、読み物探しに使ってます。
HN にある「ニュース」の類は、昔は一定程度読んでた気がしますが、最近は勤務先が批判されることが多く消耗するので読まなくなりました。特にコメント欄。
批判がみな間違ってるというつもりはないけど、気晴らしの最中に嫌われている企業で働いている事実と向かい合わうのはしんどいので。
勤務先以外のニュースも、あんまり興味ないので記事は読まずヘッドラインだけ眺めてます。</p>
<p>読み物探しも煽りっぽいのはスキップし、技術的に得るところがありそうなものを読むようにしてます。
ただ HN はいわゆるニュースに押されて、読み物は段々と探しにくくなってる気がするね。</p>
<p>それはさておき紹介してくれた newsletter さっそくいくつか購読しました。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: 読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/02-jmuk/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/02-jmuk/</guid>
      <description>うーん、そんなにいろいろ読んでいるかなぁ。
RSSフィードは私も情報収集にはあんまり使っていない。Feedlyを無料枠で使っているけど、使い方はけっこう雑。一日一回眺めるぐらいで、フォローしているのもたいがい知り合いか、そうでなくても比較的生活感の強いブログが多い。技術系の記事はフィードに入れてるやつもあるんだけど、雰囲気がミスマッチしているからか、あんまり読めていない気がする。
ほかでもたとえば、Hacker Newsも、トップページを眺めることはあんまり多くない。Redditもあんまり見てない。ニュースレターも、そこそこ登録はしてたりするんだが、あんまり読めてない。どうもこういうものを読むことが生活サイクルに組み込めてない感じがある。あと仕事内容とか興味のある技術分野とマッチしたニュースレターをあんまり見つけられていない感もあるかな……。この辺はもう少し掘り返してみたほうがいいような気もする。
というぐあいに「残念」なかんじなのにいろいろ見てるような印象を与えられているとしたら、たぶんソーシャルなサービスのおかげかなと思う。
たとえば、技術系記事の情報源は Twitter に頼っているところが大きい気がする。知り合い、同僚、同業有名人、技術系のニュースメディア（The Vergeとか）、そういった人々を適当にフォローしていて、彼らの紹介するリンクを消費している。そういえば、Twitterは昔ながらの時系列順のタイムラインと、Twitterが関連性の高いものを勝手に流してくるレコメンデーションベースのタイムラインがあるが、わたしは古参には不評な後者を使ってる。これのおかげで直接的にはフォローしていないような記事もタイムラインに上がってきていい面もある。ノイズがめちゃくちゃあるのと時系列が完全に破壊されるのが欠点だが、適当に流し見する目的ならこのほうがよいというふうに納得している。
あとは Hacker News 100 という、Hacker Newsで100以上のupvoteを集めた記事だけを流すbotアカウントがあって、これもフォローしている。100以外にもいろいろあるみたいだけど、HNの記事はこういう、何らかの基準でフィルタされたやつだけでいいかな、という気持ちがある。
あとはてブ。はてブはブックマークコメントは見るとウッとなるが、紹介されてる記事には面白いものもそれなりにあるので、そこから興味をもった記事を読んだりしている。コメントは見ないよう心がけている。あと過度にブクマを集めすぎている奴は炎上なだけなので、もっと穏当なやつのほうがおもしろい。
最後にGoogleの、えーと今なんていう名前なのか知らないんだけど、おすすめの記事を勝手に教えてくれる機能がある。あそこからいろいろ記事を読んだりもしている。ただ技術系の記事については正直なところぜんぜんかな。ローカルニュースとか、映画とかのネタは妙に豊富に拾ってくれて、まあまあ便利に使っています。とはいえ、玉石混交できびしい面もあるけれど。
まとまりがなくなってしまったが、しいていうなら、自分でフィードを整備するのではなくて、大企業のAIの力を利用してその流れに乗っている、といえるかもしれない。とか言ってみたらかっこいいかなと思ったけど、そうでもないな……。
 morrita Twitter, 人々がやってるのにはわけがあるとわかる話ですね。すっかり忘れてしまってるけれど、使ってみると良いところもあるのだろうな。
Google のあれは今でも Discover でいいんじゃないかな。 自分は Chrome でも Google Search App でも無効にしてます。案の定といえよう。
  </description>
      <content:encoded><![CDATA[<p>うーん、そんなにいろいろ読んでいるかなぁ。</p>
<p>RSSフィードは私も情報収集にはあんまり使っていない。<a href="https://feedly.com/">Feedly</a>を無料枠で使っているけど、使い方はけっこう雑。一日一回眺めるぐらいで、フォローしているのもたいがい知り合いか、そうでなくても比較的生活感の強いブログが多い。技術系の記事はフィードに入れてるやつもあるんだけど、雰囲気がミスマッチしているからか、あんまり読めていない気がする。</p>
<p>ほかでもたとえば、Hacker Newsも、トップページを眺めることはあんまり多くない。Redditもあんまり見てない。ニュースレターも、そこそこ登録はしてたりするんだが、あんまり読めてない。どうもこういうものを読むことが生活サイクルに組み込めてない感じがある。あと仕事内容とか興味のある技術分野とマッチしたニュースレターをあんまり見つけられていない感もあるかな……。この辺はもう少し掘り返してみたほうがいいような気もする。</p>
<p>というぐあいに「残念」なかんじなのにいろいろ見てるような印象を与えられているとしたら、たぶんソーシャルなサービスのおかげかなと思う。</p>
<p>たとえば、技術系記事の情報源は Twitter に頼っているところが大きい気がする。知り合い、同僚、同業有名人、技術系のニュースメディア（<a href="https://www.theverge.com/">The Verge</a>とか）、そういった人々を適当にフォローしていて、彼らの紹介するリンクを消費している。そういえば、Twitterは昔ながらの時系列順のタイムラインと、Twitterが関連性の高いものを勝手に流してくるレコメンデーションベースのタイムラインがあるが、わたしは古参には不評な後者を使ってる。これのおかげで直接的にはフォローしていないような記事もタイムラインに上がってきていい面もある。ノイズがめちゃくちゃあるのと時系列が完全に破壊されるのが欠点だが、適当に流し見する目的ならこのほうがよいというふうに納得している。</p>
<p>あとは <a href="https://twitter.com/newsyc100">Hacker News 100</a> という、Hacker Newsで100以上のupvoteを集めた記事だけを流すbotアカウントがあって、これもフォローしている。100以外にもいろいろあるみたいだけど、HNの記事はこういう、何らかの基準でフィルタされたやつだけでいいかな、という気持ちがある。</p>
<p>あとはてブ。はてブはブックマークコメントは見るとウッとなるが、紹介されてる記事には面白いものもそれなりにあるので、そこから興味をもった記事を読んだりしている。コメントは見ないよう心がけている。あと過度にブクマを集めすぎている奴は炎上なだけなので、もっと穏当なやつのほうがおもしろい。</p>
<p>最後にGoogleの、えーと今なんていう名前なのか知らないんだけど、おすすめの記事を勝手に教えてくれる機能がある。あそこからいろいろ記事を読んだりもしている。ただ技術系の記事については正直なところぜんぜんかな。ローカルニュースとか、映画とかのネタは妙に豊富に拾ってくれて、まあまあ便利に使っています。とはいえ、玉石混交できびしい面もあるけれど。</p>
<p>まとまりがなくなってしまったが、しいていうなら、自分でフィードを整備するのではなくて、大企業のAIの力を利用してその流れに乗っている、といえるかもしれない。とか言ってみたらかっこいいかなと思ったけど、そうでもないな……。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>Twitter, 人々がやってるのにはわけがあるとわかる話ですね。すっかり忘れてしまってるけれど、使ってみると良いところもあるのだろうな。</p>
<p>Google のあれは今でも <a href="https://blog.google/products/search/introducing-google-discover/">Discover</a> でいいんじゃないかな。
自分は Chrome でも Google Search App でも無効にしてます。案の定といえよう。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Facebok のハッカー的姿勢</title>
      <link>https://messagepassing.github.io/013-fboss/02-karino2/</link>
      <pubDate>Mon, 08 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/013-fboss/02-karino2/</guid>
      <description>RE2JのFacebookからのissue Facebookのオープンソース活動で、最初にこいつらなかなかいい奴らだな、と自分が思ったのは、RE2Jで見かけた時の事だったと思う。 RE2Jでbyte array使えないかなぁ、と思ってissueを眺めていたら、 Sliceという別のライブラリに依存した形で同じような事をやっていた。
Sliceはunsafeバリバリで低レベルにバイト列を効率的に扱うようなライブラリなので、 あまりJava的にお行儀が良い物では無い。 そんなものに依存したコード持っていっても取り込むのは嫌がる、というのはFacebookの人たちも分かっていたと思うけれど、 まず自分たちの問題を解決する事を優先したのだと思う。 そしてそれをどうやったか示すだけに留める、という姿勢。 手元の問題を解決する事を最優先とするハッカー気質を感じて、なかなかいいな、と思った。
このissueでGoogle側がなんのかんのと理由をつけて取り込まないくせに代替案も実現せず、結局公式ではbyte列は扱えないままなのが対照的で面白い。
なお自分は同じような機能が欲しかったが、AndroidにSlice持っていくのも大変だったので、このslice版をforkして機能削ってsliceとガワを揃えたbyte arrayの実装をでっちあげて使った。RE2Jのフルの機能は実現出来ないが、自分が使う分には問題無かったので、まぁいいか、と。Facebookとは友達になれそうなアプローチである。
Facebookのオープンソースは、使ってみると、要らない所は手を抜きつつ頑張って欲しい所は頑張っていて、こいつら分かってるなぁ、と思った。 プログラマの為のライブラリって感じがするんですよね、素人のお客様の為じゃなくて。我々の為にコードを公開している、という仲間意識を感じる。
そしてFacebookいいな、と思ったものでここで特に取り上げたいのはFollyです（今年読んだものでちょっと話しましたが)。
FollyにみるFacebookのハッカー的姿勢 Follyとは何かというと、Facebookが公開しているC++の基礎ライブラリ、と言えるだろうか。 FutureやBatonなどのちゃんとした並列プリミティブや、Arenaなどのデータ構造とかが全部ごちゃっと入っている。
一部だけ使うとかは出来なくて、全部入れる、という前提な所がモノレポカルチャーだなぁ、と思う。 また、例えばQtなどの他のフレームワークと混ぜよう、とかいうと、いろいろ困る所がある。 でも「サーバーサイドで使っている自分たちはそういう事は無かった」という姿勢なのだろう、と勝手に思っている。
使う人の視点からすると一部だけ欲しい、という事は結構あるのだけれど、そういう対応はしない。 必要な物だけ切り出して、不要な依存は排除して、thread poolはプラットフォームのものも使えるようにして…とかそういう事はしない。 自分たちの問題に最短でアプローチして、解決して、そしてそのノウハウを分かる人には分かる形で共有する。 かっこいい。
FacebookのFuture周辺の凄さ 現在C++以外の世界では、future-promiseという概念は広く使われていて、futureライブラリに期待される性質というのも、ほとんどコンセンサスが得られる段階にあると思う。（むしろちょっと今更感があるかもしれない）
昨今の多数のコアを使い切るには、小さな粒度で大量のfutureを作るスタイルが望ましい。 だから、大量のfutureを作ってもスレッド数がHWスレッド数以上に増えてしまわず、適当なスレッドプールで個々のfutureは低コストに実行される必要がある。 スレッドプールを使う為、ブロッキングで待ってスレッドを消費するのはまずいから、 全てノンブロッキングに結果を受け取って次のタスクをつなげていくスタイルで書く必要がある。 そして必要な時には特定の、例えばGUIスレッドなどで結果を受け取る必要もある。
信じがたい事だが、C++のfutureライブラリの多くは、この基本的な要求を満たしていない。 例えばSTLにはスレッドプールが無くて、executor的な概念も無いから、GUIスレッドで受け取る、みたいな事もうまく抽象化出来ていない。 futureが結果を受け取るのはwaitとか言ってブロックしてしまう。 当然スレッドを消費してしまうし、現代的なコア数がたくさんある環境でコア使い切るのにこれでは全然ダメだ。
FollyのfutureはGUIスレッドという実装は無いけれど、Executorとスレッドプール自体はあって、 どのExecutorで動かすか、という事がちゃんと指定出来る。 だからGUIスレッドのある環境で動かしたいとなれば、GUIスレッドのExecutorを書けば、GUIスレッドで結果を受け取る事もたぶん問題無い。 ちゃんと結果はノンブロッキングで待てて、 受け取るExecutorもちゃんと選べる。 こいつらちゃんとコア全部使ってんなぁ、というのが伝わってくるAPIになっている。
さらに実装を見るとスレッドプールもfutureも、 手抜きでロックしたくなるような所もatomicとかで頑張っていて、 メモリモデルの指定も細かい。 自分レベルでは全てが正しいのかは判断出来ないが、 すごい専門家っぽい人が頑張って書いたな〜って感じの実装になってて、いかにも早そう。 APIも分かっているが実装も分かっている。こいつら只者じゃない。 少なくとも私よりは大分腕が良い。やるなぁ。
Batonなどの並列primitiveも現代的で、エラーが少なく効率良く使えるような物がいろいろ用意されている。 彼らは本当にモダンな言語での現代の並列プログラムを良く分かってて、それをただ持ってくるだけでは無く、C++ではこうすべき、というアレンジもしつつ書いているように見える。 現代的な便利な発明をいろいろ理解しつつ、専門的なメモリモデルとかも最適な物で実装している。 Follyの並列すごい。
なお、並列以外も非常にC++14的な模範的なC++のコードになっていて勉強になるので、 C++を勉強するならFollyのコードを読むのは凄くオススメです。APIだけで無く実装も良い。 自分はまだ17使えない環境なので、14である事も嬉しい。
 morrita これを読んで Folly の Future は Instagram のバックエンドも使っている というのを思い出しました。 なおこの話はまったく盛り上がらなかったため、これでおしまいです。   karino2 FBのOSS、なかなか面白いの多いと思うんだが、このトピックは全然盛り上がらんかったねぇ。</description>
      <content:encoded><![CDATA[<h3 id="re2jのfacebookからのissue">RE2JのFacebookからのissue</h3>
<p>Facebookのオープンソース活動で、最初にこいつらなかなかいい奴らだな、と自分が思ったのは、<a href="https://github.com/google/re2j">RE2J</a>で見かけた時の事だったと思う。
RE2Jでbyte array使えないかなぁ、と思ってissueを眺めていたら、
<a href="https://github.com/google/re2j/issues/17">Sliceという別のライブラリに依存した形で同じような事をやっていた</a>。</p>
<p>Sliceはunsafeバリバリで低レベルにバイト列を効率的に扱うようなライブラリなので、
あまりJava的にお行儀が良い物では無い。
そんなものに依存したコード持っていっても取り込むのは嫌がる、というのはFacebookの人たちも分かっていたと思うけれど、
まず自分たちの問題を解決する事を優先したのだと思う。
そしてそれをどうやったか示すだけに留める、という姿勢。
手元の問題を解決する事を最優先とするハッカー気質を感じて、なかなかいいな、と思った。</p>
<p>このissueでGoogle側がなんのかんのと理由をつけて取り込まないくせに代替案も実現せず、結局公式ではbyte列は扱えないままなのが対照的で面白い。</p>
<p>なお自分は同じような機能が欲しかったが、AndroidにSlice持っていくのも大変だったので、<a href="https://github.com/karino2/ZipSourceCodeReading/tree/master/app/src/main/java/com/google/re2j">このslice版をforkして機能削ってsliceとガワを揃えたbyte arrayの実装をでっちあげて使った</a>。RE2Jのフルの機能は実現出来ないが、自分が使う分には問題無かったので、まぁいいか、と。Facebookとは友達になれそうなアプローチである。</p>
<p>Facebookのオープンソースは、使ってみると、要らない所は手を抜きつつ頑張って欲しい所は頑張っていて、こいつら分かってるなぁ、と思った。
プログラマの為のライブラリって感じがするんですよね、素人のお客様の為じゃなくて。我々の為にコードを公開している、という仲間意識を感じる。</p>
<p>そしてFacebookいいな、と思ったものでここで特に取り上げたいのはFollyです（<a href="https://messagepassing.github.io/004-whatiread/02-karino2/">今年読んだもの</a>でちょっと話しましたが)。</p>
<h3 id="follyにみるfacebookのハッカー的姿勢">FollyにみるFacebookのハッカー的姿勢</h3>
<p><a href="https://github.com/facebook/folly">Folly</a>とは何かというと、Facebookが公開しているC++の基礎ライブラリ、と言えるだろうか。
FutureやBatonなどのちゃんとした並列プリミティブや、Arenaなどのデータ構造とかが全部ごちゃっと入っている。</p>
<p>一部だけ使うとかは出来なくて、全部入れる、という前提な所がモノレポカルチャーだなぁ、と思う。
また、例えばQtなどの他のフレームワークと混ぜよう、とかいうと、いろいろ困る所がある。
でも「サーバーサイドで使っている自分たちはそういう事は無かった」という姿勢なのだろう、と勝手に思っている。</p>
<p>使う人の視点からすると一部だけ欲しい、という事は結構あるのだけれど、そういう対応はしない。
必要な物だけ切り出して、不要な依存は排除して、thread poolはプラットフォームのものも使えるようにして…とかそういう事はしない。
自分たちの問題に最短でアプローチして、解決して、そしてそのノウハウを分かる人には分かる形で共有する。
かっこいい。</p>
<h3 id="facebookのfuture周辺の凄さ">FacebookのFuture周辺の凄さ</h3>
<p>現在C++以外の世界では、future-promiseという概念は広く使われていて、futureライブラリに期待される性質というのも、ほとんどコンセンサスが得られる段階にあると思う。（むしろちょっと今更感があるかもしれない）</p>
<p>昨今の多数のコアを使い切るには、小さな粒度で大量のfutureを作るスタイルが望ましい。
だから、大量のfutureを作ってもスレッド数がHWスレッド数以上に増えてしまわず、適当なスレッドプールで個々のfutureは低コストに実行される必要がある。
スレッドプールを使う為、ブロッキングで待ってスレッドを消費するのはまずいから、
全てノンブロッキングに結果を受け取って次のタスクをつなげていくスタイルで書く必要がある。
そして必要な時には特定の、例えばGUIスレッドなどで結果を受け取る必要もある。</p>
<p>信じがたい事だが、C++のfutureライブラリの多くは、この基本的な要求を満たしていない。
例えばSTLにはスレッドプールが無くて、executor的な概念も無いから、GUIスレッドで受け取る、みたいな事もうまく抽象化出来ていない。
futureが結果を受け取るのはwaitとか言ってブロックしてしまう。
当然スレッドを消費してしまうし、現代的なコア数がたくさんある環境でコア使い切るのにこれでは全然ダメだ。</p>
<p><a href="https://github.com/facebook/folly/blob/master/folly/docs/Futures.md">Follyのfuture</a>はGUIスレッドという実装は無いけれど、Executorとスレッドプール自体はあって、
どのExecutorで動かすか、という事がちゃんと指定出来る。
だからGUIスレッドのある環境で動かしたいとなれば、GUIスレッドのExecutorを書けば、GUIスレッドで結果を受け取る事もたぶん問題無い。
ちゃんと結果はノンブロッキングで待てて、
受け取るExecutorもちゃんと選べる。
こいつらちゃんとコア全部使ってんなぁ、というのが伝わってくるAPIになっている。</p>
<p>さらに実装を見るとスレッドプールもfutureも、
手抜きでロックしたくなるような所もatomicとかで頑張っていて、
メモリモデルの指定も細かい。
自分レベルでは全てが正しいのかは判断出来ないが、
すごい専門家っぽい人が頑張って書いたな〜って感じの実装になってて、いかにも早そう。
APIも分かっているが実装も分かっている。こいつら只者じゃない。
少なくとも私よりは大分腕が良い。やるなぁ。</p>
<p>Batonなどの並列primitiveも現代的で、エラーが少なく効率良く使えるような物がいろいろ用意されている。
彼らは本当にモダンな言語での現代の並列プログラムを良く分かってて、それをただ持ってくるだけでは無く、C++ではこうすべき、というアレンジもしつつ書いているように見える。
現代的な便利な発明をいろいろ理解しつつ、専門的なメモリモデルとかも最適な物で実装している。
Follyの並列すごい。</p>
<p>なお、並列以外も非常にC++14的な模範的なC++のコードになっていて勉強になるので、
C++を勉強するならFollyのコードを読むのは凄くオススメです。APIだけで無く実装も良い。
自分はまだ17使えない環境なので、14である事も嬉しい。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
これを読んで Folly の Future は <a href="https://instagram-engineering.com/c-futures-at-instagram-9628ff634f49">Instagram のバックエンドも使っている</a> というのを思い出しました。
なおこの話はまったく盛り上がらなかったため、これでおしまいです。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
FBのOSS、なかなか面白いの多いと思うんだが、このトピックは全然盛り上がらんかったねぇ。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Facebook オープンソースのかっこよさ</title>
      <link>https://messagepassing.github.io/013-fboss/01-morrita/</link>
      <pubDate>Sun, 07 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/013-fboss/01-morrita/</guid>
      <description>Facebook のオープンソースプロジェクトには、妙にかっこいいものが多い。 企業発 OSS の中でもかっこよさが突出している。 有名どころでは React (2013) と PyTorch (2016) があるけれども、 他にも MySQL のストレージエンジンをとりかえた MyRocks/RocksDB, Microsoft も使い始めた静的解析ツール Infer (これは買収だな), AWS が managed service をはじめるに至った OLAP DB の Presto, Rust で書いてしまった Marcurial Backend の Eden などなど枚挙に暇がない。
プロジェクトの数だけなら他にも数多く公開している会社はあるし、 プロジェクトの規模(つっこまれている人員)が特別多い感じでもない。 が、かっこよさは企業発オープンソースの中で一歩先を行っている、気がする。
昔の Facebook は、それほどオープンソースが得意な印象ではなかった。 Hive なんかは割と古い (2010) ヒット作だけれど、 Cassandra (2008) は他の会社に引き取られてしまったし（それはある意味ではヒットしているが）、 Thrift (2007) に至っては自分ではじめたオープンソースなのに なぜか自らフォークしている。意味不明。
それがいまやこのかっこよさ。 かっこよさを感じる理由はいくつかある。
一つはプロジェクトの小粋さ。 React は全部入りのフレームワークでないし、 PyTorch は（当初は）割と小さく、API もきちんとレイヤリングされているし、 MyRocks はデータベースをフルスクラッチでなく MySQL を再利用してるし、などなど。
プログラミング言語選択のリベラルさも良い。Infer に限らず妙に OCaml が幅を利かせていたり、 一時期は Haskell や D もまじっていたし、 最近は Rust まである。 ハック精神を感じる。そういえば言語作ってたな: Hack.</description>
      <content:encoded><![CDATA[<p><a href="https://opensource.facebook.com/projects">Facebook のオープンソースプロジェクト</a>には、妙にかっこいいものが多い。
企業発 OSS の中でもかっこよさが突出している。
有名どころでは React (2013) と PyTorch (2016) があるけれども、
他にも MySQL のストレージエンジンをとりかえた <a href="http://myrocks.io/">MyRocks</a>/<a href="https://rocksdb.org/">RocksDB</a>,
<a href="https://devblogs.microsoft.com/dotnet/infer-interprocedural-memory-safety-analysis-for-c/">Microsoft も使い始めた</a>静的解析ツール <a href="https://github.com/facebook/infer">Infer</a> (これは<a href="https://techcrunch.com/2013/07/18/facebook-monoidics/">買収</a>だな),
AWS が <a href="https://aws.amazon.com/athena/">managed service</a> をはじめるに至った OLAP DB の <a href="https://prestodb.io/">Presto</a>,
Rust で書いてしまった Marcurial Backend の <a href="https://github.com/facebookexperimental/eden">Eden</a> などなど枚挙に暇がない。</p>
<p>プロジェクトの数だけなら他にも数多く公開している会社はあるし、
プロジェクトの規模(つっこまれている人員)が特別多い感じでもない。
が、かっこよさは企業発オープンソースの中で一歩先を行っている、気がする。</p>
<p>昔の Facebook は、それほどオープンソースが得意な印象ではなかった。
<a href="https://hive.apache.org/">Hive</a> なんかは割と古い (2010) ヒット作だけれど、
<a href="https://cassandra.apache.org/">Cassandra</a> (2008) は他の会社に引き取られてしまったし（それはある意味ではヒットしているが）、
<a href="https://thrift.apache.org/">Thrift</a> (2007) に至っては自分ではじめたオープンソースなのに
なぜか<a href="https://github.com/facebook/fbthrift">自らフォークしている</a>。意味不明。</p>
<p>それがいまやこのかっこよさ。
かっこよさを感じる理由はいくつかある。</p>
<p>一つはプロジェクトの小粋さ。
React は全部入りのフレームワークでないし、
PyTorch は（当初は）割と小さく、API もきちんとレイヤリングされているし、
MyRocks はデータベースをフルスクラッチでなく MySQL を再利用してるし、などなど。</p>
<p>プログラミング言語選択のリベラルさも良い。Infer に限らず妙に OCaml が幅を利かせていたり、
一時期は <a href="https://engineering.fb.com/2015/06/26/security/fighting-spam-with-haskell/">Haskell</a>
や <a href="https://forum.dlang.org/post/l37h5s$2gd8$1@digitalmars.com">D</a> もまじっていたし、
最近は <a href="https://github.com/facebookexperimental?language=rust">Rust</a> まである。
ハック精神を感じる。そういえば言語作ってたな: <a href="https://hacklang.org/">Hack</a>.</p>
<p>もう一つ感じるのはコミュニティづくりを含めた見せ方のうまさ。
これはなぜなのだろうとウェブを眺めていたら Facebook の OSS 担当者が一時期やっていた The Diff という Podcast の
<a href="https://thediffpodcast.com/docs/episode-1">最初のエピソード</a> が社内のオープンソースの取り組みを紹介していた。</p>
<p>これによれば彼らはオープンソースプロジェクトの活発さのメトリクスを監視し、関係者を ping したりしているらしい。
たとえば PR の数、その対応時間、フォークの数などをトラックしている。
オープンソースプロジェクト公開のバーも高い。担当者がきちんとコミュニティ対応にコミットできる確約がないと公開させてもらえない。
プロジェクト自身の新規性なども加味される。
こうした企業としての Facebook の取り組みは、企業オープンソース支援団体 TODO Group の
<a href="https://todogroup.org/guides/measuring/">ガイド</a>　でも紹介されている。</p>
<p>もっともこうした「オープンソースの見せ方の上手さ」は新しい世代の企業なら多かれ少なかれ持っている。
やはり見せるに値するプロジェクトを持っているのが重要。
たとえば Netflix とか<a href="https://netflixtechblog.com/">企業ブログ</a>は割とかっこいい話が多いけれど、
<a href="https://github.com/Netflix">GitHub</a> をみると（自分がクラウド素人である事実を差し引いても）そんなにピンこない。</p>
<h2 id="profilo">Profilo</h2>
<p>自分が Android アプリで性能関係の仕事をしている関係もありその手のライブラリをたまにひやかす。
そんな中ででくわしたのが <a href="https://github.com/facebookincubator/profilo">Facebok Profilo</a>.
機能豊富なのもそうだけど、実装のえげつなさが Facebook 的でとてもよい。
息をするように <a href="https://github.com/facebookincubator/profilo/blob/master/cpp/atrace/Atrace.cpp">libc の関数を置き換えたりする</a>。
ここでは Android の <a href="https://developer.android.com/reference/android/os/Trace">Trace</a> の実装をフックし、
本来ならアプリケーション内からは見えないはずの Android Framework からのトレースをアプリケーション側で採取している。
普通ならかったるくて遠ざけがちな <a href="https://developer.android.com/guide/components/aidl">AIDL</a> も<a href="https://github.com/facebookincubator/profilo/tree/master/aidl/java/com/facebook/profilo/ipc">さらっと使っており</a>、練度が高い。</p>
<p>こういう低レイヤのコードは傾向としてぐちゃっとしがちなのに、極めて淡麗。こういう C++ なら書いて良いかもと思わせる品質。
気のせいだと思うけど。</p>
<p>最近 C++ 書いてる karino2 も Facebook のコードを褒めてた気がしますが、読みどころのおすすめはありますか。</p>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
（なお「オープンソースの見せ方の上手さ」がぜんぜんダメなのが Google で、この <a href="https://opensource.google/projects/list/featured">feaured project list</a> とか割と救いようがない。その <a href="https://opensource.google/projects/science-journal">Open Science Journal</a> とかいうのと <a href="https://opensource.google/projects/android">Android</a>
を同列にならべちゃっていいの？ <a href="https://github.com/google">GitHub org</a> には 2000 個ぐらいプロジェクトがあって探索不能だし、
オープンソースというものにかけているコストを考えるとまったく見せる気を感じない。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ちゃんとやりすぎた Chainer</title>
      <link>https://messagepassing.github.io/008-justright/05-shinh/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/05-shinh/</guid>
      <description>Worse is better といえば、 Chainer ってちゃんとやりすぎていたのでは、て話をよくするんですよね。まあうまくさぼってたら競争に勝ち残れてたかというと別の話なんですけど。 Chainer の開発終了する時の PyTorch への移行ドキュメントとか、 PyTorch の人が感心してたりしたけど、ホント丁寧だなあと感心する。
一方で、 TensorFlow はともかく、 PyTorch はかなりわちゃわちゃしてて、こんなんでいいんだ……とよくなる。例えば、「LogSoftmax て exp に渡すの負にしないとすぐふっとぶから定義通りではダメで、なんかするけど、なにするんだっけ……」みたいなこと調べる時に、 PyTorch のリポジトリの下で git grep して、「さっぱりわからんな……」となってから Chainer 見てすぐわかる、みたいなことがよく起きる。ちなみに log(sum(exp(x))) を max(x) + log(sum(exp(x - max(x)))) で計算すると良いという話。
あのカオティックな状態で人気ナンバーワンというのは、さすが Done is better than perfect の総本山、と感心するものがある。なんかでもかくいう Chainer も高速な CPU 実行は numpy に丸投げ、 cupy の実装は大変とはいえ少なくともインターフェイスは numpy のものを使えば良い、など、割といい感じに手を抜けるちょうどよさを持っていたという側面もあるかもなあ、と。ちゃんとやらなさすぎても見捨てられるので、いい感じのバランスを取るのはかなり難しい、という話かもしれない。
 morrita 一方 TensorFlow は Move fast and break things しすぎて人々に見放されてしまったのだった・・・。はさておき NumPy の API は「ちょうどいい」一族に数えて良い気がする。   shinh TensorFlow に限らずグーグルは、ちゃんとやりすぎててもなんとかなるどころか人が余りまくって仕事を奪いあうくらいのリソースがあるから回ってる感がありますよね。まあ流行るかというと、あのいつもの社内のもの出しただけグーグル OSS 感ではなあ……というような話は別トピックですると良いですかね。</description>
      <content:encoded><![CDATA[<p>Worse is better といえば、 <a href="https://chainer.org/">Chainer</a> ってちゃんとやりすぎていたのでは、て話をよくするんですよね。まあうまくさぼってたら競争に勝ち残れてたかというと別の話なんですけど。 <a href="https://chainer.github.io/migration-guide/">Chainer の開発終了する時の PyTorch への移行ドキュメント</a>とか、 PyTorch の人が感心してたりしたけど、ホント丁寧だなあと感心する。</p>
<p>一方で、 TensorFlow はともかく、 PyTorch はかなりわちゃわちゃしてて、こんなんでいいんだ……とよくなる。例えば、「LogSoftmax て exp に渡すの負にしないとすぐふっとぶから定義通りではダメで、なんかするけど、なにするんだっけ……」みたいなこと調べる時に、 PyTorch のリポジトリの下で <code>git grep</code> して、「さっぱりわからんな……」となってから Chainer 見てすぐわかる、みたいなことがよく起きる。ちなみに <a href="https://github.com/chainer/chainer/blob/4fe0c3b86e1a87dbb408f0f596d4467ec56a332d/chainer/functions/activation/log_softmax.py#L14"><code>log(sum(exp(x)))</code> を <code>max(x) + log(sum(exp(x - max(x))))</code> で計算すると良いという話</a>。</p>
<p>あのカオティックな状態で人気ナンバーワンというのは、さすが <a href="https://www.fastcompany.com/3001533/truth-about-being-done-versus-being-perfect">Done is better than perfect</a> の総本山、と感心するものがある。なんかでもかくいう Chainer も高速な CPU 実行は numpy に丸投げ、 cupy の実装は大変とはいえ少なくともインターフェイスは numpy のものを使えば良い、など、割といい感じに手を抜けるちょうどよさを持っていたという側面もあるかもなあ、と。ちゃんとやらなさすぎても見捨てられるので、いい感じのバランスを取るのはかなり難しい、という話かもしれない。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
一方 TensorFlow は Move fast and break things しすぎて人々に見放されてしまったのだった・・・。はさておき NumPy の API は「ちょうどいい」一族に数えて良い気がする。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
TensorFlow に限らずグーグルは、ちゃんとやりすぎててもなんとかなるどころか人が余りまくって仕事を奪いあうくらいのリソースがあるから回ってる感がありますよね。まあ流行るかというと、あのいつもの社内のもの出しただけグーグル OSS 感ではなあ……というような話は別トピックですると良いですかね。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Go言語のちょうどよさ</title>
      <link>https://messagepassing.github.io/008-justright/04-jmuk/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/04-jmuk/</guid>
      <description>Go言語は、なんというか「ちょうどいい」言語だな、と思っている。異論は認める。
Go言語の登場時、なんせGoogleが大々的に発表した新しいプログラミング言語であるし、Rob PikeやKen Thompsonといった有名人の関わりもあり、華々しかった。そして、その登場を眺めたプログラミング言語マニアは、そのダサい仕様にわりとすぐがっかりして、興味をなくした。ということがあったと思う。今はGoはけっこう広く使われていて人気もあるけど、ここに至るまでには紆余曲折があった。
Go言語、なにせ2010年代にもなってなんせジェネリクスもない（そのわりにスライスや配列、ハッシュテーブルだけが標準にあり、特別扱いされている）。例外処理もない（これはまぁそのほうがいいだろうという人もいるだろうけど）。そこらじゅう if err != nil だらけ。テストにアサーションもなく、ひたすら地道にif文を書くべしとされている。いくつかのビルトインな関数（たとえば makeなど）は構文上も特別扱いされていて、直交性がかけらもない。
オブジェクト指向的なことはできるが、C++やJavaのようなクラス志向ではない。継承が言語仕様にない。interfaceによるduck typingはできる。メタプログラミング的なことはやりづらい。オブジェクトは動的なところが一切ない。なんかデザインしづらそうだな、というふうに思った。
というわけで、登場時は「なんだかぱっとしない」「かっこよさがない」といったイメージであったように思う。すくなくとも自分は。
Go言語の「ちょうどよさ」 結果的にはこういうマニア視点はまったくのお門違いだったといえるだろう。Go言語はおおいに流行っている。これをGoogleによるゴリ押しだという主張はきっとあるだろうけれど、それはたぶん違う……もちろん、会社の支援のもとで言語仕様の改善や標準ライブラリの拡充などの発展があって便利になっていったという側面はあるけど、それはまあ「ゴリ押し」とは言わないだろう。
Goの独特のニッチにうまくハマったのだと思う。それはたとえばWebサーバやRPCサーバ、ちょっとしたユーティリティツールやサービスにあたる。GCがあって、並列処理ができ、標準ライブラリだけでもけっこういろんなことができて（http2サーバでJSONを返したりとが簡単にかける）、単純だけど静的型付けで単純な間違いは防げる。Goのインタフェース志向なduck typingは使ってみるとわかりやすく簡単だったし、実装の継承があると便利な場面というのも別になかった。こういう用途には便利だった。
言語マニアが「ださい」と思ったところは、実用上はそんなに大きな問題になることが多くはなかった。多くのGoプログラマが証言するように、Goを書いていてジェネリクスが必要なのになくて困るという場面はほんとうに少ない。もちろんまったくゼロではないし、今後たぶんジェネリクス的な機能は入ることになるだろうから、それはそれでいいことなんだけど、でも、マニアの文句なんてそんなもんだという話でもある。標準組み込み型の特別扱いがわりとうまく機能してるとも言える。
Goコマンドの導入によりツールチェインはわかりやすく使いやすくなったし、ビルドも速く、シングルバイナリでデプロイや配布が単純というのもよかった。こういうところは言語マニアはあんまり評価対象としないと思うけれど（言語そのものというよりは処理系の話だし）、そこには大きな意味があったと思う。Goは性能がよいというイメージ（実際のところ、最速でないにしろスクリプト言語よりは十分速い）も普及に一役買ったことだろう。
Goはworse is betterか？ Goの「ちょうどよさ」というのはどういうものだろうか。先進的でかっこいい理論にもとづいた複雑な言語より、ダサいけど使いやすいのがいい、というのが端的な評価になるとおもう。これはworse is betterを思わせるところがある。ただ、読み直してみると、Goはworse is betterでいうところのNew Jerseyアプローチではないように思える。
Worse is betterの結論というのはこうだ。実装が簡単で使うのも苦じゃないようなものは、みんなが勝手に再実装しやすい。そういう再実装は完璧じゃないにしてもまあまあ使えて同じぐらい使いやすい。そうやってウィルスのように広がっていく。MITアプローチで作られるものは、ぜんぜん完成しないか、完成しても使い物にならないかで流行らない。
JSONはまさにworse is betterといえる。自作JSONパーサを作るのだってすごく大変じゃない（性能とかを気にしなければ）。コンパクトでミニマルである良さみたいなものがある。
でもGoはランタイムも大きくてけっこういろんなことをしてくれる言語だ。GCもある。goroutineはカーネルスレッドの複雑さを隠蔽してくれる。再実装はぜんぜん簡単じゃない（実際、Goの再実装なんてllvm-goとか数えるほどしかない）。GoはいろんなOS、アーキテクチャに移植されてるけど、これはどっちかというとエンジニアリングリソースの投入量によるところが大きそうだ。それにまた、Goは裏側で意外といろいろ複雑なことをしてくれることがある。Goは間口の広さと取っ付きの良さ、仕様のわかりやすさによって普及したが、そのわかりやすさ、単純さのためには実装の複雑さを引き受けている面がある。かといってMITアプローチともいいがたい。
これはたとえばTOMLのちょうどよさにも通じるところがあると思う。TOMLは書き手にはシンプルでいい言語なのだが、これまたnew jerseyスタイルではない。実際に再実装するのは意外と厄介。仕様は細かいところまでいろいろカバーされており、こういう場合はエラーになる、こういう場合はこうなる、といった仕様をすべて正しく実装するのはじゃっかん面倒くさい。そういうこまかい部分がありつつも、全体的には「なんとなく人間が書いてわかりやすいような挙動」が取られるようになっている。データ型も日付型とかがあったりしてミニマルな良さもない。
まあいまさらworse is betterでもないだろうという話でもないのかもしれない。あるいは、MITとNew Jerseyの相克は、「ちょうどよさ」の新しい相を生み出したのかもしれない。これが今の時代のちょうどいい表現なのかもね。言い過ぎな気もするけれど。
 karino2 Worse is betterはそのまま現在に語るにはどうなのか、とも思う反面、現在のコンテキストでうまい感じに翻訳して語れんもんかなぁ、という気もしている。 YAGNIとかworse is betterとかってきっちりした主張ほどわかりやすく無いのだけど、割と重要なものを含んでいる気がするのだよなぁ。
自分のGo言語評価を聞きなおしたら、 worse is betterとは言ってないが似たような事を言っている気がした。
ちょうど良さというか、だいたいこんなもんでいいんだよ感というか。
  kzys Manning から出ている Functional Programming in Scala の著者の一人でもある Paul Chiusano が、The problematic culture of &amp;ldquo;Worse is Better&amp;rdquo; というのを2014年に書いていて、</description>
      <content:encoded><![CDATA[<p>Go言語は、なんというか「ちょうどいい」言語だな、と思っている。異論は認める。</p>
<p>Go言語の登場時、なんせGoogleが大々的に発表した新しいプログラミング言語であるし、Rob PikeやKen Thompsonといった有名人の関わりもあり、華々しかった。そして、その登場を眺めたプログラミング言語マニアは、そのダサい仕様にわりとすぐがっかりして、興味をなくした。ということがあったと思う。今はGoはけっこう広く使われていて人気もあるけど、ここに至るまでには紆余曲折があった。</p>
<p>Go言語、なにせ2010年代にもなってなんせジェネリクスもない（そのわりにスライスや配列、ハッシュテーブルだけが標準にあり、特別扱いされている）。例外処理もない（これはまぁそのほうがいいだろうという人もいるだろうけど）。そこらじゅう <code>if err != nil</code> だらけ。テストにアサーションもなく、ひたすら地道にif文を書くべしとされている。いくつかのビルトインな関数（たとえば <code>make</code>など）は構文上も特別扱いされていて、直交性がかけらもない。</p>
<p>オブジェクト指向的なことはできるが、C++やJavaのようなクラス志向ではない。継承が言語仕様にない。interfaceによるduck typingはできる。メタプログラミング的なことはやりづらい。オブジェクトは動的なところが一切ない。なんかデザインしづらそうだな、というふうに思った。</p>
<p>というわけで、登場時は「なんだかぱっとしない」「かっこよさがない」といったイメージであったように思う。すくなくとも自分は。</p>
<h1 id="go言語のちょうどよさ">Go言語の「ちょうどよさ」</h1>
<p>結果的にはこういうマニア視点はまったくのお門違いだったといえるだろう。Go言語はおおいに流行っている。これをGoogleによるゴリ押しだという主張はきっとあるだろうけれど、それはたぶん違う……もちろん、会社の支援のもとで言語仕様の改善や標準ライブラリの拡充などの発展があって便利になっていったという側面はあるけど、それはまあ「ゴリ押し」とは言わないだろう。</p>
<p>Goの独特のニッチにうまくハマったのだと思う。それはたとえばWebサーバやRPCサーバ、ちょっとしたユーティリティツールやサービスにあたる。GCがあって、並列処理ができ、標準ライブラリだけでもけっこういろんなことができて（http2サーバでJSONを返したりとが簡単にかける）、単純だけど静的型付けで単純な間違いは防げる。Goのインタフェース志向なduck typingは使ってみるとわかりやすく簡単だったし、実装の継承があると便利な場面というのも別になかった。こういう用途には便利だった。</p>
<p>言語マニアが「ださい」と思ったところは、実用上はそんなに大きな問題になることが多くはなかった。多くのGoプログラマが証言するように、Goを書いていてジェネリクスが必要なのになくて困るという場面はほんとうに少ない。もちろんまったくゼロではないし、今後たぶんジェネリクス的な機能は入ることになるだろうから、それはそれでいいことなんだけど、でも、マニアの文句なんてそんなもんだという話でもある。標準組み込み型の特別扱いがわりとうまく機能してるとも言える。</p>
<p>Goコマンドの導入によりツールチェインはわかりやすく使いやすくなったし、ビルドも速く、シングルバイナリでデプロイや配布が単純というのもよかった。こういうところは言語マニアはあんまり評価対象としないと思うけれど（言語そのものというよりは処理系の話だし）、そこには大きな意味があったと思う。Goは性能がよいというイメージ（実際のところ、最速でないにしろスクリプト言語よりは十分速い）も普及に一役買ったことだろう。</p>
<h1 id="goはworse-is-betterか">Goはworse is betterか？</h1>
<p>Goの「ちょうどよさ」というのはどういうものだろうか。先進的でかっこいい理論にもとづいた複雑な言語より、ダサいけど使いやすいのがいい、というのが端的な評価になるとおもう。これはworse is betterを思わせるところがある。ただ、読み直してみると、Goはworse is betterでいうところのNew Jerseyアプローチではないように思える。</p>
<p>Worse is betterの結論というのはこうだ。実装が簡単で使うのも苦じゃないようなものは、みんなが勝手に再実装しやすい。そういう再実装は完璧じゃないにしてもまあまあ使えて同じぐらい使いやすい。そうやってウィルスのように広がっていく。MITアプローチで作られるものは、ぜんぜん完成しないか、完成しても使い物にならないかで流行らない。</p>
<p>JSONはまさにworse is betterといえる。自作JSONパーサを作るのだってすごく大変じゃない（性能とかを気にしなければ）。コンパクトでミニマルである良さみたいなものがある。</p>
<p>でもGoはランタイムも大きくてけっこういろんなことをしてくれる言語だ。GCもある。goroutineはカーネルスレッドの複雑さを隠蔽してくれる。再実装はぜんぜん簡単じゃない（実際、Goの再実装なんてllvm-goとか数えるほどしかない）。GoはいろんなOS、アーキテクチャに移植されてるけど、これはどっちかというとエンジニアリングリソースの投入量によるところが大きそうだ。それにまた、Goは裏側で意外といろいろ複雑なことをしてくれることがある。Goは間口の広さと取っ付きの良さ、仕様のわかりやすさによって普及したが、そのわかりやすさ、単純さのためには実装の複雑さを引き受けている面がある。かといってMITアプローチともいいがたい。</p>
<p>これはたとえばTOMLのちょうどよさにも通じるところがあると思う。TOMLは書き手にはシンプルでいい言語なのだが、これまたnew jerseyスタイルではない。実際に再実装するのは意外と厄介。仕様は細かいところまでいろいろカバーされており、こういう場合はエラーになる、こういう場合はこうなる、といった仕様をすべて正しく実装するのはじゃっかん面倒くさい。そういうこまかい部分がありつつも、全体的には「なんとなく人間が書いてわかりやすいような挙動」が取られるようになっている。データ型も日付型とかがあったりしてミニマルな良さもない。</p>
<p>まあいまさらworse is betterでもないだろうという話でもないのかもしれない。あるいは、MITとNew Jerseyの相克は、「ちょうどよさ」の新しい相を生み出したのかもしれない。これが今の時代のちょうどいい表現なのかもね。言い過ぎな気もするけれど。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>Worse is betterはそのまま現在に語るにはどうなのか、とも思う反面、現在のコンテキストでうまい感じに翻訳して語れんもんかなぁ、という気もしている。
YAGNIとかworse is betterとかってきっちりした主張ほどわかりやすく無いのだけど、割と重要なものを含んでいる気がするのだよなぁ。</p>
<p><a href="https://www.youtube.com/watch?v=P_uCJ4zOABY">自分のGo言語評価</a>を聞きなおしたら、
worse is betterとは言ってないが似たような事を言っている気がした。</p>
<p>ちょうど良さというか、だいたいこんなもんでいいんだよ感というか。</p>

</div>
</div>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
<p>Manning から出ている <a href="https://www.manning.com/books/functional-programming-in-scala">Functional Programming in Scala</a> の著者の一人でもある Paul Chiusano が、<a href="http://pchiusano.github.io/2014-10-13/worseisworse.html">The problematic culture of &ldquo;Worse is Better&rdquo;</a> というのを2014年に書いていて、</p>
<blockquote>
<p>“Worse is Better”, in other words, asks us to accept a false dichotomy: either we write software that is ugly and full of hacks, or we are childish idealists who try to create software artifacts of beauty and elegance.</p>
</blockquote>
<p>元エッセイはそこまで言ってたっけ? と思わなくもないけれど、もうちょっと高みを目指してもいいだろうというのはそうだし、Go が MIT か New Jersey かの二択で語れないのは、我々がもっと良い何かを見つけられている証拠のような気もします。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
でもそれがよりにもよってScalaで、Worse is betterの対象をC++として批判しているのはWorse is better批判としては微妙では？
2021年現在で当初のWorse is betterはなんだったのか、をあんまり真面目に議論するのは意味が無いとは思うけれど、それにしてもimplementationがシンプルであるのを過剰に追求するのがWorse is betterという話だったのにC++は無いだろう、と。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
<p>Go言語の「ほーこういうのでいいんだよ」感は完全に同意で、主題からそれたコメントなんですけど、コンピュータサイエンスを作ってきた人が作るのがコレかー、というガッカリ感もあるんですよね。 <a href="http://doc.cat-v.org/bell_labs/utah2000/utah2000.pdf">Systems Software Research is Irrelevant</a> と言った人ですからねぇ。引用すると Where is the Innovation? というページで</p>
<blockquote>
<p>If systems research was relevant, we&rsquo;d see new operating systems and new languages making inroads into the industry, the way we did in the &rsquo;70s and &rsquo;80s.</p>
</blockquote>
<p>と言ってるんだから何かすごい新しいもの作って欲しいところに、 <a href="https://en.wikipedia.org/wiki/Alef_(programming_language)">Alef</a> の焼きなおしみたいな言語かー。。。的な。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ちょうどいいシリアライザ、FlatBuffers</title>
      <link>https://messagepassing.github.io/008-justright/03-karino2/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/03-karino2/</guid>
      <description>ちょうどいいテクノロジ、というのは確かにあって、誰でもぱっとJSON、Markdownまでは思いつくと思うのだけど、その次が意外と難しい。 morritaさんはdataframeを挙げていて、これは確かに何かの基盤になっているとは思うのだけれど、なんとなく自分的にはjsonと並べるとしっくり来ない。
ちょうど良いでしばらく考えて思いついたものとしては、SQLiteがある。PostgreSQLやMySQLがすでにある所で登場したSQLiteは、 そのちょうど良さゆえに普及した気がする。だけれど、そこから特に語る所が無い。ふーむ。
と考えていて、そういえば最近「これはちょうど良い！」って思ったものがあった気がするな〜と考えていたら、 FlatBuffersがそれだったのを思い出した。
ちょうどいいシリアライザ、FlatBuffers FlatBuffersはProtocol Buffersのようなもの。 ようなものってことはどこが違うの？という話になるけれど、自分はProtocol Buffersそんな詳しくないので違いを説明するのは難しい。 ということでFlatBuffersの話だけをする。なお、FlatBuffersとは何か、みたいなことはそんなに語らないので公式ドキュメントでも見てください。
FlatBuffersは凄くシンプルで、大したことをしない。そこが良い。 IDLっぽいものからヘッダファイルが生成されて、FlatBuffersのヘッダと一緒にincludeすれば良い。 リンクしなくて良い。いろいろなIDEのプロジェクトファイルと付き合わなくてはいけない自分の環境では大変うれしい。 生成されるファイルも単純で（比較的）小さい。読めばだいたい理解出来る。
メモリ上にすでにデータがあれば、そこからunpackして二重に持ったりしたくない、 オフセット指定してアラインとかエンディアンとか気にせず読み書き出来るくらいのに毛がはえたくらいでいいんだよなぁ、 生成されるenumとかはそのままenum classとしてC++で使えてさぁ、 フォーマットもそんなにかっちりしすぎず、フィールド足すくらいならデフォルト値で読めるくらいで昔のもそのまま読めて、 適当に手作業で必要な所だけ読んだりしたい、 でも配列とかは使いたいし文字列はいい感じに読めてほしい、 でも変な不定長とか要らないので読み飛ばしは簡単に出来てほしい、 みたいな、「こんなもんでいいんだよ」という思いに、ちょうど答えてくれるくらいの複雑さ。
使い方もそれなりにシリアライズの都合に合わせて出来ないこともあるのだけれど、 変にドキュメントできっちり仕様とか説明せずに、都合が悪いような使い方をするとassertで落ちる。そこをデバッガで見ると長々とコメントで何故ダメなのかが書かれていたりする。 そうそう、こんなもんでいいんですよ。
すでにある物を小さくして作るカッコよさ PostgreSQLやMySQLがある所でSQLiteを作る、とか、Protocol Buffersのある所でFlatBuffersを作る、 というのは、難しいですよねぇ。 あとから小さい物で市民権を得るのは、「より労力を集めた」では無く、センスで勝負している感じがかっこいい。 どうやったらそれが出来るのか？はちょっと難しすぎる気がするので、代わりになぜFlatBuffersを使う気になるのか？を、半歩離れて見るくらいをしてみたい。
FlatBuffersが凄くいろいろな所で使う気になるポイントの一つに、手書きで書いてもだいたい同じ感じになるだろうな、という気がするというのが挙げられると思う。 手書きとの差分としてのゼロオーバーヘッド感というか（FlatBuffersは厳密にはゼロでは無いけれど）。 手書きで書いてもたぶんあんまり変わらないので、手書きの所は全部これでいいか、と思える。 だからちょっとしたものでも少し大きいものでも、なんでもかんでもFlatBuffersにしよう、となる。 最近自分はバイナリフォーマットは全部これでいいんじゃないか、と思って積極的に使っている。
ライブラリにはゼロコストで出来る範囲のことをする、という生き残りの道が一つあるよなぁ。 それでは、ある種の「良くあるがいつもでは無いユースケース」でサポート出来ない物が出てくるのだけれど、 それはライバルのライブラリに任せれば良い。ゼロコストの範囲にとどまる事で必ず一定の需要はあるし、ライバルと差別化出来る。 ゼロコストの範囲で出来る事は限られているのでどんどん機能が複雑になる事も無い。
といっても、こういうのは実際に作って市民権を得る所まで行かないと、作るという選択の正しさを証明は出来ない気がする。 すでにあるのを使わずにダメに再発明しているのとの区別は結果でしか出来ないよなぁ。
 morrita FlatBuffers は Protobuf に比べて小さいだけでなく速いという明確な利点があるのが強いですね。 それがつまりゼロコストということなのだろうけれど。 Apache Arrows が採用しているのを見た時はちょっとびっくりした。
ただ X より速い X の代替品 Y は沢山あるけれど必ずしも流行るわけではないから、そこには crack すべき code があるのだろうなあ。
  </description>
      <content:encoded><![CDATA[<p>ちょうどいいテクノロジ、というのは確かにあって、誰でもぱっとJSON、Markdownまでは思いつくと思うのだけど、その次が意外と難しい。
morritaさんはdataframeを挙げていて、これは確かに何かの基盤になっているとは思うのだけれど、なんとなく自分的にはjsonと並べるとしっくり来ない。</p>
<p>ちょうど良いでしばらく考えて思いついたものとしては、SQLiteがある。PostgreSQLやMySQLがすでにある所で登場したSQLiteは、
そのちょうど良さゆえに普及した気がする。だけれど、そこから特に語る所が無い。ふーむ。</p>
<p>と考えていて、そういえば最近「これはちょうど良い！」って思ったものがあった気がするな〜と考えていたら、
<a href="https://google.github.io/flatbuffers/">FlatBuffers</a>がそれだったのを思い出した。</p>
<h3 id="ちょうどいいシリアライザflatbuffers">ちょうどいいシリアライザ、FlatBuffers</h3>
<p>FlatBuffersはProtocol Buffersのようなもの。
ようなものってことはどこが違うの？という話になるけれど、自分はProtocol Buffersそんな詳しくないので違いを説明するのは難しい。
ということでFlatBuffersの話だけをする。なお、FlatBuffersとは何か、みたいなことはそんなに語らないので公式ドキュメントでも見てください。</p>
<p>FlatBuffersは凄くシンプルで、大したことをしない。そこが良い。
IDLっぽいものからヘッダファイルが生成されて、FlatBuffersのヘッダと一緒にincludeすれば良い。
リンクしなくて良い。いろいろなIDEのプロジェクトファイルと付き合わなくてはいけない自分の環境では大変うれしい。
生成されるファイルも単純で（比較的）小さい。読めばだいたい理解出来る。</p>
<p>メモリ上にすでにデータがあれば、そこからunpackして二重に持ったりしたくない、
オフセット指定してアラインとかエンディアンとか気にせず読み書き出来るくらいのに毛がはえたくらいでいいんだよなぁ、
生成されるenumとかはそのままenum classとしてC++で使えてさぁ、
フォーマットもそんなにかっちりしすぎず、フィールド足すくらいならデフォルト値で読めるくらいで昔のもそのまま読めて、
適当に手作業で必要な所だけ読んだりしたい、
でも配列とかは使いたいし文字列はいい感じに読めてほしい、
でも変な不定長とか要らないので読み飛ばしは簡単に出来てほしい、
みたいな、「こんなもんでいいんだよ」という思いに、ちょうど答えてくれるくらいの複雑さ。</p>
<p>使い方もそれなりにシリアライズの都合に合わせて出来ないこともあるのだけれど、
変にドキュメントできっちり仕様とか説明せずに、都合が悪いような使い方をするとassertで落ちる。そこをデバッガで見ると長々とコメントで何故ダメなのかが書かれていたりする。
そうそう、こんなもんでいいんですよ。</p>
<h3 id="すでにある物を小さくして作るカッコよさ">すでにある物を小さくして作るカッコよさ</h3>
<p>PostgreSQLやMySQLがある所でSQLiteを作る、とか、Protocol Buffersのある所でFlatBuffersを作る、
というのは、難しいですよねぇ。
あとから小さい物で市民権を得るのは、「より労力を集めた」では無く、センスで勝負している感じがかっこいい。
どうやったらそれが出来るのか？はちょっと難しすぎる気がするので、代わりになぜFlatBuffersを使う気になるのか？を、半歩離れて見るくらいをしてみたい。</p>
<p>FlatBuffersが凄くいろいろな所で使う気になるポイントの一つに、手書きで書いてもだいたい同じ感じになるだろうな、という気がするというのが挙げられると思う。
手書きとの差分としてのゼロオーバーヘッド感というか（FlatBuffersは厳密にはゼロでは無いけれど）。
手書きで書いてもたぶんあんまり変わらないので、手書きの所は全部これでいいか、と思える。
だからちょっとしたものでも少し大きいものでも、なんでもかんでもFlatBuffersにしよう、となる。
最近自分はバイナリフォーマットは全部これでいいんじゃないか、と思って積極的に使っている。</p>
<p>ライブラリにはゼロコストで出来る範囲のことをする、という生き残りの道が一つあるよなぁ。
それでは、ある種の「良くあるがいつもでは無いユースケース」でサポート出来ない物が出てくるのだけれど、
それはライバルのライブラリに任せれば良い。ゼロコストの範囲にとどまる事で必ず一定の需要はあるし、ライバルと差別化出来る。
ゼロコストの範囲で出来る事は限られているのでどんどん機能が複雑になる事も無い。</p>
<p>といっても、こういうのは実際に作って市民権を得る所まで行かないと、作るという選択の正しさを証明は出来ない気がする。
すでにあるのを使わずにダメに再発明しているのとの区別は結果でしか出来ないよなぁ。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>FlatBuffers は Protobuf に比べて小さいだけでなく速いという明確な利点があるのが強いですね。
それがつまりゼロコストということなのだろうけれど。
Apache Arrows が<a href="https://arrow.apache.org/faq/#how-does-arrow-relate-to-flatbuffers">採用している</a>のを見た時はちょっとびっくりした。</p>
<p>ただ X より速い X の代替品 Y は沢山あるけれど必ずしも流行るわけではないから、そこには crack すべき code があるのだろうなあ。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>モノレポやったことない</title>
      <link>https://messagepassing.github.io/007-repo/04-kzys/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/04-kzys/</guid>
      <description>私が仕事で開発している firecracker-containerd は、
 自分たちのチームが開発している Firecracker Go SDK 同じ会社だけど時差もある別チームの開発している Firecracker Cloud Native Computing Foundation の containerd Open Container Initiative の runc  を使っていて、これらは当然のように別のレポジトリに入っている。オープンソースでない社内のコードも、2019年の Interconnecting Code Workshop のショートペーパー、The Issue Of Source Code Repository Management In Large Enterprises で触れられているように、基本的にはモノレポではない。
というわけで、私はモノレポをやったことがない。モノレポの利点とされるものについては、Envoy の Matt Klein が Monorepos: Please don’t! で細かく反論していて、それならこのままやり過ごしてもいいかなあと思っている。
検索なんてすぐに git grep には任せられなくなって、どうせインデックスが必要になる。コードレビューは空気を読まずによそのチームに出せばいい。インフラやツールの統一はバージョン管理システムの仕事じゃない。別にモノレポじゃなくていいんじゃない?
ビルドナンバーのない世界 Matt Klein もふれているけど「このリビジョンから API 変更するけど、呼び出してる場所も全部変えといたから、あとは心配しないでね」というのは、全体をリンクしてビルドナンバーがついたバイナリがリリースされるようなソフトウェアではできるだろうけど、マイクロサービスで、サービスの境界をまたぐ変更だったりすると、途端に難しくなる。
The Amazon Builders&#39; Library にある Automating safe, hands-off deployments で詳しく説明されているけれど、会社での本番環境へのデプロイは、安全を確保しつつ、継続的・自動的に行われるようになっている。達成度にはチームによってばらつきがあったりもするけれど、目指すべきゴールはここ。
結果として何がおこるかというと、あるサービスのデプロイと、それを呼び出す別のサービスのデプロイを揃えるのは難しくなる。最初のほうのリージョンでは揃うかもしれないけれど、後半のリージョンではそろわないかもしれない。揃っていたと思ったら、どこかで片側だけロールバックされるかもしれない。ひとつのリージョン、ひとつのロードバランサーだけをみても、デプロイ中は新旧のバージョンが混在することもある。
こうなってくると、全てのサービスがひとつのレポジトリに入っていて、アトミックな変更が出来たとしても、そのアトミシティはデプロイ中にバラバラになってしまう。我々の世界にビルドナンバーは存在しないのだ。
もしかしたら Google や Facebook には、そういうアトミシティを担保する何かハイテクがあるのかもしれないけれど、でもまあ、無くてもいいハイテクは無いままでもいいかなあ。</description>
      <content:encoded><![CDATA[<p>私が仕事で開発している <a href="https://github.com/firecracker-microvm/firecracker-containerd">firecracker-containerd</a> は、</p>
<ul>
<li>自分たちのチームが開発している <a href="https://github.com/firecracker-microvm/firecracker-go-sdk">Firecracker Go SDK</a></li>
<li>同じ会社だけど時差もある別チームの開発している <a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a></li>
<li>Cloud Native Computing Foundation の <a href="https://github.com/containerd/containerd/">containerd</a></li>
<li>Open Container Initiative の <a href="https://github.com/opencontainers/runc/">runc</a></li>
</ul>
<p>を使っていて、これらは当然のように別のレポジトリに入っている。オープンソースでない社内のコードも、<a href="https://2019.programming-conference.org/track/icw-2019-papers#program">2019年の Interconnecting Code Workshop</a> のショートペーパー、<a href="https://2019.programming-conference.org/details/icw-2019-papers/5/The-Issue-Of-Source-Code-Repository-Management-In-Large-Enterprises">The Issue Of Source Code Repository Management In Large Enterprises</a> で触れられているように、基本的にはモノレポではない。</p>
<p>というわけで、私はモノレポをやったことがない。モノレポの利点とされるものについては、Envoy の Matt Klein が <a href="https://medium.com/@mattklein123/monorepos-please-dont-e9a279be011b">Monorepos: Please don’t!</a> で細かく反論していて、それならこのままやり過ごしてもいいかなあと思っている。</p>
<p>検索なんてすぐに git grep には任せられなくなって、どうせインデックスが必要になる。コードレビューは空気を読まずによそのチームに出せばいい。インフラやツールの統一はバージョン管理システムの仕事じゃない。別にモノレポじゃなくていいんじゃない?</p>
<h3 id="ビルドナンバーのない世界">ビルドナンバーのない世界</h3>
<p>Matt Klein もふれているけど「このリビジョンから API 変更するけど、呼び出してる場所も全部変えといたから、あとは心配しないでね」というのは、全体をリンクしてビルドナンバーがついたバイナリがリリースされるようなソフトウェアではできるだろうけど、マイクロサービスで、サービスの境界をまたぐ変更だったりすると、途端に難しくなる。</p>
<p><a href="https://aws.amazon.com/builders-library/">The Amazon Builders' Library</a> にある <a href="https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/">Automating safe, hands-off deployments</a> で詳しく説明されているけれど、会社での本番環境へのデプロイは、安全を確保しつつ、継続的・自動的に行われるようになっている。達成度にはチームによってばらつきがあったりもするけれど、目指すべきゴールはここ。</p>
<p>結果として何がおこるかというと、あるサービスのデプロイと、それを呼び出す別のサービスのデプロイを揃えるのは難しくなる。最初のほうのリージョンでは揃うかもしれないけれど、後半のリージョンではそろわないかもしれない。揃っていたと思ったら、どこかで片側だけロールバックされるかもしれない。ひとつのリージョン、ひとつのロードバランサーだけをみても、デプロイ中は新旧のバージョンが混在することもある。</p>
<p>こうなってくると、全てのサービスがひとつのレポジトリに入っていて、アトミックな変更が出来たとしても、そのアトミシティはデプロイ中にバラバラになってしまう。我々の世界にビルドナンバーは存在しないのだ。</p>
<p>もしかしたら Google や Facebook には、そういうアトミシティを担保する何かハイテクがあるのかもしれないけれど、でもまあ、無くてもいいハイテクは無いままでもいいかなあ。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
無駄にレポジトリが分かれたり不適切にソースが読めなくなったりという間違った方向に進む圧力に抗する為の拠り所としてモノレポという同意で進めるというスタイルがある、
というのが最初の私の話の意図だったのだけれど、
皆がそもそもに適切に管理されるという前提で良し悪しを語るのはなかなか興味深いですね。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
<p>最初に Office の話なんてするからみんなも話の規模がインフレして&hellip;</p>
<p>6人だったらモノレポでいいと思います!</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
グーグルの話だと、 protobuf とかあからさまに古い IDL で作ったメッセージをハンドルできることからわかる通り、デプロイされたら各バージョンはバラバラですね。アトミックにデプロイ、は現実的に不可能と考えてるんじゃないでしょうか。話それてますが、 <a href="https://developers.google.com/protocol-buffers/docs/proto3#unknowns">proto3 で 未知のフィールドをパース時に捨てる設計が大失敗だった</a> とされてるのは面白いなと思っています。 RPC を素通しするはずのロードバランサみたいなやつがメッセージの中身を減らしてしまうという。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
Monorepo を褒めるのに atomic change を持ち出すやつはモグリだ！というのはあおりすぎだけど、
リファクタリングの atomicity は Monorepo でもありゃしないという話は
<a href="https://dl.acm.org/doi/10.1145/3194793.3194794">Non-atomic refactoring and software sustainability</a>
および <a href="https://www.amazon.com/Software-Engineering-Google-Lessons-Programming/dp/1492082791">例の本</a> などを参照されたし。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>モノレポ好きじゃない</title>
      <link>https://messagepassing.github.io/007-repo/03-morrita/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/03-morrita/</guid>
      <description>自分は今は社内 Monorepo での作業がメインで、たまに Android とかさわってる。 レポジトリの壁というか、レポジトリの違いを含むインフラの違いの壁は、組織の壁より厚い。 この話は前にも書いたことがある。 だから向井さんの言っていることはよくわかる。 Monorepo が強制するインフラ共通化が押し下げた組織の壁の低さを、しばしば実感する。
たとえば最近だと、仕事でやっている Android アプリの APK のビルド方法が変わった際にビルドツールチェインにあるマイナーなバグにあたってしまい、 そのツールのバグを直したことがあった。そんなツールがあるとは知らなかったというくらい降って湧いた話。 でもビルドシステムが統一されているおかげでコードをビルドするのもテストするのも簡単で、 IDE も普段の設定そのまま。コードレビューもいつもと同じ。 はじめてのコードベース、レビュー相手のこともそのチームのこともなにもしらないが、つつがなくしごとが片付いた。
一方、自分が仕事で関わっている電話機の、仕事で関わっているカメラ固有の機能 (HAL) のコードを直したいとなるとすごい大変。 まったく別カルチャー (Android) の、わけのわからないビルドシステムの罠をくぐり抜け、コーディング規約ふくめ全然違うコードを睨み、 いじっていたブランチが間違っていることに気づき、コードレビューをアップロードする方法もわからず、 そもそも git rebase ってどうやるんだっけ・・・みたいになる（最後のは自分が悪い）。 組織的には隣接チームだしレビュー相手も面識あるけど、そういうの関係なくつらい。
Monorepo のいやなところ 1 - 統一されすぎ と利点は享受しつつ、個人的にいまの Monorepo はそんなに好きじゃない。
好きでない理由のひとつめは、自分のいるプロジェクトであるモバイルアプリが、Monorepo 住民のメインストリームではないこと。 この Monorepo のメインストリームは C++ なり Java なり Go なりで RPC のサーバを作る人々である。 JS (今は TS) なフロントエンドも、まあまあ歴史がある。それらと比べるとモバイルアプリ勢は人口も少なく歴史も浅い。
Monorepo の結果として利用を強いられるビルドシステムや CI/CD などのインフラもそれを反映している。 たとえば Bazel というビルドシステムは、モバイルで必須のクロスコンパイルがいまいち得意でない。 ホスト側でツールをビルドして、そのツールを使ってコードを生成して、それをデバイス向けにコンパイルみたいなのが、 できるけどぎこちない。Bazel の全体としての洗練度を考えるとぎこちなさが際立つ。 コードレビューツール付随の静的解析も、Android で使えない Java の API とかを勧めてくる。知らん。 CI/CD も毎週毎日バイナリをプッシュするサーバの人々向けにごく短いブランチ寿命を想定している。 自分のやってるアプリとか二ヶ月に一回もプッシュしないのでブランチも長生きで大量に cherrypick する。 CI ツールの Web UI が爆発気味。</description>
      <content:encoded><![CDATA[<p>自分は今は社内 Monorepo での作業がメインで、たまに Android とかさわってる。
レポジトリの壁というか、レポジトリの違いを含むインフラの違いの壁は、組織の壁より厚い。
この話は<a href="https://anemone.dodgson.org/2018/05/02/boundaries/">前にも書いたことがある</a>。
だから<a href="/007-repo/02-jmuk/">向井さんの言っていること</a>はよくわかる。
Monorepo が強制するインフラ共通化が押し下げた組織の壁の低さを、しばしば実感する。</p>
<p>たとえば最近だと、仕事でやっている Android アプリの APK のビルド方法が変わった際にビルドツールチェインにあるマイナーなバグにあたってしまい、
そのツールのバグを直したことがあった。そんなツールがあるとは知らなかったというくらい降って湧いた話。
でもビルドシステムが統一されているおかげでコードをビルドするのもテストするのも簡単で、
IDE も普段の設定そのまま。コードレビューもいつもと同じ。
はじめてのコードベース、レビュー相手のこともそのチームのこともなにもしらないが、つつがなくしごとが片付いた。</p>
<p>一方、自分が仕事で関わっている電話機の、仕事で関わっているカメラ固有の機能 (HAL) のコードを直したいとなるとすごい大変。
まったく別カルチャー (Android) の、わけのわからないビルドシステムの罠をくぐり抜け、コーディング規約ふくめ全然違うコードを睨み、
いじっていたブランチが間違っていることに気づき、コードレビューをアップロードする方法もわからず、
そもそも <code>git rebase</code> ってどうやるんだっけ・・・みたいになる（最後のは自分が悪い）。
組織的には隣接チームだしレビュー相手も面識あるけど、そういうの関係なくつらい。</p>
<h2 id="monorepo-のいやなところ-1---統一されすぎ">Monorepo のいやなところ 1 - 統一されすぎ</h2>
<p>と利点は享受しつつ、個人的にいまの Monorepo はそんなに好きじゃない。</p>
<p>好きでない理由のひとつめは、自分のいるプロジェクトであるモバイルアプリが、Monorepo 住民のメインストリームではないこと。
この Monorepo のメインストリームは C++ なり Java なり Go なりで RPC のサーバを作る人々である。
JS (今は TS) なフロントエンドも、まあまあ歴史がある。それらと比べるとモバイルアプリ勢は人口も少なく歴史も浅い。</p>
<p>Monorepo の結果として利用を強いられるビルドシステムや CI/CD などのインフラもそれを反映している。
たとえば Bazel というビルドシステムは、モバイルで必須のクロスコンパイルがいまいち得意でない。
ホスト側でツールをビルドして、そのツールを使ってコードを生成して、それをデバイス向けにコンパイルみたいなのが、
できるけどぎこちない。Bazel の全体としての洗練度を考えるとぎこちなさが際立つ。
コードレビューツール付随の静的解析も、Android で使えない Java の API とかを勧めてくる。知らん。
CI/CD も毎週毎日バイナリをプッシュするサーバの人々向けにごく短いブランチ寿命を想定している。
自分のやってるアプリとか二ヶ月に一回もプッシュしないのでブランチも長生きで大量に cherrypick する。
CI ツールの Web UI が爆発気味。</p>
<p>マイノリティである一番の象徴として、自分のチームは CI でアプリのバイナリが入ったコンテナイメージをビルドしている。
コンテナイメージをビルドすると色々よろしくやってくれるインフラに便乗するためだが、わけがわからん。</p>
<p>厳密には Monorepo イコールインフラ統一ではないけれど、インフラ統一のしやすさが Monorepo の利点なのも事実。
しかしインフラがプロジェクトの多様性をカバーしきれないとマイノリティーは割を食いがち。
これでも今はだいぶマシになった方で、 5 年前とかはもっとだいぶひどかったという。
（五年前の自分は Monorepo の外にいる Android の many repo に住み Gradle でビルドする普通のアプリを書いていた。これはこれで全然よくなかったが、また別の機会に。)</p>
<h2 id="monorepo-のいやなところ-2---オープンソースとの相性悪すぎ">Monorepo のいやなところ 2 - オープンソースとの相性悪すぎ</h2>
<p>GitHub 世代以降のオープンソースプロジェクトは、小さなレポジトリをいくつもつくって依存管理ツールで寄せ集めるスタイルが主流。
商業的なソフトウェア開発も GitHub を使うようになった結果、CI や CD 含めソフトウェア開発のインフラが細粒度のレポジトリを想定するようになった。
コンテナイメージ単位でレポジトリがある、というと言いすぎだろうか。Monorepo はそういう既存のインフラを使えない。想定が違いすぎる。だからなにかと再発明が必要。</p>
<p>再発明しがちなのはインフラに限らず、コードもオープンソースを使いにくい。Google の Monorepo は自己完結を原則にしており、オープンソースのライブラリを使いたいなら許可を得た上でレポジトリの所定の場所にコピーをコミットしないといけない。バージョンをあげるたびにコピーしなおす。がんばれば一定程度はツールで自動化できるとはいえ、めんどくさい。</p>
<p>既存のオープンソースを使うのもめんどくさいが、書いたコードをオープンソースにするのも超めんどくさい。
今度は逆に Monorepo のコードを GitHub などにコピーしないといけない。
いくつかのオープンソースプロジェクトは、一旦コピーしたオープンソース側を upstream にすることで Monorepo → GitHub へのコピーを一度で済ませている。以降は GitHub 側で開発し、それを定期的に Monorepo にコピーする。コピー作業自体は <a href="https://github.com/google/copybara">Copybara</a> というツールである程度は自動化できるらしいけど、
社内の開発インフラはまったく使えなくなる。かといってそのへんの SaaS をサクサク使わせてくれるとも限らない。チームまるごとくらいの規模があればなんとか運用できるけど、たとえばいちプログラマが書いたライブラリをいっちょ公開すっかと思っても壁が高い。GitHub メインにするのはほぼ無理。こうして社内からバーンとコピーされたまま力尽き死に絶えるオープンソースプロジェクトが後を絶たない。</p>
<p><a href="https://github.com/tensorflow/tensorflow/commits/master">TensorFlow</a> にいたっては Monorepo でバンバン開発しつつ GitHub にもコミュニティからのコミットがガンガン入てくる。
だからコードのコピーが双方向におこる。カオス。</p>
<h2 id="矯正ギプスかレガシーか">矯正ギプスかレガシーか</h2>
<p>Monorepo は企業ソフトウェア開発のベストプラクティスを自然と実現してしまう矯正ギプスとして機能した。ツール・インフラの統一、ライブラリバージョンの統一、ビルドの自己完結性、ソースコードの可視性、変更のアトミック性などなど。こういうのは理論上は Monorepo でなくても実現できるけれど、Monorepo にしておくとすごいラクで、むしろ逆らうのが難しい。</p>
<p>GitHub を中心としたオープンソースのエコシステムがソフトウェア開発を席巻する 2010 年代以前、この矯正ギプスはほぼ手放しで正解だったと思う。
けれど Monorepo の対局にある GitHub 的なソフトウェア開発が広まるにつれ、そのエコシステムと相容れられない Monorepo の良さには陰が射した。</p>
<p>少し前に出た &ldquo;<a href="https://www.amazon.com/Software-Engineering-Google-Lessons-Programming/dp/1492082791">Software Engineering at Google</a>&rdquo; という本では Monorepo と Manyrepo の利点欠点を比較し、いちばん重要なのはライブラリバージョンの統一 &ldquo;One Version Rule&rdquo; であって、これをはじめとする様々なベストプラクティスを実現できるなら別に Monorepo である必要はないと書いている。そしてバージョン管理は小さなレポジトリを Monorepo の原則に従って寄せ集める &ldquo;Federated Monorepo&rdquo; になるだろうと締めくくっている。</p>
<p>オープンソース的、というか GitHub/Git 的に federated なソフトウェア開発は open loop で、Monorepo で実現されていた完璧さは失われる。
破壊的変更に備え依存関係を全部書き直して回ることも、ライブラリのバージョンを統一しきることもできない。
組織のどこかにセキュリティホールを残したライブラリがあっても気づかないままかもしれない。
Monorepo 信奉者がこの雑さ、不完全さを嫌っているのは<a href="https://www.amazon.com/Software-Engineering-Google-Lessons-Programming/dp/1492082791">先の本</a>を読むとよくわかる。
ツールやポリシーの力でこの不完全さを取り除き Monorepo の完全さを取り戻そうとするのが Federated Monorepo  のビジョンだと理解している。</p>
<p>けれどそれってあまりに Monorepo 原理主義的な視野狭窄ではなかろうか。
Open loop な依存関係がもたらす不完全さを受け入れ、やんわり付き合っていくのがエコシステムの中で生きるというじゃないの。拒絶するんじゃなくて。
たとえば GitHub の <a href="https://docs.github.com/en/github/managing-security-vulnerabilities/about-alerts-for-vulnerable-dependencies">Dependabot</a> は自己完結な One Version Rule なしにオープンな依存関係と付き合うのを助けてくれる。こうしたツールを所定の向きに進歩させていけば 人類は Federate Monorepo の夢に近づけると思うけれど、そう厳しく取り締まらずもうちょっと loosely coupled かつ decentralized にやってこうやというのが GitHub 以降のオープンソースが世に問うたメッセージだと個人的には解釈している。</p>
<p>GitHub はもともと大企業的/閉鎖的なソフトウェア開発に嫌気が差した人々が民主的で個人主体なオープンソースの風を求めて集う場だったわけだから、
これはある意味で意図通りの帰結と言える。GitHub は Monorepo 的 elitism に戦いを挑み、勝利を収めつつあるように見える。
Monorepo はもはやレガシーなのではないか。</p>
<h2 id="あゆみよる">あゆみよる</h2>
<p>とはいえエコシステム主体のソフトウェア開発が企業内ソフトウェア開発のスケール全てを飲み込みきれたとは思わないし、
Monorepo 世代の価値観から生まれたアプローチにはまだ汲み取れることはあると思う。</p>
<p>たとえばブランチに頼らず master で開発を続ける <a href="https://trunkbaseddevelopment.com/">trunk-based development</a> は
Monorepo と相性が良い。外部の依存関係が古いままだといくらアプリがインクリメンタルなリリースでリスクを減らしても依存関係のアップデートという巨大リスクを排除できないが、依存関係がぜんぶ Monorepo の中にあって常に最新ならそういう big bang update のリスクはなくなる。</p>
<p>Manyrepo の、というかレポジトリの境界をまたいだ trunk-based development のバリエーションに <a href="https://shopify.engineering/living-on-the-edge-of-rails">Living on Edge</a> がある。ライブラリのリリースをまたず、
常に trunk/master からコードを持ってきて使う。GitHub も <a href="https://github.blog/2019-09-09-running-github-on-rails-6-0/">Ruby on Rails の最新スナップショットを毎週更新しながら使うようになった</a>とちょっと前に明かしている。</p>
<p>新しい世代のソフトウェア開発は、時代の風にのりつつ、同時にこうして前の世代の良いところを cherrypick しつつ、育っていくんじゃないかな。
Monorepo 勢も次の世代の良さを学んでちょっと若返ってほしいもんです。
Monorepo 勢であるはずの <a href="https://github.com/facebook">Facebook の GitHub</a> をみると社内で使ってると思しき大小様々なインフラコードが活発に開発されていて、なんらかの良いバランスを発見したように見える。どうやってんだろうねえ。</p>
<p>Two-pizza team の Microservices で GitHub OSS してる<a href="/007-repo/04-kzys/">かずよしさん</a>的にはどうですか。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
そうそう、monorepoは矯正ギプス的な側面があると思うんですよね。
でもmonorepoを経験するのは大きい所じゃないと難しいので、そうでない人にも使える小規模向けの矯正ギプスが欲しい、というのが最初の自分の話だったのかもしれない。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
みんなで <a href="https://github.com/team">GitHub Team</a> を使うのが現代的かつ小規模フレンドリーなギプスなのではと想像してるけど、夢見過ぎかもしれない。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ちょうどいいインターネット、Gemini</title>
      <link>https://messagepassing.github.io/008-justright/02-kzys/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/02-kzys/</guid>
      <description>個人的には TOML は「ちょうどいい」かなあ。YAML の大変さがなくて、Dhall ほど野心的ではない。言われてみると、TOML の作者も GitHub の共同創業者の一人なので、だいぶ有名人ですね。
ちょうどいいインターネット、Gemini 私がここ一年くらい気になっているプロジェクトに Gemini がある。Gemini は Gopher と Web (HTML + HTTP) のいいとこどりを目指すプロジェクトで、行志向のワイヤープロトコルと、その上にのる、これまた行志向の text/gemini フォーマットで構成されている。
ここでいう Gopher は、Go のマスコットではなくて、1993年発行の RFC 1436 で定義されている、Gopher プロトコルのこと。世の中は広いもので、2021年の今現在も Gopher を使っていたり、それでブログのようなことをしている (ブログは Web + Log の略称なので、Gopher 上のブログは Gopher + Log を略して Phlog と呼ばれる) コミュニティが存在している。その中の一人 solderpunk が、Gopher の欠点を克服しつつも、Web よりもずっとシンプルなプロトコルとして設計したのが Gemini だ。
Web の複雑さがなぜ問題なのか? Project Gemini FAQ では、こう説明されている。
 Modern web browsers are so complicated that they can only be developed by very large and expensive projects.</description>
      <content:encoded><![CDATA[<p>個人的には TOML は「ちょうどいい」かなあ。<a href="https://noyaml.com/">YAML の大変さ</a>がなくて、<a href="https://dhall-lang.org/">Dhall</a> ほど野心的ではない。言われてみると、TOML の作者も GitHub の共同創業者の一人なので、だいぶ有名人ですね。</p>
<h3 id="ちょうどいいインターネットgemini">ちょうどいいインターネット、Gemini</h3>
<p>私がここ一年くらい気になっているプロジェクトに <a href="https://gemini.circumlunar.space/">Gemini</a> がある。Gemini は Gopher と Web (HTML + HTTP) のいいとこどりを目指すプロジェクトで、行志向のワイヤープロトコルと、その上にのる、これまた行志向の <code>text/gemini</code> フォーマットで構成されている。</p>
<p>ここでいう Gopher は、<a href="https://blog.golang.org/gopher">Go のマスコット</a>ではなくて、1993年発行の <a href="https://tools.ietf.org/html/rfc1436">RFC 1436</a> で定義されている、Gopher プロトコルのこと。世の中は広いもので、2021年の今現在も Gopher を使っていたり、それでブログのようなことをしている (ブログは Web + Log の略称なので、Gopher 上のブログは Gopher + Log を略して Phlog と呼ばれる) コミュニティが存在している。その中の一人 solderpunk が、Gopher の欠点を克服しつつも、Web よりもずっとシンプルなプロトコルとして設計したのが Gemini だ。</p>
<p>Web の複雑さがなぜ問題なのか? <a href="https://gemini.circumlunar.space/docs/faq.html">Project Gemini FAQ</a> では、こう説明されている。</p>
<blockquote>
<p>Modern web browsers are so complicated that they can only be developed by very large and expensive projects. This naturally leads to a very small number of near-monopoly browsers, which stifles innovation and diversity and allows the developers of these browsers to dictate the direction in which the web evolves.</p>
</blockquote>
<p>実際のところ、2021年の Web ブラウザ、とりわけレンダリングエンジンで、最近の仕様を一通りサポートしていて、いまも開発が続いているものは</p>
<ol>
<li>Apple の WebKit</li>
<li>Google の Blink (2013年に WebKit からフォーク)</li>
<li>Mozilla の Gecko</li>
</ol>
<p>の3つしかない。ここにマーケットシェアを加味すると、WebKit と Blink の二強状態といっても過言ではないだろう。私は Microsoft や Opera が自前のレンダリングエンジンを開発していた時代を知っているので、この現状には一抹の不安を感じる。</p>
<p>FAQ では Gemini のシンプルさについて、こうも説明されている。</p>
<blockquote>
<p>Early Gemini discussion included three clear goals with regard to simplicity:</p>
<ul>
<li>It should be possible for somebody who had no part in designing the protocol to accurately hold the entire protocol spec in their head after reading a well-written description of it once or twice.</li>
<li>A basic but usable (not ultra-spartan) client should fit comfortably within 50 or so lines of code in a modern high-level language. Certainly not more than 100.</li>
<li>A client comfortable for daily use which implements every single protocol feature should be a feasible weekend programming project for a single developer.</li>
</ul>
</blockquote>
<p>プロジェクトがはじまった2019年の6月から1年半ほどたった2021年の1月現在で、<a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/software/">クライアント、サーバーともに10を超える実装がある</a>現状は、Gemini がこれらのゴールを満たせているのを示していると思う。</p>
<h3 id="ちょうどよさの射程">ちょうどよさの射程</h3>
<p>Gemini が本当にちょうどいいというと、ほとんどの人にとってはミニマルすぎてちょうどよくはないと思う。なんせ画像のインライン表示すらサポートされていない。FAQ でも、Gemini は Web も Gopher も置き換えない、共存するものである、というのは明言されている。</p>
<p>一方で、前述のようにクライアントやサーバーは沢山あるし、はてなアンテナのような更新時間順リンク集である <a href="https://portal.mozz.us/gemini/gemini.circumlunar.space/capcom/">CAPCOM</a> を見ると、毎日誰かが何かを更新していたりもする。検索エンジンも2つある。Gemini がちょうどいい人は、多くはないけどゼロでもない。</p>
<p>多数派にもなれないし、何かをディスラプトするわけでもない、でも同好の士を引きつけるだけのちょうどよさってのも悪くないと思う今日この頃です。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
すごく流行りはしないけれどニッチの間でカルト的に好かれるものは、別の軸のちょうど良さがあるのかもしれない。
自分の中では Emacs の <a href="https://orgmode.org/">org-mode</a> とかそういうかんじだな。
そういうニッチツールは個人向けには結構あるけれど、Gemini はソーシャル要素があるのが新しいというか、特殊ですねえ。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>モノレポは良いもの</title>
      <link>https://messagepassing.github.io/007-repo/02-jmuk/</link>
      <pubDate>Sun, 17 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/02-jmuk/</guid>
      <description>参加する会社ごとにレポジトリが分かれたり、チーム単位で別のレポジトリになるのって、コンウェイの法則っぽいですね。わたしはモノレポは良いものだと思っているので、どういうふうになっているかという話をざっと概観したい。
広く知られているようにGoogle社内はモノレポになってて、だいたいのプロジェクトはこのレポジトリにすべて入っている（例外はあるけれど）。で、実際どんなもんですか、という話についての雑感でいえば、モノレポはわたしのような末端の従業員にはけっこういいものだと思っている。
いろいろメリットがあると思うけれど、インフラというかコアの部分を共通化できるというのが大きい気がする。様々なユーティリティは一箇所にまとまっていて再発明をする必要がない（再発明をする楽しみがない、という面はあるかもしれないけど）。GoogleエンジニアといえばProtocol Buffersを詰め替える仕事だという自虐ネタがあるけれど、それほどまでにProtocol Buffersが広まり、使われているのもモノレポゆえだろう。ビルドシステムも共通。こういうのは、いろんな問題を簡単にする。たとえばサービス間のトレースを取るようなユーティリティを作りたくなっても、Protobufのことだけを考えておけばいい。などなど。
コア部分を開発するエンジニアとしても、モノレポの利点は非互換な変更を入れやすいことだと思う。このリビジョンからAPIはこう変わりました、というアナウンスを一本入れる。使ってるところがあっても全部変えればいいだけ。レポジトリが分かれていたら、ユーティリティのバージョンを上げるだけで根回しが必要だったりするし、面倒くさい。コンポーネントごとに依存するライブラリ（たとえばJSONパーサ）やそのバージョンが違ったりして、それで微妙なバグが特定のコンポーネントにだけあったりとか。
モノレポでない世界 つまり、モノレポでない環境の場合、それぞれのレポジトリのあいだの同期を取る必要がある。AndroidやChromeOSはrepoという独自のスクリプトを使って実現している。Bazelのworkspaceで頑張っているプロジェクトもある。でなければgit submoduleという手もある。この辺はずいぶんいろいろ整備されてきたので、だいぶ改善されてるように思うが、いずれにせよメンテナンスのコストがあり、それぐらいならモノレポのほうがいいんじゃないか、という気がする。そういえばIstioというGitHubメインのプロジェクトの仕事をしていたときは、各コンポーネントごとにレポジトリが分かれていたが、レポジトリ間同期の問題に悩まされていた。誰かがrepoを使おうと提案したりして、やめてくれと思った覚えがある。いまはモノレポ化したようだ。
モノレポにはレポジトリに誰が書き込めるか、というコミット権限の問題もある。ふつうにレポジトリが分かれている場合、レポジトリの切れ目がオーナーシップの切れ目になっていて、このレポジトリに書き込めるのは（あるいはapprovalを出せるのは）このチームの人たちだけ、みたいになっているだろう。圧倒的にわかりやすい。あと管理が楽。
モノレポだとこういうことはできないので、何らかの仕組みを導入する必要がある（もしくは、プロジェクト参加者は誰でもオッケーのカオスを受け入れるか、優しい独裁者がすべての権限を握るかだ）。Googleの場合、OWNERSファイルというファイルによってapprovalの権限が記述されている（これはChromiumにも踏襲されている）。OWNERSはたんにファイルというだけではなくて、実際にコミット権限を制限している。つまり、基本的には直接コミットは禁止して、なんらかのボットやCIを経由したコミット以外は通さないようにするということだ。これについては、何らかの仕組みを構築する手間がある。
モノレポの維持コスト Googleのモノレポがどれぐらいヤバいのか、という点については、一般の利用者である自分からははっきり言えないところがある。が、その維持コストは相当のものなはずだ。
たとえばその傍証としては、もともとPerforceを使っていたのにスケールしなくなったから社内専用のバージョン管理システムを独自に作っちゃう、みたいなことをやってしまっているというのはあるだろう（facebookもMercurialを魔改造していると伝え聞く）。会社が大きくなってきてもモノレポを維持したいなら、どうしてもそういうことは起こる。
あとたとえば、そもそもGoogleの社内レポジトリはレポジトリ全体をチェックアウトしたりできないので、部分的に開発に使うところだけチェックアウトしている。それでもうまく動くような様々な仕組みもたくさんある。そういうのの開発コスト、超大変そう。そこまでして社内全体でモノレポを維持するメリットはあるんだろうか？　まあ「ある」と誰かが判断してるからそうなんだろうけれど。
まぁこの辺は想像するだけでやばそうだなと思うし興味深くはあるけれど、一プロジェクト内でレポジトリを分けるかどうかという話とはあんまり関係ないな。
さて、いろいろ書いてみたけれど、私はけっこう社内レポジトリの経験は大昔にしかない。最近は社内レポジトリでないプロジェクトばっかりやってるから、今は社内の実情がわかってない面があるかもしれない。たとえば、昔なら社内レポジトリの大半はようするにみんなWebサーバだったり社内RPCサーバを作ってるだけだったけど、今はそうでもないだろうという話もあるだろう。そこんとこどうでしょう＞もりたさん
 morrita Facebook の Mercurial Monorepo, 2014 年のアナウンス以降どうなったのか眺めてみたら EdenSCM という名前で Rust でバックエンドサーバを書き C++ で Fuse を書きと楽しくやってるようですね。
詳しいことは知りませんが Facebook による Mercurial の拡張の成果は Google も部分的な恩恵に預かっていて、 おかげで最近は Perforce でなく Mercurial のフロントエンドを使って仕事をできるようになりました。個人的にはここ五年くらいで一番の社内革命。
  karino2 Rustでバックエンド、C++でFuseってすごいね。Facebookはいろいろ作るよなぁ。カルチャーなのかね。</description>
      <content:encoded><![CDATA[<p>参加する会社ごとにレポジトリが分かれたり、チーム単位で別のレポジトリになるのって、コンウェイの法則っぽいですね。わたしはモノレポは良いものだと思っているので、どういうふうになっているかという話をざっと概観したい。</p>
<p>広く知られているようにGoogle社内はモノレポになってて、だいたいのプロジェクトはこのレポジトリにすべて入っている（例外はあるけれど）。で、実際どんなもんですか、という話についての雑感でいえば、モノレポはわたしのような末端の従業員にはけっこういいものだと思っている。</p>
<p>いろいろメリットがあると思うけれど、インフラというかコアの部分を共通化できるというのが大きい気がする。様々なユーティリティは一箇所にまとまっていて再発明をする必要がない（再発明をする楽しみがない、という面はあるかもしれないけど）。GoogleエンジニアといえばProtocol Buffersを詰め替える仕事だという自虐ネタがあるけれど、それほどまでにProtocol Buffersが広まり、使われているのもモノレポゆえだろう。ビルドシステムも共通。こういうのは、いろんな問題を簡単にする。たとえばサービス間のトレースを取るようなユーティリティを作りたくなっても、Protobufのことだけを考えておけばいい。などなど。</p>
<p>コア部分を開発するエンジニアとしても、モノレポの利点は非互換な変更を入れやすいことだと思う。このリビジョンからAPIはこう変わりました、というアナウンスを一本入れる。使ってるところがあっても全部変えればいいだけ。レポジトリが分かれていたら、ユーティリティのバージョンを上げるだけで根回しが必要だったりするし、面倒くさい。コンポーネントごとに依存するライブラリ（たとえばJSONパーサ）やそのバージョンが違ったりして、それで微妙なバグが特定のコンポーネントにだけあったりとか。</p>
<h2 id="モノレポでない世界">モノレポでない世界</h2>
<p>つまり、モノレポでない環境の場合、それぞれのレポジトリのあいだの同期を取る必要がある。AndroidやChromeOSは<a href="https://gerrit.googlesource.com/git-repo/">repo</a>という独自のスクリプトを使って実現している。Bazelのworkspaceで頑張っているプロジェクトもある。でなければgit submoduleという手もある。この辺はずいぶんいろいろ整備されてきたので、だいぶ改善されてるように思うが、いずれにせよメンテナンスのコストがあり、それぐらいならモノレポのほうがいいんじゃないか、という気がする。そういえば<a href="https://istio.io/">Istio</a>というGitHubメインのプロジェクトの仕事をしていたときは、各コンポーネントごとにレポジトリが分かれていたが、レポジトリ間同期の問題に悩まされていた。誰かがrepoを使おうと提案したりして、やめてくれと思った覚えがある。いまはモノレポ化したようだ。</p>
<p>モノレポにはレポジトリに誰が書き込めるか、というコミット権限の問題もある。ふつうにレポジトリが分かれている場合、レポジトリの切れ目がオーナーシップの切れ目になっていて、このレポジトリに書き込めるのは（あるいはapprovalを出せるのは）このチームの人たちだけ、みたいになっているだろう。圧倒的にわかりやすい。あと管理が楽。</p>
<p>モノレポだとこういうことはできないので、何らかの仕組みを導入する必要がある（もしくは、プロジェクト参加者は誰でもオッケーのカオスを受け入れるか、優しい独裁者がすべての権限を握るかだ）。Googleの場合、OWNERSファイルというファイルによってapprovalの権限が記述されている（これは<a href="https://chromium.googlesource.com/chromium/src/+/master/docs/code_reviews.md#owners-files">Chromiumにも踏襲されている</a>）。OWNERSはたんにファイルというだけではなくて、実際にコミット権限を制限している。つまり、基本的には直接コミットは禁止して、なんらかのボットやCIを経由したコミット以外は通さないようにするということだ。これについては、何らかの仕組みを構築する手間がある。</p>
<h2 id="モノレポの維持コスト">モノレポの維持コスト</h2>
<p>Googleのモノレポがどれぐらいヤバいのか、という点については、一般の利用者である自分からははっきり言えないところがある。が、その維持コストは相当のものなはずだ。</p>
<p>たとえばその傍証としては、もともと<a href="https://www.perforce.com/">Perforce</a>を使っていたのにスケールしなくなったから社内専用のバージョン管理システムを独自に作っちゃう、みたいなことをやってしまっているというのはあるだろう（facebookもMercurialを魔改造していると伝え聞く）。会社が大きくなってきてもモノレポを維持したいなら、どうしてもそういうことは起こる。</p>
<p>あとたとえば、そもそもGoogleの社内レポジトリはレポジトリ全体をチェックアウトしたりできないので、部分的に開発に使うところだけチェックアウトしている。それでもうまく動くような様々な仕組みもたくさんある。そういうのの開発コスト、超大変そう。そこまでして社内全体でモノレポを維持するメリットはあるんだろうか？　まあ「ある」と誰かが判断してるからそうなんだろうけれど。</p>
<p>まぁこの辺は想像するだけでやばそうだなと思うし興味深くはあるけれど、一プロジェクト内でレポジトリを分けるかどうかという話とはあんまり関係ないな。</p>
<p>さて、いろいろ書いてみたけれど、私はけっこう社内レポジトリの経験は大昔にしかない。最近は社内レポジトリでないプロジェクトばっかりやってるから、今は社内の実情がわかってない面があるかもしれない。たとえば、昔なら社内レポジトリの大半はようするにみんなWebサーバだったり社内RPCサーバを作ってるだけだったけど、今はそうでもないだろうという話もあるだろう。そこんとこどうでしょう＞<a href="/007-repo/03-morrita/">もりたさん</a></p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>Facebook の Mercurial Monorepo, <a href="https://engineering.fb.com/2014/01/07/core-data/scaling-mercurial-at-facebook/">2014 年のアナウンス</a>以降どうなったのか眺めてみたら
<a href="https://github.com/facebookexperimental/eden">EdenSCM</a> という名前で Rust でバックエンドサーバを書き C++ で Fuse を書きと楽しくやってるようですね。</p>
<p>詳しいことは知りませんが Facebook による Mercurial の拡張の成果は Google も部分的な恩恵に預かっていて、
おかげで最近は Perforce でなく Mercurial のフロントエンドを使って仕事をできるようになりました。個人的にはここ五年くらいで一番の社内革命。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
Rustでバックエンド、C++でFuseってすごいね。Facebookはいろいろ作るよなぁ。カルチャーなのかね。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ハイテクないので昔話を</title>
      <link>https://messagepassing.github.io/006-hitech/04-kzys/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/04-kzys/</guid>
      <description>私もみなさんと同じで、自分でハイテクを書く機会というのはほとんどない。隣のチームの Firecracker はハイテク感があるけれど、QEMU の Tiny Code Generator の話 なんかに比べるとずっと平和で、別のアーキテクチャのエミュレーションをがんばったりはしない。
社内を見渡すと、EBS の Physalia なんかは、自分のチームとの距離の遠さも手伝って、だいぶハイテク感がある。これは morrita さんの書いていた「巨大製品の中で使われる、ドメインに特化したものを作る、組織戦のハイテク」だと思う。
2000年のハイテクと、2020年のハイテク 「Berkeley DB のようなものを再実装」と言われて思い出すのは Tokyo Cabinet のことで、そう考えると2000年初頭にミクシィで働いていたころには、C/C++ なミドルウェアが突如としてプロダクションに導入されることが時折あった。
ミクシィの全文検索は Hyper Estraier そのままではなかった気がするけど、KVS の Tokyo Tyrant はそのまま使っていたし、非同期実行の仕組みは、MySQL を分散キューにする Q4M がベースになっていた。GREE には KVS の Flare が、DeNA には MySQL の SQL 部分を迂回して NoSQL 風に使う HandlerSocket があった。
2020年代にこういうソフトウェアを作る機会はなかなかない。これには、オープンソースの既存実装の充実にあわせて、クラウドの発展もあると思う。自分で MySQL を運用していた人が、改造された MySQL を運用するときのギャップに比べると、Aurora みたいなマネージドなデータベースを使っていた人が、改造された MySQL を運用するときのギャップは大きくて、だいぶ頑張らないと説得しきれない。
アプリケーションを作る人々がビジネスロジックに集中できるのは良いことだし、私は AWS 勤務なので滅多なことは書けないけれど、でもまあちょっとの寂しさは感じる。
新しいプログラミング言語と再実装 そういえば、containerd では Berkeley DB の代わりに bbolt というのを使っている。
新しいプログラミング言語とそのコミュニティでは、C/C++ を呼び出さない &amp;ldquo;pure XXX&amp;rdquo; な実装が欲しいという需要がある。Ruby や Python だと、そういう実装は「遅いけれど、インストールが簡単」くらいのところに落ち着きがちだけど、Go なら十分に速い実装を書けるかもしれないし、Rust なら C/C++ から呼び出されるのも夢じゃない。Rust のパーサコンビネーターである nom の作者の論文、Writing parsers like it is 2017 (PDF) でも、VLC の FLV パーサーを Rust で置き換えたりしていたし、curl には Rust バックエンドが入るらしい。</description>
      <content:encoded><![CDATA[<p>私もみなさんと同じで、自分でハイテクを書く機会というのはほとんどない。隣のチームの Firecracker はハイテク感があるけれど、<a href="https://msyksphinz.hatenablog.com/entry/2020/12/29/040000">QEMU の Tiny Code Generator の話</a> なんかに比べるとずっと平和で、別のアーキテクチャのエミュレーションをがんばったりはしない。</p>
<p>社内を見渡すと、<a href="https://www.amazon.science/blog/amazon-ebs-addresses-the-challenge-of-the-cap-theorem-at-scale">EBS の Physalia</a> なんかは、自分のチームとの距離の遠さも手伝って、だいぶハイテク感がある。これは <a href="/006-hitech/02-morrita/">morrita さん</a>の書いていた「巨大製品の中で使われる、ドメインに特化したものを作る、組織戦のハイテク」だと思う。</p>
<h2 id="2000年のハイテクと2020年のハイテク">2000年のハイテクと、2020年のハイテク</h2>
<p>「Berkeley DB のようなものを再実装」と言われて思い出すのは <a href="https://dbmx.net/tokyocabinet/">Tokyo Cabinet</a> のことで、そう考えると2000年初頭にミクシィで働いていたころには、C/C++ なミドルウェアが突如としてプロダクションに導入されることが時折あった。</p>
<p>ミクシィの全文検索は <a href="https://dbmx.net/hyperestraier/">Hyper Estraier</a> そのままではなかった気がするけど、KVS の <a href="https://dbmx.net/tokyotyrant/">Tokyo Tyrant</a> はそのまま使っていたし、非同期実行の仕組みは、MySQL を分散キューにする <a href="https://q4m.github.io/">Q4M</a> がベースになっていた。GREE には KVS の <a href="https://github.com/gree/flare">Flare</a> が、DeNA には MySQL の SQL 部分を迂回して NoSQL 風に使う <a href="https://github.com/DeNA/HandlerSocket-Plugin-for-MySQL">HandlerSocket</a> があった。</p>
<p>2020年代にこういうソフトウェアを作る機会はなかなかない。これには、オープンソースの既存実装の充実にあわせて、クラウドの発展もあると思う。自分で MySQL を運用していた人が、改造された MySQL を運用するときのギャップに比べると、Aurora みたいなマネージドなデータベースを使っていた人が、改造された MySQL を運用するときのギャップは大きくて、だいぶ頑張らないと説得しきれない。</p>
<p>アプリケーションを作る人々がビジネスロジックに集中できるのは良いことだし、私は AWS 勤務なので滅多なことは書けないけれど、でもまあちょっとの寂しさは感じる。</p>
<h2 id="新しいプログラミング言語と再実装">新しいプログラミング言語と再実装</h2>
<p>そういえば、containerd では Berkeley DB の代わりに <a href="https://github.com/etcd-io/bbolt">bbolt</a> というのを使っている。</p>
<p>新しいプログラミング言語とそのコミュニティでは、C/C++ を呼び出さない &ldquo;pure XXX&rdquo; な実装が欲しいという需要がある。Ruby や Python だと、そういう実装は「遅いけれど、インストールが簡単」くらいのところに落ち着きがちだけど、Go なら十分に速い実装を書けるかもしれないし、Rust なら C/C++ から呼び出されるのも夢じゃない。Rust のパーサコンビネーターである nom の作者の論文、<a href="http://spw17.langsec.org/papers/chifflier-parsing-in-2017.pdf">Writing parsers like it is 2017 (PDF)</a> でも、VLC の FLV パーサーを Rust で置き換えたりしていたし、curl には <a href="https://daniel.haxx.se/blog/2020/10/09/rust-in-curl-with-hyper/">Rust バックエンドが入るらしい</a>。</p>
<p>というわけで、ハイテクに飢えている我々は Rust 書くのが良いんじゃないでしょうか。ベタに C/C++ から移植しただけでも「俺の実装はメモリセーフである」と主張できます。多分。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>やはりハイテクと言えばBerkeley DBを再実装ですね！（なぜ？）＞bbolt</p>
<p>Hyper Estraierを作るのはハイテク感ありますな。昔の方が自分たちでいろいろ 作っていた/作らざるを得なかった という事はある気はする。半分くらいはC++のせいかも。</p>
<p>現代の方がオープンソースですでにある出来の良い物が多くて、それらの再実装は正当化されない分、機会が少ない、というのは確かに思う。
ただ現代でもオープンソースに存在しない新しい物はやはり自分で生み出すしか無いので、そこにはハイテク仕事の機会はあり続けるんじゃないかなぁ。
我々一人一人がやる機会がどれほどあるのか？というのはよく分からないけれど。（それを聞きたかったというのがこのトピックの趣旨でもある）</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>kzys</div>
<div class='message-body'>
Go の FFI は遅いので、Berkeley DB とかを関数ごとにラップするより、Go で書いたほうが速くなりそう、というのはありますね。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ちょうどよさのはなし</title>
      <link>https://messagepassing.github.io/008-justright/01-morrita/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/01-morrita/</guid>
      <description>その「ちょうどよさ」ゆえに普及したテクノロジ - アイデアや標準があると思う。 そういうのは、科学や工学でなく匠としてのプログラミングを表している気がして成功が嬉しい。
自分にとって「ちょうどいいテクノロジ」の代表は JSON (2002) と Markdown (2004). どちらも技術的にはさほど大したことはないけれど、どちらも広く使われている。
「ちょうどいいテクノロジ」はこれ以前にも色々あった。UNIX(1969) や HTTP/REST (1991) なんかが思い当たる。 ただ同時代性がないせいか成功が華やかすぎるせいか、まいち親近感がない。 ついでにいうと、自分はもはやこれらに「ちょうどよさ」を感じない。 UNIX の代表 Linux は超巨大ソフトウェアだし、HTTP の最新版 HTTP/3 は随分複雑なプロトコルに見える。 JSON と Markdown は、今のところ当初の「ちょうどよさ」を留めている、気がする。 UNIX と Markdown を並べると怒られちゃいそうだけど、別に UNIX がだめって話じゃないんだよ。 自分にとって「ちょうどよさ」の範疇にないだけで。
「ちょうどよい」テクノロジの成功はよく Worse Is Better として説明される。 間違ってはいないだろうけれど、テクノロジの市場が scarcity から abundance にシフトする中でこの説明が十分な力を持っているとも思えない。 たとえば JSON 的なものは YAML なり TOML なりいくつかあった。Markdown にもライバルは沢山いた。 （自分は当時 Textile に肩入れしていた。RST は今でも現役だ。) これらはどれもまあまあちょうどよかったはずだけれど、JSON や Markdown の成功には及ばなかった。
何が違ったのだろう。たとえば Markdown の発明者が John Gruber や Aaron Swartz のようなインターネット有名人だった事実は、どのくらい成功を助けたのだろう。 あるいは JSON が JS のサブセットなのはどれくらい重要だったろう。 そういえば JSON の Douglas Crockford も有名人だ。</description>
      <content:encoded><![CDATA[<p>その「ちょうどよさ」ゆえに普及したテクノロジ - アイデアや標準があると思う。
そういうのは、科学や工学でなく匠としてのプログラミングを表している気がして成功が嬉しい。</p>
<p>自分にとって「ちょうどいいテクノロジ」の代表は JSON (2002) と Markdown (2004).
どちらも技術的にはさほど大したことはないけれど、どちらも広く使われている。</p>
<p>「ちょうどいいテクノロジ」はこれ以前にも色々あった。UNIX(1969) や HTTP/REST (1991) なんかが思い当たる。
ただ同時代性がないせいか成功が華やかすぎるせいか、まいち親近感がない。
ついでにいうと、自分はもはやこれらに「ちょうどよさ」を感じない。
UNIX の代表 Linux は超巨大ソフトウェアだし、HTTP の最新版 HTTP/3 は随分複雑なプロトコルに見える。
JSON と Markdown は、今のところ当初の「ちょうどよさ」を留めている、気がする。
UNIX と Markdown を並べると怒られちゃいそうだけど、別に UNIX がだめって話じゃないんだよ。
自分にとって「ちょうどよさ」の範疇にないだけで。</p>
<p>「ちょうどよい」テクノロジの成功はよく <a href="https://www.jwz.org/doc/worse-is-better.html">Worse Is Better</a> として説明される。
間違ってはいないだろうけれど、テクノロジの市場が scarcity から abundance にシフトする中でこの説明が十分な力を持っているとも思えない。
たとえば JSON 的なものは YAML なり TOML なりいくつかあった。Markdown にもライバルは沢山いた。
（自分は当時 <a href="https://textile-lang.com/">Textile</a> に肩入れしていた。<a href="https://docutils.sourceforge.io/rst.html">RST</a> は今でも現役だ。)
これらはどれもまあまあちょうどよかったはずだけれど、JSON や Markdown の成功には及ばなかった。</p>
<p>何が違ったのだろう。たとえば Markdown の発明者が <a href="https://daringfireball.net/">John Gruber</a> や <a href="http://www.aaronsw.com/">Aaron Swartz</a>
のようなインターネット有名人だった事実は、どのくらい成功を助けたのだろう。
あるいは JSON が JS のサブセットなのはどれくらい重要だったろう。
そういえば JSON の <a href="https://www.crockford.com/">Douglas Crockford</a> も有名人だ。</p>
<h2 id="最近のちょうどいいテクノロジはどこに">最近のちょうどいいテクノロジはどこに</h2>
<p>それはさておき　JSON も Markdown も 15 年以上前の話で、UNIX や HTTP と比べたら若いとはいえだいぶベテラン。
もっと最近のちょうどよさに親しんでソフトウェアの匠を見直したい。でも流行りに疎くてこれという例がぱっと思い浮かばない。</p>
<p>ちょっと敷居を下げてみると、たとえば AWS Lambda に並ぶ FaaS たちははなかなかちょうどいい気がしている。
Heroku や App Engine と比べてだいぶ素朴でいい。だんだん複雑化してそうだけれど。</p>
<p>R の DataFrame もちょうどいいデータ表現として成功を収めた気がしている。
Python(Pandas) や Scala(Spark) に移植されているし、<a href="https://arrow.apache.org/use_cases/">Apache Arrow</a> なんてのもあるし。</p>
<p>おきにいりのちょうどいいテクノロジ、なにかないですか。
<a href="/008-justright/02-kzys/">かずよしさん</a>、<a href="/008-justright/03-karino2/">ありのさん</a>、<a href="/008-justright/04-jmuk/">向井さん</a>、
<a href="/008-justright/05-shinh/">はまじさん</a>？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>案外やってないなという感じ</title>
      <link>https://messagepassing.github.io/006-hitech/03-shinh/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/03-shinh/</guid>
      <description>ハイテク @Google ハイテク、グーグルにいた時の感覚は morrita さんに近い。「面接の時はアルゴリズム問題とか聞くけど、実際仕事で難しいアルゴリズムとか書いてないよね、簡単な再帰すら書かねーよな」みたいな雑談をよくしていた。11年くらい勤めて、あれはハイテクだったなーと思う自分の作業は 2,3 くらいで、期間としては合計半年から一年くらいじゃないかな。
割と、それで良いのだと思っている。5割の力で、余力を残して働くのがプロじゃないかと。余力があるくらいでできたプロダクトの方が、完成度が高い。持てる技術ギリギリを使って書いたコードは、たぶんバグってるか、開発に時間を使いすぎているか、悪いとその両方。
いざとなれば難しいデータ構造を使いこなすことも、超絶技巧の高速化もできるかもしれないけど、別に困ってないのに導入されたハイテクは単にメンテ性を落とすだけ。普通のコードで要件を満たせるのであればそれでいい。いざとなった時にハイテクができる牙を研ぐのは家でやればいい。その牙を使う日が来るのかは知らないけど。
ハイテク @PFN PFN に転職して、 PFN は零細企業や小規模スタートアップというほど小さい会社ではないけどなんだかやたらと多角的に色々やってるので、一人当たりの守備範囲は零細と大差ないんじゃないだろうか。入社して言われたことを要約すると「TensorFlow XLA の汎用性増やしたみたいなの作ってね、人員は一名。あ、インターンが一人いるよ」みたいな感じ。さあ大変だ、というか、できるわけないだろ！
できるかはともかくとして、これは楽しい。でも「ハイテクを一人占めするベテランはもういない、ハイテク祭りだ！」となってるかというと、あまりなっていない。自明にやるべきこと、ハリボテでいいから存在しないと話にならないコンポーネントが多すぎて、何を作っても「とりあえずここはこれで動くには動く……あとでもっとかっこよくしたいけど、もっとやるべきことがあるので、次に行こう」となる。それはそれで楽しくはある。
ベースライン 最近では「落ちついたらここは僕のハイテクですごくするんだ！楽しみだなあ。論文とかも参考にしちゃうぞ」と思っていたところを人に譲るというのが何度も起きている。いくつか例があったんだけど、 karino さんが最初に計算グラフの話をしていたので、それ系の話をしてみる。
計算グラフのスケジューラは topological order を満たしていれば計算順序を自由に変えていいのでなるべく速くなるように並べましょう、という問題。 DRAM が相対的に遅いので SRAM にあるデータをなるべく使いまわせる計算順が良くて、使い回せない時にどれを spill するかを賢く選びたい。最終的にはメタヒューリスティクスでも導入しましょ、という話をしてたんだけど(これはかなりハイテクぽくない？)高速に動作する貪欲のベースラインは欲しいので、とりあえず適当なのをでっちあげた。
計算順序はテキトーなヒューリスティクスで決めて、 SRAM が足りなくなったら spill する感じ。 DRAM と SRAM とか言うとソフトウェアエンジニアは構えてしまうけど、キャッシュから何捨てる？みたいな話なので、まあ LRU でしょとテキトーに最近使ってないのを捨てるつもりのコードを書いた。そのあとハイテクメタヒューリスティクスやるぞ、てことまで手が回らないうちに他のことやった方が良い雰囲気になってたので、アルゴリズム強いってウワサの人に譲ることにした。（強いってどんくらいなんだろ、と後から競プロサイトで検索してみたら、なんかちょっとドン引きするくらい強かった。）
その競プロすごい人は、なんだかすごい速度で僕の実装を改良再実装して、そこからさらに進めて当初予定していたメタヒューリスティクスまで実装してくれて、実際に高速化を達成、さらなる改良に従事している。ついでに「LRU は未来がわからない時に有効なオンラインアルゴリズムであって、将来の計算が静的にわかってる状況では単に最も遠い未来で使うやつ捨てれば良いことが知られてますよ」と指摘してくれたし、さらに言うと僕が LRU だと思っていたものはそもそも LRU になってなかった。
「後で自分でやろうと思って、それを楽しみにそこまでの道の整備をしたのにな」という気持ちも少しある。でも他の人にやってもらってみると、スケジューラの例のように、正直自分でやってたらここまで良くならなかったなと思うことがほとんどだし、労せず成果物ができているのだからまあいっか、となっている。
大企業を出て、今一緒に作業してる中ではたぶん僕が一番ベテランだし、ハイテクをやる権利も機会もあるのだけど、案外やってないなという感じ。立場とか環境とか機会とかもあるんでしょうけど、人に依存するする面も多いんでないかな、と。
 morrirta ここでいうベースラインは自分からみるとだいぶハイテクなので、 ハイテクの期待値は個人差がありそうですね。 プログラマにとってハイテクなコードとは「背伸びしたコード」なのかもしれない。
それはさておき難しいコードを競プロ勢に任せるの、すごいわかる。 ただ東京にいた頃は競プロ勢いっぱいいた気がするけれど転勤したあとすっかり見なくなりました。 気づいてないだけでみなやってるのかもしれませんが。
  shinh 日本、 OSS とかに参加するには英語のバリアが厳しいので競プロが流行る、みたいな仮説を持っています。もちろん公平な評価と明確な得点を好むとか、他の要因も色々考えられますが……</description>
      <content:encoded><![CDATA[<h2 id="ハイテク-google">ハイテク @Google</h2>
<p>ハイテク、グーグルにいた時の感覚は <a href="/006-hitech/02-morrita/">morrita さん</a>に近い。「面接の時はアルゴリズム問題とか聞くけど、実際仕事で難しいアルゴリズムとか書いてないよね、簡単な再帰すら書かねーよな」みたいな雑談をよくしていた。11年くらい勤めて、あれはハイテクだったなーと思う自分の作業は 2,3 くらいで、期間としては合計半年から一年くらいじゃないかな。</p>
<p>割と、それで良いのだと思っている。5割の力で、余力を残して働くのがプロじゃないかと。余力があるくらいでできたプロダクトの方が、完成度が高い。持てる技術ギリギリを使って書いたコードは、たぶんバグってるか、開発に時間を使いすぎているか、悪いとその両方。</p>
<p>いざとなれば難しいデータ構造を使いこなすことも、超絶技巧の高速化もできるかもしれないけど、別に困ってないのに導入されたハイテクは単にメンテ性を落とすだけ。普通のコードで要件を満たせるのであればそれでいい。いざとなった時にハイテクができる牙を研ぐのは家でやればいい。その牙を使う日が来るのかは知らないけど。</p>
<h2 id="ハイテク-pfn">ハイテク @PFN</h2>
<p>PFN に転職して、 PFN は零細企業や小規模スタートアップというほど小さい会社ではないけどなんだかやたらと多角的に色々やってるので、一人当たりの守備範囲は零細と大差ないんじゃないだろうか。入社して言われたことを要約すると「<a href="https://www.tensorflow.org/xla">TensorFlow XLA</a> の汎用性増やしたみたいなの作ってね、人員は一名。あ、インターンが一人いるよ」みたいな感じ。さあ大変だ、というか、できるわけないだろ！</p>
<p>できるかはともかくとして、これは楽しい。でも「ハイテクを一人占めするベテランはもういない、ハイテク祭りだ！」となってるかというと、あまりなっていない。自明にやるべきこと、ハリボテでいいから存在しないと話にならないコンポーネントが多すぎて、何を作っても「とりあえずここはこれで動くには動く……あとでもっとかっこよくしたいけど、もっとやるべきことがあるので、次に行こう」となる。それはそれで楽しくはある。</p>
<h3 id="ベースライン">ベースライン</h3>
<p>最近では「落ちついたらここは僕のハイテクですごくするんだ！楽しみだなあ。論文とかも参考にしちゃうぞ」と思っていたところを人に譲るというのが何度も起きている。いくつか例があったんだけど、 <a href="/006-hitech/01-karino2/">karino さんが最初に計算グラフの話をしていた</a>ので、それ系の話をしてみる。</p>
<p>計算グラフのスケジューラは topological order を満たしていれば計算順序を自由に変えていいのでなるべく速くなるように並べましょう、という問題。 DRAM が相対的に遅いので SRAM にあるデータをなるべく使いまわせる計算順が良くて、使い回せない時にどれを spill するかを賢く選びたい。最終的にはメタヒューリスティクスでも導入しましょ、という話をしてたんだけど(これはかなりハイテクぽくない？)高速に動作する貪欲のベースラインは欲しいので、とりあえず適当なのをでっちあげた。</p>
<p>計算順序はテキトーなヒューリスティクスで決めて、 SRAM が足りなくなったら spill する感じ。 DRAM と SRAM とか言うとソフトウェアエンジニアは構えてしまうけど、キャッシュから何捨てる？みたいな話なので、まあ LRU でしょとテキトーに最近使ってないのを捨てるつもりのコードを書いた。そのあとハイテクメタヒューリスティクスやるぞ、てことまで手が回らないうちに他のことやった方が良い雰囲気になってたので、アルゴリズム強いってウワサの人に譲ることにした。（強いってどんくらいなんだろ、と後から競プロサイトで検索してみたら、なんかちょっとドン引きするくらい強かった。）</p>
<p>その競プロすごい人は、なんだかすごい速度で僕の実装を改良再実装して、そこからさらに進めて当初予定していたメタヒューリスティクスまで実装してくれて、実際に高速化を達成、さらなる改良に従事している。ついでに「LRU は未来がわからない時に有効なオンラインアルゴリズムであって、<a href="https://en.wikipedia.org/wiki/Page_replacement_algorithm#The_theoretically_optimal_page_replacement_algorithm">将来の計算が静的にわかってる状況では単に最も遠い未来で使うやつ捨てれば良い</a>ことが知られてますよ」と指摘してくれたし、さらに言うと僕が LRU だと思っていたものはそもそも LRU になってなかった。</p>
<p>「後で自分でやろうと思って、それを楽しみにそこまでの道の整備をしたのにな」という気持ちも少しある。でも他の人にやってもらってみると、スケジューラの例のように、正直自分でやってたらここまで良くならなかったなと思うことがほとんどだし、労せず成果物ができているのだからまあいっか、となっている。</p>
<p>大企業を出て、今一緒に作業してる中ではたぶん僕が一番ベテランだし、ハイテクをやる権利も機会もあるのだけど、案外やってないなという感じ。立場とか環境とか機会とかもあるんでしょうけど、人に依存するする面も多いんでないかな、と。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrirta</div>
<div class='message-body'>
<p>ここでいうベースラインは自分からみるとだいぶハイテクなので、
ハイテクの期待値は個人差がありそうですね。
プログラマにとってハイテクなコードとは「背伸びしたコード」なのかもしれない。</p>
<p>それはさておき難しいコードを競プロ勢に任せるの、すごいわかる。
ただ東京にいた頃は競プロ勢いっぱいいた気がするけれど転勤したあとすっかり見なくなりました。
気づいてないだけでみなやってるのかもしれませんが。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
日本、 OSS とかに参加するには英語のバリアが厳しいので競プロが流行る、みたいな仮説を持っています。もちろん公平な評価と明確な得点を好むとか、他の要因も色々考えられますが……
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>モノレポのはなし</title>
      <link>https://messagepassing.github.io/007-repo/01-karino2/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/01-karino2/</guid>
      <description>モノレポについて経験豊富そうな皆さんの話を聞きたい。 まずはその背景から。
会社で分かれるレポジトリ フリーランスをやっていると、たまにいろんな零細企業を集めて一つのサービスを作る場に遭遇する。 人を集める時に、一つの会社だけじゃなくて複数の会社が集まることがよくある。 たとえばマーケティングが強みの会社が自社ではエンジニアを持っていなくて、開発は外部の人たちを集めてやるみたいな。 しかもそれぞれの会社からは一人とか二人だけしか来ないので、 6人の小規模なチームなのに会社は4つあるとかいう状況になったりもする。
そうすると何が起こるかというと、レポジトリが会社ごとに分かれたりする。 「クラウドとフロントの間はAPIを決めましょう、 それでクラウド側がバイナリをリリースして、フロント側がたまにそれをマージしましょう」みたいなフローになる。フロントとバックエンドなんて関わっているのは3人しか居なくて、コードの規模も凄く小さいのに。
酷い時にはフロントはバックエンドのコードが読めないとか変更出来ないとか、そんな事態になったりする事もある。 そこまで行かなくてもレポジトリは触らせてくれないくらいは良くある。
ログや履歴が見れないデメリットは説明するまでも無い。 あとはAPIの変更が無駄に難しくなるし、お互いソースが読めないと継ぎ目の所ですぐバグったりするし、バグを追うのが無駄に大変だったり。
しかもレポジトリが分かれていると、手動でコードを持っていってマージするみたいなのをえんえんやる人が発生したりもする。 お前6人しか居ないプロジェクトで一人それかよっ！（この物語はフィクションです）。
レポジトリを一つにしようという意思 この手の開発でレポジトリが分かれるのは、実に些細な理由である事が多い。 ソースコードを見せない理由も実際はほとんど無くて、ちゃんとその辺を話し合って決める人が居なかったので念の為（？）見せない事にしたとか、その程度。 もともと寄せ集めで開発するケースでは、力関係的にプロジェクトを立ち上げる会社がだいたい凄く強いので、ちゃんとその会社が望めばレポジトリは一つでソースコードも全員が見える状態に出来る。 でも、プロジェクトを立ち上げる会社が開発以外の所に強みを持つ会社だと、そうした方針について強い意思を持っていなかったりする。そうすると些細な理由でなんとなくレポジトリが分かれてしまうのを防げない。
分かれる理由が些細であっても分かれた影響はでかい。 レポジトリが一つかどうかとかソースにアクセス出来るとか、開発効率には大きな影響を与える。 少し話し合いを頑張れば劇的に改善出来るのだから、頑張った方がいいのは間違いない。 だけれども些細な障害を乗り越えてレポジトリを一つにする為には確固とした意思を必要とする。 そうした強い意思を持つためにはしっかりとした「あるべき姿」が見えている必要があると思う。 でもフリーランスになってTech企業の外に出てみると、 そうした姿は意外と知られていないと感じた。
自分はどこでそうした「あるべき姿」を学んだのだろう？ 自分の場合を思うと、自分はモノレポ的な経験から学んだ気がする。
自分のモノレポ的な体験 自分の経験は厳密な意味ではモノレポでは無くて、その辺が今回皆さまに見解を聞きたいと思った所でもある。 でもまぁまぁモノレポと言っても良い経験はあるので、その辺の話を。
自分が一番モノレポに近い環境だったのは、MSでOfficeのチームだった時。 OfficeはOffice全体で一つのレポジトリだった。会社にはOfficeの他に（雑にいえば）WindowsとVisualStudioがあって、それらは別のレポジトリだった。厳密な意味ではモノレポでは無い。 （10年くらい前の話で、モノレポという概念もまだ無かったと思うし。） ただ、Officeの中にはWordやExcelなどの他にも、OutlookとかSharePointのようなサーバーサイドなどだいぶ他とは毛色の違う物も混じっていて、 それらが一つのレポジトリで開発されているのは当時それなりに衝撃だった。
ローカルに無い状態で全部syncすると３日くらい掛かるとかいう世界だったので、それなりに巨大なコードベースでもあった。 ローカルにある状態でもsyncはめっちゃ時間掛かるので、家に帰る前にsyncする風習になっていた。syncのコマンドを実行すると最初にネットワークなどのエラーが無い事を確認して、ここからは時間がかかるという所まで行ったら「もう家に帰ってもいいですよ」とビープ音が鳴ったりする。
当時の環境がモノレポ的だと自分が思う事の一つに、独自のツールが充実していた事が挙げられる。 例えばレポジトリの検索ツールがあって、 ローカルにコードが無いプロジェクトも、コマンドラインからローカルにあるかのように一括検索が出来た。 新しいAPIの使い方や言語機能の使い方はとりあえずレポジトリを検索してみて他のプロジェクトを参考にしたりしていた。
また依存が他のチームにまで及ぶ場合、自分が他のチームまで含めて全部を変える事が出来た。 もちろんレビューとかは必要だけれど、皆が同じレポジトリを使っているので、 チームごとの別々のツリーに入れなくてはいけないみたいな作業は無かった。 関係無いチームも全部コードにアクセス出来るのはモノレポ的だと思う所だ。
あれだけのレポジトリのでかさを維持する為には、凄まじいエンジニアリングコストが掛かっていた。 そんな膨大なコストというのはまさにモノレポの欠点でもあるのだけど、 プロジェクトのいろいろな事を決める人たちがそれだけのコストを払ってでも維持するだけのメリットがあると思ってくれていた訳だ。
実際欠点もあるにせよ、当時あの規模の開発を行う為にはレポジトリを一つにするしか無かったと思う。 ツリーが別だったら、あっという間に置いていかれてしまって永遠にマージが終わらないに違いない。 実際ツリーが一つでもcommitは凄い大変だったし。
モノレポってどうなんでしょう？ 冒頭に述べたようなプロジェクトだと、 何故か自分がレポジトリやブランチマネージメントの基本的な事をレクチャーしたりする事もあるのだけど、 この手の事は実体験が無いとうまく伝えるのは意外と難しい。
一般的には、モノレポの功罪とかって、 最近だとGoogleとかFacebookのモノレポなどの議論で学ぶ事だと思う。 でもその辺の話が好きなのはその辺の経験をすでに持っている人ばかりで、 意外とその辺の常識が共有されているのは、狭い世界だけだった。 そんな事にフリーランスになって初めて気づいたりした。
そうした時にFacebookとかGoogleのモノレポの記事にリンクを貼ってもいいのだけど、 記事は記事なのでやっぱり一面的というか、説得力が微妙。 もうちょっと実体験に基づいた話がある方が良い。
さらに、Googleのモノレポはおそらく当時のOfficeよりは遥かにでかくなっているはずなので、 ヤバさもずっと上になっているはずだ。 そうした経験があると自分とは違った見解もありそうで、自分個人としても聞いてみたい気がした。</description>
      <content:encoded><![CDATA[<p>モノレポについて経験豊富そうな皆さんの話を聞きたい。
まずはその背景から。</p>
<h2 id="会社で分かれるレポジトリ">会社で分かれるレポジトリ</h2>
<p>フリーランスをやっていると、たまにいろんな零細企業を集めて一つのサービスを作る場に遭遇する。
人を集める時に、一つの会社だけじゃなくて複数の会社が集まることがよくある。
たとえばマーケティングが強みの会社が自社ではエンジニアを持っていなくて、開発は外部の人たちを集めてやるみたいな。
しかもそれぞれの会社からは一人とか二人だけしか来ないので、
6人の小規模なチームなのに会社は4つあるとかいう状況になったりもする。</p>
<p>そうすると何が起こるかというと、レポジトリが会社ごとに分かれたりする。
「クラウドとフロントの間はAPIを決めましょう、
それでクラウド側がバイナリをリリースして、フロント側がたまにそれをマージしましょう」みたいなフローになる。フロントとバックエンドなんて関わっているのは3人しか居なくて、コードの規模も凄く小さいのに。</p>
<p>酷い時にはフロントはバックエンドのコードが読めないとか変更出来ないとか、そんな事態になったりする事もある。
そこまで行かなくてもレポジトリは触らせてくれないくらいは良くある。</p>
<p>ログや履歴が見れないデメリットは説明するまでも無い。
あとはAPIの変更が無駄に難しくなるし、お互いソースが読めないと継ぎ目の所ですぐバグったりするし、バグを追うのが無駄に大変だったり。</p>
<p>しかもレポジトリが分かれていると、手動でコードを持っていってマージするみたいなのをえんえんやる人が発生したりもする。
お前6人しか居ないプロジェクトで一人それかよっ！（この物語はフィクションです）。</p>
<h2 id="レポジトリを一つにしようという意思">レポジトリを一つにしようという意思</h2>
<p>この手の開発でレポジトリが分かれるのは、実に些細な理由である事が多い。
ソースコードを見せない理由も実際はほとんど無くて、ちゃんとその辺を話し合って決める人が居なかったので念の為（？）見せない事にしたとか、その程度。
もともと寄せ集めで開発するケースでは、力関係的にプロジェクトを立ち上げる会社がだいたい凄く強いので、ちゃんとその会社が望めばレポジトリは一つでソースコードも全員が見える状態に出来る。
でも、プロジェクトを立ち上げる会社が開発以外の所に強みを持つ会社だと、そうした方針について強い意思を持っていなかったりする。そうすると些細な理由でなんとなくレポジトリが分かれてしまうのを防げない。</p>
<p>分かれる理由が些細であっても分かれた影響はでかい。
レポジトリが一つかどうかとかソースにアクセス出来るとか、開発効率には大きな影響を与える。
少し話し合いを頑張れば劇的に改善出来るのだから、頑張った方がいいのは間違いない。
だけれども些細な障害を乗り越えてレポジトリを一つにする為には確固とした意思を必要とする。
そうした強い意思を持つためにはしっかりとした「あるべき姿」が見えている必要があると思う。
でもフリーランスになってTech企業の外に出てみると、
そうした姿は意外と知られていないと感じた。</p>
<p>自分はどこでそうした「あるべき姿」を学んだのだろう？
自分の場合を思うと、自分はモノレポ的な経験から学んだ気がする。</p>
<h2 id="自分のモノレポ的な体験">自分のモノレポ的な体験</h2>
<p>自分の経験は厳密な意味ではモノレポでは無くて、その辺が今回皆さまに見解を聞きたいと思った所でもある。
でもまぁまぁモノレポと言っても良い経験はあるので、その辺の話を。</p>
<p>自分が一番モノレポに近い環境だったのは、MSでOfficeのチームだった時。
OfficeはOffice全体で一つのレポジトリだった。会社にはOfficeの他に（雑にいえば）WindowsとVisualStudioがあって、それらは別のレポジトリだった。厳密な意味ではモノレポでは無い。
（10年くらい前の話で、モノレポという概念もまだ無かったと思うし。）
ただ、Officeの中にはWordやExcelなどの他にも、OutlookとかSharePointのようなサーバーサイドなどだいぶ他とは毛色の違う物も混じっていて、
それらが一つのレポジトリで開発されているのは当時それなりに衝撃だった。</p>
<p>ローカルに無い状態で全部syncすると３日くらい掛かるとかいう世界だったので、それなりに巨大なコードベースでもあった。
ローカルにある状態でもsyncはめっちゃ時間掛かるので、家に帰る前にsyncする風習になっていた。syncのコマンドを実行すると最初にネットワークなどのエラーが無い事を確認して、ここからは時間がかかるという所まで行ったら「もう家に帰ってもいいですよ」とビープ音が鳴ったりする。</p>
<p>当時の環境がモノレポ的だと自分が思う事の一つに、独自のツールが充実していた事が挙げられる。
例えばレポジトリの検索ツールがあって、
ローカルにコードが無いプロジェクトも、コマンドラインからローカルにあるかのように一括検索が出来た。
新しいAPIの使い方や言語機能の使い方はとりあえずレポジトリを検索してみて他のプロジェクトを参考にしたりしていた。</p>
<p>また依存が他のチームにまで及ぶ場合、自分が他のチームまで含めて全部を変える事が出来た。
もちろんレビューとかは必要だけれど、皆が同じレポジトリを使っているので、
チームごとの別々のツリーに入れなくてはいけないみたいな作業は無かった。
関係無いチームも全部コードにアクセス出来るのはモノレポ的だと思う所だ。</p>
<p>あれだけのレポジトリのでかさを維持する為には、凄まじいエンジニアリングコストが掛かっていた。
そんな膨大なコストというのはまさにモノレポの欠点でもあるのだけど、
プロジェクトのいろいろな事を決める人たちがそれだけのコストを払ってでも維持するだけのメリットがあると思ってくれていた訳だ。</p>
<p>実際欠点もあるにせよ、当時あの規模の開発を行う為にはレポジトリを一つにするしか無かったと思う。
ツリーが別だったら、あっという間に置いていかれてしまって永遠にマージが終わらないに違いない。
実際ツリーが一つでもcommitは凄い大変だったし。</p>
<h2 id="モノレポってどうなんでしょう">モノレポってどうなんでしょう？</h2>
<p>冒頭に述べたようなプロジェクトだと、
何故か自分がレポジトリやブランチマネージメントの基本的な事をレクチャーしたりする事もあるのだけど、
この手の事は実体験が無いとうまく伝えるのは意外と難しい。</p>
<p>一般的には、モノレポの功罪とかって、
最近だとGoogleとかFacebookのモノレポなどの議論で学ぶ事だと思う。
でもその辺の話が好きなのはその辺の経験をすでに持っている人ばかりで、
意外とその辺の常識が共有されているのは、狭い世界だけだった。
そんな事にフリーランスになって初めて気づいたりした。</p>
<p>そうした時にFacebookとか<a href="https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext">Googleのモノレポの記事</a>にリンクを貼ってもいいのだけど、
記事は記事なのでやっぱり一面的というか、説得力が微妙。
もうちょっと実体験に基づいた話がある方が良い。</p>
<p>さらに、Googleのモノレポはおそらく当時のOfficeよりは遥かにでかくなっているはずなので、
ヤバさもずっと上になっているはずだ。
そうした経験があると自分とは違った見解もありそうで、自分個人としても聞いてみたい気がした。</p>
<p>という事で他の人にも聞いてみたい。とりあえず検索で世界最大規模のモノレポの仕事の経験がありつつ小さなオープンソースの仕事での非モノレポの経験もあって、
さらにChromeとAndroidという見るからにやばそうなコードと深いつながりのあるChrome OSの仕事をしている<a href="/007-repo/02-jmuk/">jmuk</a>にまず聞いてみたい。
モノレポってどうなんですか？</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
Microsoft の Windows は 2017 年に <a href="https://devblogs.microsoft.com/bharry/the-largest-git-repo-on-the-planet/">Git へ移行</a>し、
<a href="https://github.com/microsoft/VFSForGit">GVFS</a> という仮想ファイルシステムまで作ってロックだなと思いました。
Linux のためのバージョン管理ツールを Windows がつかっているこのロック感、ゼロ年代育ちにしかわかるまい。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
MSはたまに謎のフットワークの軽さを見せる事ありますよねぇ。自分の頃はPerforceのカスタム版っぽい奴（source depotという名前だった）だったけど、きっと今は全然違う世界になってるのだろうなぁ。
MSもGoogleもFacebookも何か作っていてみんなバラバラってちょっと面白い状況ですね。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ブックマークしたい</title>
      <link>https://messagepassing.github.io/005-bookmark/04-kzys/</link>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/04-kzys/</guid>
      <description>みなさんありがとうございます。
自分も jmuk さんと同じ「虚無」に落ち着いてしまったのですが、昔はもうちょっとちゃんとしてたんですよね。どこからこうなったんだっけ。
虚無への道 最初に、ブラウザのブックマークの後に使っていたのは、今は亡き del.icio.us だった。その後に、はてなブックマーク に移ったのは、なんでだったっけ?
でも、しばらく使って思ったのが
 Go についてブックマークしたページに &amp;ldquo;go&amp;rdquo; とタグをつけるのは間違っていて、全文検索で解決するべき 言いたいことがあったらブログに書くなりメールを送るべきで、ブックマークでワイワイするべきではない  で、タグをつけるというアイデアと、ソーシャルなブックマークというアイデア両方になんとなくしっくりこなくなってしまって、現在に至る。
karino2 さんと morrita さんと同じように、仕事だと雑多なノート兼 TODO リストみたいなものを Quip に作っていて、そこにブックマークも行きがち。
仕事の外でもそうしたらいいかなと思って Evernote にノートを作ったりしているけど、いまひとつ定着しない。これは morrita さんの
 昔は Evernote とか org-mode のいわゆる journal に記録をつけていた時期もあったけれど、定着しなかった。Fragments は「友達に送る」という口実が少しは支えになってる気がする。
 これと同じ問題そう。一方で、結婚して子供ができてから、公開したくない/する必要がない情報がだんだん増えてきているので、公開することで何かを担保するのもなあ。Sharenting したくない。
とりあえず今年は Evernote か Scrapbox でやってみます。</description>
      <content:encoded><![CDATA[<p>みなさんありがとうございます。</p>
<p>自分も jmuk さんと同じ「虚無」に落ち着いてしまったのですが、昔はもうちょっとちゃんとしてたんですよね。どこからこうなったんだっけ。</p>
<h3 id="虚無への道">虚無への道</h3>
<p>最初に、ブラウザのブックマークの後に使っていたのは、今は亡き <a href="http://del.icio.us/">del.icio.us</a> だった。その後に、<a href="https://b.hatena.ne.jp/">はてなブックマーク</a> に移ったのは、なんでだったっけ?</p>
<p>でも、しばらく使って思ったのが</p>
<ul>
<li>Go についてブックマークしたページに &ldquo;go&rdquo; とタグをつけるのは間違っていて、全文検索で解決するべき</li>
<li>言いたいことがあったらブログに書くなりメールを送るべきで、ブックマークでワイワイするべきではない</li>
</ul>
<p>で、タグをつけるというアイデアと、ソーシャルなブックマークというアイデア両方になんとなくしっくりこなくなってしまって、現在に至る。</p>
<p>karino2 さんと morrita さんと同じように、仕事だと雑多なノート兼 TODO リストみたいなものを <a href="https://www.salesforce.com/video/3642926/">Quip</a> に作っていて、そこにブックマークも行きがち。</p>
<p>仕事の外でもそうしたらいいかなと思って <a href="https://evernote.com/">Evernote</a> にノートを作ったりしているけど、いまひとつ定着しない。これは morrita さんの</p>
<blockquote>
<p>昔は Evernote とか org-mode のいわゆる journal に記録をつけていた時期もあったけれど、定着しなかった。Fragments は「友達に送る」という口実が少しは支えになってる気がする。</p>
</blockquote>
<p>これと同じ問題そう。一方で、結婚して子供ができてから、公開したくない/する必要がない情報がだんだん増えてきているので、公開することで何かを担保するのもなあ。<a href="https://en.wikipedia.org/wiki/Sharenting">Sharenting</a> したくない。</p>
<p>とりあえず今年は Evernote か <a href="https://scrapbox.io/">Scrapbox</a> でやってみます。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/01-morrita/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/01-morrita/</guid>
      <description>時間および精神的余裕のなさもあり、ここ数年あまりオンラインの技術読みものを読んでいない。というか真面目に探してない。 オンライン読みもの流通の場は時とともに移り変わるので、置いていかれている感がある。 わかってはいたけれど、みんな何読んでるのかなと気になりはする。
というわけで、皆様が何を読んでるのかきいて周るターンです。 手始めに自分の話をちょっと書いてみたい。
読んでいないもの そもそもの話のきっかけとして、自分は宗教的理由などからあまりソーシャルメディアを見ないようにしている。 （ソーシャルブックマークの類はトップページだけぼちぼちひやかすかんじ。以前はこれもやめていたが今は息抜きとして受け入れている。） おかげで時間を溶かす量は昔より減って、心も平安。けれど先に書いた置いてかれる感に繋がってもいる。
RSS ソーシャルメディアやソーシャルブックマークのような無限にリンクが振ってくるメディアのかわりに、 昔ながらの RSS は購読数を絞りつつ今も使っている。 具体的なサービスは Feedbin と Feeder を使っている。Feedbin には金を払っている。
ともだちフィード 二つ RSS リーダーを使っているのは、知り合いのブログなどをそれ以外の世間から分離するため。 自分にとって知り合いの blog は social media みたいなもので、ほっこりした気分になりたくて読んでる。 友達の言動というのはと中身によらず「元気にやってるなよしよし」となるでしょ。 そういうのと意識高い engineering blog みたいのが同時に目に入るのは嬉しくない。
この友達 RSS reader には Feeder を使っているのだけれど、Feeder は RSS に加え Twitter フィードもユーザ単位で購読できる。 だからなかなかブログを書かないけど Twitter ではアクティブな友達は　Feeder ごしの Twitter で見守っている。 タイムラインみたいな概念は崩壊するとはいえ、それほど困らない。
なお Feeder の出来は特に良くない。というか悪い。ただ自分がブログや Twitter を読んでる友達なんて 10 人くらいなので、 出来の悪さで困ることはない。(友達の少なさは問題かもしれない。)
ともだち以外フィード そういう友達以外フィードは Feedbin で読んでいる。 友達フィードよりは沢山購読してる。数えてないけど、たぶん 100 くらいだろうか。 ただ基本的には読んでなく、既読にしてるだけ。それが良いことだとは思っていないが、現状そうなっている。 全部読んでいる友達と既読にするだけの友達以外を分離したかったのは、デフォルトの態度の違いもあるかもしれない。</description>
      <content:encoded><![CDATA[<p>時間および精神的余裕のなさもあり、ここ数年あまりオンラインの技術読みものを読んでいない。というか真面目に探してない。
オンライン読みもの流通の場は時とともに移り変わるので、置いていかれている感がある。
わかってはいたけれど、みんな何読んでるのかなと気になりはする。</p>
<p>というわけで、皆様が何を読んでるのかきいて周るターンです。
手始めに自分の話をちょっと書いてみたい。</p>
<h2 id="読んでいないもの">読んでいないもの</h2>
<p>そもそもの話のきっかけとして、自分は宗教的理由などからあまりソーシャルメディアを見ないようにしている。
（ソーシャルブックマークの類はトップページだけぼちぼちひやかすかんじ。以前はこれもやめていたが今は息抜きとして受け入れている。）
おかげで時間を溶かす量は昔より減って、心も平安。けれど先に書いた置いてかれる感に繋がってもいる。</p>
<h2 id="rss">RSS</h2>
<p>ソーシャルメディアやソーシャルブックマークのような無限にリンクが振ってくるメディアのかわりに、
昔ながらの RSS は購読数を絞りつつ今も使っている。
具体的なサービスは <a href="https://feedbin.com/">Feedbin</a> と <a href="https://feeder.co/reader">Feeder</a> を使っている。Feedbin には金を払っている。</p>
<h2 id="ともだちフィード">ともだちフィード</h2>
<p>二つ RSS リーダーを使っているのは、知り合いのブログなどをそれ以外の世間から分離するため。
自分にとって知り合いの blog は social media みたいなもので、ほっこりした気分になりたくて読んでる。
友達の言動というのはと中身によらず「元気にやってるなよしよし」となるでしょ。
そういうのと意識高い engineering blog みたいのが同時に目に入るのは嬉しくない。</p>
<p>この友達 RSS reader  には Feeder を使っているのだけれど、Feeder は RSS に加え Twitter フィードもユーザ単位で購読できる。
だからなかなかブログを書かないけど Twitter ではアクティブな友達は　Feeder ごしの Twitter で見守っている。
タイムラインみたいな概念は崩壊するとはいえ、それほど困らない。</p>
<p>なお Feeder の出来は特に良くない。というか悪い。ただ自分がブログや Twitter を読んでる友達なんて 10 人くらいなので、
出来の悪さで困ることはない。(友達の少なさは問題かもしれない。)</p>
<h2 id="ともだち以外フィード">ともだち以外フィード</h2>
<p>そういう友達以外フィードは Feedbin で読んでいる。
友達フィードよりは沢山購読してる。数えてないけど、たぶん 100 くらいだろうか。
ただ基本的には読んでなく、既読にしてるだけ。それが良いことだとは思っていないが、現状そうなっている。
全部読んでいる友達と既読にするだけの友達以外を分離したかったのは、デフォルトの態度の違いもあるかもしれない。</p>
<p>気になったものも Feedbin の中で読むことは少なく、だいたいブラウザで開くか、 Instapaper とかに入れてから読んでいる。
Feedbin にも Read Later 機能があるが、使ってない。</p>
<p>ニュースサイトなど流量の多いフィードは購読していない。未読件数が増えすぎてイヤになるから。
逆にたまーに書かれる個人の blog とかは積極的に購読するようにしている。
あと自分の使っているオープンソースプロジェクトの blog もバージョンアップ通知がわりに読んでる。</p>
<p>企業 blog は色々とっており、まったく読んでない。ひどい。
あまり読んでないので参考にならないだろうけれど、賑やかしでリンクだけ置いておく:
<a href="https://medium.com/airbnb-engineering">Airbnb</a>,
<a href="https://engineering.fb.com/">Facebook</a>,
<a href="https://opensource.googleblog.com/">Google Open Soruce</a>,
<a href="https://ai.googleblog.com/">Google AI</a>,
<a href="https://engineering.linkedin.com/blog">LinkedIn</a>,
<a href="https://www.microsoft.com/en-us/research/blog/">Microsoft Research</a>,
<a href="https://slack.engineering/">Slack</a>,
<a href="https://netflixtechblog.com/">Netflix</a>,
<a href="https://eng.uber.com/">Uber</a>&hellip; まったくランダムな羅列と言って良いなこれ&hellip;
(良い機会だからと
<a href="https://aws.amazon.com/blogs/architecture/">AWS Architecture Blog</a>,
<a href="https://medium.com/@Pinterest_Engineering">Pinterest</a>,
<a href="https://medium.engineering/">Medium</a> も足してあげた。読むとは言ってない。)</p>
<p>Feedbin は Feed を &ldquo;mute&rdquo; できるので、面白くないやつや流量が多いやつは積極的に mute するようにしている。
Mute は事実上 unsubscribe でありながら購読している事実はどこかに残っており、本気の unsubscribe よりは FOMO 的躊躇がない。
良い機能だと思う。</p>
<h2 id="newsletter-feed">Newsletter Feed</h2>
<p>Feedbin には newsletter を購読して表示する機能があり、Newsletter の類はこれで読んでいる。
GMail の inbox を mess しないのがよい。
(Feedly の有償バージョンにも同じ機能は<a href="https://blog.feedly.com/get-newsletters-in-feedly/">あるらしい</a>。
そういえば <a href="https://hey.com/how-it-works/">Hey</a> もそのへんうまくやってくれると主張してたね。)</p>
<p>自分は特に気の利いた newsletter はとっておらず、X Weekly 系が主。
こういうのは自分の身近な要素技術の weekly をとればいいのでおすすめは特に無い。面白いものでもないし。
<a href="https://weekly.statuscode.com/">StatusCode Weekly</a> はそこそこ総花的かもしれない。</p>
<h2 id="feed-を探す">Feed を探す</h2>
<p>読みもの探しと言えば、少し前に「学会 blog」が実は面白いのではないかと探し、
PL の学会である <a href="https://blog.sigplan.org/">SIGPLAN の blog</a> と
コンピュータアーキテクチャの学会 <a href="https://www.sigarch.org/blog/">SIGARCH の blog</a>
を購読した。SIGPLAN だとたとえばこの <a href="https://blog.sigplan.org/2020/06/25/hopl-not-an-ordinary-conference/">HOPL 紹介記事</a>
がよいし、SIGARC は <a href="https://www.sigarch.org/chiplet-based-systems/">Chiplet の話</a> や <a href="https://www.sigarch.org/the-future-of-sparsity-in-deep-neural-networks/">Sparse Kernel accelerator</a> なんて夢がある。</p>
<p>こうやって気になる話題の blog を探して面白いものがみつかると嬉しい。</p>
<h2 id="探す苦労より読む苦労">探す苦労より読む苦労</h2>
<p>改めて考えると、自分は（最近の書き手がわらかない以外は）それほど読むものに困っておらず、
むしろ読みたいものを読み始める・読み切る集中力の無さに困っている気がする。長いウェブの文章をよむのがどんどん苦手になっている。
良い機会なので今年はもうちょっとウェブの文章を読んでいきたい気がしてきた。</p>
<p>その点、<a href="/009-feed/02-jmuk/">むかいさん</a>は長いやつも含めさらっと色々ウェブを読んでますねえ。Twitter みてていつも感心してます。
<a href="/009-feed/03-kzys/">かずよしさん</a>も引用しているものをみると色々最近のを読んでるなと思う。
<a href="/009-feed/04-karino2/">有野さんは</a>はいつものように BOOX の自慢でもしてください。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>読んだ本はBlog、Webの記事は適当</title>
      <link>https://messagepassing.github.io/005-bookmark/03-karino2/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/03-karino2/</guid>
      <description>向井さんのお察しの通り、全公開上等でブログですね。 ブログせずに読んだ本も少しはあるけれど。
このトピックの元だった2020年に読んだ本の話を書いた時は、過去のブログを眺めて、 あとはKindleアプリで他に買ったの無いかなぁ、と軽く確認したぐらいですね。 そういう点ではmorritaさんと似ている。
技術記事の場合、仕事で調査している時は社内のWikiを基本に、 Wikiに書くほどの事でも無い場合はSlackの分報に書いています。 仕事で読む物は記録は必ず残している。
仕事では無く、すぐ読んで終わりのつもりの技術ブログなどは、あまりちゃんと管理してないですね。 だいたいスマホで見かけてBOOXで読む、というパターンが多いので、 スマホからBOOXへはGoogle Driveのテキストファイル(自作メモアプリを使っている)経由か、 Pocket経由で送っています。Pocketは一応あとで以前読んだのを探す事は出来るので、ブックマークも兼ねて使っている。 使い分けには特にルールは無いけど、たくさん送る時はPocket、ちょっとSNSとかで流れてきたのが気になった、くらいだと自作メモアプリですね。
すぐに読む気は無いけど記録として残しておきたいwebの記事には、Google Bookmarksを使ってます。 いつサービス終了するかドキドキしながら使ってますが…必要十分でいいサービスだと思うんだけどなぁ。
論文は必ずGoogle Driveの特定フォルダ下に置く事にして、ちゃんと読んだ物は基本的にはブログを書く、というルールで管理していますね。
たぶん皆もそうだと思うけれど、全体的に昔よりも雑になってますねぇ。 前はもうちょっとちゃんと管理していたのだけれど。
あと誰も興味無いだろうけれど、なろう小説は、なろう公式のブックマーク機能を使っています。最新話を追っかけているものはカテゴリ1、読み終わったものや読むのを止めたものはカテゴリ2、 そのうち読もうと思っているものや読んでいる途中でまだ最新話には追いついていない物はカテゴリ3にしている。
 morrita Google Bookmarks! まだあったのか!! しかも Maps 上で Like した場所のサイトが勝手に追加されている&amp;hellip;
自分も仕事関係で読んだものは、バグトラッカーなり作業記録なりからリンクしてます。あるいはコードのコメントとか、関連ドキュメントとか。 必要性があって読むものは文脈があるから、その文脈に埋め込めばよいよね。
  </description>
      <content:encoded><![CDATA[<p><a href="/005-bookmark/02-jmuk/">向井さん</a>のお察しの通り、全公開上等でブログですね。
ブログせずに読んだ本も少しはあるけれど。</p>
<p>このトピックの元だった2020年に読んだ本の話を書いた時は、過去のブログを眺めて、
あとはKindleアプリで他に買ったの無いかなぁ、と軽く確認したぐらいですね。
そういう点ではmorritaさんと似ている。</p>
<p>技術記事の場合、仕事で調査している時は社内のWikiを基本に、
Wikiに書くほどの事でも無い場合はSlackの分報に書いています。
仕事で読む物は記録は必ず残している。</p>
<p>仕事では無く、すぐ読んで終わりのつもりの技術ブログなどは、あまりちゃんと管理してないですね。
だいたいスマホで見かけてBOOXで読む、というパターンが多いので、
スマホからBOOXへはGoogle Driveのテキストファイル(<a href="https://karino2.github.io/2020/12/12/textdeck.html">自作メモアプリ</a>を使っている)経由か、
Pocket経由で送っています。Pocketは一応あとで以前読んだのを探す事は出来るので、ブックマークも兼ねて使っている。
使い分けには特にルールは無いけど、たくさん送る時はPocket、ちょっとSNSとかで流れてきたのが気になった、くらいだと自作メモアプリですね。</p>
<p>すぐに読む気は無いけど記録として残しておきたいwebの記事には、<a href="https://www.google.com/bookmarks/">Google Bookmarks</a>を使ってます。
いつサービス終了するかドキドキしながら使ってますが…必要十分でいいサービスだと思うんだけどなぁ。</p>
<p>論文は必ずGoogle Driveの特定フォルダ下に置く事にして、ちゃんと読んだ物は基本的にはブログを書く、というルールで管理していますね。</p>
<p>たぶん皆もそうだと思うけれど、全体的に昔よりも雑になってますねぇ。
前はもうちょっとちゃんと管理していたのだけれど。</p>
<p>あと誰も興味無いだろうけれど、なろう小説は、なろう公式のブックマーク機能を使っています。最新話を追っかけているものはカテゴリ1、読み終わったものや読むのを止めたものはカテゴリ2、
そのうち読もうと思っているものや読んでいる途中でまだ最新話には追いついていない物はカテゴリ3にしている。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>Google Bookmarks! まだあったのか!!
しかも Maps 上で Like した場所のサイトが勝手に追加されている&hellip;</p>
<p>自分も仕事関係で読んだものは、バグトラッカーなり作業記録なりからリンクしてます。あるいはコードのコメントとか、関連ドキュメントとか。
必要性があって読むものは文脈があるから、その文脈に埋め込めばよいよね。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ブックマークはしない</title>
      <link>https://messagepassing.github.io/005-bookmark/02-jmuk/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/02-jmuk/</guid>
      <description>みんな記録とかどうしてるんだろうっていうのは私も疑問に思ってたところがある（笑）。管理、一切してないというのが一番近いな。管理したほうがいいんだけど……。
紙の本については、書棚の量が今のところたかが知れているので眺めるぐらいでだいたいわかるようになっている。内容についてはだいたい見れば思い出す……というか思い出せないぐらいの本は自分にとって重要ではないっていうことだと思う。
電子書籍は、Amazon Kindleについては提供されているライブラリで事足りる。それ以外のものは、Google Driveにつっこんだりしているけれど、未読管理であるとか、いつ読んだかとか、感想とかは、なんにもしてない。基本的に買ったはしから読み、それで読まなかったものは埋もれていってしまっている気がする。PDFも同様で基本的には散逸しまくっていると思う。ポッドキャストで扱うであろう論文についてはそれだと立ち行かないので、Dropbox paperで読みたいPDFのリストをまとめているけれど、それぐらい。
インターネットの記事のブックマークとかは一層の虚無であり、読み終わったらそれで終わりということが一番多い気がする。あとで読む記事とかは、ブラウザのタブを開きっぱなしにしておいて後日見る、みたいな運用にしている。
という次第で、端的に要約すると、無。読んだものの管理はしていません。自分の記憶力と印象に頼りきりでボーッと生きている。さすがに何らかのものは記録したほうがいい気がしないでもない、と思いつつ、でも面倒だしな、というのを繰り返している。タスク管理もいろいろ試してみたがあんまりうまくいってないし。
基本的なソリューションはブログに書いておくことなんじゃないかと思うけれど、ブログはやっぱりなんか気合が必要になってしまった感がある。そんなにちゃんとした感想を書きたいわけでもないときもある。あと別に公開したくないときもある。というわけでうだう悩んでいる。
twitterはヘビーに使っているけれど、こういう用途には使っていないし向いていない気がするな。twitterをどう使ったとしても記録は簡単に散逸してしまう気がするので。
という本当に虚無みたいな回答になっちゃうんだよな。有野さんは全公開上等でブログっていうスタイルですか？</description>
      <content:encoded><![CDATA[<p>みんな記録とかどうしてるんだろうっていうのは私も疑問に思ってたところがある（笑）。管理、一切してないというのが一番近いな。管理したほうがいいんだけど……。</p>
<p>紙の本については、書棚の量が今のところたかが知れているので眺めるぐらいでだいたいわかるようになっている。内容についてはだいたい見れば思い出す……というか思い出せないぐらいの本は自分にとって重要ではないっていうことだと思う。</p>
<p>電子書籍は、Amazon Kindleについては提供されているライブラリで事足りる。それ以外のものは、Google Driveにつっこんだりしているけれど、未読管理であるとか、いつ読んだかとか、感想とかは、なんにもしてない。基本的に買ったはしから読み、それで読まなかったものは埋もれていってしまっている気がする。PDFも同様で基本的には散逸しまくっていると思う。ポッドキャストで扱うであろう論文についてはそれだと立ち行かないので、Dropbox paperで読みたいPDFのリストをまとめているけれど、それぐらい。</p>
<p>インターネットの記事のブックマークとかは一層の虚無であり、読み終わったらそれで終わりということが一番多い気がする。あとで読む記事とかは、ブラウザのタブを開きっぱなしにしておいて後日見る、みたいな運用にしている。</p>
<p>という次第で、端的に要約すると、無。読んだものの管理はしていません。自分の記憶力と印象に頼りきりでボーッと生きている。さすがに何らかのものは記録したほうがいい気がしないでもない、と思いつつ、でも面倒だしな、というのを繰り返している。タスク管理もいろいろ試してみたがあんまりうまくいってないし。</p>
<p>基本的なソリューションはブログに書いておくことなんじゃないかと思うけれど、ブログはやっぱりなんか気合が必要になってしまった感がある。そんなにちゃんとした感想を書きたいわけでもないときもある。あと別に公開したくないときもある。というわけでうだう悩んでいる。</p>
<p>twitterはヘビーに使っているけれど、こういう用途には使っていないし向いていない気がするな。twitterをどう使ったとしても記録は簡単に散逸してしまう気がするので。</p>
<p>という本当に虚無みたいな回答になっちゃうんだよな。<a href="/005-bookmark/03-karino2/">有野さん</a>は全公開上等でブログっていうスタイルですか？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: Re: 今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/04-kzys/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/04-kzys/</guid>
      <description>ここ数年ずっと技術書は O&amp;rsquo;Reilly Online Learning (もう Safari と呼ばないんですね) で読んでいる。ACM の年会費を払うだけで、ちょっとだけ興味があるトピックに関してでも、本を複数冊パラパラと読めるし、O&amp;rsquo;Reilly の本だけではないので、本屋気分で新着を冷やかすのも楽しい。
ただ、高い技術書を買って値段分の価値をとるべく読み切る、という動機が弱くなるという問題があって、ここまでが長い言い訳なんですが、2020年は通読して印象に残っている技術書がありません。2021年はがんばります。
BPF Performance Tools jmuk さんと同じく &amp;ldquo;BPF Performance Tools&amp;rdquo; は途中まで読んだ。構成にはあまり不満はなくて「BPF すごいなあ。便利だなあ。なんでもできるなあ。」という印象。
BPF そのものは、bpftrace で色々書くのも DTrace みたいでかっこいいけれど、BCC に入っている小物スクリプトを使うだけでも結構良くて、昔だったらあたりをつけて strace したり、lsof を連打するような局面で「このホストの全ての open を tail -F 風にずっと流す」みたいなことができて便利。containerd/cgroup のこのバグを直したときにも使ったはず。
Practical TLA+ AWS 社員たるもの PlusCal 経由でいいので TLA+ くらい書けなくては、と思って読み出した。これはまだ本当に冒頭までしか読めていなくて、語るべきことなし。
著者の Hillel Wayne は TLA+ や Alloy など形式手法のコンサルティングやワークショップなどを仕事にしている人で、ブログもある。
Why the Sorbet typechecker is fast Sorbet は Stripe の開発している Ruby むけの静的型チェッカ。初期開発メンバーの一人である Nelson Elhage は、この他にも Sorbet の開発上の工夫について色々と書いていて、どれも面白い。
 Record/Replay testing in Sorbet Reflections on software performance  以前は Scala のコンパイラを書いていた Dmitry Petrashko も Sorbet には関わっていて、Software Engineering Daily ポッドキャストの Sorbet: Typed Ruby with Dmitry Petrashko で話している。</description>
      <content:encoded><![CDATA[<p>ここ数年ずっと技術書は <a href="https://www.oreilly.com/online-learning/">O&rsquo;Reilly Online Learning</a> (もう Safari と呼ばないんですね) で読んでいる。ACM の年会費を払うだけで、ちょっとだけ興味があるトピックに関してでも、本を複数冊パラパラと読めるし、O&rsquo;Reilly の本だけではないので、本屋気分で新着を冷やかすのも楽しい。</p>
<p>ただ、高い技術書を買って値段分の価値をとるべく読み切る、という動機が弱くなるという問題があって、ここまでが長い言い訳なんですが、2020年は通読して印象に残っている技術書がありません。2021年はがんばります。</p>
<h3 id="bpf-performance-toolshttpwwwbrendangreggcombpf-performance-tools-bookhtml"><a href="http://www.brendangregg.com/bpf-performance-tools-book.html">BPF Performance Tools</a></h3>
<p>jmuk さんと同じく &ldquo;BPF Performance Tools&rdquo; は途中まで読んだ。構成にはあまり不満はなくて「BPF すごいなあ。便利だなあ。なんでもできるなあ。」という印象。</p>
<p>BPF そのものは、bpftrace で色々書くのも DTrace みたいでかっこいいけれど、<a href="https://github.com/iovisor/bcc">BCC</a> に入っている小物スクリプトを使うだけでも結構良くて、昔だったらあたりをつけて strace したり、lsof を連打するような局面で「このホストの全ての open を tail -F 風にずっと流す」みたいなことができて便利。<a href="https://github.com/containerd/cgroups/pull/147">containerd/cgroup のこのバグ</a>を直したときにも使ったはず。</p>
<h3 id="practical-tlahttpswwwapresscomgpbook9781484238288"><a href="https://www.apress.com/gp/book/9781484238288">Practical TLA+</a></h3>
<p><a href="https://blog.acolyer.org/2014/11/24/use-of-formal-methods-at-amazon-web-services/">AWS 社員たるもの PlusCal 経由でいいので TLA+ くらい書けなくては</a>、と思って読み出した。これはまだ本当に冒頭までしか読めていなくて、語るべきことなし。</p>
<p>著者の <a href="https://www.hillelwayne.com/">Hillel Wayne</a> は TLA+ や Alloy など形式手法のコンサルティングやワークショップなどを仕事にしている人で、ブログもある。</p>
<h3 id="why-the-sorbet-typechecker-is-fasthttpsblognelhagecompostwhy-sorbet-is-fast"><a href="https://blog.nelhage.com/post/why-sorbet-is-fast/">Why the Sorbet typechecker is fast</a></h3>
<p>Sorbet は Stripe の開発している Ruby むけの静的型チェッカ。初期開発メンバーの一人である Nelson Elhage は、この他にも Sorbet の開発上の工夫について色々と書いていて、どれも面白い。</p>
<ul>
<li><a href="https://blog.nelhage.com/post/record-replay-in-sorbet/">Record/Replay testing in Sorbet</a></li>
<li><a href="https://blog.nelhage.com/post/reflections-on-performance/">Reflections on software performance</a></li>
</ul>
<p>以前は Scala のコンパイラを書いていた Dmitry Petrashko も Sorbet には関わっていて、Software Engineering Daily ポッドキャストの <a href="https://softwareengineeringdaily.com/2020/03/25/sorbet-typed-ruby-with-dmitry-petrashko/">Sorbet: Typed Ruby with Dmitry Petrashko</a> で話している。</p>
<h3 id="i-want-off-mr-golangs-wild-ridehttpsfasterthanlimearticlesi-want-off-mr-golangs-wild-ride"><a href="https://fasterthanli.me/articles/i-want-off-mr-golangs-wild-ride">I want off Mr. Golang&rsquo;s Wild Ride</a></h3>
<p>Go は現実問題の複雑さ、例えば Unix のパスは必ずしも UTF-8 として妥当なバイト列ではないとか、モノトニック時刻とカレンダ時刻の違いとか、Windows とかを「シンプルさ」の名のもとに隠蔽しようとしているけど、それはいかがなものか、という批判。</p>
<p>著者が比較しているのは Rust で、それは結局 Rust は C++ で、Go は Java なのだから仕方がないのでは、と思わなくもないけれど、書きぶりが良いし、熊がかわいい。</p>
<h3 id="node-vol-02-manifesting-realityhttpsn-o-d-enetzineindexhtml"><a href="https://n-o-d-e.net/zine/index.html">NODE VOL 02: MANIFESTING REALITY</a></h3>
<p>NODE は Raspberry Pi ベースのハードウェアとかを自作している (売っているわけではない) 謎のウェブサイトで、その同人誌 (zine)。自分は PDF を iPad で読んだ。<a href="https://makezine.com/">Make Magazine</a> みたいな感じだけど、よりハッカー/カウンターカルチャー色が強い。</p>
<p>オンライン雑誌でいうと Stripe の　<a href="https://increment.com/">Increment</a> も良いけれど、あまり読めていない。紙で買うといいのかもしれないけれど、節約を美徳とする身としては紙はちょっと&hellip;</p>
<h3 id="ところでブックマークってどうしてます">ところでブックマークってどうしてます?</h3>
<p>みなさんがするすると読んだものを列挙できるのにちょっとびっくりしているんですが、ブックマークというか、PDF もふくんだ読んだものの管理ってどうしてます?</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
さっそく Sorbet の話を読みました。面白い。そしてこの人が <a href="https://accidentallyquadratic.tumblr.com/">Accidentally Quadratic</a> を集めていたのか！
Stripe やめてヒマしてそうだし、また更新してほしいなあ。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>ブックマークのはなし</title>
      <link>https://messagepassing.github.io/005-bookmark/01-morrita/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/01-morrita/</guid>
      <description>From kzys:
 みなさんがするすると読んだものを列挙できるのにちょっとびっくりしているんですが、 ブックマークというか、PDF もふくんだ読んだものの管理ってどうしてます?
 そこそこのインターネット中毒者であるところのわたくしから・・・。 といっても家事子守とかがあると管理が必要なほど沢山のテキストを読めないので、今はそんなにがんばってない。
近況ニュースレター ここ二年くらい簡易 journal として Twitter の代わりに Notion や WordPress で箇条書き公開日記みたいな記録を つけてる。一週間で 1 ページ。 Fragments と読んでいる。
この Fragments の中に読んだものへのリンクと感想を並べ、ブックマークがわりにしてる。 これは世間の一部の人が Twitter にリンクを蓄積しているのと似たようなものだと思う。 公開する意義があるのか怪しい内容だが自分にとってはソーシャルメディアなので、 ページを更新するタイミングで友達数人に近況ニュースレターとして送りつけている。 （頼まれもしないのに送ってるのでニュースレターというよりは迷惑メールだけど。）
それとは別に古き良きブックマークサービスの Pinboard もつかっているけれど、 こっちは読んで「ない」ものと純粋に資料的価値のあるものをファイルしておくかんじ。 プライバシー優先のため Pinboard は公開していない。 日本の人だと「はてなブックマーク」とかを使うところだと思う。 Pinboard は特段優れた機能を持つわけではないが、 ソーシャルメディアではなく単なるツールなのでうっかり嫌な気持ちにならない点は良い。
Podcast のために読む論文の管理には Paperpile を使っているが、 自分は別にアカデミアではないので書誌管理機能は活用していない。 付属の PDF ビューアの出来の良さと、論文特化の Chrome extension とかが割と良い。 ただアカデミアみたいに大量に読んでしかも引用するとかで限り Pinboard のような普通のブックマークでダメな理由は無い気がする。
電子書籍類は大して量がないので電子書籍アプリの書棚で足りている。 あと先の Fragments やブログに感想文を書いたりもしている。
こうしてみると純粋に時系列に読んだ記録としては Fragments が一番機能しているかな。こないだの記事を書くのにも見返した。 昔は Evernote とか org-mode のいわゆる journal に記録をつけていた時期もあったけれど、定着しなかった。 Fragments は「友達に送る」という口実が少しは支えになってる気がする。 Twitter や Facebook でダメなのかは個人によると思うけれど、自分は気が散りすぎて無理。</description>
      <content:encoded><![CDATA[<p>From <a href="https://messagepassing.github.io/004-whatiread/04-kzys/">kzys</a>:</p>
<blockquote>
<p>みなさんがするすると読んだものを列挙できるのにちょっとびっくりしているんですが、
ブックマークというか、PDF もふくんだ読んだものの管理ってどうしてます?</p>
</blockquote>
<p>そこそこのインターネット中毒者であるところのわたくしから・・・。
といっても家事子守とかがあると管理が必要なほど沢山のテキストを読めないので、今はそんなにがんばってない。</p>
<h2 id="近況ニュースレター">近況ニュースレター</h2>
<p>ここ二年くらい簡易 journal として Twitter の代わりに Notion や WordPress で箇条書き公開日記みたいな記録を
<a href="https://anemone.dodgson.org/tags/fragments/">つけてる</a>。一週間で 1 ページ。
Fragments と読んでいる。</p>
<p>この Fragments の中に読んだものへのリンクと感想を並べ、ブックマークがわりにしてる。
これは世間の一部の人が Twitter にリンクを蓄積しているのと似たようなものだと思う。
公開する意義があるのか怪しい内容だが自分にとってはソーシャルメディアなので、
ページを更新するタイミングで友達数人に近況ニュースレターとして送りつけている。
（頼まれもしないのに送ってるのでニュースレターというよりは迷惑メールだけど。）</p>
<p>それとは別に古き良きブックマークサービスの <a href="https://pinboard.in/">Pinboard</a> もつかっているけれど、
こっちは読んで「ない」ものと純粋に資料的価値のあるものをファイルしておくかんじ。
プライバシー優先のため Pinboard は公開していない。
日本の人だと「はてなブックマーク」とかを使うところだと思う。
Pinboard は特段優れた機能を持つわけではないが、
ソーシャルメディアではなく単なるツールなのでうっかり嫌な気持ちにならない点は良い。</p>
<p>Podcast のために読む論文の管理には <a href="https://paperpile.com/">Paperpile</a> を使っているが、
自分は別にアカデミアではないので書誌管理機能は活用していない。
付属の PDF ビューアの出来の良さと、論文特化の Chrome extension とかが割と良い。
ただアカデミアみたいに大量に読んでしかも引用するとかで限り Pinboard のような普通のブックマークでダメな理由は無い気がする。</p>
<p>電子書籍類は大して量がないので電子書籍アプリの書棚で足りている。
あと先の Fragments やブログに感想文を書いたりもしている。</p>
<p>こうしてみると純粋に時系列に読んだ記録としては Fragments が一番機能しているかな。こないだの記事を書くのにも見返した。
昔は Evernote とか org-mode のいわゆる journal に記録をつけていた時期もあったけれど、定着しなかった。
Fragments は「友達に送る」という口実が少しは支えになってる気がする。
Twitter や Facebook でダメなのかは個人によると思うけれど、自分は気が散りすぎて無理。</p>
<h3 id="ふりかえりフィルタ">ふりかえりフィルタ</h3>
<p>日々の蓄積とは別に、こないだみたいに読んだものを見直すのも良い気がする。
<a href="https://www.amazon.com/Getting-Things-Done-Stress-Free-Productivity/dp/0143126563/">Getting Things Done</a>
でも毎日タスクをリストに貯めつつ週に一回そのリストを見直して整理しろといってる。
自分は読書記録についてはこれまでも年に一回見直してた。でもオンラインの記事も見直すと案外良いね。
序列づけ重要。これを 10-20 年前からやっていたら素敵なオンライン目録が出来たのに無念。今年からはやります。</p>
<p><a href="/005-bookmark/02-jmuk/">むかいさん</a>は主に Twitter ですか？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: 今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/03-jmuk/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/03-jmuk/</guid>
      <description>いろいろ忙しかったのと、私事などもあり、2020年はあんまりいろいろ読んだりはしない年になった。のであんまり書くことなかったりするんだよなぁ。
reMarkable2 話をふられたのでまずそこから書くと、reMarkable2を買った。e-inkのタブレットデバイス。なかみは独自のOSで、基本的には文書や本を読むためのものというくくり。見かけてすぐ予約したけど、パンデミックの影響もあり、入手したのは10月。まだそんなに使いこなしているわけでもない。
もともとの動機として、論文を読むのに向いてるe-inkタブレットがほしかったのだった。reMarkable2は基本的にはPDFとepubリーダになっていて、PDFとかebookはアプリ・拡張機能からクラウド経由でデバイスに送り込んで読める。その用途なら、Amazon Kindleデバイス＋instapaperでもまぁいいんだけどね……（まあそれなりの大きさがあるのは良い）。
e-inkリーダとしての性能は、まあそこそこかな。やっぱり画面遷移が遅いし、前後のページにしか遷移できないので、いきなり前の方にジャンプしたりできなくて、ちょっと不便。でもやっぱり読みやすい。それと、専用のスタイラスがあって、PDFでもebookでも好き勝手にメモを書き込めるのが面白い。というわけで、論文読みデバイスとしてはなかなか優秀だと思う。でもまあ、向いている人が必ずしも多いわけではないニッチ製品かなぁ。いちおうウェブページも同じ仕組みで（ebookに変換して転送して）読むことはできる。けどまあウェブ閲覧としてはイマイチ。やってみたら日本語ウェブページも読めなかったし（日本語PDFは読めるようだ。フォント埋め込みしてるからかな）。
Let&amp;rsquo;s Encrypt: An Automated Certificate Authority to Encrypt the Entire Web というわけで、reMarkable2で読むのはもっぱら論文なんだけど、読んだ論文は基本的にはポッドキャストで紹介するつもりなので、ここで紹介するものがあんまりない。ただそういえば、このLet&amp;rsquo;s Encryptの論文はおもしろかったけどポッドキャスト向きじゃあないかも。あんまりアカデミックな内容じゃないんだよね。
Let&amp;rsquo;s Encryptのことのおこり、組織構成、資金、クライアントツールのデモグラフィック、成功の要因などが詳しく書かれている。技術面だとLet&amp;rsquo;s Encryptのプロトコルが解説されていて、これでようやくどういうものか理解できたっていうのはある。完全に自動化されていて間に人間がいっさい介在しない（できない）っていうのはやっぱり面白いね。
そういえばLet&amp;rsquo;s Encryptの証明書は有効期限が短く3ヶ月しかない。それはまあちょっと不便なんだけど、なぜそうなっているのか。なんとなく勝手に、完全自動化で無料である意味でほかのCAのような信頼性の担保がないからだとずっと思っていたが、この論文を読んだらぜんぜんそういう理由じゃなかったので、そこは読んでて思わず声が出た。有効期限が短くなれば人間としても手作業で更新するのが手間になるから、ユーザ側も更新をcronなどで完全自動化するモチベーションが出てくる。そうなるようにわざと短い有効期限にしているのだそうだ。そうだったのかよ！？
BPF Performance Tools さて、本でいえばBPF Performance Toolsを2020年初に買っていた。BPFまわりで活発に活動しているBrendan Gregg氏の本だ。めちゃくちゃ分厚い。あと残念な告白をすると、通読はできていません。
買って読んでみてわかったのだが、ある意味では膨大なレシピブックという側面があり、こういうことをしたいならこうする、といったコードサンプル、事例がふんだんに盛り込まれていて、扱われているネタは広範なんだけど、悪くいえば散漫でもあり、なんか読みづらい。序盤の数章は読んで面白かったんだけどね。karinoさんも、Brendan Greggの他の本への感想に似たようなことを書いていたので、これはこの人の方向性ということなんだろう。悪い本ではぜんぜんないというか、持っていて良い本だとは思うけれど。
並列コンピュータ &amp;ndash; 非定量的アプローチ 出身大学の天野英晴先生が書いた日本語の本。これは面白く読んだ。並列コンピュータの構成方法についての細かい話がいろいろわかりやすくまとまっている。たとえばキャッシュコヒーレンシや共有メモリモデル、クラスタマシンなどなど。まえがきによれば過去あった本の再編とのことだけど、最後にGPUなどのアクセラレータを扱った章も書き足されている。こういう分野は普段の仕事と縁遠いから、それゆえに読んでいて面白い。
なお、タイトルはヘネパタ（『コンピュータ・アーキテクチャ　定量的アプローチ』）をもじったものだけど、そんなヘネパタみたいなことは普通はできないし、複雑化したコンピュータを定量的に理解するのもだんだん難しくなってきているから……といった話がまえがきに書いてあるのがわりと面白い。これは出版社のサイトの「試し読み」から一読できるので興味があればどうぞ。
Reverse Engineering the source code of the BioNTech/Pfizer SARS-CoV-2 Vaccine そういえば年末に読んだこれはけっこう面白かった。新型コロナウィルスのワクチンの「ソースコード」を解説する記事。DNAの各パートについて、それぞれがどういう意味なのかを説明してくれている。この記事にかぎらず解説記事というのはいくつもあるものだと思うけれど、この記事はプログラマによる解説記事なのでプログラマが読んでわかりやすいたとえが入っているのが特徴。これを読んだ後にほかの解説記事を読んだら理解しやすくなったように感じた（気のせいだと思うけど）。日本語翻訳も上がっていて、そちらも良いけれどこのプログラマ向けっぽい感じが少し薄れている気がする。
 morrita 自分も BPF Performance Tools 読みました。 Systems Performance もそうですが、 この人の「持っている知識の確かさ」と「著者としてのいまいちさ」のギャップはなんなんでしょうね・・・。   </description>
      <content:encoded><![CDATA[<p>いろいろ忙しかったのと、私事などもあり、2020年はあんまりいろいろ読んだりはしない年になった。のであんまり書くことなかったりするんだよなぁ。</p>
<h2 id="remarkable2httpsremarkablecom"><a href="https://remarkable.com/">reMarkable2</a></h2>
<p>話をふられたのでまずそこから書くと、reMarkable2を買った。e-inkのタブレットデバイス。なかみは独自のOSで、基本的には文書や本を読むためのものというくくり。見かけてすぐ予約したけど、パンデミックの影響もあり、入手したのは10月。まだそんなに使いこなしているわけでもない。</p>
<p>もともとの動機として、論文を読むのに向いてるe-inkタブレットがほしかったのだった。reMarkable2は基本的にはPDFとepubリーダになっていて、PDFとかebookはアプリ・拡張機能からクラウド経由でデバイスに送り込んで読める。その用途なら、Amazon Kindleデバイス＋instapaperでもまぁいいんだけどね……（まあそれなりの大きさがあるのは良い）。</p>
<p>e-inkリーダとしての性能は、まあそこそこかな。やっぱり画面遷移が遅いし、前後のページにしか遷移できないので、いきなり前の方にジャンプしたりできなくて、ちょっと不便。でもやっぱり読みやすい。それと、専用のスタイラスがあって、PDFでもebookでも好き勝手にメモを書き込めるのが面白い。というわけで、論文読みデバイスとしてはなかなか優秀だと思う。でもまあ、向いている人が必ずしも多いわけではないニッチ製品かなぁ。いちおうウェブページも同じ仕組みで（ebookに変換して転送して）読むことはできる。けどまあウェブ閲覧としてはイマイチ。やってみたら日本語ウェブページも読めなかったし（日本語PDFは読めるようだ。フォント埋め込みしてるからかな）。</p>
<h2 id="lets-encrypt-an-automated-certificate-authority-to-encrypt-the-entire-webhttpsjhaldermcompubpapersletsencrypt-ccs19pdf"><a href="https://jhalderm.com/pub/papers/letsencrypt-ccs19.pdf">Let&rsquo;s Encrypt: An Automated Certificate Authority to Encrypt the Entire Web</a></h2>
<p>というわけで、reMarkable2で読むのはもっぱら論文なんだけど、読んだ論文は基本的にはポッドキャストで紹介するつもりなので、ここで紹介するものがあんまりない。ただそういえば、このLet&rsquo;s Encryptの論文はおもしろかったけどポッドキャスト向きじゃあないかも。あんまりアカデミックな内容じゃないんだよね。</p>
<p>Let&rsquo;s Encryptのことのおこり、組織構成、資金、クライアントツールのデモグラフィック、成功の要因などが詳しく書かれている。技術面だとLet&rsquo;s Encryptのプロトコルが解説されていて、これでようやくどういうものか理解できたっていうのはある。完全に自動化されていて間に人間がいっさい介在しない（できない）っていうのはやっぱり面白いね。</p>
<p>そういえばLet&rsquo;s Encryptの証明書は有効期限が短く3ヶ月しかない。それはまあちょっと不便なんだけど、なぜそうなっているのか。なんとなく勝手に、完全自動化で無料である意味でほかのCAのような信頼性の担保がないからだとずっと思っていたが、この論文を読んだらぜんぜんそういう理由じゃなかったので、そこは読んでて思わず声が出た。有効期限が短くなれば人間としても手作業で更新するのが手間になるから、ユーザ側も更新をcronなどで完全自動化するモチベーションが出てくる。そうなるようにわざと短い有効期限にしているのだそうだ。そうだったのかよ！？</p>
<h2 id="bpf-performance-toolshttpwwwbrendangreggcombpf-performance-tools-bookhtml"><a href="http://www.brendangregg.com/bpf-performance-tools-book.html">BPF Performance Tools</a></h2>
<p>さて、本でいえばBPF Performance Toolsを2020年初に買っていた。BPFまわりで活発に活動しているBrendan Gregg氏の本だ。めちゃくちゃ分厚い。あと残念な告白をすると、通読はできていません。</p>
<p>買って読んでみてわかったのだが、ある意味では膨大なレシピブックという側面があり、こういうことをしたいならこうする、といったコードサンプル、事例がふんだんに盛り込まれていて、扱われているネタは広範なんだけど、悪くいえば散漫でもあり、なんか読みづらい。序盤の数章は読んで面白かったんだけどね。karinoさんも、Brendan Greggの他の本への感想に似たようなことを書いていたので、これはこの人の方向性ということなんだろう。悪い本ではぜんぜんないというか、持っていて良い本だとは思うけれど。</p>
<h2 id="並列コンピュータ----非定量的アプローチhttpswwwohmshacojpbook9784274225710"><a href="https://www.ohmsha.co.jp/book/9784274225710/">並列コンピュータ &ndash; 非定量的アプローチ</a></h2>
<p>出身大学の天野英晴先生が書いた日本語の本。これは面白く読んだ。並列コンピュータの構成方法についての細かい話がいろいろわかりやすくまとまっている。たとえばキャッシュコヒーレンシや共有メモリモデル、クラスタマシンなどなど。まえがきによれば過去あった本の再編とのことだけど、最後にGPUなどのアクセラレータを扱った章も書き足されている。こういう分野は普段の仕事と縁遠いから、それゆえに読んでいて面白い。</p>
<p>なお、タイトルはヘネパタ（『コンピュータ・アーキテクチャ　定量的アプローチ』）をもじったものだけど、そんなヘネパタみたいなことは普通はできないし、複雑化したコンピュータを定量的に理解するのもだんだん難しくなってきているから……といった話がまえがきに書いてあるのがわりと面白い。これは出版社のサイトの「試し読み」から一読できるので興味があればどうぞ。</p>
<h2 id="reverse-engineering-the-source-code-of-the-biontechpfizer-sars-cov-2-vaccinehttpsberthubeuarticlespostsreverse-engineering-source-code-of-the-biontech-pfizer-vaccine"><a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">Reverse Engineering the source code of the BioNTech/Pfizer SARS-CoV-2 Vaccine</a></h2>
<p>そういえば年末に読んだこれはけっこう面白かった。新型コロナウィルスのワクチンの「ソースコード」を解説する記事。DNAの各パートについて、それぞれがどういう意味なのかを説明してくれている。この記事にかぎらず解説記事というのはいくつもあるものだと思うけれど、この記事はプログラマによる解説記事なのでプログラマが読んでわかりやすいたとえが入っているのが特徴。これを読んだ後にほかの解説記事を読んだら理解しやすくなったように感じた（気のせいだと思うけど）。日本語翻訳も上がっていて、そちらも良いけれどこのプログラマ向けっぽい感じが少し薄れている気がする。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
自分も BPF Performance Tools 読みました。
Systems Performance もそうですが、
この人の「持っている知識の確かさ」と「著者としてのいまいちさ」のギャップはなんなんでしょうね・・・。
</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: ハイテクしごと</title>
      <link>https://messagepassing.github.io/006-hitech/02-morrita/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/02-morrita/</guid>
      <description>大企業におけるハイテク私感 大企業下っ端なので全然ハイテクとかしてない。 ここでいうハイテクは、それなりに (CS 的な) 難しさのある、それなりの規模のコードという風に解釈している。
ある程度成熟した大企業だと、インフラ部門とかリサーチ部門とかがあってハイテクなものを専業で作っている。 なのでハイテク指向な人はそういう部門ではたらく傾向がある。
一方のアプリやサービス部門の人は、実製品開発が好きだからそういうチームにいる。 だから個人の性向としてハイテクより仕事を片付けるのを優先しがち。 それを退屈に感じたこともあったけれど、最近は締切を守ってモノを出す姿勢も大事だなと考えるようになった。 なぜならちゃんとモノが出ていくから。大企業、野心的すぎて完成する前にお蔵入りしてしまうプロジェクトもよくあるね。
専業のインフラ部門とは別に、巨大製品チームはインフラ部門やリサーチ部門相当を内部で抱えている。 たとえば YouTube は Procella というデータベースを内製しているらしい。わけがわからない。 製品内ハイテクはインフラやリサーチ発のテクノロジよりドメイン依存で、身近な面もある。 とはいえ巨大製品のハイテクは黎明期の発明の二周目三周目なことが多く、個人作品というより組織戦の色が濃い。
そんなアプリ・サービス部門でもバーンと一周目のハイテクをキメる人はたまにいて、 そういう野心がある人はだいたい出世して TL とかになる。そして二周目三周目の製品内ハイテクプロジェクトを主導していく。
つまり実勢品でハイテクをキメられるくらいならもっと出世してるっつーの！（突然の八つ当たり。） 下っ端の実力は推して知るべし。
傍から見ていると、小さいチームより成功してある程度規模のあるチームの方がハイテクの機会は多いように見える。 というのも小さいチームは技術的障壁以前に product-market fit みたいので苦戦することが多いので、 よくいえばスタートアップ的に動くものを優先しがちだから。成功して、はじめてハイテクの必要性が生まれるのではないか。 あと勢い良く伸びている製品の方が予算の融通が効く面もある気がする。やんちゃする余裕がある。
テクノロジーありきの製品も色々あるけど、 というか自分が仕事で手伝っているのもそうした製品の一つだけれど、コアテクノロジは先に書いたようなリサーチ部門や、 リサーチ部門ではないにせよリサーチ的な性格のチームとから出てくることが多い。 たとえば実験的な OS を作ってしまうチームとか。
零細企業でのハイテク 自分が零細企業勤務だった十年前のことを考えると、その会社はなぜか自社ミドルウェア用に公開鍵暗号を実装していた。 細かいことは忘れたが他にも似たレベルの再発明ハイテクがもう一つ二つあったと思う。 再発明に見合う品質やユニークさはなかったと思うが、組織の未熟さゆえにこれらのハイテクは生まれることができた。 要するに良くない判断を止める人がいなかったからやんちゃできた。こういうのは零細、中小企業だと割とよくある話だと思う。
製品の要請から意味のあるハイテクが生まれることは、小さい企業でもあるだろう。 インフラ部門やリサーチ部門がないぶん製品チームが腕まくりしてハイテクに挑む。 karino2 はきっとこのケースに近いのでしょう。
企業規模とは無関係に、ハイテク自作の文脈でオープンソースの影響は無視できないと思う。 よいニッチを見つけないとオープンソースの既存実装に勝てない。 自分で何か書くと言い張るのは、昔よりやや難しい。 オープンソースの隆盛にあわせ、世の中全体としてハイテクを自作する割合は減っているんじゃないかな。 ソフトウェア産業は拡大してるから絶対数は増えてるかもしれないけれど。
ベテランの気晴らしハイテク 権力のある古株のエンジニアが、仕事に飽きて気晴らしにハイテクをはじめてしまうことがある。 そんなハイテクは難しくて新しいことをすること自体が動機になりがちで、製品の要請に基づかないことが多い。 その一方で権力者の仕事だけに割と影響範囲もでかくなりがち。
森田は過去に何度もこの気晴らしハイテクを目撃しており、そのせいで迷惑したことも一度ではない。 そのせいかこうしたプロジェクトには強い嫌悪があり、 反動でなるべく地味に堅実な成果を出したいバイアスがある。
とはいえ退屈していたベテランが考え事をしていたら製品の隠れた要請に気づいてしまうこともあるわけで、 あるハイテクプロジェクトが製品の要請なのか単なる気晴らしなのかは、最初ははっきりしない。 自分が「それ趣味プロジェクトでしょ」と斜に構えていたらいい成果を出したベテラン発のハイテクも何度か目にしてきた。
小粒な気晴らし 自分も今のチームに異動して三年。社歴に至っては十年。だいぶ飽きている。 あーなんか気の利いたコードを書きたいなーと思いつつ地味にバグをなおして暮らしている。
が、ふとした思いつきから年末に仕事でプログラミング言語を実装した。 三日で書いて二千行みたいな超小粒言語で、仕様も大学生の宿題みたいに素朴なもの。 GC も Java まかせで、ハイテクとは程遠い。 ただ「仕事でプログラミング言語を書く」というハッタリじみた響きが気に入っている。</description>
      <content:encoded><![CDATA[<h2 id="大企業におけるハイテク私感">大企業におけるハイテク私感</h2>
<p>大企業下っ端なので全然ハイテクとかしてない。
ここでいうハイテクは、それなりに (CS 的な) 難しさのある、それなりの規模のコードという風に解釈している。</p>
<p>ある程度成熟した大企業だと、インフラ部門とかリサーチ部門とかがあってハイテクなものを専業で作っている。
なのでハイテク指向な人はそういう部門ではたらく傾向がある。</p>
<p>一方のアプリやサービス部門の人は、実製品開発が好きだからそういうチームにいる。
だから個人の性向としてハイテクより仕事を片付けるのを優先しがち。
それを退屈に感じたこともあったけれど、最近は締切を守ってモノを出す姿勢も大事だなと考えるようになった。
なぜならちゃんとモノが出ていくから。大企業、野心的すぎて完成する前にお蔵入りしてしまうプロジェクトもよくあるね。</p>
<p>専業のインフラ部門とは別に、巨大製品チームはインフラ部門やリサーチ部門相当を内部で抱えている。
たとえば YouTube は <a href="https://research.google/pubs/pub48388/">Procella</a>
というデータベースを内製しているらしい。わけがわからない。
製品内ハイテクはインフラやリサーチ発のテクノロジよりドメイン依存で、身近な面もある。
とはいえ巨大製品のハイテクは黎明期の発明の二周目三周目なことが多く、個人作品というより組織戦の色が濃い。</p>
<p>そんなアプリ・サービス部門でもバーンと一周目のハイテクをキメる人はたまにいて、
そういう野心がある人はだいたい出世して TL とかになる。そして二周目三周目の製品内ハイテクプロジェクトを主導していく。</p>
<p>つまり実勢品でハイテクをキメられるくらいならもっと出世してるっつーの！（突然の八つ当たり。）
下っ端の実力は推して知るべし。</p>
<p>傍から見ていると、小さいチームより成功してある程度規模のあるチームの方がハイテクの機会は多いように見える。
というのも小さいチームは技術的障壁以前に product-market fit みたいので苦戦することが多いので、
よくいえばスタートアップ的に動くものを優先しがちだから。成功して、はじめてハイテクの必要性が生まれるのではないか。
あと勢い良く伸びている製品の方が予算の融通が効く面もある気がする。やんちゃする余裕がある。</p>
<p>テクノロジーありきの製品も<a href="https://techcrunch.com/2019/12/05/googles-a-i-powered-voice-recorder-and-transcription-app-comes-to-older-pixel-phones/">色々</a>あるけど、
というか自分が仕事で手伝っているのもそうした製品の一つだけれど、コアテクノロジは先に書いたようなリサーチ部門や、
リサーチ部門ではないにせよリサーチ的な性格のチームとから出てくることが多い。
たとえば<a href="https://fuchsia.dev/">実験的な OS</a> を作ってしまうチームとか。</p>
<h2 id="零細企業でのハイテク">零細企業でのハイテク</h2>
<p>自分が零細企業勤務だった十年前のことを考えると、その会社はなぜか自社ミドルウェア用に公開鍵暗号を実装していた。
細かいことは忘れたが他にも似たレベルの再発明ハイテクがもう一つ二つあったと思う。
再発明に見合う品質やユニークさはなかったと思うが、組織の未熟さゆえにこれらのハイテクは生まれることができた。
要するに良くない判断を止める人がいなかったからやんちゃできた。こういうのは零細、中小企業だと割とよくある話だと思う。</p>
<p>製品の要請から意味のあるハイテクが生まれることは、小さい企業でもあるだろう。
インフラ部門やリサーチ部門がないぶん製品チームが腕まくりしてハイテクに挑む。
karino2 はきっとこのケースに近いのでしょう。</p>
<p>企業規模とは無関係に、ハイテク自作の文脈でオープンソースの影響は無視できないと思う。
よいニッチを見つけないとオープンソースの既存実装に勝てない。
自分で何か書くと言い張るのは、昔よりやや難しい。
オープンソースの隆盛にあわせ、世の中全体としてハイテクを自作する割合は減っているんじゃないかな。
ソフトウェア産業は拡大してるから絶対数は増えてるかもしれないけれど。</p>
<h2 id="ベテランの気晴らしハイテク">ベテランの気晴らしハイテク</h2>
<p>権力のある古株のエンジニアが、仕事に飽きて気晴らしにハイテクをはじめてしまうことがある。
そんなハイテクは難しくて新しいことをすること自体が動機になりがちで、製品の要請に基づかないことが多い。
その一方で権力者の仕事だけに割と影響範囲もでかくなりがち。</p>
<p>森田は過去に何度もこの気晴らしハイテクを目撃しており、そのせいで迷惑したことも一度ではない。
そのせいかこうしたプロジェクトには強い嫌悪があり、
反動でなるべく地味に堅実な成果を出したいバイアスがある。</p>
<p>とはいえ退屈していたベテランが考え事をしていたら製品の隠れた要請に気づいてしまうこともあるわけで、
あるハイテクプロジェクトが製品の要請なのか単なる気晴らしなのかは、最初ははっきりしない。
自分が「それ趣味プロジェクトでしょ」と斜に構えていたらいい成果を出したベテラン発のハイテクも何度か目にしてきた。</p>
<h2 id="小粒な気晴らし">小粒な気晴らし</h2>
<p>自分も今のチームに異動して三年。社歴に至っては十年。だいぶ飽きている。
あーなんか気の利いたコードを書きたいなーと思いつつ地味にバグをなおして暮らしている。</p>
<p>が、ふとした思いつきから年末に仕事でプログラミング言語を実装した。
三日で書いて二千行みたいな超小粒言語で、仕様も大学生の宿題みたいに素朴なもの。
GC も Java まかせで、ハイテクとは程遠い。
ただ「仕事でプログラミング言語を書く」というハッタリじみた響きが気に入っている。</p>
<p>これは性能試験のためにアプリの動作を自動化するミニ言語で、Android アプリの中で動く。
テスト用なので出荷バージョンには入っていない。</p>
<p>Android アプリの自動化は <a href="https://source.android.com/compatibility/tests/development/instrumentation">instrumentation</a>
という仕組みを使うのが定番だけど、性能テストの目的だと侵入的すぎて都合が悪い。
自分のいるチームではかわりにホスト側で動く Python のフレームワーク <a href="https://github.com/google/mobly">Mobly</a> を使っている。
つまり ADB 越しに自動化をする。</p>
<p>これは悪くはないが、際どいタイミングの操作を書くのが難しい、というかできない。
たとえばアプリを起動してビューファインダーが表示された瞬間にシャッターボタンを押す、みたいなコードは書けない。
ADB 越しでは「ビューファインダーが表示された瞬間」を検知できないし、なんとかして polling するにしても負荷やレイテンシが犠牲になる。</p>
<p>自分はもともと自動化のロジックを Java でハードコードすれば良いと思っていたが、別の同僚が「(組み込み言語であるところの) <a href="http://www.lua.org/">Lua</a> を使えばよくね？」と言い出した。自分も Lua はさわったことがあり、悪くないアイデアに思えた。
とはいえ Java で書かれたアプリの自動化のために C で書かれた Lua を使うのはインテグレーションが億劫そうだ。
世の中には <a href="https://github.com/luaj/luaj">luaj</a> という Lua の Java 実装があるのでこれを使えばいいとも思ったが、
社内のアーカイブを検索すると過去に他の製品で行われた同じ試みが安定性の問題から頓挫した事例が見つかった。</p>
<p>一歩さがると、自分の目的には Lua すら大げさすぎる。ちょっとした制御構造があればいい。
自動化スクリプトの長さもせいせい 10 行くらいなので、性能も必要ない。
奇しくも年末にチームの hakcathon があり、良い機会だからと書いてみたら割とあっさり動くものが出来た。
コードサイズも 2000 行。Luaj の数万行と比べ一桁小さい。
え、言語とか作っちゃうの・・・と釘を刺す（まっとうな）同僚もいたけれど、コードサイズを見せたら納得してくれた。</p>
<p>さっそくいくつかのシナリオを自動化してみると早速アプリのバグが見つかった。手応えあり。</p>
<p>三ヶ月かけて書いた一万行のデータフロー DSL とくらべると格段にしょぼいけれども、
先に書いた大企業アプリ部門したっぱ勤めの現実を踏まえると自分の「ハイテク」はこんなもんかなと思う。
すくなくとも有閑ベテランの迷惑ハイテクではない・・・とおもってる。
なおこんなしょぼい成果だと迷惑もないけど出世の足しにもならない。残念。</p>
<p>そういえば一昨年くらいにやった <a href="https://notes.dodgson.org/android/ioopts-01-pinninig/">profile guided pinning</a> も自分の水準ではギリギリハイテクかな・・・
とおもったけど一週間くらいでやった雑な仕事なうえに Python と C++ それぞれ 100 行みたいな規模。ぱっとしない・・・。
いちおう自分なりにがんばった仕事なのでひっそり自慢させていただきます。</p>
<p>ハイテク企業で組織戦を先導してそうな<a href="/006-hitech/03-shinh/">はまじさん</a>どうですか。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>そういえばふと思い出した、森田が karino2 と同じ職場で働いていた大昔のこと。
隣のチームにいた karino2 は C 言語で書かれた自社製品コードをパースしてへぼいツールチェイン向けのコードに書き換える C の transpiler を Ruby 実装し、それがちゃんと動く前に転職してしまった。
その保守を押し付けられた森田はメモリ不足や実行速度の遅さや挙動の不完全さをに苦しめられ、しかし直し方もわからず、
残業とかをする羽目になったのだった。</p>
<p>今思えばあれは一種の気晴らしハイテクだった気がするが、書いたのは若者（当時）だった。
気晴らしの文脈でベテランだけを責めるのはフェアでないかもしれない。
森田のアンチハイテクバイアスが芽生えた瞬間だったのは間違いない。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>くっ、これだから官僚的大企業社員は…嘘です、ごめんなさい。
まさか20代のやらかしを15年越しに問われるとは(^^;</p>
<p>もはや全く意味の無い言い訳をさせてもらうと、あれは普通に実現出来る事を趣味に走って複雑にした、
というよりは、もともとあの環境への移植は無理だと断るべき所を無理やり力づくで実現してしまった筋の悪さが根底にあると思う。
当時の自分のトランスパイラの実装力の低さがそこに重なって負の遺産にしてしまっていた気がする。</p>
<p>ハイテクに舵を切る時に、やらかしなのか素晴らしい何かが生まれるかの違いは難しいよなぁ。
Linusなら山にこもってgitが出来る訳だが、なかなかLinusにはなれないやね。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>shinh</div>
<div class='message-body'>
<p>そうそう、はしゃいだルーキーの背伸び気味オーバーエンジニアリングみたいなハイテクもありますよね。実際タイミングが合致すれば大成功したりもするので悪いとも限らないんじゃないですかね。あまり知らずに書きますけど、例えば <a href="https://msgpack.org/">MessagePack</a> とかそういう側面あるんじゃないかな……？（当時 RPC のシリアライズフォーマット作りたい、って目を輝かせてる作者と <a href="https://developers.google.com/protocol-buffers">protobuf</a> について話した思い出があるので、そこからの想像）</p>
<p>自分も相対的な基準で見ると一番ハイテクを指向していたのはバイトの時で、知ってるものはなんでも使おうという気概で、迷惑なヤツでしたね……他の人にわけわからないものを作ればジョブセキュリティが保てるという理解を得ることになったので結果オーライ。</p>

</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>ハイテクしごと</title>
      <link>https://messagepassing.github.io/006-hitech/01-karino2/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/01-karino2/</guid>
      <description>お仕事で計算グラフなコードを書いた 先日、仕事で計算グラフを構築して変形して実行するようなコードを書く必要があって、 そんな類のライブラリを書いて機能を実装した。コアの部分で1万行くらい。まぁまぁ大変で三ヶ月くらい掛かった。
DSLで計算グラフを構築し、 それをいろいろと操作し、最後に生成されたIRをなんらかの形で実行する。 ここ数年、こうした形で新しいものがいろいろ生まれているように思う。 古くはLINQ、より最近だとTensorFlowとかHalideとか。 あまり詳しくないが分散ビルドなどもこうした形式だとか。
そういう訳で近年この手の、実際にコードと実行の間に一旦シンボリックなグラフを置いて、 それをいろいろ操作する事で、そのまま実行するのでは得られない付加機能をつけるのは一般的になっている気はしていた。
でもそれを自分で実装するのは今回初めてで、おぉ、これが噂のあれかという気分。
ハイテクな物を実装するレア度とチャンス こういう流行りのハイテク技術を仕事で実装する機会というのはどの位レアなものだろうか？ バグを修正したり普通の機能を足すような「日常のタスク」よりはだいぶレアな気がする。 でも、ハイテクなプロダクトを売りにしていこうと思えば一つや二つは含まれる事もままある訳で、 それを実現するのが我らであることを思えばそこまでレアでも無いのでは無いか。 仕事をしていれば2〜3年に一回くらいは実装して良いような機会に出会う程度のレアさな気もする。（本当だろうか？）
一方で実装しても良い機会にあっても、別に実装せず見過ごす事も出来る。 仕事のタスクとして現れるハイテクな可能性には、だいたい迂回してもっと普通に泥臭く実装できる方法がある。 LevelDBを新しく作らずにSQLiteを使う事も出来る。 TensorFlowを実装せずにOpenMPとCUDAで手書き実装していく事だって出来る。 機会がある事と、その機会に直面した時にハイテクの実装に踏み切る事はイコールでは無い、というか見送る事も多い気はする。 踏み切るかかどうかは立場や環境にも依る。
チームの規模とか会社の規模とか 大規模チームだと、本当に一握りの中心に居るエースしかそういうのにチャレンジしない気がする。 別に末端のプログラマもガンガンチャレンジしていっても良い気もするが、あんまり見かけない。
大規模チームでは一部の人だけかもしれないが、大企業という枠ならどうだろう？ 大企業でも小さなプロジェクトの立ち上げなら割と自分でいろいろ実装する機会はあるので、 普通のプログラマでもそれなりにハイテク実装する機会もあるのかしら？「普通のプログラマ」の定義も難しい所だが。
小規模のスタートアップなら、テクノロジーを売りにするならそういうのには挑みそうな気もするが、、、挑むかな？ 口先だけではやってるとは言うだろうが、本当にやってるのがどのくらいいるかは良く分からない。 失敗するとそこで会社は終わりなので、結構勇気はいる。 今回自分が実装に踏み切る時も、頓挫したらごめんなさいねと説明した上で始めた。 気軽に失敗させてくれるのはCTOの器かもしれない。
何がハイテクなのか 完全に主観の話になりますが。
例えばコンビネータ型のライブラリを自分で作るくらいなら、目新しい応用例なら自分的には日常からはずれたハイテクの範囲に入る気がする。 でも、本質的にパーサーだが微妙にテキストじゃない、みたいな、既存のパーサーコンビネータそのまんまの用途の場合はハイテクという気もしない。 割と新しい用途にコンビネータ型の解決を見出す所にハイテク感を感じる訳だ。 余談だが、今回自分はコンビネータ型のライブラリでクールに作れる所を気づかずに手実装してしまい、後で気づいた。悔しい。 みんなはどのくらいコンビネータ型のライブラリを仕事で自作する機会ありますか？＞all
FollyのFutureを参考に自分らの環境でFuture-Promiseを実装するくらいではハイテクとは認めない。 C++だとそれなりにenable_ifとか必要だけれど。 通常のタスクの中の普通のライブラリ作成くらいだとハイテク感は感じないよなぁ。FutureをAtomicだけで実装するとかかなり大変だけどね。 大変さとハイテク感はまたちょっと違うんだろうな。かっこよさが無いとダメな気がする。 Futureにハイテク感を感じないのはいまさらに感じるからかもしれない。
なんとなくだが、自分の中ではBerkeleyDBのような物を再実装するのはハイテク枠に入っている。 再実装自体はどうという事も無いのだけど、わざわざそんな物を再実装するくらいの何かを作っているというのはハイテクな気がする。どうだろう？
仕事でハイテクな何か実装する機会とか、ハイテクとはそもそもどんなものかとか、その辺どうっすか？＞ハイテクに一家言ありそうなmorritaさん</description>
      <content:encoded><![CDATA[<h2 id="お仕事で計算グラフなコードを書いた">お仕事で計算グラフなコードを書いた</h2>
<p>先日、仕事で計算グラフを構築して変形して実行するようなコードを書く必要があって、
そんな類のライブラリを書いて機能を実装した。コアの部分で1万行くらい。まぁまぁ大変で三ヶ月くらい掛かった。</p>
<p>DSLで計算グラフを構築し、
それをいろいろと操作し、最後に生成されたIRをなんらかの形で実行する。
ここ数年、こうした形で新しいものがいろいろ生まれているように思う。
古くはLINQ、より最近だとTensorFlowとかHalideとか。
あまり詳しくないが分散ビルドなどもこうした形式だとか。</p>
<p>そういう訳で近年この手の、実際にコードと実行の間に一旦シンボリックなグラフを置いて、
それをいろいろ操作する事で、そのまま実行するのでは得られない付加機能をつけるのは一般的になっている気はしていた。</p>
<p>でもそれを自分で実装するのは今回初めてで、おぉ、これが噂のあれかという気分。</p>
<h2 id="ハイテクな物を実装するレア度とチャンス">ハイテクな物を実装するレア度とチャンス</h2>
<p>こういう流行りのハイテク技術を仕事で実装する機会というのはどの位レアなものだろうか？
バグを修正したり普通の機能を足すような「日常のタスク」よりはだいぶレアな気がする。
でも、ハイテクなプロダクトを売りにしていこうと思えば一つや二つは含まれる事もままある訳で、
それを実現するのが我らであることを思えばそこまでレアでも無いのでは無いか。
仕事をしていれば2〜3年に一回くらいは実装して良いような機会に出会う程度のレアさな気もする。（本当だろうか？）</p>
<p>一方で実装しても良い機会にあっても、別に実装せず見過ごす事も出来る。
仕事のタスクとして現れるハイテクな可能性には、だいたい迂回してもっと普通に泥臭く実装できる方法がある。
LevelDBを新しく作らずにSQLiteを使う事も出来る。
TensorFlowを実装せずにOpenMPとCUDAで手書き実装していく事だって出来る。
機会がある事と、その機会に直面した時にハイテクの実装に踏み切る事はイコールでは無い、というか見送る事も多い気はする。
踏み切るかかどうかは立場や環境にも依る。</p>
<h2 id="チームの規模とか会社の規模とか">チームの規模とか会社の規模とか</h2>
<p>大規模チームだと、本当に一握りの中心に居るエースしかそういうのにチャレンジしない気がする。
別に末端のプログラマもガンガンチャレンジしていっても良い気もするが、あんまり見かけない。</p>
<p>大規模チームでは一部の人だけかもしれないが、大企業という枠ならどうだろう？
大企業でも小さなプロジェクトの立ち上げなら割と自分でいろいろ実装する機会はあるので、
普通のプログラマでもそれなりにハイテク実装する機会もあるのかしら？「普通のプログラマ」の定義も難しい所だが。</p>
<p>小規模のスタートアップなら、テクノロジーを売りにするならそういうのには挑みそうな気もするが、、、挑むかな？
口先だけではやってるとは言うだろうが、本当にやってるのがどのくらいいるかは良く分からない。
失敗するとそこで会社は終わりなので、結構勇気はいる。
今回自分が実装に踏み切る時も、頓挫したらごめんなさいねと説明した上で始めた。
気軽に失敗させてくれるのはCTOの器かもしれない。</p>
<h2 id="何がハイテクなのか">何がハイテクなのか</h2>
<p>完全に主観の話になりますが。</p>
<p>例えばコンビネータ型のライブラリを自分で作るくらいなら、目新しい応用例なら自分的には日常からはずれたハイテクの範囲に入る気がする。
でも、本質的にパーサーだが微妙にテキストじゃない、みたいな、既存のパーサーコンビネータそのまんまの用途の場合はハイテクという気もしない。
割と新しい用途にコンビネータ型の解決を見出す所にハイテク感を感じる訳だ。
余談だが、今回自分はコンビネータ型のライブラリでクールに作れる所を気づかずに手実装してしまい、後で気づいた。悔しい。
みんなはどのくらいコンビネータ型のライブラリを仕事で自作する機会ありますか？＞all</p>
<p>FollyのFutureを参考に自分らの環境でFuture-Promiseを実装するくらいではハイテクとは認めない。
C++だとそれなりにenable_ifとか必要だけれど。
通常のタスクの中の普通のライブラリ作成くらいだとハイテク感は感じないよなぁ。FutureをAtomicだけで実装するとかかなり大変だけどね。
大変さとハイテク感はまたちょっと違うんだろうな。かっこよさが無いとダメな気がする。
Futureにハイテク感を感じないのはいまさらに感じるからかもしれない。</p>
<p>なんとなくだが、自分の中ではBerkeleyDBのような物を再実装するのはハイテク枠に入っている。
再実装自体はどうという事も無いのだけど、わざわざそんな物を再実装するくらいの何かを作っているというのはハイテクな気がする。どうだろう？</p>
<p>仕事でハイテクな何か実装する機会とか、ハイテクとはそもそもどんなものかとか、その辺どうっすか？＞ハイテクに一家言ありそうな<a href="/006-hitech/02-morrita/">morritaさん</a></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: 今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/02-karino2/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/02-karino2/</guid>
      <description>今年はあんまり読んでないかと思っていたが、見直してみると数は多いので代表的なのだけ。
System Performance Brendan Greggの本、これは仕事をはじめる前の無職の頃に買って読んでいた本。 森田さんが良くBrendan Greggの言及をするので自分もdtraceって奴をちゃんと勉強しておくか〜、と思って買った。能書きが多くて同じようなことを延々と繰り返してて辛い本だが、レシピ集的には素晴らしい、という二面性のある、評価の難しい本。当時の読書記録はこちら。 読書記録: System Performance
なお、パフォーマンスつながりでiOSの事情を知る為に iOS and macOS Performance Tuning: Cocoa, Cocoa Touch, Objective-C, and Swift も読んだ。 そんなに深い話では無いが、普通にiOS上で使えるツール等が書いてあってiOSの基本的な話題もあって悪くはない。 ちなみにiOSではdtraceを使えそうな事が書いてあったが、たぶん使えないのでは？でもiOSにトレーシング系のプロファイラが無いというのも信じがたい？知っている人居たら教えて下さい。
C++の本 今年はC++の本をいろいろ読んだ。
 The C++ Programming Language 4th edition Effective Modern C++  上記２冊の当時の感想 最近読んだC++の本2冊の感想   Modern C++ Programming Cookbook  この本はいまいち。当時の感想 書籍: Modern C++ Programming Cookbook    一番上のStroustrup本は業務でも日常的に（一日に数回くらい）参照するくらいには良く使ってる。 でもこの本がC++ 11までしか扱っていない、というのが、 現状のC++を学ぶ時の困った状況を表している気がする。せめてC++14に対応した版が欲しいなぁ… 上２冊は良い本だとは思うけれど、これだけでは言語をとりまく状況の複雑さを思うと、全然足りないなぁ、とも思ってしまう。 Stroustrup本は1279ページ（！）もあるのに足りないとか言われても…という気もするが。
* OS Internals iOSとOS Xのインターナルの本。何故か物理本でしか売ってない上に上記のサイトがどう買ったらいいか謎が多く、Paypalでお金を振り込んでメールをする、みたいな不安のあるフローで、HTTPSじゃないし怪しさ爆裂。でもちゃんと届いた。
期待よりもOS Xの話が多くてちょっとがっかりだが、InternalはOS Xの方がわかるんだろうねぇ。 やっぱコアの部分はAndroidの方が良く分かるので勉強し甲斐は向こうの方があるよなぁ。</description>
      <content:encoded><![CDATA[<p>今年はあんまり読んでないかと思っていたが、見直してみると数は多いので代表的なのだけ。</p>
<h2 id="system-performancehttpswwwamazoncojpdpb00flyu9t2"><a href="https://www.amazon.co.jp/dp/B00FLYU9T2/">System Performance</a></h2>
<p>Brendan Greggの本、これは仕事をはじめる前の無職の頃に買って読んでいた本。
森田さんが良くBrendan Greggの言及をするので自分もdtraceって奴をちゃんと勉強しておくか〜、と思って買った。能書きが多くて同じようなことを延々と繰り返してて辛い本だが、レシピ集的には素晴らしい、という二面性のある、評価の難しい本。当時の読書記録はこちら。 <a href="https://karino2.github.io/2020/01/29/163921.html">読書記録: System Performance</a></p>
<p>なお、パフォーマンスつながりでiOSの事情を知る為に <a href="https://www.amazon.co.jp/dp/B06X9Z79C7/">iOS and macOS Performance Tuning: Cocoa, Cocoa Touch, Objective-C, and Swift</a> も読んだ。
そんなに深い話では無いが、普通にiOS上で使えるツール等が書いてあってiOSの基本的な話題もあって悪くはない。
ちなみにiOSではdtraceを使えそうな事が書いてあったが、たぶん使えないのでは？でもiOSにトレーシング系のプロファイラが無いというのも信じがたい？知っている人居たら教えて下さい。</p>
<h2 id="cの本">C++の本</h2>
<p>今年はC++の本をいろいろ読んだ。</p>
<ul>
<li><a href="https://www.amazon.co.jp/dp/0321563840/">The C++ Programming Language 4th edition</a></li>
<li><a href="https://www.amazon.co.jp/dp/1491903996/">Effective Modern C++</a>
<ul>
<li>上記２冊の当時の感想 <a href="https://karino2.github.io/2020/03/31/cpp_book.html">最近読んだC++の本2冊の感想</a></li>
</ul>
</li>
<li><a href="https://www.amazon.co.jp/dp/1786465183/">Modern C++ Programming Cookbook</a>
<ul>
<li>この本はいまいち。当時の感想 <a href="https://karino2.github.io/2020/04/19/232920.html">書籍: Modern C++ Programming Cookbook</a></li>
</ul>
</li>
</ul>
<p>一番上のStroustrup本は業務でも日常的に（一日に数回くらい）参照するくらいには良く使ってる。
でもこの本がC++ 11までしか扱っていない、というのが、
現状のC++を学ぶ時の困った状況を表している気がする。せめてC++14に対応した版が欲しいなぁ…
上２冊は良い本だとは思うけれど、これだけでは言語をとりまく状況の複雑さを思うと、全然足りないなぁ、とも思ってしまう。
Stroustrup本は1279ページ（！）もあるのに足りないとか言われても…という気もするが。</p>
<h2 id="-os-internalshttpnewosxbookcomindexphp"><a href="http://newosxbook.com/index.php">* OS Internals</a></h2>
<p>iOSとOS Xのインターナルの本。何故か物理本でしか売ってない上に上記のサイトがどう買ったらいいか謎が多く、Paypalでお金を振り込んでメールをする、みたいな不安のあるフローで、HTTPSじゃないし怪しさ爆裂。でもちゃんと届いた。</p>
<p>期待よりもOS Xの話が多くてちょっとがっかりだが、InternalはOS Xの方がわかるんだろうねぇ。
やっぱコアの部分はAndroidの方が良く分かるので勉強し甲斐は向こうの方があるよなぁ。</p>
<p>トピックの提示とヘッダファイルの中身くらいまでは書いてあるのだが、内部のメカニズムみたいなのの解説がいまいちな印象。目次とかで判断すると良さそうに見えるんだけど、いざ読んでいくと肝心の知りたい所の手前で止まっている事が多い。
例えばメモリ不足でプロセスが殺される条件ではメモリ確保だけじゃなくてアドレスのbookでも別のしきい値があるのだが、そういう事情は本からは分からず、実機でぶつかって調べて初めて理解出来た。</p>
<p>自分はiOS素人だったので、トピックの提示はそれなりに全体像を掴む役には立ったけれど、もっとしっかりした本を誰か書いて、とは思う。</p>
<p>次にブログとか。</p>
<h2 id="futures-for-c11-at-facebookhttpsengineeringfbcom20150619developer-toolsfutures-for-c-11-at-facebook"><a href="https://engineering.fb.com/2015/06/19/developer-tools/futures-for-c-11-at-facebook/">Futures for C++11 at Facebook</a></h2>
<p>FollyのFutureの話。<a href="https://github.com/facebook/folly/blob/master/folly/docs/Futures.md">Folly公式のFutures.md</a>も必読。
Facebookの奴らは分かってるよなぁ。</p>
<p>ようするに、FinangleのFuture(参考: <a href="https://twitter.github.io/finagle/guide/Futures.html">Concurrent Programming with Futures</a>、こちらも必読)のC++版なのだが、
こういうのをちゃんと理解した上でC++ではどうなるか、というコードになっていて素晴らしい。
STLの<a href="https://en.cppreference.com/w/cpp/thread/future">std::future</a>に爪の垢を煎じて飲ませたい。</p>
<p>FollyはFutureに限らず、いかにもC++14の模範的なコードで、現代のC++の書き方を勉強する上でも良いお手本になる。</p>
<h2 id="design-with-typesシリーズf-for-fun-and-profithttpsswlaschingitbooksiofsharpforfunandprofitcontentseriesdesigning-with-typeshtml"><a href="https://swlaschin.gitbooks.io/fsharpforfunandprofit/content/series/designing-with-types.html">Design with typesシリーズ(F# for Fun and Profit)</a></h2>
<p>F# for Fun and Profitは素晴らしいブログのシリーズなのだが、一番のおすすめは上記のDesign with typesシリーズ。F#的なコードの書き方がすごく良く分かって良い。
やっぱalgebraic typeとパターンマッチの組み合わせはいいよなぁ。
言語の良さはこう語りたいものだ。</p>
<h2 id="最近の技術文書とかbooxとかの話">最近の技術文書とかBOOXとかの話</h2>
<p>今年はMetalとかSwfit周辺とかFollyとか、ライブラリやフレームワークを調べる事が多かった。
そういうのはだいたい公式のドキュメントを読む事になった。
最近は、善悪は別にして、その手のものは本よりも公式のWeb文書で学ぶものだと思う。</p>
<p>という事でwebの技術文書を読む環境を改善しよう、と思って <a href="https://sktgroup.co.jp/boox-note3/">BOOX Note3</a> を買った。
「PDFの論文を読むために大きなe-inkデバイスが欲しい」は良く聞く話だが、
Webの技術文書の為にe-inkデバイスってあまり聞かない気がする。
でも自分的にはすごく良かった。</p>
<p>何故かしらないけれど、「Webを見ている」というよりも、「Webの文書を印刷して持ち歩いている」ような感覚になるんですよねぇ。Webから切り離して持ち歩いている感覚。
あと読む時にデバイスを変えるというのもパブロフの犬的な集中のスイッチみたくなっている気がする。</p>
<p>という事で自分的にはBOOX Note3でWebの技術文書の時代ですよ！という気分なのだけど、
reMarkable 2買った <a href="/004-whatiread/03-jmuk/">jmuk</a> 的には時代はPDFなんですか？Webの技術文書を読む事の方が多く無い？</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
最近<a href="https://news.ycombinator.com/item?id=25609669">たまたま知った</a>んですが、
&ldquo;F# for Fun and Profit&rdquo; の作者は書籍 <a href="https://pragprog.com/titles/swdddf/domain-modeling-made-functional/">Domain Modeling Made Functional</a> を書いた人なんですね。
気になりつつ F# かーとおもってスルーしてましたが、興味が湧きました。
</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
自分もその本興味あるので、もし読んだら感想聞かせてください。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re^3: テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/04-karino2/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/04-karino2/</guid>
      <description>自分もjmukに似てて、VS Codeです。 以前のように自分でいじったエディタを使ったりはしてないですね。 あまり面白みは無いですが、それが何かの結論を表している気もする。
現在のエディタ環境 メインはVS Codeでエディタ作業はプログラム以外もこれでやっている。 Cloudとかターミナル上の作業ではvimも使っている。カスタマイズ無し。
また、Android開発はAndroid Studioで、iOSはXCodeで、Qt開発はQtCreatorを使っている。 これらのIDEを使っている時間もそれなりに長い。 自分はデフォルト教の熱心な信者なので、 全て基本はカスタマイズ無しのデフォルトで使っていて、 各環境に自分の方を訓練で適応させている。
RascalとIDE体験 自分は昔、xyzzy というエディタをいろいろいじったカスタム版を自分でビルドして使っていて、lispもかなり書いていた。 かなり重度のEmacs系エディタ派閥だった。
ところが2005年に Microsoft 社内向けの簡易版VSであるRascalというのを使うようになり、 これがめちゃくちゃ出来が良かった。 今振り返るとこの時がEmacs系エディタ派からIDE派に鞍替えした瞬間だったと思う。
Rascalは、外にリリースされた物ではVisual C# Express Editionに近い。 だがRascalはよりエディタ的に使えて、小さいのでインストールもすぐに終わって、 デバッガもついててリファクタリングブラウザも補完もちゃんと動いた。 テストサーバーでテストがこけた時なども、ログインしてちょろっと持ってきてデバッグに使えて良かった。 このRascalが自分的な最初の現代的なIDE体験で、 これ以降メインの環境はIDEにしようと思い、IDEの学習に多くの時間を投資するようになった。
この2005年が自分には画期だったと思う。 世の中もIntelliJが革命的な進歩を果たしたのは2004年という事になっていて、 この2004年〜2005年あたりにIDEの時代が到来したんじゃないか。
今回のトピックでもVS CodeとIntelliJ系列がほぼ全てを占めているので、 15年かけてJavaとC#以外の環境にもその２つが浸透したんじゃないか。 だが15年の間にはそれなりに回り道もあった。
それ以外のIDEとしてのVS Code Rascal以後、全てがIDEになってめでたしめでたしになるかと思っていたが、その後クラウドの時代が来ると、 スクリプトなどを書く事が増えたり設定をしてないターミナル上（EMR上のインスタンスの中とか）での作業が増えて、 vimとか原始的な環境で作業をしてた。
この辺の時代になると、自分の環境は、
 IDE上の開発 IDE以外での開発  の2つが大きく分かれた別の世界になっていた。 IDEは日々進んでいて新しい機能が入っていく。 一方でIDE以外での開発は昔から変わらぬ環境。
IDE以外の環境ももうちょっとなんとかならんかなぁ〜と思っていた所にVS Codeが登場した。 触ってみると昔のRascalっぽい。いいねっ！と一気にファンになり、 IDE以外の世界にもIDE的な物がやってきて、以後みんな幸せに暮らしましたとさ。
vimの台頭 自分は長らく Emacs 系エディタに多くの時間を投資していたが、 IDEの時代、そのあとクラウドの時代が来てみると、Emacs系のエディタは不便さが目立つようになる。 一方でvimは自分のマシンでない一時的な環境での作業やIDEの隙間のちょっとした作業にいい感じにミートして、 それ以外+vimという形で割と皆が使うようになってきた（気がする）。 自分もそうだしjmukもそうだと言っている。
vimの方がEmacsよりもむしろ現代的なのは、逆説的で面白いなぁ、と思うのだった。
 morrita 案外あっさりおわってしまった。時代ですかね。
なお読者への補足として karino2 と jmuk は一時期 VS Code のコアを使ったウェブベースのエディタを開発していた VS Code 愛ある人々です。</description>
      <content:encoded><![CDATA[<p>自分もjmukに似てて、VS Codeです。
以前のように自分でいじったエディタを使ったりはしてないですね。
あまり面白みは無いですが、それが何かの結論を表している気もする。</p>
<h2 id="現在のエディタ環境">現在のエディタ環境</h2>
<p>メインはVS Codeでエディタ作業はプログラム以外もこれでやっている。
Cloudとかターミナル上の作業ではvimも使っている。カスタマイズ無し。</p>
<p>また、Android開発はAndroid Studioで、iOSはXCodeで、Qt開発はQtCreatorを使っている。
これらのIDEを使っている時間もそれなりに長い。
自分は<a href="http://0xcc.net/bknotes/31.html">デフォルト教</a>の熱心な信者なので、
全て基本はカスタマイズ無しのデフォルトで使っていて、
各環境に自分の方を訓練で適応させている。</p>
<h2 id="rascalとide体験">RascalとIDE体験</h2>
<p>自分は昔、<a href="https://xyzzy-022.github.io/">xyzzy</a>
というエディタをいろいろいじったカスタム版を自分でビルドして使っていて、lispもかなり書いていた。
かなり重度のEmacs系エディタ派閥だった。</p>
<p>ところが2005年に Microsoft 社内向けの簡易版VSであるRascalというのを使うようになり、
これがめちゃくちゃ出来が良かった。
今振り返るとこの時がEmacs系エディタ派からIDE派に鞍替えした瞬間だったと思う。</p>
<p>Rascalは、外にリリースされた物ではVisual C# Express Editionに近い。
だがRascalはよりエディタ的に使えて、小さいのでインストールもすぐに終わって、
デバッガもついててリファクタリングブラウザも補完もちゃんと動いた。
テストサーバーでテストがこけた時なども、ログインしてちょろっと持ってきてデバッグに使えて良かった。
このRascalが自分的な最初の現代的なIDE体験で、
これ以降メインの環境はIDEにしようと思い、IDEの学習に多くの時間を投資するようになった。</p>
<p>この2005年が自分には画期だったと思う。
世の中もIntelliJが革命的な進歩を果たしたのは2004年という事になっていて、
この2004年〜2005年あたりにIDEの時代が到来したんじゃないか。</p>
<p>今回のトピックでもVS CodeとIntelliJ系列がほぼ全てを占めているので、
15年かけてJavaとC#以外の環境にもその２つが浸透したんじゃないか。
だが15年の間にはそれなりに回り道もあった。</p>
<h2 id="それ以外のideとしてのvs-code">それ以外のIDEとしてのVS Code</h2>
<p>Rascal以後、全てがIDEになってめでたしめでたしになるかと思っていたが、その後クラウドの時代が来ると、
スクリプトなどを書く事が増えたり設定をしてないターミナル上（EMR上のインスタンスの中とか）での作業が増えて、
vimとか原始的な環境で作業をしてた。</p>
<p>この辺の時代になると、自分の環境は、</p>
<ul>
<li>IDE上の開発</li>
<li>IDE以外での開発</li>
</ul>
<p>の2つが大きく分かれた別の世界になっていた。
IDEは日々進んでいて新しい機能が入っていく。
一方でIDE以外での開発は昔から変わらぬ環境。</p>
<p>IDE以外の環境ももうちょっとなんとかならんかなぁ〜と思っていた所にVS Codeが登場した。
触ってみると昔のRascalっぽい。いいねっ！と一気にファンになり、
IDE以外の世界にもIDE的な物がやってきて、以後みんな幸せに暮らしましたとさ。</p>
<h2 id="vimの台頭">vimの台頭</h2>
<p>自分は長らく Emacs 系エディタに多くの時間を投資していたが、
IDEの時代、そのあとクラウドの時代が来てみると、Emacs系のエディタは不便さが目立つようになる。
一方でvimは自分のマシンでない一時的な環境での作業やIDEの隙間のちょっとした作業にいい感じにミートして、
それ以外+vimという形で割と皆が使うようになってきた（気がする）。
自分もそうだしjmukもそうだと言っている。</p>
<p>vimの方がEmacsよりもむしろ現代的なのは、逆説的で面白いなぁ、と思うのだった。</p>
<hr>
<p><div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
<p>案外あっさりおわってしまった。時代ですかね。</p>
<p>なお読者への補足として karino2 と jmuk は一時期 <a href="https://github.com/karino2/editbook">VS Code のコアを使ったウェブベースのエディタ</a>を開発していた VS Code 愛ある人々です。</p>

</div>
</div>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
Emacs系の話もいろいろ書こうと思ったけれど、長い割には現在の環境と関係が無いので、
今回は現在の環境に関わる事を中心にしてみました。
IDEにもかなり思い入れはあるので、これはこれで自分らしい気はする。
</div>
</div></p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/03-morrita/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/03-morrita/</guid>
      <description>自分の状況は 向井さんと似てる。つまり Emacs は使ってない。 ただ VS Code もそんなに使ってない。VS Code は他のものがないときの fallback というかんじ。カスタマイズもしてない。 仕事が Andoid アプリなのでそこは必然的に Android Studio. 一時期サーバ側の C++ を書いていた頃は CLion に金を払っていた。 これらは今はリモートデスクトップ越しに使っている。きびしい。
Git のコミットログとかは vim だけれど、それはエディタというより Git の機能みたいな気分で使ってる。まったく使いこなしてない。 2020 になってようやくコピーアンドペーストのキーバインドを覚えた。なにこれ革命的に便利。
仕事だと他に社内の Web-based のエディタがあって、最近は Java 以外だとだいたいそれを使っている。
Web-based なエディタ その内製 Web-based エディタ、所詮は内製ツールなので VS code みたいな出来のよさには遠く及ばない。補完もなんとなくされるかな程度。 イメージとしては Jupyter Notebook/Lab くらいの編集力。ただレポジトリとくっついてるのでブラウザ上でブランチつくってコミットもとかできるし、ビルドもテストもできる。 コードレビューも出せる、のみならず、レビューコメントがエディタから見えたりもする。
あとコードは CITC という仕組みで ブラウザ上での編集がなぜか手元にも反映されるので、ブラウザでできないこと (ビルドされたアプリを adb install するとか)はローカル環境でできる。
サーバ側のプログラマにはこれだけで暮らしている人も割といる。ほんまいかなと思うけど、 いわゆる「コード」だけでなく謎の設定ファイルをいじる仕事が大量にある場合はウェブエディタでも大差ないのかもしれない。 SQL や Python みたいにどのみち IDE の強力な支援が期待できない言語にも同じことがいる。 リモートデスクトップと比べるとキータイプ単位でレイテンシが無いのも良い。不毛な比較だけれど。
Web-based なエディタが存在できる理由の一つは「ローカルの設定」を必要としない monorepo と hermetic build の力かもしれない。 エディタからのビルドは要するに CI をトリガするようなものだけれど、ビルドのたびに環境をつくったら時間がかかって仕方がないし、 状態のキャッシュとかも下手にやるとビルドの安定性を損ねる。そのへんの問題が解決済なので Web-based エディタでもなんとかなる。</description>
      <content:encoded><![CDATA[<p>自分の状況は <a href="/003-editors/02-jmuk/">向井さんと似てる</a>。つまり Emacs は使ってない。
ただ VS Code もそんなに使ってない。VS Code は他のものがないときの fallback というかんじ。カスタマイズもしてない。
仕事が Andoid アプリなのでそこは必然的に Android Studio. 一時期サーバ側の C++ を書いていた頃は CLion に金を払っていた。
これらは今はリモートデスクトップ越しに使っている。きびしい。</p>
<p>Git のコミットログとかは vim だけれど、それはエディタというより Git の機能みたいな気分で使ってる。まったく使いこなしてない。
2020 になってようやくコピーアンドペーストのキーバインドを覚えた。なにこれ革命的に便利。</p>
<p>仕事だと他に社内の Web-based のエディタがあって、最近は Java 以外だとだいたいそれを使っている。</p>
<h2 id="web-based-なエディタ">Web-based なエディタ</h2>
<p>その内製 Web-based エディタ、所詮は内製ツールなので VS code みたいな出来のよさには遠く及ばない。補完もなんとなくされるかな程度。
イメージとしては Jupyter Notebook/Lab くらいの編集力。ただレポジトリとくっついてるのでブラウザ上でブランチつくってコミットもとかできるし、ビルドもテストもできる。
コードレビューも出せる、のみならず、レビューコメントがエディタから見えたりもする。</p>
<p>あとコードは <a href="https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext">CITC</a> という仕組みで
ブラウザ上での編集がなぜか手元にも反映されるので、ブラウザでできないこと (ビルドされたアプリを <code>adb install</code> するとか)はローカル環境でできる。</p>
<p>サーバ側のプログラマにはこれだけで暮らしている人も割といる。ほんまいかなと思うけど、
いわゆる「コード」だけでなく謎の設定ファイルをいじる仕事が大量にある場合はウェブエディタでも大差ないのかもしれない。
SQL や Python みたいにどのみち IDE の強力な支援が期待できない言語にも同じことがいる。
リモートデスクトップと比べるとキータイプ単位でレイテンシが無いのも良い。不毛な比較だけれど。</p>
<p>Web-based なエディタが存在できる理由の一つは「ローカルの設定」を必要としない monorepo と hermetic build の力かもしれない。
エディタからのビルドは要するに CI をトリガするようなものだけれど、ビルドのたびに環境をつくったら時間がかかって仕方がないし、
状態のキャッシュとかも下手にやるとビルドの安定性を損ねる。そのへんの問題が解決済なので Web-based エディタでもなんとかなる。</p>
<p>あとデフォルトが分散ビルドなので、手元でコマンドを動かしてもクラウドから呼んでも違いがないのはシームレスさに繋がっている。</p>
<h3 id="github-codespaces">Github Codespaces</h3>
<p>手元に環境をつくらなくていい Web-based エディタの気楽さが仕事の外にもあればと探していた頃、
ちょうど <a href="https://github.com/features/codespaces">Github Codespaces</a> がリリースされたので試してみた。
けっこう良い。ただ結局ブラウザ上のターミナルで色々やる前提があり、目に見えない状態に依存せざるを得ない。
特に裏で VM を動かす前提なのが残念。</p>
<p>ただそれは Github Codepaces の問題というよりは編集しているプロジェクトの制限に思える。
ビルド作業がより宣言的になり、かつ Github Actions のようなコード実行環境がコミットなしに使えるようになればビルドやテストが severless になる。
そうすれば Serverless Codespaces を実現できるはずで、VM はいらなくなる、かもしれない。今後の進歩を見守りたい。</p>
<p>なおこのブログも Codespaces で書けないかと試したが、ベータ期間中は organization の repo を編集できないらしい。
submodule なり fork なりワークアラウンドはあるんだろうけれど、めんどくさいので保留。</p>
<h2 id="web-based-なエディタ-1">Web-based な「エディタ」</h2>
<p>コードはさておき、人々は自然言語もテキストエディタで書いてるのだろうか？
Emacs にべったりな暮らしをしていた 20 年前はメモをとるのもメールを書くのもチャットをするのも全部 Emacs だった。
いまはそういうのは全部ブラウザでやっている。このブログは例外だけど、でも下書きはエディタより Gist でやることが多い。</p>
<p>仕事だとメモをとるのは（セキュリティがうるさいので社外のサービスは使えず) Google Docs.
タイプ量が多いメール、チャットやバグトラッカーもウェブベースだし、ローカルのファイルに何か書く機会がない。
個人でも Notion なり Wordpress なりが主要なテキスト入力環境なのでやはりローカルのファイルはさわらない。
このテキストは例外的に VS code で書いてるけど、我ながらショートカットとか全然覚えてなさすぎてぎこちなさがすごい。</p>
<p>20 年前に Firefox でテキストフィールドを外部エディタで編集する add-on を使いながら脱 Emacs を夢想していた頃は、
そのうちブラウザのテキストフィールドが進化してガチガチにカスタマイズできる日が来るとか思っていたけれど、
そういうことは一ミリも起きなかった。やや残念。
ただ Google Docs にしろ Notion にしろ WYSIWYG な環境はテキストフィールドですらないので、
カスタマイズ可能なテキストフィールドというアイデアはあまりにプレインテキスト至上主義すぎた。</p>
<hr>
<p>テキストエディタ愛は kzys &gt; jmuk &gt; morrita というかんじであることが判明。
我々この話題を書くべきだったのが疑問が湧いてきた・・・。
一時期テキストエディタ自作勢だった <a href="/003-editors/04-karino2/">karino2</a> はきっともうちょっとなんかいうことあることでしょう。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/01-morrita/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/01-morrita/</guid>
      <description>年の瀬なので振り返りもかねて今年読んだものでも紹介してみたい。 (草稿を書いたのは年末だけど、ぼんやりしてるうちに年が明けてしまった！)
といっても森田は今年は他人に勧められるほど良い読み物との出会いはなかった。 世が不作なわけではなく、パンデミックのせいで可処分時間や心の余裕がなかった。 なので他の人のおすすめに従って失われた一年をちょっとでも取り戻したい下心がある。
それでもブックマークなどを発掘したら少しはものを読んでいた（あるいは audiobook で聴いていた）ので、 その範囲で面白かったものを紹介したい。
まず書籍 3 冊。
Remote: Office Not Required Rails の開発者 DHH がつくったウェブ企業 Basecamp (当時は 37signals) がリモートワークについて書いた本。2013 年出版だが、 パンデミックの今年読むと趣深い。いいこと言ってる。7 年の月日を経てテクノロジーの問題はだいたい解決した感があるけれど、 文化的には企業間の差は大きいように思う。この本は動きの鈍い大企業に先んじてリモート化を進め差をつけろと謳う。 自分は差をつけられる側だと思うと複雑な心境。
リモート勤務、企業の個体差だけでなく我々従業員の個人差も大きいと思う。 たとえば長い通勤と引き換えに広い家を選んだ人はリモートが嬉しいだろうし、 通勤を縮めるために狭い家、高い家賃を選んだ自分のような人に嬉しさは薄い。 パンデミックはさておくと自由度の高い独身者はリモートワークの柔軟性を目一杯活かせる一方、 自分のように妻子があったり、更に子が就学していたりすると、 学校という時間的・地理的自由ゼロの活動に縛られてリモートがもたらすはずの生活の柔軟性は生かせない。
Basecamp 書籍は読むたびに我が身とくらべしょんぼりするが、そのしょんぼりが顕著な一冊だった。リモート欲を高めたい人にはおすすめ。
Facebook: The Inside Story Steven Levy による Facebook 読み物。 In the Plex や The Everything Store が好きだった人にはおすすめだし、それだけでなくゼロ年代のウェブの盛り上がりを生きてきた自分と同世代のひと（おっさん）も楽しく読めると思う。 今は色々言われている Facebook だけど、「ウェブでクールなサービスを出してゲットリッチ」というその世代の夢の頂点なのもまた事実なので。
電話機の OS を開発していた（が途中でやめた）話など、それなりに目新しいインサイダーストーリーも多い。
Google BigQuery: The Definitive Guide: Data Warehousing, Analytics, and Machine Learning at Scale 自分は仕事でよく BigQuery (の祖先の Dremel) の SQL を書いているが、いかんせん SQL 素人すぎていつも辛い。ちょっと付け焼き刃でなんとかしたいと思っても、世の SQL 入門書は OLTP 系の用途に偏っていて分析/OLAP 向けの入門に良いやつがない。しかも BigQuery/Dremel の SQL はネストしたデータがバンバンでてくるなど特殊な面も多い。助けてくれ・・・とおもってこの本を眺めたら、そういう「SQL 素人が BigQuery でやっつけ仕事をする」のに必要な SQL がちょうどよく紹介されていて救われた。ユーザ分析とかしたいけど SQL わからん・・・と腰が重いモバイル開発者におすすめ。</description>
      <content:encoded><![CDATA[<p>年の瀬なので振り返りもかねて今年読んだものでも紹介してみたい。
(草稿を書いたのは年末だけど、ぼんやりしてるうちに年が明けてしまった！)</p>
<p>といっても森田は今年は他人に勧められるほど良い読み物との出会いはなかった。
世が不作なわけではなく、パンデミックのせいで可処分時間や心の余裕がなかった。
なので他の人のおすすめに従って失われた一年をちょっとでも取り戻したい下心がある。</p>
<p>それでもブックマークなどを発掘したら少しはものを読んでいた（あるいは audiobook で聴いていた）ので、
その範囲で面白かったものを紹介したい。</p>
<p>まず書籍 3 冊。</p>
<h2 id="remote-office-not-requiredhttpswwwamazoncomremote-office-required-jason-frieddp0804137501"><a href="https://www.amazon.com/Remote-Office-Required-Jason-Fried/dp/0804137501/">Remote: Office Not Required</a></h2>
<p>Rails の開発者 DHH がつくったウェブ企業 Basecamp (当時は 37signals) がリモートワークについて書いた本。2013 年出版だが、
パンデミックの今年読むと趣深い。いいこと言ってる。7 年の月日を経てテクノロジーの問題はだいたい解決した感があるけれど、
文化的には企業間の差は大きいように思う。この本は動きの鈍い大企業に先んじてリモート化を進め差をつけろと謳う。
自分は差をつけられる側だと思うと複雑な心境。</p>
<p>リモート勤務、企業の個体差だけでなく我々従業員の個人差も大きいと思う。
たとえば長い通勤と引き換えに広い家を選んだ人はリモートが嬉しいだろうし、
通勤を縮めるために狭い家、高い家賃を選んだ自分のような人に嬉しさは薄い。
パンデミックはさておくと自由度の高い独身者はリモートワークの柔軟性を目一杯活かせる一方、
自分のように妻子があったり、更に子が就学していたりすると、
学校という時間的・地理的自由ゼロの活動に縛られてリモートがもたらすはずの生活の柔軟性は生かせない。</p>
<p>Basecamp 書籍は読むたびに我が身とくらべしょんぼりするが、そのしょんぼりが顕著な一冊だった。リモート欲を高めたい人にはおすすめ。</p>
<h2 id="facebook-the-inside-storyhttpswwwamazoncomfacebook-inside-story-steven-levydp0735213151"><a href="https://www.amazon.com/Facebook-Inside-Story-Steven-Levy/dp/0735213151">Facebook: The Inside Story</a></h2>
<p>Steven Levy による Facebook 読み物。
<a href="https://www.amazon.com/Plex-Google-Thinks-Works-Shapes/dp/1416596585">In the Plex</a>
や
<a href="https://www.amazon.com/Everything-Store-Jeff-Bezos-Amazon-ebook/dp/B00BWQW73E">The Everything Store</a>
が好きだった人にはおすすめだし、それだけでなくゼロ年代のウェブの盛り上がりを生きてきた自分と同世代のひと（おっさん）も楽しく読めると思う。
今は色々言われている Facebook だけど、「ウェブでクールなサービスを出してゲットリッチ」というその世代の夢の頂点なのもまた事実なので。</p>
<p>電話機の OS を開発していた（が途中でやめた）話など、それなりに目新しいインサイダーストーリーも多い。</p>
<h2 id="google-bigquery-the-definitive-guide-data-warehousing-analytics-and-machine-learning-at-scalehttpswwwamazoncomgoogle-bigquery-definitive-warehousing-analyticsdp1492044466"><a href="https://www.amazon.com/Google-BigQuery-Definitive-Warehousing-Analytics/dp/1492044466/">Google BigQuery: The Definitive Guide: Data Warehousing, Analytics, and Machine Learning at Scale</a></h2>
<p>自分は仕事でよく BigQuery (の祖先の <a href="https://research.google/pubs/pub36632/">Dremel</a>) の SQL を書いているが、いかんせん SQL 素人すぎていつも辛い。ちょっと付け焼き刃でなんとかしたいと思っても、世の SQL 入門書は OLTP 系の用途に偏っていて分析/OLAP 向けの入門に良いやつがない。しかも BigQuery/Dremel の SQL はネストしたデータがバンバンでてくるなど特殊な面も多い。助けてくれ・・・とおもってこの本を眺めたら、そういう「SQL 素人が BigQuery でやっつけ仕事をする」のに必要な SQL がちょうどよく紹介されていて救われた。ユーザ分析とかしたいけど SQL わからん・・・と腰が重いモバイル開発者におすすめ。</p>
<p>運用の話とかものってたけど、それらは読んでない。</p>
<p>つぎ、論文二本。</p>
<h2 id="javascript-the-first-20-yearshttpwwwwirfs-brockcomallenposts866"><a href="http://www.wirfs-brock.com/allen/posts/866">JavaScript: The First 20 Years</a></h2>
<p>当事者による JS の歴史。
<a href="https://misreading.chat/2020/10/19/86-javascript-the-first-20-years-hopl/">Podcast で紹介した</a>
ので内容は割愛するけれど、無駄な JS トリビアが凝縮されており面白い。
特に役には立たないが、JS 好きな人は読めば間違いなく満足すると思う。</p>
<h2 id="slow-softwarehttpswwwinkandswitchcomslow-softwarehtml"><a href="https://www.inkandswitch.com/slow-software.html">Slow Software</a></h2>
<p>なんか最近のソフトウェア遅いよね？なんでなの？というのを様々な文献を紹介しつつウォークスルーする論文ようなブログ記事のような文章。
ハードウェア、ソフトウェア（単一デバイス）のアーキテクチャから分散システムとしての性質までを早足で駆け抜ける。
文章自体に新規性はないけど話題が幅広いので、リンクをたどれば誰でも一つくらいは興味深いものを見つけられるのではないかな。</p>
<p>さいごにブログを二本。</p>
<h2 id="xi-editor-retrospective--raph-leviens-bloghttpsraphlinusgithubioxi20200627xi-retrospectivehtml"><a href="https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html">xi-editor retrospective | Raph Levien’s blog</a></h2>
<p>Rust で書かれた野心的なテキストエディタ <a href="https://github.com/xi-editor/xi-editor">Xi Editor</a> の野心の成否を作者が振り返る。
<a href="https://raph.levien.com/">経歴</a>を見ればわかるとおり、この作者はテキスト編集プログラムの超専門家。そんな専門家が野心をぶちこんでコケた結果を振り返る文章なんて、なかなか読めない。仕事だったら色々差し障るだろうけれど、オープンソースの趣味活動（というと語弊があるが）の結末なのでそういう遠慮がない。良い。</p>
<h2 id="a-simple-way-to-get-more-value-from-metricshttpsdanluucommetrics-analytics"><a href="https://danluu.com/metrics-analytics/">A simple way to get more value from metrics</a></h2>
<p>最近のインターネットでいちばんかっこいい（森田評）プログラマの一人である Dan Luu が、Twitter に入社して早々 SQL をちょいちょいと書きながらインフラの性能問題を突き止める話。かっこいい。自分の仕事で SQL ばかり書いていてうんざりしがちだけれど (<a href="https://notes.dodgson.org/android/trace-processor/">この話はブログにも書きました</a>), こういうスタープログラマが SQL してるのをみて気分を高めている。</p>
<hr>
<p>といったところ。最近 <a href="https://karino2.github.io/2020/12/10/boox_note3.html">e-ink tablet</a> を買って読書が捗ってる <a href="/004-whatiread/02-karino2/">karino2</a> なんかないですか。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/02-jmuk/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/02-jmuk/</guid>
      <description>エディタ、いまはもうだいたいVScodeだけでやっている。昔はEmacsだったけど、完全に脱却してしまった。もう一切使っていない。
VScodeへの移行 あれは2016年のことだったか。それとも2017年？　そのころにVScodeに移行したのだと思う。それまではずっとEmacs使いだったけれど、同時にもう何年も、いいかげんやめようと思っていたのだった。正直自分はEmacsを使いこなしていなかったし、Emacsラブということもとくにない。手に馴染むから使っていただけのことだった。それまで、たとえばIntelliJやEclipseを試したこともあったが、重さが気になったり、しっくりこなかった。社内C++業だとなかなかうまく動かないという事情もあるけれど。そういえば一瞬だけちょっとAndroidのことをやったことがあったときはIntelliJを使ったと思う。
さて、そんなわけで「もうEmacsじゃないだろう」とはずっと思っていたけれど、代替物がなかなかないなと思っていたころに、試してみるかと思って使ってみたのが当時流行っていたAtomと、出始めで勢いのあるVScodeだった。で、そのとき試してみたところVScodeのほうがちゃんと動いたのでそっちにするか、と思ってそのまま。VScode / Electronへの理解はまったく深まっていないのだが、なんとなく使えるのでそのまま使っているという、ある種堕落したような使い方をしている。凝った設定はなにもしていない。Emacsからの脱却が目的なのでキーバインド等もいじっていない。
Chromium規模のC++だと標準のモードはけっきょくあまり役に立たないのだが、さいわいChromium内で開発者向けの設定tipsが公開されているので、それをありがたく参照させていただいている。clangdを使った設定がよく動いているのでそれを利用している。OS側でのGo言語利用も、ちょっとだけGOPATH設定などをカスタマイズしているだけで、VScodeで使っている。Goland/CLionはちょっと興味あるけど、使ったことはないなあ。
リモートワークとエディタ環境 さて、2020年になって大部分の時間をリモートワークとして自宅から仕事するようになった。自分の場合、開発用のワークステーションは会社内に置きっぱなしのままで、手元の環境はChromebookだけという状態で仕事をしている。そうすると、sshだけで作業を完結させたくて、コンソール内で動作するテキストエディタに利点が出てきた、ように思える。2020年リモートワークの時代から、コンソールエディタの復権があったりするだろうか？
などと妄想するものの、自分の場合はそうなっていない。実は自分は会社に出勤して仕事してたときから、ずっと手元の操作環境はChromeOSにしていて、開発用ワークステーションへはリモートアクセスしていた。VScodeはリモートデスクトップで接続してそこから使うかたちにしている。リモートデスクトップだとレイテンシが気になるところだと思うのだけど、社内で仕事をしているかぎりはストレスを感じることはほぼなかった。これが自宅からだとどうなるか……と戦々恐々だったが、おもいのほかなんとかなっているので、そのままvscode on remote desktopというスタイルで仕事を続けている。
みんなどうしているんだろうか。自分のごく狭い範囲を観測するかぎり、リモートデスクトップは極端なパターンで、たいていの人はローカルに開発環境を持っていて、そこで開発をしているような気がする。やっぱりコンソールエディタの復権ということはないかな。それに復権するべきコンソールエディタというものの選択肢があまりにもないわけですが。
リモートワーク開発環境どうでしょう。&amp;gt; morrita
 vim ところで今年は Advent of Code を完走してみたのだが、Go言語を使い、コーディングにはおもにvimを使った。手元のChromebookのLinux環境を使っていたので、あんまりヘビーウェイトなもので書きたくない、というわけでvim。gvim使ったりしたけど途中でふつうのvimに移行してしまった。vimのGo言語プラグインはわりとよくできていて不満がない。
ところで、仕事ではだいたいVSCodeだと書いたけど、ちょっとしたことにはやっぱりvimを使っている（なんせgit commitしたらvimでコミットメッセージを書いている）。Emacsからは脱却できたけど、vimを完全に追い出すことはできていない。やっぱりコンソールエディタなのか……というのはふざけているにすぎないが、vimはどこででも動くし役に立つ。でも正直なところ、vimにはいまさらbetしたくないし、凝った設定も入れたくはない。ちょっとしたことを書くのに使うのみにとどめていたい。</description>
      <content:encoded><![CDATA[<p>エディタ、いまはもうだいたいVScodeだけでやっている。昔はEmacsだったけど、完全に脱却してしまった。もう一切使っていない。</p>
<h2 id="vscodeへの移行">VScodeへの移行</h2>
<p>あれは2016年のことだったか。それとも2017年？　そのころにVScodeに移行したのだと思う。それまではずっとEmacs使いだったけれど、同時にもう何年も、いいかげんやめようと思っていたのだった。正直自分はEmacsを使いこなしていなかったし、Emacsラブということもとくにない。手に馴染むから使っていただけのことだった。それまで、たとえばIntelliJやEclipseを試したこともあったが、重さが気になったり、しっくりこなかった。社内C++業だとなかなかうまく動かないという事情もあるけれど。そういえば一瞬だけちょっとAndroidのことをやったことがあったときはIntelliJを使ったと思う。</p>
<p>さて、そんなわけで「もうEmacsじゃないだろう」とはずっと思っていたけれど、代替物がなかなかないなと思っていたころに、試してみるかと思って使ってみたのが当時流行っていたAtomと、出始めで勢いのあるVScodeだった。で、そのとき試してみたところVScodeのほうがちゃんと動いたのでそっちにするか、と思ってそのまま。VScode / Electronへの理解はまったく深まっていないのだが、なんとなく使えるのでそのまま使っているという、ある種堕落したような使い方をしている。凝った設定はなにもしていない。Emacsからの脱却が目的なのでキーバインド等もいじっていない。</p>
<p>Chromium規模のC++だと標準のモードはけっきょくあまり役に立たないのだが、さいわい<a href="https://chromium.googlesource.com/chromium/src.git/+/refs/heads/master/docs/vscode.md">Chromium内で開発者向けの設定tipsが公開されている</a>ので、それをありがたく参照させていただいている。clangdを使った設定がよく動いているのでそれを利用している。OS側でのGo言語利用も、ちょっとだけGOPATH設定などをカスタマイズしているだけで、VScodeで使っている。Goland/CLionはちょっと興味あるけど、使ったことはないなあ。</p>
<h2 id="リモートワークとエディタ環境">リモートワークとエディタ環境</h2>
<p>さて、2020年になって大部分の時間をリモートワークとして自宅から仕事するようになった。自分の場合、開発用のワークステーションは会社内に置きっぱなしのままで、手元の環境はChromebookだけという状態で仕事をしている。そうすると、sshだけで作業を完結させたくて、コンソール内で動作するテキストエディタに利点が出てきた、ように思える。2020年リモートワークの時代から、コンソールエディタの復権があったりするだろうか？</p>
<p>などと妄想するものの、自分の場合はそうなっていない。実は自分は会社に出勤して仕事してたときから、ずっと手元の操作環境はChromeOSにしていて、開発用ワークステーションへはリモートアクセスしていた。VScodeはリモートデスクトップで接続してそこから使うかたちにしている。リモートデスクトップだとレイテンシが気になるところだと思うのだけど、社内で仕事をしているかぎりはストレスを感じることはほぼなかった。これが自宅からだとどうなるか……と戦々恐々だったが、おもいのほかなんとかなっているので、そのままvscode on remote desktopというスタイルで仕事を続けている。</p>
<p>みんなどうしているんだろうか。自分のごく狭い範囲を観測するかぎり、リモートデスクトップは極端なパターンで、たいていの人はローカルに開発環境を持っていて、そこで開発をしているような気がする。やっぱりコンソールエディタの復権ということはないかな。それに復権するべきコンソールエディタというものの選択肢があまりにもないわけですが。</p>
<p>リモートワーク開発環境どうでしょう。&gt; <a href="/003-editors/03-morrita/">morrita</a></p>
<hr>
<h2 id="vim">vim</h2>
<p>ところで今年は <a href="https://adventofcode.com/2020">Advent of Code</a> を完走してみたのだが、Go言語を使い、コーディングにはおもにvimを使った。手元のChromebookのLinux環境を使っていたので、あんまりヘビーウェイトなもので書きたくない、というわけでvim。gvim使ったりしたけど途中でふつうのvimに移行してしまった。vimのGo言語プラグインはわりとよくできていて不満がない。</p>
<p>ところで、仕事ではだいたいVSCodeだと書いたけど、ちょっとしたことにはやっぱりvimを使っている（なんせgit commitしたらvimでコミットメッセージを書いている）。Emacsからは脱却できたけど、vimを完全に追い出すことはできていない。やっぱりコンソールエディタなのか……というのはふざけているにすぎないが、vimはどこででも動くし役に立つ。でも正直なところ、vimにはいまさらbetしたくないし、凝った設定も入れたくはない。ちょっとしたことを書くのに使うのみにとどめていたい。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/01-kzys/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/01-kzys/</guid>
      <description>morrita 我々みな Emacs 世代だと思うけど、最近つかってるエディタなんかあります？ (内輪のスレッドより引用)   GoLand 仕事で IntelliJ を使っていたこともあって、仕事の Go は GoLand で書いている。定義元に飛ぶとか、シンボルのリネームとか、IDE っぽい機能が一通り動いて便利。
IDE を使うのは Emacs に無い機能が嬉しいからで、つまり Emacs のキーボードショートカットと IDE のそれは一対一対応にならないので、それなら IDE のキーボードショートカットをちゃんと覚えたほうがいいのでは、と思っているけれど、結局カーソルを動かすとかは Emacs の C-f/n/b/p に慣れすぎていて変えられず、デフォルトのものをちょっとだけ Emacs 風にしている。
Visual Studio Code 自分のブログの Markdown とか、IDE を使わないときは Visual Studio Code を使うことが多い。Visual Studio Code の Emacs 風の拡張はたくさんあるけれど、私は作者の VSCodeのキーバインド拡張を作ったので、その勘所を紹介 に説得 (?) されて、Awesome Emacs Keymap を使っている。
Remote Development が結構よかったのと、edamagit という Magit クローンが気になっていて、この二つをちゃんと自分が使えるようになったら、Emacs 使わなくても良くなるかもしれない。
Emacs でも Emacs もまだ使っている。用途は、Magit:ファイル1枚くらいで完結するスクリプト:複数のプロジェクトを行き来する必要があるとき = 8:1:1 くらいで、昔に比べるとだいぶ減った。
これをここからゼロにするかというと、うーん、どうなんだろう。私は Linux 使いはじめるまえに Meadow (というのは Windows で動く Emacs の一種です) を使っていたりして、Emacs とか Unix っぽいツール群がスッと動くことが Linux 使い出したときの感動のひとつだったりしたので、結構 Emacs 愛があるような気がする。</description>
      <content:encoded><![CDATA[<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>morrita</div>
<div class='message-body'>
我々みな Emacs 世代だと思うけど、最近つかってるエディタなんかあります？ (内輪のスレッドより引用)
</div>
</div>
<h2 id="goland">GoLand</h2>
<p>仕事で IntelliJ を使っていたこともあって、仕事の Go は GoLand で書いている。定義元に飛ぶとか、シンボルのリネームとか、IDE っぽい機能が一通り動いて便利。</p>
<p>IDE を使うのは Emacs に無い機能が嬉しいからで、つまり Emacs のキーボードショートカットと IDE のそれは一対一対応にならないので、それなら IDE のキーボードショートカットをちゃんと覚えたほうがいいのでは、と思っているけれど、結局カーソルを動かすとかは Emacs の C-f/n/b/p に慣れすぎていて変えられず、デフォルトのものをちょっとだけ Emacs 風にしている。</p>
<h2 id="visual-studio-code">Visual Studio Code</h2>
<p>自分のブログの Markdown とか、IDE を使わないときは Visual Studio Code を使うことが多い。Visual Studio Code の Emacs 風の拡張はたくさんあるけれど、私は作者の <a href="https://qiita.com/tuttieee/items/af8baa19fc4280ac1c0a">VSCodeのキーバインド拡張を作ったので、その勘所を紹介</a> に説得 (?) されて、<a href="https://marketplace.visualstudio.com/items?itemName=tuttieee.emacs-mcx">Awesome Emacs Keymap</a> を使っている。</p>
<p><a href="https://code.visualstudio.com/docs/remote/remote-overview">Remote Development</a> が結構よかったのと、<a href="https://marketplace.visualstudio.com/items?itemName=kahole.magit">edamagit</a> という Magit クローンが気になっていて、この二つをちゃんと自分が使えるようになったら、Emacs 使わなくても良くなるかもしれない。</p>
<h2 id="emacs">Emacs</h2>
<p>でも Emacs もまだ使っている。用途は、Magit:ファイル1枚くらいで完結するスクリプト:複数のプロジェクトを行き来する必要があるとき = 8:1:1 くらいで、昔に比べるとだいぶ減った。</p>
<p>これをここからゼロにするかというと、うーん、どうなんだろう。私は Linux 使いはじめるまえに Meadow (というのは Windows で動く Emacs の一種です) を使っていたりして、Emacs とか Unix っぽいツール群がスッと動くことが Linux 使い出したときの感動のひとつだったりしたので、結構 Emacs 愛があるような気がする。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: Re: 言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/04-morrita/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/04-morrita/</guid>
      <description>F# を日用する karino2, Scala にパッチを書いていた kzys, Haskell の本を書いてしまった jmuk のあとに 日々 for 文を書いて暮らしている自分になにか言うことがあるのか疑問だが、賑やかし程度になんか書く。
Arrow まず冒頭に出てきた F# の bind に相当するのは Kotlin には無いという話。 Kotlin には Arrow という FP 愛好家向けのマイナーライブラリがある。 そして Kotlin には coroutine がある。その二つは一緒に使われて Monad Comprehension という機能になっている。（らしい。）これがどのくらい F# の bind に近いのか自分はよくわからないけれど、そういうのが好きな人はいることはわかる。
一方で、仮にこれがまあまあ monad してるとしても、こうした流儀が Kotlin コミュニティの中心にあるとは思えない。 端的にいうと Android プログラマは(近似的には)誰も仕事で Arrow 使ってないよね。 同じ JVM 言語でも、Scala なら scalaz なり cats なりは もうちょっと受け入れられているように外野からは見える。 (なお森田の Scala FP 力はこの本 を途中で投げ出したくらい。つまり雑魚。あまり真に受けないでいただきたく。) F# は、よくしらないけどたぶんもうちょっと Haskell に近く functional first なのではなかろうか。</description>
      <content:encoded><![CDATA[<p><a href="https://github.com/karino2/uit">F# を日用する</a> karino2,
<a href="https://github.com/scala/scala/commits?author=kzys">Scala にパッチを書いていた</a> kzys,
<a href="https://www.amazon.co.jp/dp/4839919623">Haskell の本を書いてしまった</a> jmuk のあとに
日々 <code>for</code> 文を書いて暮らしている自分になにか言うことがあるのか疑問だが、賑やかし程度になんか書く。</p>
<h2 id="arrow">Arrow</h2>
<p>まず冒頭に出てきた <a href="https://fsharpforfunandprofit.com/posts/computation-expressions-bind/">F# の bind</a> に相当するのは Kotlin には無いという話。
Kotlin には <a href="https://arrow-kt.io/docs/patterns/monad_comprehensions/">Arrow</a> という FP 愛好家向けのマイナーライブラリがある。
そして Kotlin には coroutine がある。その二つは一緒に使われて <a href="https://arrow-kt.io/docs/patterns/monad_comprehensions/">Monad Comprehension</a>
という機能になっている。（らしい。）これがどのくらい F# の bind に近いのか自分はよくわからないけれど、そういうのが好きな人はいることはわかる。</p>
<p>一方で、仮にこれがまあまあ monad してるとしても、こうした流儀が Kotlin コミュニティの中心にあるとは思えない。
端的にいうと Android プログラマは(近似的には)誰も仕事で Arrow 使ってないよね。
同じ JVM 言語でも、Scala なら <a href="https://github.com/scalaz/scalaz">scalaz</a> なり <a href="https://typelevel.org/cats/">cats</a> なりは
もうちょっと受け入れられているように外野からは見える。
(なお森田の Scala FP 力は<a href="https://www.manning.com/books/functional-programming-in-scala">この本</a> を途中で投げ出したくらい。つまり雑魚。あまり真に受けないでいただきたく。)
F# は、よくしらないけどたぶんもうちょっと Haskell に近く functional first なのではなかろうか。</p>
<h2 id="一級市民への道">一級市民への道</h2>
<p>別の言い方をすると Haskell なり F# なりの monad は言語仕様を超えて一級市民である。Kotlin ではそうでない。</p>
<p>Monad の話をこれ以上続けるのは心苦しいのでもうちょっと身近なところに話を持ってくると、
データ分析言語の R では DataFrame というオブジェクトが一級市民である。
一方データ解析もできる Python にとって DataFrame は単なるライブラリの一つ (<a href="https://pandas.pydata.org/">Pandas</a>) である。
R のエコシステムではなにかと DataFrame を使う。
JavaScript では何かと JSON を使うみたいな雰囲気を想像すると近い。
一方で Python は DataFrame が出てこない世界の方がずっと広い。
なので R と比べると Python の DataFrame はいまいちしっくりこない。
ここでは jmuk や kzys がいうところのエコシステムが、逆の向きで問題になる。
つまり DSL として特化するが故に強い R のエコシステムが強さになっている。</p>
<p>・・・のかというと、どうだろう。自分は主に Python (Pandas) で DataFrame を使っているけれど、そんなに困っていない。
むかし R をかじってみたことがあるけれど、結局板につかず Python に戻ってきてしまった。
そして今や Python DataFrame 周辺のエコシステムは（分野によっては） R と戦える感じになっている。
汎用言語としての Python エコシステムの強さが R のニッチを侵略している。</p>
<p>つまり、一級市民として特定のアイデアを後押しできるニッチ言語の優位もあるし、
メインストリームの強さがそれをうわ塗るケースもある。
Monad が DataFrame くらい良い抽象なのだとしたら、
non-FP 言語で async 用途以外の monad が普及する日が来るかもしれない。
そんなに重要ではないかもと karino2 はいう。自分にはわからない。</p>
<p>それはさておき NumPy と Pandas の躍進はミラクルじみているとも思っていて、
イノベーションの話をするとき iPhone を引き合いに出すのに似た心苦しさもある。
一般化するにはちょっと飛躍あるんじゃないの？
あとはベースの言語自体の versatality は無視できない。
Python は DataFrame をホストできるくらいには強力な文法をもっていた(添字アクセスをフックできるとか)。
でも Kotlin やその他のメインストリーム言語の型システムや構文機能がどれくらい
Monad-capable なのか自分にはわからない。言語の懐の深さあってのエコシステムだろうから。</p>
<p>結論としては Android/JetBrains の中の人が勢い余って Arrow やそれ相応の何かを
フレームワーク/言語の下の方につっこむようなミラクルを期待しつつ
しばらく <code>for</code> (Stream ですらない)と <code>throw new RuntieException()</code> (Kotlin ですらない)
を書いて僕は生きていきていきますよ・・・</p>
<p>自分がわかってないから難しく感じる面はあると思う。
F# や Scala をやる気にもならないので、せめてそのうち Arrow に入門したい。
中の人は Manning から本を出してほしいもんです。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino2</div>
<div class='message-body'>
<p>Arrowどうなんですかね。何度か眺めた事あるんだけど、良く分からなかったんですよね。
なんか以下のように書いちゃダメで（これは当たり前）、</p>
<pre><code>IO.fx {
  val a = IO.invoke { 1 }
  a + 1
}.fix().unsafeRunSync()
</code></pre><p>でもaの所にカッコをつけるとOKなんですよね。</p>
<pre><code>  val (a) = IO.invoke { 1 }
</code></pre><p>このカッコの意味が良くわかってない。
これで以下と同じ意味になるらしいけど、</p>
<pre><code>  val a = IO.invoke { 1 }.bind()
</code></pre><p>同じになるメカニズムがわかって無くて、ちょっと理解しようとしたけれどどこ見たらいいのか分からなかった。</p>
<p>それは置いといて、kotlinにはDSLを作る他のメカニズムがある。
それで十分なんじゃないの、というのがコアにはこういうのが入っていない理由と思うのだけど、どうなんですかね。
SwiftとKotlinの両方が同じ姿勢だと、なんか正しそうな気もするのだけど（<a href="http://www.paulgraham.com/avg.html">beatされるaverage</a>な見解）。</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: 言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/03-kzys/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/03-kzys/</guid>
      <description>私はむかし Scala が好きだったので、あんまり流行らなかったのは残念です。いや、Scala 3 が Developer Preview に入る年の瀬に過去形で語るのもよくないけれど。
ランタイムが同じ言語を売り込むのは難しい C# と F#, Java と Scala みたいなランタイムが同じ言語は、既存のライブラリなどを使えるという利点はあるけれど、客観的な性能指標とかで明確に「勝つ」ことはなくて、チーム全員を説得するのが大変だと最近は思う。
ファイル一つをコピーすれば動くような実行ファイルを作りたければ Go で、メモリ安全性は手放したくないけれど、ガベージコレクションや大きいランタイムに起因する色々が嫌なら Rust で、みたいな分かりやすさに比べると、F# や Scala の良さって、言語のセマンティクスやシンタックスの話になりがちで、ちょっと弱い。
変数に再代入しない、という当たり前のことを表現するのに final って5文字も書かなくていいんですよ! ていうか Java の Collections.unmodifiableMap() って型に mutable なメソッドが生えてて実行時例外投げるってなんなの? 型に対する冒涜じゃないの? といっても、それがどのくらい許容できるかって人によってだいぶ差があって、我慢できるたぐいの良し悪しと、プログラミング言語に起因するトラブルを抱えるリスクを天秤にかけて、よし今回はこの言語でやってみよう、となることはなかなかない。10年以上プログラマをしているけど、チームの言語を切り替えられた経験って、そういえば一度もないような気がする。
その点でいうと、TypeScript は「型があるんですよ」というのが分かりやすくていい。Kotlin はどうなんだろう。
Scala のキラーアプリは Spark だったのか? Scala に関していうと、Scala が流行り出した頃は、アクターシステムの Akka とか、Rails みたいなフルスタックフレームワークの Lift や Play がキラーアプリになるかと思っていたんだけど、蓋をあけてみると、キラーアプリは Spark だったのかと思う。新しい言語には新しい問題が必要なのかもしれない。
ライブラリってどのくらいあればいいの? あと、ここ10年くらいに出てきた、Node.js (2009-), Go (2009-), Rust (2010-) がそれぞれそれなりの規模のライブラリ群を備えているのをみると、まあ10年くらいはかかっているけど、既存の言語の資産を引き継がなくてもなんとかなるんじゃないか、とも思う。
 karino ランタイムが同じ言語を売り出すのが難しいというのは、まさにC#からF#に乗り換える人はいないというのと同じ話に思う。
F#が面白かったのは、C#から乗り換える人は居なかったのだけどOCamlとかから乗り換える人が居た所だと思うんだよね。 自分もKotlinみたいに使えるコマンドライン言語がほしかったのであって、C#の代替とかCLR上の良い言語を探していた訳じゃない。Golangみたいに使えるKotlinを探していた。 これはF#使っている人が MS MVPとかじゃなくて全然別の、Unix上とかで普段生きている人でGCPやAWS使ってる人になっているところにも現れているんじゃないか。 会社の主流でない事をやっていたら会社には関心の無い他人が寄ってきた、みたいな。</description>
      <content:encoded><![CDATA[<p>私はむかし Scala が好きだったので、あんまり流行らなかったのは残念です。いや、<a href="https://www.scala-lang.org/blog/2020/12/15/scala-3-crossing-the-finish-line.html">Scala 3</a> が Developer Preview に入る年の瀬に過去形で語るのもよくないけれど。</p>
<h2 id="ランタイムが同じ言語を売り込むのは難しい">ランタイムが同じ言語を売り込むのは難しい</h2>
<p>C# と F#, Java と Scala みたいなランタイムが同じ言語は、既存のライブラリなどを使えるという利点はあるけれど、客観的な性能指標とかで明確に「勝つ」ことはなくて、チーム全員を説得するのが大変だと最近は思う。</p>
<p>ファイル一つをコピーすれば動くような実行ファイルを作りたければ Go で、メモリ安全性は手放したくないけれど、ガベージコレクションや大きいランタイムに起因する色々が嫌なら Rust で、みたいな分かりやすさに比べると、F# や Scala の良さって、言語のセマンティクスやシンタックスの話になりがちで、ちょっと弱い。</p>
<p>変数に再代入しない、という当たり前のことを表現するのに <code>final</code> って5文字も書かなくていいんですよ! ていうか Java の <code>Collections.unmodifiableMap()</code> って型に mutable なメソッドが生えてて実行時例外投げるってなんなの? 型に対する冒涜じゃないの? といっても、それがどのくらい許容できるかって人によってだいぶ差があって、我慢できるたぐいの良し悪しと、プログラミング言語に起因するトラブルを抱えるリスクを天秤にかけて、よし今回はこの言語でやってみよう、となることはなかなかない。10年以上プログラマをしているけど、チームの言語を切り替えられた経験って、そういえば一度もないような気がする。</p>
<p>その点でいうと、TypeScript は「型があるんですよ」というのが分かりやすくていい。Kotlin はどうなんだろう。</p>
<h2 id="scala-のキラーアプリは-spark-だったのか">Scala のキラーアプリは Spark だったのか?</h2>
<p>Scala に関していうと、Scala が流行り出した頃は、アクターシステムの Akka とか、Rails みたいなフルスタックフレームワークの Lift や Play がキラーアプリになるかと思っていたんだけど、蓋をあけてみると、キラーアプリは Spark だったのかと思う。新しい言語には新しい問題が必要なのかもしれない。</p>
<h2 id="ライブラリってどのくらいあればいいの">ライブラリってどのくらいあればいいの?</h2>
<p>あと、ここ10年くらいに出てきた、Node.js (2009-), Go (2009-), Rust (2010-) がそれぞれそれなりの規模のライブラリ群を備えているのをみると、まあ10年くらいはかかっているけど、既存の言語の資産を引き継がなくてもなんとかなるんじゃないか、とも思う。</p>
<hr>
<div class='message is-medium  is-size-6-touch comment'>
<div class='message-header'>karino</div>
<div class='message-body'>
<p>ランタイムが同じ言語を売り出すのが難しいというのは、まさにC#からF#に乗り換える人はいないというのと同じ話に思う。</p>
<p>F#が面白かったのは、C#から乗り換える人は居なかったのだけどOCamlとかから乗り換える人が居た所だと思うんだよね。
自分もKotlinみたいに使えるコマンドライン言語がほしかったのであって、C#の代替とかCLR上の良い言語を探していた訳じゃない。Golangみたいに使えるKotlinを探していた。
これはF#使っている人が <a href="https://en.wikipedia.org/wiki/Microsoft_Most_Valuable_Professional">MS MVP</a>とかじゃなくて全然別の、Unix上とかで普段生きている人でGCPやAWS使ってる人になっているところにも現れているんじゃないか。
会社の主流でない事をやっていたら会社には関心の無い他人が寄ってきた、みたいな。</p>
<p>だからScalaもJavaからの乗り換えとしてJavaの資産とかJVM用の良い言語という視点から探している人はなかなか採用までには至らず、
Javaなんて最初から眼中に無くScalaみたいな言語でライブラリとかIDEもしっかりしている奴、というふうに探している人の目に止まるんじゃないかなぁ。</p>
<p>最近F#が良いように見える一因として、C#の凋落による部分もあるんじゃないかな。
Microsoftがいかに「Androidのアプリも開発出来ます」と主張しても、そんな事は別にしたくない。Kotlinでいいから。
C#の存在感が減ってきた結果F#が見えるようになってきた気がする。
でもJavaも存在感も減ってるか？</p>

</div>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: 言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/02-jmuk/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/02-jmuk/</guid>
      <description>話をふられてなんなんだけど、最近あんまりML系の言語を使ってみたりしていないんだよな。最後になにかやったのは、min-camlがwasmを吐けるようにしたことで、あれはOCamlで書いたのだったか（min-camlはセルフホストではなく、OCamlで書かれている）。公開もしていない……自分で書いた部分がかなりmessyで気が滅入る感じになってしまったので放置している。
Haskellの型クラス そういえばポッドキャストで最近、Haskellの歴史の論文を読んだのを紹介した。2カラムで50ページ以上という長大なる論文なので仕方なくかなりの部分を割愛したが、なかでも型クラスの話はほとんど触れずに飛ばしたように思う。ところがあの論文は &amp;ldquo;being lazy with class&amp;rdquo; という副題がついてるくらい、なにかと型クラスの話をする論文なのだった。論文著者の気持ちとしては、型クラスこそがHaskellの最大の発明であり、特徴であるという気持ちなのかもしれない。
これはポッドキャストでは言及したとおもうが、そもそも型クラスというのは、もともとは数値型と演算子をどうするか、というのが発端だったようだ。プログラミング言語ではたいてい整数型と浮動小数点型があり、+とかみたいな演算子を2引数の関数とみなしたとき、その型が問題になる。たとえば let add x y = x + y のような関数の型はどうあるべきなのか。この解決策として「数値という型クラス」が導入され、型クラスの仕様をみたせばどんな型でもよいことがキレイに表現できる。やったぜ。
しかしこれ、比較的どうでもよい問題について大げさなツールで解決した感は否めない。ほとんどの言語は数値型は特別扱いして、それで大きな問題は起きていない。複数の型を受け入れるためのジェネリクスはよさそうだけど、型クラスというものはなんだか大げさにも思える。
面白いのは、Haskellはこの素朴な型クラスの成功を受けて、それを発展・深化させていったところだった。たとえばモナドができたときも、モナドってつまり型クラスだよね、という話になった。ところが既存の素朴な型クラスの話とモナドは、実はうまくマッチしない。たとえばIntがNumですよ、というのとIOがMonadですよ、というのは話が違う。IOは処理結果を返す型コンストラクタにすぎないから（StringがやってくるIO Stringとか、意味のある値のないIO ()とかが、個別具体的な型になる）。だから、型クラスを拡張して、型コンストラクタも指定できるようにした。さらに、型コンストラクタが複数の型パラメータをもつとき、その型パラメータ間の関係にどんな制約をつけられるだろうか、みたいな方向性にも発展した。
こうやって、型クラスという基礎から始まり、いろいろ複雑な論理関係を表現できるようになった。型クラスというのは出発点の動機は素朴でわりとどうでもいいものだったが、その先にはいろんな発展が見込まれる、豊かな領域の基礎になるものだった（数学者みたいな物言いだけど）。そのことがHaskellまわりの人達を魅了してきたのだろう。
言語のよさと、エコシステムのよさ 話は少しそれるが、あるプログラミング言語のよさみたいなものがあるとして、それってエコシステムに大いに影響されるものだよな、などとこのごろは強く思う。昔はそうでもなかったから、これは自分の年齢が関係するんだろうな。はー歳はとりたくないものだ。でもこれが間違っているというふうにも思いづらい。
エコシステムというのは周辺ツール、ライブラリなどの話であり、言語仕様そのものとは直接的な関係はないといってもいい。どちらかといえば、人がどれだけたくさん寄り付いたかとか、サポートしてくれる企業がどれだけいたか、といった話にもなりがち。でもエコシステムってやっぱり大事なんじゃないか。エコシステムの発達は新しいニーズを生み、それが言語仕様を豊かにしていくという面もある。直接的な関係がないからといって、無関係というわけではない。
Haskellにエコシステムがない……というつもりはない。そんなことを言うと多方面から怒られそう。十分に実用されているとすらいえる。でも他の人気の言語よりはエコシステムはどうしたって薄いだろう。Haskellみたいな言語の型システムは、長年研究者たちを魅了してきたし、それによって豊かに発達したわけだが、でもたとえばtypescriptが急激に発達していろいろわけのわからない型表現を生み出し取り入れているのを眺めるに、エコシステムの発達が生み出す言語仕様の発展ということについても思い馳せるところがないでもない。
F#なんだか面白そうだな、よさそうだな、という感じも、.NETというエコシステムの上によって立つところがあるんじゃないか、というふうに思う。そしてたぶん、その基盤ゆえに独自に発達した言語仕様とかもあるんじゃないかな。そうだとすると面白いな。……と思う一方、いろいろあるJVM系言語については自分は懐疑的な視点を崩せてない（Kotlinはよさそうですけどね）。自分のJava系の経験のうすさゆえだろうか。どうですかね＞和良さんとか？</description>
      <content:encoded><![CDATA[<p>話をふられてなんなんだけど、最近あんまりML系の言語を使ってみたりしていないんだよな。最後になにかやったのは、<a href="https://github.com/esumii/min-caml">min-caml</a>がwasmを吐けるようにしたことで、あれはOCamlで書いたのだったか（min-camlはセルフホストではなく、OCamlで書かれている）。公開もしていない……自分で書いた部分がかなりmessyで気が滅入る感じになってしまったので放置している。</p>
<h2 id="haskellの型クラス">Haskellの型クラス</h2>
<p>そういえばポッドキャストで最近、<a href="https://misreading.chat/2020/10/27/88-a-history-of-haskell-being-lazy-with-class/">Haskellの歴史の論文を読んだのを紹介した</a>。2カラムで50ページ以上という長大なる論文なので仕方なくかなりの部分を割愛したが、なかでも型クラスの話はほとんど触れずに飛ばしたように思う。ところがあの論文は &ldquo;being lazy with class&rdquo; という副題がついてるくらい、なにかと型クラスの話をする論文なのだった。論文著者の気持ちとしては、型クラスこそがHaskellの最大の発明であり、特徴であるという気持ちなのかもしれない。</p>
<p>これはポッドキャストでは言及したとおもうが、そもそも型クラスというのは、もともとは数値型と演算子をどうするか、というのが発端だったようだ。プログラミング言語ではたいてい整数型と浮動小数点型があり、+とかみたいな演算子を2引数の関数とみなしたとき、その型が問題になる。たとえば <code>let add x y = x + y</code> のような関数の型はどうあるべきなのか。この解決策として「数値という型クラス」が導入され、型クラスの仕様をみたせばどんな型でもよいことがキレイに表現できる。やったぜ。</p>
<p>しかしこれ、比較的どうでもよい問題について大げさなツールで解決した感は否めない。ほとんどの言語は数値型は特別扱いして、それで大きな問題は起きていない。複数の型を受け入れるためのジェネリクスはよさそうだけど、型クラスというものはなんだか大げさにも思える。</p>
<p>面白いのは、Haskellはこの素朴な型クラスの成功を受けて、それを発展・深化させていったところだった。たとえばモナドができたときも、モナドってつまり型クラスだよね、という話になった。ところが既存の素朴な型クラスの話とモナドは、実はうまくマッチしない。たとえばIntがNumですよ、というのとIOがMonadですよ、というのは話が違う。IOは処理結果を返す型コンストラクタにすぎないから（StringがやってくるIO Stringとか、意味のある値のないIO ()とかが、個別具体的な型になる）。だから、型クラスを拡張して、型コンストラクタも指定できるようにした。さらに、型コンストラクタが複数の型パラメータをもつとき、その型パラメータ間の関係にどんな制約をつけられるだろうか、みたいな方向性にも発展した。</p>
<p>こうやって、型クラスという基礎から始まり、いろいろ複雑な論理関係を表現できるようになった。型クラスというのは出発点の動機は素朴でわりとどうでもいいものだったが、その先にはいろんな発展が見込まれる、豊かな領域の基礎になるものだった（数学者みたいな物言いだけど）。そのことがHaskellまわりの人達を魅了してきたのだろう。</p>
<h2 id="言語のよさとエコシステムのよさ">言語のよさと、エコシステムのよさ</h2>
<p>話は少しそれるが、あるプログラミング言語のよさみたいなものがあるとして、それってエコシステムに大いに影響されるものだよな、などとこのごろは強く思う。昔はそうでもなかったから、これは自分の年齢が関係するんだろうな。はー歳はとりたくないものだ。でもこれが間違っているというふうにも思いづらい。</p>
<p>エコシステムというのは周辺ツール、ライブラリなどの話であり、言語仕様そのものとは直接的な関係はないといってもいい。どちらかといえば、人がどれだけたくさん寄り付いたかとか、サポートしてくれる企業がどれだけいたか、といった話にもなりがち。でもエコシステムってやっぱり大事なんじゃないか。エコシステムの発達は新しいニーズを生み、それが言語仕様を豊かにしていくという面もある。直接的な関係がないからといって、無関係というわけではない。</p>
<p>Haskellにエコシステムがない……というつもりはない。そんなことを言うと多方面から怒られそう。十分に実用されているとすらいえる。でも他の人気の言語よりはエコシステムはどうしたって薄いだろう。Haskellみたいな言語の型システムは、長年研究者たちを魅了してきたし、それによって豊かに発達したわけだが、でもたとえばtypescriptが急激に発達していろいろわけのわからない型表現を生み出し取り入れているのを眺めるに、エコシステムの発達が生み出す言語仕様の発展ということについても思い馳せるところがないでもない。</p>
<p>F#なんだか面白そうだな、よさそうだな、という感じも、.NETというエコシステムの上によって立つところがあるんじゃないか、というふうに思う。そしてたぶん、その基盤ゆえに独自に発達した言語仕様とかもあるんじゃないかな。そうだとすると面白いな。……と思う一方、いろいろあるJVM系言語については自分は懐疑的な視点を崩せてない（Kotlinはよさそうですけどね）。自分のJava系の経験のうすさゆえだろうか。どうですかね＞<a href="/002-pl/03-kzys/">和良さん</a>とか？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/04-karino2/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/04-karino2/</guid>
      <description>ここまでのかっこいいバグの話を見て、少し考えてみたが、自分の場合は10年以上前のものが多い。 最近はあんまりそういうバグが無いのだが、なんでかと考えてみる。
 長く使われるコードを書いていない 多くのユーザーに使われるコードを書いていない  という事かなぁ、と思った。
機械学習のバグ 自分のバグでかっこいいのが少ない事の一つに、機械学習の仕事が多かったからというのはあると思う。
例えば機械学習のモデルで変な推論をするみたいな話はまぁあるのだけれど、そういうのが二人のようなかっこいい感じのバグの話にならないのは、 結局そのモデルは早ければ一週間、遅くても開発が続いていれば一ヶ月後には更新されてしまうから。 すぐに更新されちゃうとバグの重みは軽い。というか機械学習のモデルの変な挙動の重みが軽くなるようにみんな体制を作っている。 特にディープなモデルは良く分からん挙動をする事があるからね。
デプロイしたモデルが動いてませんでしたみたいな事はたまにあるし、それは結構な機会損失を生んでたりもするけれど、 revertして直したのを数日後にリリースするだけなのであんまり面白みが無い。
短期のフリーランス的な立ち位置 自分の仕事は短期のフリーランスなので、エンドユーザーになにかデプロイするよりも社内向けのツールとかの仕事が多かったというのもある。 ハードウェアのテストのコードとかは、ハードウェア自身のバグに比べると面白みが無い。 ハードウェアは何億円とか掛けて工場で作って完全に使えない物が出来てしまう事もあるので、結構大ダメージではある。 なのでそういうバグは見てる分には面白かったが、 自分のバグでは無いのであんまりここに書く感じでも無い。
でもフリーランスだから雑用的な仕事が多いのか？というと…どうだろう？そうだとも、そうでないとも言える。 どちらに答えてもやや違和感が残る。
自分の印象としては、働いていた時の他のチームメンバと自分の仕事を比較して、そんなに雑用的な仕事が多かったことも無く、 むしろ短期の手伝いなので重要な仕事をする事の方が多かった。そのチーム内で見た時は正規雇用の社員に比べて雑用をしていた気はしない。
だけれど、そもそも短期のフリーランスを使うチームだという時点で、ある程度の実験的なプロジェクトとかなにかのプロジェクトの立ち上げのところとかが多く、 長く開発が続いているプロジェクトで、バグなどがバグトラッキングシステムで管理されて、それを日々直しつつ開発を続けていく、 みたいな体制のチームでは無い事が多い。 そういう仕事こそが重要な仕事であると思うなら、フリーランスは重要でない仕事が多いといえるかもしれない。
ただ自分はまぁそういうのはもういいかなぁという思いもあるので、フリーランスのお仕事は性にあってる。
会社の主流でない良さ 最近F#が雑用言語としてすごくいいなぁと思っている。 F#がいいと思う事の理由の一つに、Microsoftが力を入れて推し進めているわけ「では無い」ところがある。
C#はMicrosoftの現在の方針を色濃く反映してしまうので、クラウドに力を入れていればクラウドに、 モバイルのクロスプラットフォーム開発に力を入れていればモバイルのクラスプラットフォームに引きづられていろいろと変わっていく。 そうした方針がいつも正しく、よりよい方向に進むとは限らない。特に会社が苦戦している時には。 最近のMicrosoftのモバイル戦略なんかに合わされたらたまったものでは無い（最近の戦略なんて知りもしないで適当な事を言っているが）。
一方F#はそんなに会社の方針に合わせている感じは無く、自由にやらせている雰囲気だ。 VS CodeよりVSを優先しなきゃいけない理由も無くて、中の人も普通にVS Codeの環境をプッシュ出来る。 だからMacで開発する時も普通にVS Codeで快適に開発出来る。 Microsoftが迷走していてもあまり関係無いたたずまいに、ある種の安心感をおぼえる。 でもC#向けにいろいろ入れてくれるクラウド向けのコードなどはありがたく使わせてもらえる。 おいしくタダ乗りさせてもらっている感じが良い。
F#の良さの一つには、こうしたMicrosoftの方針の主流から外れている点があると思う。
外れているせいでC#に比べるとずっと人は掛かっていないと思うが、でも技術的につまらない事をやっている訳では無い。 むしろクロスプラットフォームでML的な関数型言語で大企業にバックアップされた豊富なライブラリというこれまでに無い価値を提供しており、 自分のようにC#よりも価値を見出している人は、Microsoftエコシステムの外にはそれなりに居る気がする。
大本営の方針に従ってやっていく方が価値があるとは限らない。この側面は、ソフトウェア業界にはあるんじゃないかね。 たくさん予算をかけて、凄いたくさんの人で壮大な計画でやった物は失敗する方が多い。 暇な時にちょっと始めた事が大きく広がる事はちょこちょこある。
大多数はどちらも大成功を生み出せないのが結論ではあるので、大本営の方針に従って粛々と働くのがダメって訳じゃない。 でもそういうのから外れた所で小粋にやっていくのもそれなりに意義のある事を生み出せるんじゃないかという気が最近していて、 その辺が「フリーランスの仕事はより雑用的で意義がない」と言う事に違和感を覚える理由にもなっている気がする。
ただフリーランスの仕事には継続的なプレッシャーにさらされる事はあまり無い。 そうした物に耐えてしかなせない事もあるとは思っているので、やっている人たちには敬意を持って接したいとは思うけれど。
という事でF#良いよという話に続く訳だが… 長くなったのでここまででこの話は一旦終えて、F#の話は次回（？）に回す事に。</description>
      <content:encoded><![CDATA[<p>ここまでのかっこいいバグの話を見て、少し考えてみたが、自分の場合は10年以上前のものが多い。
最近はあんまりそういうバグが無いのだが、なんでかと考えてみる。</p>
<ol>
<li>長く使われるコードを書いていない</li>
<li>多くのユーザーに使われるコードを書いていない</li>
</ol>
<p>という事かなぁ、と思った。</p>
<h2 id="機械学習のバグ">機械学習のバグ</h2>
<p>自分のバグでかっこいいのが少ない事の一つに、機械学習の仕事が多かったからというのはあると思う。</p>
<p>例えば機械学習のモデルで変な推論をするみたいな話はまぁあるのだけれど、そういうのが二人のようなかっこいい感じのバグの話にならないのは、
結局そのモデルは早ければ一週間、遅くても開発が続いていれば一ヶ月後には更新されてしまうから。
すぐに更新されちゃうとバグの重みは軽い。というか機械学習のモデルの変な挙動の重みが軽くなるようにみんな体制を作っている。
特にディープなモデルは良く分からん挙動をする事があるからね。</p>
<p>デプロイしたモデルが動いてませんでしたみたいな事はたまにあるし、それは結構な機会損失を生んでたりもするけれど、
revertして直したのを数日後にリリースするだけなのであんまり面白みが無い。</p>
<h2 id="短期のフリーランス的な立ち位置">短期のフリーランス的な立ち位置</h2>
<p>自分の仕事は短期のフリーランスなので、エンドユーザーになにかデプロイするよりも社内向けのツールとかの仕事が多かったというのもある。
ハードウェアのテストのコードとかは、ハードウェア自身のバグに比べると面白みが無い。
ハードウェアは何億円とか掛けて工場で作って完全に使えない物が出来てしまう事もあるので、結構大ダメージではある。
なのでそういうバグは見てる分には面白かったが、
自分のバグでは無いのであんまりここに書く感じでも無い。</p>
<p>でもフリーランスだから雑用的な仕事が多いのか？というと…どうだろう？そうだとも、そうでないとも言える。
どちらに答えてもやや違和感が残る。</p>
<p>自分の印象としては、働いていた時の他のチームメンバと自分の仕事を比較して、そんなに雑用的な仕事が多かったことも無く、
むしろ短期の手伝いなので重要な仕事をする事の方が多かった。そのチーム内で見た時は正規雇用の社員に比べて雑用をしていた気はしない。</p>
<p>だけれど、そもそも短期のフリーランスを使うチームだという時点で、ある程度の実験的なプロジェクトとかなにかのプロジェクトの立ち上げのところとかが多く、
長く開発が続いているプロジェクトで、バグなどがバグトラッキングシステムで管理されて、それを日々直しつつ開発を続けていく、
みたいな体制のチームでは無い事が多い。
そういう仕事こそが重要な仕事であると思うなら、フリーランスは重要でない仕事が多いといえるかもしれない。</p>
<p>ただ自分はまぁそういうのはもういいかなぁという思いもあるので、フリーランスのお仕事は性にあってる。</p>
<h2 id="会社の主流でない良さ">会社の主流でない良さ</h2>
<p>最近<a href="https://fsharp.org/">F#</a>が雑用言語としてすごくいいなぁと思っている。
F#がいいと思う事の理由の一つに、Microsoftが力を入れて推し進めているわけ「では無い」ところがある。</p>
<p>C#はMicrosoftの現在の方針を色濃く反映してしまうので、クラウドに力を入れていればクラウドに、
モバイルのクロスプラットフォーム開発に力を入れていればモバイルのクラスプラットフォームに引きづられていろいろと変わっていく。
そうした方針がいつも正しく、よりよい方向に進むとは限らない。特に会社が苦戦している時には。
最近のMicrosoftのモバイル戦略なんかに合わされたらたまったものでは無い（最近の戦略なんて知りもしないで適当な事を言っているが）。</p>
<p>一方F#はそんなに会社の方針に合わせている感じは無く、自由にやらせている雰囲気だ。
VS CodeよりVSを優先しなきゃいけない理由も無くて、中の人も普通にVS Codeの環境をプッシュ出来る。
だからMacで開発する時も普通にVS Codeで快適に開発出来る。
Microsoftが迷走していてもあまり関係無いたたずまいに、ある種の安心感をおぼえる。
でもC#向けにいろいろ入れてくれるクラウド向けのコードなどはありがたく使わせてもらえる。
おいしくタダ乗りさせてもらっている感じが良い。</p>
<p>F#の良さの一つには、こうしたMicrosoftの方針の主流から外れている点があると思う。</p>
<p>外れているせいでC#に比べるとずっと人は掛かっていないと思うが、でも技術的につまらない事をやっている訳では無い。
むしろクロスプラットフォームで<a href="https://en.wikipedia.org/wiki/ML_(programming_language)">ML</a>的な関数型言語で大企業にバックアップされた豊富なライブラリというこれまでに無い価値を提供しており、
自分のようにC#よりも価値を見出している人は、Microsoftエコシステムの外にはそれなりに居る気がする。</p>
<p>大本営の方針に従ってやっていく方が価値があるとは限らない。この側面は、ソフトウェア業界にはあるんじゃないかね。
たくさん予算をかけて、凄いたくさんの人で壮大な計画でやった物は失敗する方が多い。
暇な時にちょっと始めた事が大きく広がる事はちょこちょこある。</p>
<p>大多数はどちらも大成功を生み出せないのが結論ではあるので、大本営の方針に従って粛々と働くのがダメって訳じゃない。
でもそういうのから外れた所で小粋にやっていくのもそれなりに意義のある事を生み出せるんじゃないかという気が最近していて、
その辺が「フリーランスの仕事はより雑用的で意義がない」と言う事に違和感を覚える理由にもなっている気がする。</p>
<p>ただフリーランスの仕事には継続的なプレッシャーにさらされる事はあまり無い。
そうした物に耐えてしかなせない事もあるとは思っているので、やっている人たちには敬意を持って接したいとは思うけれど。</p>
<h2 id="という事でf良いよという話に続く訳だが">という事でF#良いよという話に続く訳だが…</h2>
<p>長くなったのでここまででこの話は一旦終えて、F#の話は次回（？）に回す事に。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/01-karino2/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/01-karino2/</guid>
      <description>F#とかML系言語の話 最近どこでもF#いいよしか言ってない気もするけれど、なかなかいいですよ、F#。 Microsoftエコシステムの外の人間の方が使いみちが多いというのが面白いところに思う。 Windows使ってる人じゃなくてMacとかLinux上でコマンドラインでなにかやりたい人にマッチしているのが盲点になりがち。 自分がまさにその盲点にはまってたんですが。
MacとかUnixでも動いて、ファイルのmoveとかcopyとかのシステム周りが一通り揃っていて、 新しい圧縮だとか通信だとかにもちゃんと大企業が対応してくれて（.NETがだけど）、 VSCodeのextentionも良く出来ていて、なおかつML系言語。 Unix系コンソールでのML系言語の時代来たな！
とか思っていたら、和良さんに DarkもOcamlからF#の時代ですよ！ とか教えてもらって、 リンク先を読んでたらReasonML とか Elm を知る。 以前AltJSとしてどっかで見かけた事はあった気がするが、 その時は好きものがやってるだけのマイナープロジェクトくらいに思っていたけれど、 F#もそんな風に思っていたのに使ってみると意外と使える感じだった。 こいつらも結構いいんじゃないか？とか思い始める。
この辺のAltJS系、それなりに流行ってるんですかね？ 自分が知らなかっただけで意外とML系言語の時代来ていた？
F#が普通のプログラマにどのくらい受け入れられるか的な話 流行るといえばどの位一般のプログラマに受けいられるのかが課題。という事で言語的な学習のしやすさを。
F#（というかML）は、表面上はPythonとかとそんなに変わらなくて、見様見真似でもちょっとは書ける。 一方で、いい感じにF#の良さを活かそうとすると、これまでのスタイルとは大きく変えてプログラミングをしないといけない。 例えばF#のパイプ演算子をうまく使うためには関数はカリー化したものを基本としてプログラムしてる方が良くて、 そうするとクラスやオブジェクトでは無くValueを基本にプログラミングをしないといけない。
このプログラムの構成の仕方の変更はそれなりに難しさ、関数型言語の素養を必要とす。 入り口は普通のプログラム言語っぽくても、結局は関数型言語として接する必要はある。 この「関数型言語としてのプログラム構成の仕方を学んで従う」のは、どのくらい普通のプログラマに受け入れられるのか？
あと、F#は割と基本的な所でモナドが出てくる。Option型を扱うのにDSLを作るのが推奨されてるっぽい感じ。 専用の構文があればいいはずなのにそういうのは無くて、 computation expressionというbind系の関数を幾つか実装すると使えるDSLを作る枠組みがあって、それを勧られる。 それにしたって最初からOption用のcomputation expressionで使えるビルダを用意しておいてくれれば、理解しなくてもしばらくは使えると思うのだが、 F#には何故かビルドインではOption用のcomputation expressionのビルダが無いので自分で書かないといけない（6行くらいで書けるけど）。
自分で書くためにはbindってなんだよ、というのを学ぶ必要があり、これはお決まりのモナド入門をやらないといけない。 提供してくれているのを使うだけならもうちょっと後回しに出来るのだけど、 提供してくれてないので言語の入門の割と初期でどうしてもbindの話が出てきてしまう。
教育的配慮もあってそうなってるのかもしれないが、 大多数の人には不要な壁になってしまっている。 F#を使う時の期待値として関数型言語の勉強という側面も持っている気がするので、 初期にbindの必要性に当たるのは悪いとも言い切れないのだけれど。
そもそもbindのシンタックスシュガーってどうなのか？ Bindって今どきのプログラマはどこかでは乗り越え済みなんですかね？
C#はLINQが入った時にみんな頑張ったし、F#も.NET勢なので.NET界隈はなぜかこの辺を普通のプログラマもやる、 という良く分からん風習があった。 でもふと冷静になって外の世界を見渡すと、なんだかんだでモバイルの2大主流言語であるKotlinにもSwiftにもない。 機械学習で主流のPythonにも、Webのフロントエンドで使うJSにもない。
パーサーコンビネータはみんな使ってると思うのだけど、別にbindとか知らんでも使える。
こうして考えると、普通にプログラム言語を使っているとbindのシンタックスシュガーのある言語を触る機会は今でも意外と無さそう。
そもそもF#で初期にbindの例で出てくるOption、先程も言ったとおりちゃんと専用のシンタックスシュガーを導入すればbindのシンタックスシュガーなんて要らないんですよね。 実際KotlinはOption(Nullable)周りに専用のシンタックスシュガーがいろいろ入っていて、 bindのシンタックスシュガーなんて無くてもむしろF#より快適に書ける。
Computation expressionの枠組みでいろいろな物を汎用的に美しく書けるとは言っても、良く出てくるケースはだいたい決まってて、 それ独自のシンタックスシュガーを入れれば特に問題は無い。 Asyncとawaitもcomputation expressionで美しく書けます、と言われても、別にsuspend関数で問題が無い。 専用の構文を入れるのはダサいかもしれないけれど、どうせ似たような仕組みに落ち着くのだから使う側的に違いは無い。 理論的に美しくないだけで学習コストを大きく下げられるのだから、そっちの方が良いのでは？という気もする。
Computation expressionは新たにDSLを作りたい時には強力な仕組みとなる訳だけど、 if elseのショートカットとかをちゃんと実現しようとすれば遅延評価みたいな仕組みも必要になってきて（F#ではDelayというのでこれを行う）、 そんなにシンプルで美しいという訳でも無い。 でもそうしたフルな機能が要らないなら別にKotlinのようにインライン周りの工夫が入っているだけで十分だったりする。 むしろreturn周りなんかはKotlinの方がシンプルに書ける事も多い。</description>
      <content:encoded><![CDATA[<h2 id="fとかml系言語の話">F#とかML系言語の話</h2>
<p>最近どこでも<a href="https://fsharp.org/">F#</a>いいよしか言ってない気もするけれど、なかなかいいですよ、F#。
Microsoftエコシステムの外の人間の方が使いみちが多いというのが面白いところに思う。
Windows使ってる人じゃなくてMacとかLinux上でコマンドラインでなにかやりたい人にマッチしているのが盲点になりがち。
自分がまさにその盲点にはまってたんですが。</p>
<p>MacとかUnixでも動いて、ファイルのmoveとかcopyとかのシステム周りが一通り揃っていて、
新しい圧縮だとか通信だとかにもちゃんと大企業が対応してくれて（.NETがだけど）、
VSCodeのextentionも良く出来ていて、なおかつML系言語。
Unix系コンソールでのML系言語の時代来たな！</p>
<p>とか思っていたら、和良さんに <a href="https://blog.darklang.com/new-backend-fsharp/">DarkもOcamlからF#の時代ですよ！</a> とか教えてもらって、
リンク先を読んでたら<a href="https://reasonml.github.io/">ReasonML</a> とか <a href="https://elm-lang.org/">Elm</a> を知る。
以前AltJSとしてどっかで見かけた事はあった気がするが、
その時は好きものがやってるだけのマイナープロジェクトくらいに思っていたけれど、
F#もそんな風に思っていたのに使ってみると意外と使える感じだった。
こいつらも結構いいんじゃないか？とか思い始める。</p>
<p>この辺のAltJS系、それなりに流行ってるんですかね？
自分が知らなかっただけで意外とML系言語の時代来ていた？</p>
<h2 id="fが普通のプログラマにどのくらい受け入れられるか的な話">F#が普通のプログラマにどのくらい受け入れられるか的な話</h2>
<p>流行るといえばどの位一般のプログラマに受けいられるのかが課題。という事で言語的な学習のしやすさを。</p>
<p>F#（というかML）は、表面上はPythonとかとそんなに変わらなくて、見様見真似でもちょっとは書ける。
一方で、いい感じにF#の良さを活かそうとすると、これまでのスタイルとは大きく変えてプログラミングをしないといけない。
例えばF#のパイプ演算子をうまく使うためには関数はカリー化したものを基本としてプログラムしてる方が良くて、
そうするとクラスやオブジェクトでは無くValueを基本にプログラミングをしないといけない。</p>
<p>このプログラムの構成の仕方の変更はそれなりに難しさ、関数型言語の素養を必要とす。
入り口は普通のプログラム言語っぽくても、結局は関数型言語として接する必要はある。
この「関数型言語としてのプログラム構成の仕方を学んで従う」のは、どのくらい普通のプログラマに受け入れられるのか？</p>
<p>あと、F#は割と基本的な所でモナドが出てくる。Option型を扱うのにDSLを作るのが推奨されてるっぽい感じ。
専用の構文があればいいはずなのにそういうのは無くて、
computation expressionという<a href="https://fsharpforfunandprofit.com/posts/computation-expressions-bind/">bind系の関数</a>を幾つか実装すると使えるDSLを作る枠組みがあって、それを勧られる。
それにしたって最初からOption用のcomputation expressionで使えるビルダを用意しておいてくれれば、理解しなくてもしばらくは使えると思うのだが、
F#には何故かビルドインではOption用のcomputation expressionのビルダが無いので自分で書かないといけない（6行くらいで書けるけど）。</p>
<p>自分で書くためにはbindってなんだよ、というのを学ぶ必要があり、これはお決まりのモナド入門をやらないといけない。
提供してくれているのを使うだけならもうちょっと後回しに出来るのだけど、
提供してくれてないので言語の入門の割と初期でどうしてもbindの話が出てきてしまう。</p>
<p>教育的配慮もあってそうなってるのかもしれないが、
大多数の人には不要な壁になってしまっている。
F#を使う時の期待値として関数型言語の勉強という側面も持っている気がするので、
初期にbindの必要性に当たるのは悪いとも言い切れないのだけれど。</p>
<h2 id="そもそもbindのシンタックスシュガーってどうなのか">そもそもbindのシンタックスシュガーってどうなのか？</h2>
<p>Bindって今どきのプログラマはどこかでは乗り越え済みなんですかね？</p>
<p>C#はLINQが入った時にみんな頑張ったし、F#も.NET勢なので.NET界隈はなぜかこの辺を普通のプログラマもやる、
という良く分からん風習があった。
でもふと冷静になって外の世界を見渡すと、なんだかんだでモバイルの2大主流言語であるKotlinにもSwiftにもない。
機械学習で主流のPythonにも、Webのフロントエンドで使うJSにもない。</p>
<p>パーサーコンビネータはみんな使ってると思うのだけど、別にbindとか知らんでも使える。</p>
<p>こうして考えると、普通にプログラム言語を使っているとbindのシンタックスシュガーのある言語を触る機会は今でも意外と無さそう。</p>
<p>そもそもF#で初期にbindの例で出てくるOption、先程も言ったとおりちゃんと専用のシンタックスシュガーを導入すればbindのシンタックスシュガーなんて要らないんですよね。
実際KotlinはOption(Nullable)周りに<a href="https://kotlinlang.org/docs/reference/null-safety.html">専用のシンタックスシュガーがいろいろ入っていて</a>、
bindのシンタックスシュガーなんて無くてもむしろF#より快適に書ける。</p>
<p>Computation expressionの枠組みでいろいろな物を汎用的に美しく書けるとは言っても、良く出てくるケースはだいたい決まってて、
それ独自のシンタックスシュガーを入れれば特に問題は無い。
Asyncとawaitもcomputation expressionで美しく書けます、と言われても、別に<a href="https://kotlinlang.org/docs/reference/coroutines-overview.html">suspend関数</a>で問題が無い。
専用の構文を入れるのはダサいかもしれないけれど、どうせ似たような仕組みに落ち着くのだから使う側的に違いは無い。
理論的に美しくないだけで学習コストを大きく下げられるのだから、そっちの方が良いのでは？という気もする。</p>
<p>Computation expressionは新たにDSLを作りたい時には強力な仕組みとなる訳だけど、
if elseのショートカットとかをちゃんと実現しようとすれば遅延評価みたいな仕組みも必要になってきて（F#ではDelayというのでこれを行う）、
そんなにシンプルで美しいという訳でも無い。
でもそうしたフルな機能が要らないなら別にKotlinのようにインライン周りの工夫が入っているだけで十分だったりする。
むしろreturn周りなんかはKotlinの方がシンプルに書ける事も多い。</p>
<p>いろいろなDSLをしょっちゅう作って、それがかなり汎用な言語機能を要求するならbindのシンタックスシュガーがある方がいい。
でもそういうのって一部の人だけがやればいい気もするんですよねぇ。
一方でF#とかの良さを享受出来る人というのはもっとたくさん居る訳で、
もっとそういう多数派に向けてシンタックスシュガーいろいろ入れてbindに触れずに済む範囲を増やした方が流行るんじゃないか。</p>
<p>Kotlinとかってまさにそういう言語で、algebraic typeの良さとかは受け入れつつ、
汎用だが全てを含めると複雑になるbindのシンタックスシュガーでいろいろ統一せず必要に応じたシンタックスシュガーを入れて便利に書ける。
これでいいというのが現在の答えなのかね。</p>
<p>一方でKotlinみたいな言語だとオブジェクトが多くなりがちで、algebraic typeをガンガン使ったモデリングというF#の教義（というかたぶんML系言語の教義なんでしょうが）に従わない事も多い。
そもそもAndroidはActivityとかViewがオブジェクトで作られていて、
それらとの相互作用がプログラムの多くの部分を占めるので、そうなるもっともな理由もある。</p>
<p>ただそういう日々をすごしているとfunctionalなスタイルを学ぶ事は難しくて、
いろいろ切り離してpureなドメインモデルの世界を構築してML的に書ける時でもそれを行わない事が多く、
関数型言語の教育的側面としてはよろしく無い部分もある気もする。</p>
<p>などととりとめも無く書いてきたけど、以前<a href="https://misreading.chat/2018/12/25/episode-41-idris-systems-programming-meets-full-dependent-types/">Idrisの話をしたり</a>
Mini OCaml動かしたりしていた<a href="/002-pl/02-jmuk/">jmuk</a>的にはなにかコメントはありませんかね？</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: Re: バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/03-jmuk/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/03-jmuk/</guid>
      <description>あんまりかっこいいバグというわけでもないが、解決が楽しかったのでここに書いて供養しておこう。
最近はOSの性能テストをよく書いて計測している。Go言語で書いたテストコードがコンパイルされた上で実機上で動いてOSをいろいろ操作させるというものだが、こういうend-to-endなテストの性質上、壊れることもよくある。ある日のテストの失敗レポートもそういうよくあるやつに見えた。
ログを見ると、なかなか失敗しなさそうなところでタイムアウトして失敗している。理由もよくわからない。手元で再現させてみるが、もちろん再現しない。ところがCIでは頻繁に失敗している。なぜだろう？　考えられるのは、同じ試行で走っている前のテストケースの影響だ。それで思いつく関係しそうなテストケースをいろいろ組み合わせてみるが、それでも再現しない。
もうちょっと良く見てみよう、と失敗したログを見てみる。失敗した場合、psのダンプも保存してくれるので、それも見てみる。すると……実機上のテストコード自体のCPU負荷が300%を越えてる！！　これなのは間違いない。テストコードが狂っていてCPU負荷が高くなりすぎてOSがまともに動作できず、普段なら失敗しないところでもタイムアウトしてしまうというわけだ。
しかし何が原因なのか、どこにCPUを使っているのかは謎のままだった。仕方ないので、同じ試行で走るべき全テストを実行させつつtopでCPU使用率を目で追ってみた。するとテストの早い段階でとあるテストケースが失敗すると、その後のCPU使用率が100%を越えることがわかった。これだろう。CPU利用率は違うが、同じ問題を引き起こすテストケースがほかにいくつかあるのだろう。
問題の分析 再現環境が手に入ったので話はずいぶん簡単になったが、まだ何故これが起きたのかはわかっていない。Go言語にはプロファイラが標準で入っているから、これを使ってみることにする。自分のテストのほうでプロファイラを取るようにし、問題を起こすテストケースと自分のテストケースの2つだけを実行させる。で、これをflame graphで眺めてみたら問題は一目瞭然。cdpというライブラリのなかの、とあるgoroutineが大幅にCPUサイクルを消費している。しかもその消費の大部分は文字列フォーマットとエラーオブジェクトの構築。ようするに、エラーの報告しまくっているということだ。
cdpというのはChrome devtools protocolの略だ。OSやブラウザをテストから操作するためにこのプロトコルを使っていて、cdpというのはこれをGoから使えるようにしているサードパーティのライブラリだったが、どうもここにバグがあるらしい。それで調べてみると、たしかに問題の起きたOSバージョンから、cdpのバージョンを上げる変更が入っている。手元でcdpのバージョンを落としてみると問題が直る。
というわけでcdpのバージョンを戻せば解決するが、それじゃ本質的な解決にはならないので、もうすこしcdpの中身を眺めてみる。すると、このgoroutineは実際にchromeとのメッセージをやりとりするようなものだった。何らかの理由で通信チャネルが閉じたらエラーになるが、エラーといってもいろいろなので「エラーが起きたらエラーオブジェクトを作って報告する。もしそれがcloseに関係するエラーだったらgoroutineを終了する」といったロジックになっていた。どうも、問題の事例では本当は通信チャネルが閉じたのに、closeエラーかどうかの判定が間違っていたためgoroutineが止まらず、ビジーループでエラーオブジェクトを作り続ける無限ループに陥っていたようだ。
実際に起きているエラーがなんなのか見る方法はないだろうか？　テストは実機で走っているので、ログは簡単には仕込めない。テストインフラ側には専用のロガーがあるが、依存先であるサードパーティライブラリはそのロガーのことを知らない……。ただcdpはエラーをGoのchannelに書き出してくれていたので、テストシナリオの側でこのchannelを読んでテストインフラのロガーに流すコードを仕込んでみた。すると、たしかにエラーオブジェクトが無数に流れてくる。根本的には、cdpライブラリがさらに依存しているwebsocketライブラリのcloseエラーになっているが、手前がcdpのcloseエラーになっていないので、判定に失敗しているようだ。
解決 いったん手元では雑なパッチで修正し、問題としてはひとまず解決した。これをupstreamすることにしたのだが、そこでもうすこし問題の詳細を眺めてみた。
さっきも書いたように、いちばん根底のエラーはwebsocketライブラリのエラーだった。一番手前のエラーは全然別のエラーだ。Go言語では、こういうふうにエラーオブジェクトをベースにしてちょっとエラーメッセージを追記するようなwrapがよく行われている。cdpライブラリの場合、Causeという独自のメソッドがあり、wrappingを剥がして元のエラーオブジェクトを取れるようになっている。
ライブラリとしての構造が複雑になってくると、こういうwrappingは多段化しがちだ。実際このケースでもそうで、複数段のwrappingが入っていた。ところが問題の無限ループでは、一番手前のエラーオブジェクトと、一番奥のエラーオブジェクト（websocketライブラリのエラーオブジェクト）しかチェックしていない。実際にはcdpライブラリのcloseエラーは正しく存在していたが、この多段wrappingの中間にしかなかったので、無視される状態になっていた。そこで、このwrappingを一段ずつはがしてチェックするように修正をつくってupstreamした。これがマージされたのでこの問題はおしまい。
ところで、ちょっと勘のいいGoプログラマは気づいたかもしれないが、これはGo 1.13で導入されたerrors.Isと類似性がある( https://blog.golang.org/go1.13-errors )。Go 1.13ではerrors.Isという関数ができて、こういう「ほかのエラーオブジェクトをラップしたエラーオブジェクトとの一致チェック」というパターンを簡単にかけるようになった。errors.Isでは、エラーオブジェクトにUnwrapというメソッドがないかチェックする。あるならそれを使ってwrapを外す。どこかでtargetと一致するエラーがあったらtrueを返す。どこにもなくunwrapできなくなったらfalse。
ただ、cdpライブラリの状況ではこれはそのまま使えるものではない（とくに==でのチェックだと厳しい）。使えるようにするにしてもかなりの再設計が必要になるだろう。でもまあよくあるパターンとして比較的最近、標準でサポートされるような問題ではあるという話だったのは興味深かった。
 最後は karino2.</description>
      <content:encoded><![CDATA[<p>あんまりかっこいいバグというわけでもないが、解決が楽しかったのでここに書いて供養しておこう。</p>
<p>最近はOSの性能テストをよく書いて計測している。<a href="https://chromium.googlesource.com/chromiumos/third_party/autotest/+/HEAD/docs/user-doc.md">Go言語で書いたテストコード</a>がコンパイルされた上で実機上で動いてOSをいろいろ操作させるというものだが、こういうend-to-endなテストの性質上、壊れることもよくある。ある日のテストの失敗レポートもそういうよくあるやつに見えた。</p>
<p>ログを見ると、なかなか失敗しなさそうなところでタイムアウトして失敗している。理由もよくわからない。手元で再現させてみるが、もちろん再現しない。ところがCIでは頻繁に失敗している。なぜだろう？　考えられるのは、同じ試行で走っている前のテストケースの影響だ。それで思いつく関係しそうなテストケースをいろいろ組み合わせてみるが、それでも再現しない。</p>
<p>もうちょっと良く見てみよう、と失敗したログを見てみる。失敗した場合、psのダンプも保存してくれるので、それも見てみる。すると……実機上のテストコード自体のCPU負荷が300%を越えてる！！　これなのは間違いない。テストコードが狂っていてCPU負荷が高くなりすぎてOSがまともに動作できず、普段なら失敗しないところでもタイムアウトしてしまうというわけだ。</p>
<p>しかし何が原因なのか、どこにCPUを使っているのかは謎のままだった。仕方ないので、同じ試行で走るべき全テストを実行させつつtopでCPU使用率を目で追ってみた。するとテストの早い段階でとあるテストケースが失敗すると、その後のCPU使用率が100%を越えることがわかった。これだろう。CPU利用率は違うが、同じ問題を引き起こすテストケースがほかにいくつかあるのだろう。</p>
<h2 id="問題の分析">問題の分析</h2>
<p>再現環境が手に入ったので話はずいぶん簡単になったが、まだ何故これが起きたのかはわかっていない。Go言語にはプロファイラが標準で入っているから、これを使ってみることにする。自分のテストのほうでプロファイラを取るようにし、問題を起こすテストケースと自分のテストケースの2つだけを実行させる。で、これを<a href="http://www.brendangregg.com/flamegraphs.html">flame graph</a>で眺めてみたら問題は一目瞭然。<a href="https://github.com/mafredri/cdp">cdp</a>というライブラリのなかの、とあるgoroutineが大幅にCPUサイクルを消費している。しかもその消費の大部分は文字列フォーマットとエラーオブジェクトの構築。ようするに、エラーの報告しまくっているということだ。</p>
<p>cdpというのはChrome devtools protocolの略だ。OSやブラウザをテストから操作するためにこのプロトコルを使っていて、cdpというのはこれをGoから使えるようにしているサードパーティのライブラリだったが、どうもここにバグがあるらしい。それで調べてみると、たしかに問題の起きたOSバージョンから、cdpのバージョンを上げる変更が入っている。手元でcdpのバージョンを落としてみると問題が直る。</p>
<p>というわけでcdpのバージョンを戻せば解決するが、それじゃ本質的な解決にはならないので、もうすこしcdpの中身を眺めてみる。すると、このgoroutineは実際にchromeとのメッセージをやりとりするようなものだった。何らかの理由で通信チャネルが閉じたらエラーになるが、エラーといってもいろいろなので「エラーが起きたらエラーオブジェクトを作って報告する。もしそれがcloseに関係するエラーだったらgoroutineを終了する」といったロジックになっていた。どうも、問題の事例では本当は通信チャネルが閉じたのに、closeエラーかどうかの判定が間違っていたためgoroutineが止まらず、ビジーループでエラーオブジェクトを作り続ける無限ループに陥っていたようだ。</p>
<p>実際に起きているエラーがなんなのか見る方法はないだろうか？　テストは実機で走っているので、ログは簡単には仕込めない。テストインフラ側には専用のロガーがあるが、依存先であるサードパーティライブラリはそのロガーのことを知らない……。ただcdpはエラーをGoのchannelに書き出してくれていたので、テストシナリオの側でこのchannelを読んでテストインフラのロガーに流すコードを仕込んでみた。すると、たしかにエラーオブジェクトが無数に流れてくる。根本的には、cdpライブラリがさらに依存しているwebsocketライブラリのcloseエラーになっているが、手前がcdpのcloseエラーになっていないので、判定に失敗しているようだ。</p>
<h2 id="解決">解決</h2>
<p>いったん手元では雑なパッチで修正し、問題としてはひとまず解決した。これをupstreamすることにしたのだが、そこでもうすこし問題の詳細を眺めてみた。</p>
<p>さっきも書いたように、いちばん根底のエラーはwebsocketライブラリのエラーだった。一番手前のエラーは全然別のエラーだ。Go言語では、こういうふうにエラーオブジェクトをベースにしてちょっとエラーメッセージを追記するようなwrapがよく行われている。cdpライブラリの場合、Causeという独自のメソッドがあり、wrappingを剥がして元のエラーオブジェクトを取れるようになっている。</p>
<p>ライブラリとしての構造が複雑になってくると、こういうwrappingは多段化しがちだ。実際このケースでもそうで、複数段のwrappingが入っていた。ところが問題の無限ループでは、一番手前のエラーオブジェクトと、一番奥のエラーオブジェクト（websocketライブラリのエラーオブジェクト）しかチェックしていない。実際にはcdpライブラリのcloseエラーは正しく存在していたが、この多段wrappingの中間にしかなかったので、無視される状態になっていた。そこで、このwrappingを一段ずつはがしてチェックするように<a href="https://github.com/mafredri/cdp/pull/122">修正</a>をつくってupstreamした。これがマージされたのでこの問題はおしまい。</p>
<p>ところで、ちょっと勘のいいGoプログラマは気づいたかもしれないが、これはGo 1.13で導入された<a href="https://golang.org/pkg/errors/#Is">errors.Is</a>と類似性がある( <a href="https://blog.golang.org/go1.13-errors">https://blog.golang.org/go1.13-errors</a> )。Go 1.13ではerrors.Isという関数ができて、こういう「ほかのエラーオブジェクトをラップしたエラーオブジェクトとの一致チェック」というパターンを簡単にかけるようになった。errors.Isでは、エラーオブジェクトにUnwrapというメソッドがないかチェックする。あるならそれを使ってwrapを外す。どこかでtargetと一致するエラーがあったらtrueを返す。どこにもなくunwrapできなくなったらfalse。</p>
<p>ただ、cdpライブラリの状況ではこれはそのまま使えるものではない（とくに==でのチェックだと厳しい）。使えるようにするにしてもかなりの再設計が必要になるだろう。でもまあよくあるパターンとして比較的最近、標準でサポートされるような問題ではあるという話だったのは興味深かった。</p>
<hr>
<p>最後は <a href="/001-bug/04-karino2/">karino2</a>.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Re: バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/02-kzys/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/02-kzys/</guid>
      <description>他人にバグ修正を頼むのはよくないという反省から、このあと森田は OS ツリーのビルド、インストール方法を調べ 手元で OS のコードをいじれるようにしたのだった。ただしその成果を発揮する日は今の所きていない。来なくていいです
サーバサイドのかっこいいバグの話なんかないですか &amp;gt; 和良
 よくないまでいうと語弊があるけれど、自分で直したほうが楽ですよね。そうして軽い気持ちで手を出すと大事になったりするんですが&amp;hellip;。
というわけで、1行変更するだけのつもりが大事になった話をひとつ。
seccomp Firecracker では Linux の seccomp という仕組みを使って、Firecracker プロセスが呼び出せるシステムコールについて許可リストをもっている。Firecracker のなかで動くゲストの Linux は様々なシステムコールを自由に発行できるけれど、Firecracker プロセスがホストの Linux に対して呼び出すシステムコールは厳選されている。
実際の許可リストは、src/vmm/src/default_syscalls/filters.rs にある。この仕組みは、本来なら libc やライブラリが隠蔽してくるはずの実装の詳細であるシステムコールを細かく列挙しなくてはいけないので、結構きびしい。
このとき直したかったバグでは
 After more digging, looks like the rt_sigprocmask is unescapable. It&amp;rsquo;s also called from __block_all_sigs, which is in turn called by pthread_exit. Basically musl took every precaution and blocks signals whenever something signal-unsafe is underway.
 Firecracker がスレッドを終了すると、musl libc 経由で pthread_exit が呼ばれて、そこから rt_sigprocmask というシステムコールが呼ばれてしまうので、結果として seccomp 違反で Firecracker が殺されてしまう、という話だった。</description>
      <content:encoded><![CDATA[<blockquote>
<p>他人にバグ修正を頼むのはよくないという反省から、このあと森田は OS ツリーのビルド、インストール方法を調べ 手元で OS のコードをいじれるようにしたのだった。ただしその成果を発揮する日は今の所きていない。来なくていいです</p>
<p>サーバサイドのかっこいいバグの話なんかないですか &gt; 和良</p>
</blockquote>
<p>よくないまでいうと語弊があるけれど、自分で直したほうが楽ですよね。そうして軽い気持ちで手を出すと大事になったりするんですが&hellip;。</p>
<p>というわけで、1行変更するだけのつもりが大事になった話をひとつ。</p>
<h2 id="seccomp">seccomp</h2>
<p><a href="https://firecracker-microvm.github.io/">Firecracker</a> では Linux の <a href="https://lwn.net/Articles/656307/">seccomp</a> という仕組みを使って、Firecracker プロセスが呼び出せるシステムコールについて許可リストをもっている。Firecracker のなかで動くゲストの Linux は様々なシステムコールを自由に発行できるけれど、Firecracker プロセスがホストの Linux に対して呼び出すシステムコールは厳選されている。</p>
<p>実際の許可リストは、<a href="https://github.com/firecracker-microvm/firecracker/blob/v0.23.1/src/vmm/src/default_syscalls/filters.rs">src/vmm/src/default_syscalls/filters.rs</a> にある。この仕組みは、本来なら libc やライブラリが隠蔽してくるはずの実装の詳細であるシステムコールを細かく列挙しなくてはいけないので、結構きびしい。</p>
<p><a href="https://github.com/firecracker-microvm/firecracker/issues/1456">このとき直したかったバグ</a>では</p>
<blockquote>
<p>After more digging, looks like the <code>rt_sigprocmask</code> is unescapable. It&rsquo;s also called from <code>__block_all_sigs</code>, which is in turn called by <code>pthread_exit</code>. Basically <code>musl</code> took every precaution and blocks signals whenever something signal-unsafe is underway.</p>
</blockquote>
<p>Firecracker がスレッドを終了すると、<a href="https://musl.libc.org/">musl libc</a> 経由で pthread_exit が呼ばれて、そこから rt_sigprocmask というシステムコールが呼ばれてしまうので、結果として seccomp 違反で Firecracker が殺されてしまう、という話だった。</p>
<h2 id="スレッドを終了させるのをやめてみよう">スレッドを終了させるのをやめてみよう</h2>
<p>rt_sigprocmask なんて別に悪いことできるシステムコールでもないんだし、許可リストに1行足せばいいんじゃないの? と手元でやってみるとちゃんと動く。これでいけるかな、と聞いてみると、Firecracker 側の人から「そもそもスレッドが終了する必要は無いよね」と修正案を提案される。</p>
<p>問題のスレッドは Firecracker が vCPU と 1:1 で割り当てるスレッドなので、Firecracker の実行中に数が減ったりはしない。そもそもの問題は Firecracker のプロセス自体が終了するときにしか発生しないので、スレッド自体は止めておいて、プロセス全体が死ぬのを待てばいい、というわけ。</p>
<p>なんか大事になってきたなあと思いつつ、乗り掛かった船なので<a href="https://github.com/firecracker-microvm/firecracker/pull/1586">プルリクエスト</a>を出してみる。</p>
<h2 id="x86_64-と-aarch64-で終了イベントの扱いが違うのを直そう">x86_64 と aarch64 で終了イベントの扱いが違うのを直そう</h2>
<p>Firecracker は x86_64 だけではなく aarch64、いわゆる ARM もサポートしている。自分が出したプルリクエストでは Rust の <code>#ifdef</code> 相当の <code>#[cfg(target_arch = ...)]</code> を使って、x86_64 と aarch64 を書き分けていた。x86_64 では i8042 をエミュレーションする部分から、ファイルディスクリプタを取り出して、それで終了イベントを扱うようになっていたんだけど、i8042 はすなわち &ldquo;Intel 8042&rdquo; なので、aarch64 には存在しないのだった。</p>
<p>「エミュレーション部分は無くていいから、終了イベントを扱うためのファイルディスクリプタは、aarch64 にも欲しいよね」という話になったので、それも実装して<a href="https://github.com/firecracker-microvm/firecracker/pull/1598">プルリクエスト</a>を出してみる。なぜ私がリファクタリングを&hellip;。</p>
<h2 id="ところでスレッドを終了させない変更は">ところでスレッドを終了させない変更は&hellip;</h2>
<p>なんてやっているうちに、もともとの「スレッドをどうやって終了させずにおくか」という問題は進展して、Firecracker 側の人が、<a href="https://github.com/firecracker-microvm/firecracker/pull/1603">別のプルリクエスト</a>を出して、無事マージされた。</p>
<p>というわけで、1行変更で終わるはずが、なぜかリファクタリングにまきこまれ、本題のバグは相手に直してもらった話でした。まあ Rust が書けたしバグも直ったのでめでたしめでたし。</p>
<p>じゃあ次は <a href="/001-bug/03-jmuk/">jmuk</a> さんで。</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/01-morrita/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/01-morrita/</guid>
      <description>なにか話すことはないかと Hacker News をみていたら（ろくでもない）、 Youtube や Gmail など Google のサービスが一時間落ちていたというニュースで 盛り上がっていた。担当者の想像するだけで胃が痛い。
森田はクライアントサイドで仕事をしているので、この手の outage は起きない。 けれど自分のところに担当したくないイヤなバグが回ってくることはたまにある。 そういうのを精神衛生を害さない程度で思い出してみたい。
A Ship Blocker 何年か前にカメラアプリのチームに入った直後、ハカソンでカメラのビューファインダに OpenGL のシェーダで簡単なエフェクトをかけるコードを書いた。
ハカソン最終日のデモで成果を紹介すると、より洗練されたリアルタイムエフェクトを近隣のアルゴリズムチームが長いこと構想していたことがわかった。 そこで彼らが開発していたエフェクトのフレームワークを森田がカメラアプリにインテグレートすることになった。 とはいえアルゴリズムの開発は始まったばかりで出荷するのはまだ先になりそうな雰囲気。 アルゴリズムチームがアプリ内で試行錯誤できるよう、早速ハカソンのコードをベースに最低限のインテグレーションを済ませた。
その仕事のことをすっかり忘れていたある日、アルゴリズムチームの人が「そろそろ出荷に向けて準備したいのでバグなおしてくれない？」とやってきた。 改めて自分のインテグレーションを見直すと・・・バグだらけじゃん。特に電話機の向きを縦から横にかえた時に描画が壊れる。 やれやれ・・・と直そうとするも、API が期待通りに動かない。
一週間以上たってもなぜ動かないのかわからないので途方にくれ、 小さな再現ケースをつくって、 正しくうごくケースすなわちエフェクトなしのコードパスと挙動を比べてみると・・・。
これ OS のバグじゃね？という結論に至った。 一般に OS のバグを疑うときは自分が間違っているものだが、Android に限るとその限りでない。 先に書いた再現ケースを片手にバグ報告をする。
が、まったく相手にされる様子がない。 しびれを切らしたアルゴリズムチームのプログラマがやってきた。「担当者に直談判しましょう」という。 仕方ないので質問ドキュメントを事前に送付の上ミーティング。「ああわかったきがする。すぐ直すよ」と担当者。
しかしコードがチェックインされたのはそこから一ヶ月後だった。しかも直ってない！どうなってんた！ アルゴリズムチームにつつかれ、ふたたびミーティング。前回は問題だけ伝えたのがよくなかっという反省から、 もう少し要求を細かく伝える。このあとようやく修正が通り、デモが動くようになった。
しかし OS のバグはトランクでのみ修正されており、気がつくとリリースブランチはとっくの昔に切られていた。 そして cherry-pick の締切も過ぎていた。この OS のバグにブロックされ、リアルタイムエフェクトの出荷は一年先送りとなった。
二年目 一年後に向けてアルゴリズムチームはエフェクト実装の改善を進めていた。 具体的には消費電力の改善に取り組んでいた。（つまり OS のバグがあろうがなかろうが出荷できなかったのだね・・・。） 試行錯誤の過程で、彼らはアプリとのインテグレーションも大きくデザインを変えていた。つまり森田がハカソンで書いたコードは姿を消していた。
その仕事のことをすっかり忘れていたある日、アルゴリズム班の人がやってきて「エフェクトが動かないのでなんとかしてほしい」という。 久しぶりに見ると見慣れないコードばかり。インテグレーションに使う OS の API も SurfaceView から ImageReader へ、ずいぶん変わっている。 そしてこれが動かないのは・・・ OS のバグなのでは？ 嫌な既視感に襲われつつバグを報告するも、やはり直らないバグ。またしびれを切らして直談判。</description>
      <content:encoded><![CDATA[<p>なにか話すことはないかと Hacker News をみていたら（ろくでもない）、
<a href="https://news.ycombinator.com/item?id=25415989">Youtube や Gmail など Google のサービスが一時間落ちていた</a>というニュースで
盛り上がっていた。担当者の想像するだけで胃が痛い。</p>
<p>森田はクライアントサイドで仕事をしているので、この手の outage は起きない。
けれど自分のところに担当したくないイヤなバグが回ってくることはたまにある。
そういうのを精神衛生を害さない程度で思い出してみたい。</p>
<h2 id="a-ship-blocker">A Ship Blocker</h2>
<p>何年か前にカメラアプリのチームに入った直後、ハカソンでカメラのビューファインダに OpenGL のシェーダで簡単なエフェクトをかけるコードを書いた。</p>
<p>ハカソン最終日のデモで成果を紹介すると、より洗練されたリアルタイムエフェクトを近隣のアルゴリズムチームが長いこと構想していたことがわかった。
そこで彼らが開発していたエフェクトのフレームワークを森田がカメラアプリにインテグレートすることになった。
とはいえアルゴリズムの開発は始まったばかりで出荷するのはまだ先になりそうな雰囲気。
アルゴリズムチームがアプリ内で試行錯誤できるよう、早速ハカソンのコードをベースに最低限のインテグレーションを済ませた。</p>
<p>その仕事のことをすっかり忘れていたある日、アルゴリズムチームの人が「そろそろ出荷に向けて準備したいのでバグなおしてくれない？」とやってきた。
改めて自分のインテグレーションを見直すと・・・バグだらけじゃん。特に電話機の向きを縦から横にかえた時に描画が壊れる。
やれやれ・・・と直そうとするも、API が期待通りに動かない。</p>
<p>一週間以上たってもなぜ動かないのかわからないので途方にくれ、
小さな再現ケースをつくって、
正しくうごくケースすなわちエフェクトなしのコードパスと挙動を比べてみると・・・。</p>
<p>これ OS のバグじゃね？という結論に至った。
一般に OS のバグを疑うときは自分が間違っているものだが、Android に限るとその限りでない。
先に書いた再現ケースを片手にバグ報告をする。</p>
<p>が、まったく相手にされる様子がない。
しびれを切らしたアルゴリズムチームのプログラマがやってきた。「担当者に直談判しましょう」という。
仕方ないので質問ドキュメントを事前に送付の上ミーティング。「ああわかったきがする。すぐ直すよ」と担当者。</p>
<p>しかしコードがチェックインされたのはそこから一ヶ月後だった。しかも直ってない！どうなってんた！
アルゴリズムチームにつつかれ、ふたたびミーティング。前回は問題だけ伝えたのがよくなかっという反省から、
もう少し要求を細かく伝える。このあとようやく修正が通り、デモが動くようになった。</p>
<p>しかし OS のバグはトランクでのみ修正されており、気がつくとリリースブランチはとっくの昔に切られていた。
そして cherry-pick の締切も過ぎていた。この OS のバグにブロックされ、リアルタイムエフェクトの出荷は一年先送りとなった。</p>
<h2 id="二年目">二年目</h2>
<p>一年後に向けてアルゴリズムチームはエフェクト実装の改善を進めていた。
具体的には消費電力の改善に取り組んでいた。（つまり OS のバグがあろうがなかろうが出荷できなかったのだね・・・。）
試行錯誤の過程で、彼らはアプリとのインテグレーションも大きくデザインを変えていた。つまり森田がハカソンで書いたコードは姿を消していた。</p>
<p>その仕事のことをすっかり忘れていたある日、アルゴリズム班の人がやってきて「エフェクトが動かないのでなんとかしてほしい」という。
久しぶりに見ると見慣れないコードばかり。インテグレーションに使う OS の API も
<a href="https://developer.android.com/reference/android/view/SurfaceView">SurfaceView</a> から
<a href="https://developer.android.com/reference/android/media/ImageReader">ImageReader</a>  へ、ずいぶん変わっている。
そしてこれが動かないのは・・・ OS のバグなのでは？
嫌な既視感に襲われつつバグを報告するも、やはり直らないバグ。またしびれを切らして直談判。</p>
<p>今年もダメかな・・・と思っていたら、最近 OS のチームに入ったプログラマが颯爽とあらわれ、さっとコードを直してしまった。
あれ？なにそれ？ことしは出荷できちゃう？</p>
<h2 id="225-年目">2.25 年目</h2>
<p>と喜んだのも束の間、アルゴリズムチームは再びインテグレーションを書き換えはじめた。
チームの偉い人の推薦に従い、新しい内製フレームワークの流儀にあわせることにしたのだという。
フレームワークに乗せるだけで OS とのインテグレーション方法は変わらないからそんなリスクないでしょ、ということらしい。
なぜそれを今やるんだ！</p>
<p>そんなことを知らない森田がいつもようにアプリをつついていると、
起動時にビューファインダーの画像がコマ落ちし、カクついていることに気づいた。
嫌な予感がしたのでエフェクトのフラグを切ると、カクつきが消える。
仕方なく調査をすると、チームの偉い人が勧めるフレームワークに性能問題があることがわかった。
リアルタイムエフェクトによって今まで使われていいなかったコードパスを通過するようになり、隠れた問題が露呈した次第。</p>
<p>仕方ないのでプロファイルをとりつつフレームワークを直したのは良いが・・・まったくコードがレビューされん！
というのも、そのフレームワークを書いたエンジニアは出世してマネージメントとかもするようになり、
手を動かす仕事はあまりやらなくなっていたのだった。本来ならマネージされているチームメイトにレビューを頼むところ、
スレッドの使い方など繊細なコードをいじった手前、義理を立てたのが裏目に出た。</p>
<p>結局締切までにレビューが間に合わず、リアルアイムエフェクトの出荷は三ヶ月先送りとなった。
OS と違い三ヶ月で済んで良かったですねー・・・。</p>
<p>さすがに今はもう出荷されている。</p>
<hr>
<p>初回だというのに随分長くなってしまった。けれどこの長さこそがこのバグのイヤなところなので仕方ない:
つまり、自分の知らないところで起こった問題を締め切り前に押し付けられ、結果として誰かの新機能が出荷できないバグ。イヤすぎる！</p>
<p>他人にバグ修正を頼むのはよくないという反省から、このあと森田は OS ツリーのビルド、インストール方法を調べ
手元で OS のコードをいじれるようにしたのだった。ただしその成果を発揮する日は今の所きていない。来なくていいです</p>
<p>サーバサイドのかっこいいバグの話なんかないですか &gt; <a href="/001-bug/02-kzys/">和良</a></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>