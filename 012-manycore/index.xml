<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>コアあまりのはなし on Message Passing</title>
    <link>https://messagepassing.github.io/012-manycore/</link>
    <description>Recent content in コアあまりのはなし on Message Passing</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://messagepassing.github.io/012-manycore/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>コアを使い切るとかあんまり考えたことない</title>
      <link>https://messagepassing.github.io/012-manycore/06-jmuk/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/06-jmuk/</guid>
      <description>コア、使い切るとか考えたことないなぁ。
仕事ではOSのウィンドウマネージャとか、デスクトップUIとかを作る仕事をしているが、こういう部分のコードというのは、コアは使い切らないほうが良い。ユーザの主たる感心はアプリケーションであって、コアみたいなリソースはそっちに割り振られるべき。だから考えるべきなのは、所望するエフェクトを実現しつつ、きびきびと動作しつつコアのようなものは使わないようなやり方はどうなのか、っていうことだ。
結果的に検討しないといけない条件や、導入するべきテクニックや方法論は似通ってる。たとえば、ブロッキングを避ける。コアを専有しないように、無駄な計算は避けて、コアが渋滞しないように気をつける。UIスレッドはひとつだけなので、重くなる処理は別のスレッドに移譲したり。でもその結果としてCPUがストールしてても、そこは比較的どうでもいい。というかそんな重たい処理はあるべきではない、というべきか。
もちろんこれが全てではなく、コアを大量に使ってでもうまく動いてくれるとありがたい部分ていうのもあるだろうとは思う。たとえばログイン時とかはいろんな初期化が走るけど、こういうのはできるだけすぐ終わってほしいし、へんな初期化プロセスがコアを専有してそれがシステム全体を阻害してくれては困る。でもそこをすごくきちんと頑張ってコアを使い切る、といったことは意義がありそうだが（あんま詳しくないけど）ちゃんと達成できてはいない気もする。大量のサービスやプロセスが行き来して全体像は把握しづらいし。無駄にブロックしないとか、UIやアニメーションの足を引っ張るようなことはしない、ぐらいは気をつけているだろうけれど。
あと、仕事のレイヤが変わってカーネルレベルになれば、アプリケーションが各種走ったときにきちんとコアが使い切れてくれるか、といったスケジューリング的な意味での興味とかも、あったりするのかもしれない。そのへんも詳しくないのでよくわからないけど。
今はChromebookはたいがいしょぼいのでコアが少ないけど、今後どんどんコアが増えてきたら話はかわるだろうか？　そんな変わんないんじゃないか。どんなコアが増えても、シングルコア性能の伸びがサチっても、ウィンドウマネージャがマルチコアで複雑な計算をすることは、正直考えづらい。あとラップトップOSみたいな文脈では、単一のアプリケーションがコアを使い切れなくて余っても別にそんな困らないだろうという気がする。複数アプリが同時に動いても総合的にきびきび動くなら嬉しいし、仮にコアがあまったりしてもそれだけ消費電力が減り、利用時間が伸びるだけなので、それはそれでいいことのような気もする。かつまた、いつまでたってもローエンド機は居残り、ローエンドでもひどくならないような工夫は残るんじゃないかなあ。
各種のアクセラレータが搭載されることで、別種のパラレリズムが要求されるようなことはありそう。アクセラレータを利用するようなOSサービス（たとえばローカルで動く音声アシスタント機能とか）が増えて、きちんとタスクを分配して無駄なく協調動作させるにはどうしたらいいだろうか、みたいな問題。モバイルでこの問題は起こりつつあるという認識だけど、ラップトップOSだとどうだろうか。そんな特殊なアクセラレータが入ったデバイスは多くないから、まだまだ未来の話かなあ。
morrita OS がコア、に限らず余計な資源を使うべきでないというのはほんとにそうですね。 新品のデバイスでメモリやディスクの残量が妙にすくないのに気づいた時のがっかり感を思い出しました。   karino2 Chromebookって今何コアくらいあるもんなんですか？ちらっとググったらMediaTekのが8コア、PixelBookなんかは2コア4HTくらいと引っかかったけれど、ユーザーの手元にあるのはだいたい幾つくらいと思っておくと丼が合うのかしら。
OSの視点だと、コアをOSが使うというよりは、その上のアプリがちゃんと使えるような仕組みを提供出来ているのか？というのが本題のような気もするけれど、 そもそものChromeOSのコンセプトに対してコアを使い切るようなアプリがユーザーに望まれているのか、というのは良く分からないなぁ。
  jmuk  OSの視点だと、コアをOSが使うというよりは、その上のアプリがちゃんと使えるような仕組みを提供出来ているのか？
 その話はちょっと考えたんですが、ChromeOSはそのへんはなにも提供してないので（基本はシングルスレッドなウェブアプリなので）、書くことが思い浮かびませんでした。ChromeOS上のAndroidやLinux appは仮想環境なので、vCPUがどう見えてるかとかいろいろ話がある気がしますが全然くわしくない。
現実としてはウィンドウマネージャ＋デスクトップシステム＋各種OSサービスはけっこうリソースをくっていている気がしますが、具体的な数値はすぐは出てこないかな……。
  kzys OS の話はコンテナランタイムの話に近いなあ。脇役/裏方仲間。</description>
    </item>
    
    <item>
      <title>誰かがどこかで使ってる</title>
      <link>https://messagepassing.github.io/012-manycore/05-morrita/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/05-morrita/</guid>
      <description>自分は仕事で電話機のカメラアプリ開発を手伝っている。 なのでカメラアプリから見るとどうかを中心に議論してみたい。
電話機の CPU はどのくらい使われているのか 電話機の CPU, 最近だと 8 コアくらいある。こいつらを活用したい。
わけだけれど、まず現実にはどのくらい活用されているのか実例を眺めてみる。 ちょっと前に自分のブログで Perfetto というトレーシングツール (プロファイラだと思ってください)を紹介した。 その中で実際にいくつかのアプリのトレースを集めた。手頃な実例になっている。
アプリの起動 このデータ をダウンロードして、ui.perfetto.dev から開いてほしい。 以下画面写真:
このトレースは Pixel 2 という電話機の上で TikTok というアプリの起動直後 5 秒間をキャプチャしている。 細かいところはわからなくていいけど、&amp;ldquo;CPU 0&amp;rdquo; から &amp;ldquo;CPU 7&amp;rdquo; までの行に細かい線が詰まっているのが見えると思う。
ちょっとズームインすると何がおきているかもう少しわかる。 これは起動 500ms 後くらい。
各 CPU がいつどのスレッドに使われているのか、時系列で可視化されているのがわかる。 隙間の空白は CPU が何もしていない瞬間を示している。
わかること: TikTok 起動の瞬間は CPU がそれなりに使われている。 目一杯限界まで使われているとは言わないけれど、半分以上は埋まってる。 自分は仕事でよく「起動が遅いのなんとかして」と送りつけられて来るトレースを睨む。 そういう「遅い起動」のトレースは CPU のタスクがもっとびっちり詰まっているのも珍しくない。 というかアプリの起動が遅い時、だいたい CPU は目一杯使われている。（みんな電話機酷使しすぎだよ・・・）
一体だれが CPU を使っているのか。Perfetto はそれも簡単に調べられる。 起動後二秒くらいを適当に切り出してプロセス単位の CPU 使用時間を眺めると&amp;hellip;
com.zhiliaoapp.musically が TikTok. たしかに一番 CPU を使っているけれど、 他にも Android のサービスをまるごとホストしたデーモンの system_server, Out-Of-Process された WebView, kthreadd(Linux カーネル) などもわりと熱心に活動されている。直前まで開いていた NYTimes のアプリもいる。 仕事でやっているカメラアプリだと、このほかに Camera HAL (ユーザランドのドライバみたいなものです) も コア 1-2 個分くらいなんかしてる。</description>
    </item>
    
    <item>
      <title>なんとかなってる</title>
      <link>https://messagepassing.github.io/012-manycore/04-shinh/</link>
      <pubDate>Tue, 30 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/04-shinh/</guid>
      <description>たぶん WebKit のミーティングに行った時に、 GPU rendering のトピックがとても盛り上がっていて、 morita さんが「GPUとか「ちょっとオレも一言言わせろ」って感じで盛り上がっちゃうテーマだよね」と言っていて、不思議なくらいなるほどーと思った記憶があります。何が言いたいかというと、並列とかそういうテーマですよね、と。ということで、一言というか、色々と言いたいことがあるのです。
バカパラサイコーという話 Embarassingly parallel をバカパラと訳したの、どなたが考えたのか知らないけど、とても好き。ほぼ独立したタスク群であれば自明にコアを使い切れるし、その数だけ速度がスケールする、という話。 MapReduce の mapper 、ピクセルシェーダ、並列ビルド、深層学習モデルのデータパラレルもそう。普通同じタスクが違うデータに対して動く時にバカパラと言う気もするけど、独立しているから並列化可能、という意味で並列ビルドも同じ箱に入れて考えている。 kzys さんの話しているようなクラウドのケースも、そもそも物理 CPU を切り売りしていて、コンテナごとに完全に独立なので、これも僕はバカパラ、くらいの認識でいる。
プログラムもとても簡単。プロセス並列でいいなら shell script で
for i in `seq 10`; do ./my_command $i &amp;amp; done wait とかで十分だし、 OpenMP 使うなら #pragma omp parallel つければいいし、適当なスレッドプールを使うのも、自分で作るのも、そんなに難しくない。
並列プログラムは難しい、でもなんとかなってる気がする バカパラ以外のケースは、並列 reduce などのよく知られたケースを除くと、なかなか大変なことが多いように思う。特に個々に別々の役割を持ったスレッド・プロセスが協調して動いてるようなやつ。サーバサイドだと、フロントエンドのリクエストを受けて、バックエンドにリクエスト投げたりキャッシュしたりゴチャゴチャやってからレスポンスを返す、ミドルエンド的なやつが大変だった記憶がある（例）。あとは Chrome もなんだかたくさんプロセスもスレッドもあって、大変なところはとても大変な印象だった。 Chrome はブラウザというよりはユーザランドで動いてるマイクロカーネルという認識をしているので、カーネルとかもそうなんだろうなーと思っている。
ここで言う大変というのはバグっていないプログラムを書くのが大変ということで、この手のスレッドプログラミングは、書くのもレビューするのもデバッグするのも難しい。ただ、難しいんだけど、個人的には人類はなんとかなりそうな道具を揃えられたんじゃないかな、と思っている。
morita さんや karino2 さんが紹介していた Future/Promise や、 Go のチャンネルのように、 mutex のような古いプリミティブよりバグりにくい、新しい抽象が出てきたのがひとつ。 Rust のように型レベルでスレッドのバグをコンパイルタイム時に検出する言語もあるし、よく使うロックフリーデータ構造とかのライブラリも整ってきているので、難しい atomic op を直接使う理由はあまり無いと思う。あと何より、その手のものを一切使ってなくても、 ThreadSanitizer が割とバグを見つけてくれる。余談だけど、 sanitizer の類は C++ という言語の寿命を延命させているように感じている。</description>
    </item>
    
    <item>
      <title>意識したことない</title>
      <link>https://messagepassing.github.io/012-manycore/03-kzys/</link>
      <pubDate>Mon, 29 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/03-kzys/</guid>
      <description>私はあんまりコアを意識したことないなあ。
これは、どのくらい CPU がボトルネックになる処理を行うかという、ソフトウェアの中身によるところと、karino2 さんが作っているような、デスクトップやモバイルで前面に出てくるようなソフトウェアと、私が作っているような、いわゆるサーバーサイドかつクラウド上のソフトウェアという環境の違いからきているところがあると思う。
まず、ソフトウェアの中身として、ネットワークのどこかにあるサービスをコールをして、その結果を待つようなものだと、そこまで CPU がボトルネックになるようなことはない。
それに加えて、
 リクエストは並列にやってくるし、リクエストの間で共有しつつ書き換えるデータはそこまでないので、1リクエストでたくさんのコアを使い切らなくても、他のリクエストが使ってくれる (はず)。 新しい世代の XL なインスタンス、例えば t3.xlarge や t4g.xlarge でも4コアしかないので、そもそも8コアも存在しない。デスクトップ/モバイルと違って、サーバーのスペックは自分で選ぶものなので、コアを使いきれなかったら安いインスタンスに変えても良い。 AZ (availability zone) 単位の障害に statically stable に対応するために、サーバーの処理能力はは 1AZ が消失してもなんとかなるように余裕をもって用意する。全部のコアを文字通り 100% 使っていると負荷が高すぎ。  という理由で、頼んでもいないのに8コア来た! 使いきれない! 困った! という気持ちになったことはあまり無い。
もちろん、色々サービスコールをして、その結果を待つようなものでも、結果を待っている間はその処理をコアから下ろして&amp;hellip;みたいな処理を、例えば Java だったら CompletableFuture を使って頑張ることもできる。ただこれも、Go みたいなランタイムが代わりに頑張ってくれる言語を使えば、自分が書くコードからは追い出せる。
私の関わっている仕事のうち、containerd とか firecracker-containerd といったオープンソースソフトウェアは、クラウド上の自分達が管理するインスタンスではなくて、世界のどこかにあるメニーコアのマシンで運用されている可能性はある。ただ、これらはコンテナのランタイムという性格上、余っているコアはコンテナが使ってくれればいいので、これもまた自分でコアを使い切る必要はないのだった。オープンソースのリレーショナルデータベースエンジンを開発していたりすると違うのかなあ。でもこれも CPU よりは IO がボトルネックになりそう。
karino2 CPUをどれだけ有効活用するかとCPUリソースにどれくらい余裕をもたせるかは別の話なのでは…と思ったのだけれど、 結果として現れる現象が運用費をもうちょっと安く出来るのか、 ユーザーの手元の端末で遅いアプリを提供するハメになるのか、 と大きく違うんだな、と理解した。 運用費を下げるという点では別にCPUだけ特別扱いする理由も無いですしね。   </description>
    </item>
    
    <item>
      <title>Coreを使い切る苦労</title>
      <link>https://messagepassing.github.io/012-manycore/02-karino2/</link>
      <pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/02-karino2/</guid>
      <description>前の記事がめっちゃ良くまとまっていて、 自分の動画（以後「並列プログラムの動画」と呼ぶ）なのに自分が語る資格があるのだろうか、とか考えてしまう。 相対的に一発撮りで何も考えずに作った自分の動画の粗が目立ってしまったが、メッセージ自体には価値はあると思いたい所。 なお、なんでいまさらC++？は、おっさんだからです…
歴史的な事とかコンテキストの説明には特に訂正したり付け足す事も無いので、自身の話をしてみます。
目の前のターゲットはiPad ProとMac Book まず並列プログラムの動画を録っていた時、自分が頭で思い浮かべていた環境はなんだったのか。自分の目の前の開発のターゲットは、iPad ProとMacBook用アプリでした。特にメインはiPad Pro。
iPadでは、既にプロフェッショナルユースの制作に使うような物をユーザーがいろいろ激しく使い込んでいて、もっと大きなデータでもっと速く動いてほしいと強く思われている。 そうしたアプリはMac版もある場合が結構あって、iPadのアプリをMacBookでの動きと比較している。 新しいiPadを買ったら、よりMacBookに近づいて欲しいという期待がある。
そんなMacBookの方は16コアというか16HTで、プログラムから見れば16コア。 iPadは8コア。4コア+遅い4コア を8と呼ぶのはどうなのか、という向きもあるだろうけれど、 コーディングの難しさという視点では立派に8コア。
そもそもそういう用途で使うなら 4コア+遅い4コアという構成はどうなの？とか言いたい事はあるのかもしれないけれど、 ユーザーの期待は16HTにどこまで近づけるか、という事なので、アプリ開発者の我々は、与えられた物を最大限に使うしか無い、 というか使っても足りていない。
対応すべきコア数という観点では、現時点で8と16、近い将来にも動くと期待すると32コアも無いとは言えないくらいのゾーンに居ると思っているので、 今からアプリを作る時にはそのくらいの範囲はadaptiveに対応出来るように作る必要がある、と思っている。
4コアと8コアの違い 4コアまでは、Concurrentなプログラムの延長で書いても、それほどコアを無駄にしている感じは無かった。 何かOSが1.5コアくらい使って、自分たちが２コアくらい使って、たまに1コア余る事もあるけれど、使っているのは3/4だ。まぁそんなもんだろう、みたいな。 大きくあいた所をちょっと再構成してキュッキュッと重そうな物を裏にやれば、だいたい埋まっている感じにはなる。 よくよく見るとまだ結構詰められるのだけど、見なかった事にしてまぁいいか、という気分でいた。 morritaさんの普段の仕事の話を見ているともっと頑張って詰めてそうなので立場に依るのだろうけれど。
4コア時代の主な関心は、いわゆる「ジャンク」を取る事、つまりフレームレートを出す事だったと言えると思う。 実際2コアでジャンクを取り切るのは厳しかった事からも、4コア時代の関心事として割と妥当な所だった。
でも「8コア使ってMacBookに近づいたパフォーマンスをプロフェッショナルに届けよ」とか言われるようになると、もうちょっとCPUインテンシブな事もやっていかないといけない。
でも、8コア使い切るにはConcurrentにちょっと毛がはえたくらいでは厳しい。 8個って結構多くて、コードの構成が最初からそういう前提じゃないとすぐやる事が無いコアが出てきてしまって、全然スケールしてくれない。 リアルにアムダールの法則状態というか。
「iPadが8コアになった」というのは、自分的には大きなニュースで、 morritaさんが言ってた所のSEDA的にプログラムを変えなきゃいけない、 という大きなジャンプを強制された訳です。
この4コアと8コアのギャップみたいなのって、皆はどう思っていますかね？ ビルドの時にninjaが全部使ってくれれば、他は気にしてないっすよ、とかそんな感じだったりします？
自分たちはどうしているか的な話 教科書的な話はまぁいいだろう、という事で、実際に自分がどうしているかの話も少し。
まず、もともと簡単に並列化出来る所はスレッドで並列化してある所が結構ある。 関数の外から見て区別無い形で並列化出来て、それなりにパフォーマンス的に重要な所は、結構頑張って並列化してある。 内部はまぁまぁスレッド同士で依存があるような物を、いろいろと工夫してちゃんとパフォーマンスを出している。
これまではそうやっていたのだけれど、最近は関数単位で閉じた形での並列化が難しい大物がだんだんと目立つようになってきて、 これをどうにかしていかないとなぁ、というのがプロジェクトを始めた時に置かれていた状況。 やはり8コア時代はもうちょっと真面目にやらないといけないと結論づけて、道具を頑張って揃える所から始めている。
道具立ての基礎となるライブラリはfuture-promise。 基本的には、follyのfuture-promiseを真似ているがもうちょっと単純化したものを自分たちでスクラッチから実装していて、これを基本に並列化を進めていっている。 現在は他と依存が少ない新規コードでfuture化したコードを書いていって、ちゃんとパフォーマンスが出る事を確認していっている段階。
下のスレッドプールはQtとかWindowsはシステムのものを、iOSはGCDを、それ以外はとりあえず現在はpthreadで自前実装した物につなげている。 STLじゃなくてpthreadなのは完全に歴史的事情で、STLに直してもいいんだけどなぁ、と思いながらpthreadを使っている。 スレッドプールのAPIはGCDを真似ているけれどもうちょっと単純な感じにしていて、コア数全部使うキューと、シリアルな事が保証されているキューがある感じにしている。 この辺はいろんな環境のいろんなスレッドプール事情を調べて、どれにもつなげられるように作ったつもり。
ちょっとモバイルが特殊なのはGUIスレッドが特別扱いな所。 自分たちはfutureを最終的にGUIスレッドで待てるようにしていて、 この待っている時にプログレスバーを回したり、イベントループに戻せるシステムでは戻したりしている。 他のスレッドからもworkitem的な物をポスト出来るようにはなっていて、待っている時にwork itemが来た場合はGUIスレッドで処理出来るような仕組みはある。 この辺はGUI環境ごとにいろいろあるので、うまくそれらに合わせらるように頑張ってはいる。
Android以外はシステムのスレッドプールがあるのでいいのだけれど、Androidはどうするもんですかねぇ。 AndroidもJava側には十分その辺の道具は揃っているのだけれど、JNI側ではどうするのがいいのだろうか。 あんまりボトルネックになってないので自作の奴でこのまま行くのでもいいのだけれど、この令和の時代に自作のスレッドプール使うのもなぁ…
みんなって意外とみんなじゃなかった そんな訳でiPadとMacBookを頭に浮かべつつ「並列プログラムの動画」を作ったつもりなのだけれど、そうはいってもだいたい「みんな」が対象となるだろう、と思っていた。
最近8コアになった、というのはモバイル特有の事情であって、 サーバーなどでは8コアなんてはるか昔に通った所だ。 morritaさんのポストの最初の方に挙がってるような例で、8コア時代をどうすべきかなんてとっくに結論も出ている。 動画はモバイル向けに作ったものではあるけれど、基本的なアイデアはサーバー時代の結論を元にしているので、サーバーサイドの人でもそう違った事は考えていないんじゃないか、と。</description>
    </item>
    
    <item>
      <title>非同期と並列</title>
      <link>https://messagepassing.github.io/012-manycore/01-morrita/</link>
      <pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/012-manycore/01-morrita/</guid>
      <description>karino2 が 並列プログラムから見たFuture というビデオを作って公開していたので、引っ越しの荷造りをしながら眺めた。
 長いのでここにざっくりとした主張をまとめると:
 Future/Promise (およびその後釜の async/await) は非同期プログラミングで callback hell にならない発明という見方をされているが、 そもそもなぜ callback hell が必要だったかの時代背景が十分に理解されていない。 背景の一つはブラウザ JavaScript のプログラミングモデルにシングルスレッド・ノンブロッキング(イベントループ)という制限があったから。 これは(特にフロントエンド開発者の間では)よく理解されている。 もう一つの視点は SEDA みたいなマルチスレッド・ノンブロッキング環境の必要性で、 こっちはいまいち広く理解されていないように思える。 結果としてサーバやデスクトップなどで C++ (なんで?) を書いているプログラマに Fuure/Promise の重要性を説明する良い資料がない。 なぜ Twitter が Finable を、 Facebook が Folly Future を、 Netflix が ReactiveX を、 Apple が Dispatch を、 Google が ListenableFuture を (一個だけダサいのが混じってるぞ!) 持っているのかが伝わらない。  ので俺が説明してやんよ、という内容。
いいたいことに大きな異論はないのだけれど、 先のビデオは準備不足なのか色々わかりにくい部分もあって議論を続けるのが難しい。 そこでまずは話を整理し、そのあと仕事のコードとかだと実際どうなんですかと人々に聞いてみる回です。
20 年前のデスクトップ: スレッドは雑に作る。UI スレッドはブロックする。 というわけでおっさんの昔話から始まるのだよ・・・。
スレッドの使い方という点でいちばんしょうもない例を見るには、15-25 年くらい前のデスクトップアプリを見ると良い。 この世界ではみんな基本的にシングルスレッドでコードを書いている。 のみならず、UI スレッドをブロックしないという現代の常識すらあまり守られていない。 容赦なくダイアログボックスとかを表示して UI スレッドを止める。 厳密にいうと UI スレッド (イベントループ) は止まっておらず、かわりにネストしている。 ただ細かいことなのでブロックしていると思っておけばだいあいあってる。</description>
    </item>
    
  </channel>
</rss>
